{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/dmitry/Desktop/Thesis/topics_ds/models')\n",
    "sys.path.append('/Users/dmitry/Desktop/Thesis/topics_ds/data')\n",
    "sys.path.append('/Users/dmitry/Desktop/Thesis/topics_ds/pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data import data\n",
    "from pytorch import torch_models, radam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img, x_txt, y = data.get_unpacked_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified train-val-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(\n",
    "    x_img, \n",
    "    x_txt, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "x_img_train, x_img_val, x_txt_train, x_txt_val, y_train, y_val = train_test_split(\n",
    "    x_img_train,\n",
    "    x_txt_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sscaler = StandardScaler()\n",
    "img_sscaler.fit(x_img_train)\n",
    "\n",
    "x_img_train = img_sscaler.transform(x_img_train)\n",
    "x_img_val = img_sscaler.transform(x_img_val)\n",
    "x_img_test = img_sscaler.transform(x_img_test)\n",
    "\n",
    "txt_sscaler = StandardScaler()\n",
    "txt_sscaler.fit(x_txt_train)\n",
    "\n",
    "x_txt_train = txt_sscaler.transform(x_txt_train)\n",
    "x_txt_val = txt_sscaler.transform(x_txt_val)\n",
    "x_txt_test = txt_sscaler.transform(x_txt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from numpy arrays to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train_t = torch.tensor(x_img_train)\n",
    "x_img_val_t = torch.tensor(x_img_val)\n",
    "x_img_test_t = torch.tensor(x_img_test)\n",
    "\n",
    "x_txt_train_t = torch.tensor(x_txt_train)\n",
    "x_txt_val_t = torch.tensor(x_txt_val)\n",
    "x_txt_test_t = torch.tensor(x_txt_test)\n",
    "\n",
    "y_train_t = torch.tensor(y_train)\n",
    "y_val_t = torch.tensor(y_val)\n",
    "y_test_t = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_img_train_t, x_txt_train_t, y_train_t)\n",
    "val_ds = TensorDataset(x_img_val_t, x_txt_val_t, y_val_t)\n",
    "test_ds = TensorDataset(x_img_test_t, x_txt_test_t, y_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before 14.03.2020 it was 512\n",
    "# experiments marked bs*number* is on batch_size == number\n",
    "# otherwise batch_size == 512\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trivial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(1.8746, grad_fn=<NllLossBackward>) average train loss tensor(2.3927, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5617365710080942 val_avg_loss: tensor(1.6949)\n",
      "epoch: 1 train_loss: tensor(1.5977, grad_fn=<NllLossBackward>) average train loss tensor(1.7040, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5951140544518028 val_avg_loss: tensor(1.5169)\n",
      "epoch: 2 train_loss: tensor(1.4508, grad_fn=<NllLossBackward>) average train loss tensor(1.5814, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.605121412803532 val_avg_loss: tensor(1.4628)\n",
      "epoch: 3 train_loss: tensor(1.4213, grad_fn=<NllLossBackward>) average train loss tensor(1.5314, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6111552612214863 val_avg_loss: tensor(1.4361)\n",
      "epoch: 4 train_loss: tensor(1.3888, grad_fn=<NllLossBackward>) average train loss tensor(1.4942, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.613598233995585 val_avg_loss: tensor(1.4204)\n",
      "epoch: 5 train_loss: tensor(1.3185, grad_fn=<NllLossBackward>) average train loss tensor(1.4700, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6158057395143488 val_avg_loss: tensor(1.4083)\n",
      "epoch: 6 train_loss: tensor(1.3071, grad_fn=<NllLossBackward>) average train loss tensor(1.4500, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6174540103016924 val_avg_loss: tensor(1.4020)\n",
      "epoch: 7 train_loss: tensor(1.2504, grad_fn=<NllLossBackward>) average train loss tensor(1.4341, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.616953642384106 val_avg_loss: tensor(1.3951)\n",
      "epoch: 8 train_loss: tensor(1.1792, grad_fn=<NllLossBackward>) average train loss tensor(1.4162, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6174540103016924 val_avg_loss: tensor(1.3921)\n",
      "epoch: 9 train_loss: tensor(1.2403, grad_fn=<NllLossBackward>) average train loss tensor(1.4078, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6181015452538632 val_avg_loss: tensor(1.3900)\n",
      "epoch: 10 train_loss: tensor(1.1600, grad_fn=<NllLossBackward>) average train loss tensor(1.3952, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6196909492273731 val_avg_loss: tensor(1.3864)\n",
      "epoch: 11 train_loss: tensor(1.1565, grad_fn=<NllLossBackward>) average train loss tensor(1.3880, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6180132450331126 val_avg_loss: tensor(1.3854)\n",
      "epoch: 12 train_loss: tensor(1.1609, grad_fn=<NllLossBackward>) average train loss tensor(1.3778, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6193377483443708 val_avg_loss: tensor(1.3829)\n",
      "epoch: 13 train_loss: tensor(1.1324, grad_fn=<NllLossBackward>) average train loss tensor(1.3713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6186607799852833 val_avg_loss: tensor(1.3837)\n",
      "epoch: 14 train_loss: tensor(1.1295, grad_fn=<NllLossBackward>) average train loss tensor(1.3605, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6182192788815305 val_avg_loss: tensor(1.3829)\n",
      "epoch: 15 train_loss: tensor(1.1117, grad_fn=<NllLossBackward>) average train loss tensor(1.3568, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6184841795437822 val_avg_loss: tensor(1.3827)\n",
      "epoch: 16 train_loss: tensor(1.0919, grad_fn=<NllLossBackward>) average train loss tensor(1.3479, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6196615158204563 val_avg_loss: tensor(1.3832)\n",
      "epoch: 17 train_loss: tensor(1.0668, grad_fn=<NllLossBackward>) average train loss tensor(1.3430, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.619308314937454 val_avg_loss: tensor(1.3828)\n",
      "epoch: 18 train_loss: tensor(1.0586, grad_fn=<NllLossBackward>) average train loss tensor(1.3380, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6194554819720383 val_avg_loss: tensor(1.3835)\n",
      "epoch: 19 train_loss: tensor(1.0625, grad_fn=<NllLossBackward>) average train loss tensor(1.3317, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6193966151582045 val_avg_loss: tensor(1.3835)\n",
      "epoch: 20 train_loss: tensor(1.0834, grad_fn=<NllLossBackward>) average train loss tensor(1.3293, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6185430463576159 val_avg_loss: tensor(1.3840)\n",
      "epoch: 21 train_loss: tensor(1.0567, grad_fn=<NllLossBackward>) average train loss tensor(1.3238, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6178366445916115 val_avg_loss: tensor(1.3847)\n",
      "epoch: 22 train_loss: tensor(1.0379, grad_fn=<NllLossBackward>) average train loss tensor(1.3185, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6172774098601913 val_avg_loss: tensor(1.3850)\n",
      "epoch: 23 train_loss: tensor(1.0378, grad_fn=<NllLossBackward>) average train loss tensor(1.3139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6174245768947756 val_avg_loss: tensor(1.3857)\n",
      "epoch: 24 train_loss: tensor(1.0434, grad_fn=<NllLossBackward>) average train loss tensor(1.3118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6179543782192789 val_avg_loss: tensor(1.3872)\n",
      "epoch: 25 train_loss: tensor(1.0406, grad_fn=<NllLossBackward>) average train loss tensor(1.3082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6186607799852833 val_avg_loss: tensor(1.3878)\n",
      "epoch: 26 train_loss: tensor(1.0168, grad_fn=<NllLossBackward>) average train loss tensor(1.3042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6167770419426049 val_avg_loss: tensor(1.3895)\n",
      "epoch: 27 train_loss: tensor(1.0085, grad_fn=<NllLossBackward>) average train loss tensor(1.2995, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6178366445916115 val_avg_loss: tensor(1.3908)\n",
      "epoch: 28 train_loss: tensor(0.9817, grad_fn=<NllLossBackward>) average train loss tensor(1.2961, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6180132450331126 val_avg_loss: tensor(1.3913)\n",
      "epoch: 29 train_loss: tensor(0.9728, grad_fn=<NllLossBackward>) average train loss tensor(1.2921, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6163355408388521 val_avg_loss: tensor(1.3920)\n",
      "epoch: 30 train_loss: tensor(0.9753, grad_fn=<NllLossBackward>) average train loss tensor(1.2921, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6168653421633554 val_avg_loss: tensor(1.3937)\n",
      "epoch: 31 train_loss: tensor(0.9288, grad_fn=<NllLossBackward>) average train loss tensor(1.2870, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6170125091979397 val_avg_loss: tensor(1.3951)\n",
      "epoch: 32 train_loss: tensor(0.9782, grad_fn=<NllLossBackward>) average train loss tensor(1.2826, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6176306107431935 val_avg_loss: tensor(1.3954)\n",
      "epoch: 33 train_loss: tensor(0.9488, grad_fn=<NllLossBackward>) average train loss tensor(1.2793, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6174540103016924 val_avg_loss: tensor(1.3999)\n",
      "epoch: 34 train_loss: tensor(0.9700, grad_fn=<NllLossBackward>) average train loss tensor(1.2782, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6177777777777778 val_avg_loss: tensor(1.3987)\n",
      "epoch: 35 train_loss: tensor(0.9604, grad_fn=<NllLossBackward>) average train loss tensor(1.2761, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6154525386313465 val_avg_loss: tensor(1.4001)\n",
      "epoch: 36 train_loss: tensor(0.9159, grad_fn=<NllLossBackward>) average train loss tensor(1.2752, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6164238410596027 val_avg_loss: tensor(1.4008)\n",
      "epoch: 37 train_loss: tensor(0.9702, grad_fn=<NllLossBackward>) average train loss tensor(1.2718, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6164827078734364 val_avg_loss: tensor(1.4029)\n",
      "epoch: 38 train_loss: tensor(0.9357, grad_fn=<NllLossBackward>) average train loss tensor(1.2706, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6163944076526858 val_avg_loss: tensor(1.4034)\n",
      "epoch: 39 train_loss: tensor(0.9382, grad_fn=<NllLossBackward>) average train loss tensor(1.2647, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6151876379690949 val_avg_loss: tensor(1.4059)\n",
      "epoch: 40 train_loss: tensor(0.9479, grad_fn=<NllLossBackward>) average train loss tensor(1.2650, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.616364974245769 val_avg_loss: tensor(1.4062)\n",
      "epoch: 41 train_loss: tensor(0.9013, grad_fn=<NllLossBackward>) average train loss tensor(1.2623, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6152759381898455 val_avg_loss: tensor(1.4086)\n",
      "epoch: 42 train_loss: tensor(0.9167, grad_fn=<NllLossBackward>) average train loss tensor(1.2602, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6156585724797645 val_avg_loss: tensor(1.4077)\n",
      "epoch: 43 train_loss: tensor(0.8994, grad_fn=<NllLossBackward>) average train loss tensor(1.2559, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6154819720382634 val_avg_loss: tensor(1.4096)\n",
      "epoch: 44 train_loss: tensor(0.9184, grad_fn=<NllLossBackward>) average train loss tensor(1.2571, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6160117733627667 val_avg_loss: tensor(1.4129)\n",
      "epoch: 45 train_loss: tensor(0.8844, grad_fn=<NllLossBackward>) average train loss tensor(1.2534, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6160706401766004 val_avg_loss: tensor(1.4116)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.8971, grad_fn=<NllLossBackward>) average train loss tensor(1.2510, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6141574687270052 val_avg_loss: tensor(1.4155)\n",
      "epoch: 47 train_loss: tensor(0.9027, grad_fn=<NllLossBackward>) average train loss tensor(1.2495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6129801324503311 val_avg_loss: tensor(1.4155)\n",
      "epoch: 48 train_loss: tensor(0.9085, grad_fn=<NllLossBackward>) average train loss tensor(1.2514, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6146284032376748 val_avg_loss: tensor(1.4158)\n",
      "epoch: 49 train_loss: tensor(0.8776, grad_fn=<NllLossBackward>) average train loss tensor(1.2468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6132744665194997 val_avg_loss: tensor(1.4152)\n",
      "epoch: 50 train_loss: tensor(0.9042, grad_fn=<NllLossBackward>) average train loss tensor(1.2454, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6148050036791759 val_avg_loss: tensor(1.4168)\n",
      "epoch: 51 train_loss: tensor(0.8625, grad_fn=<NllLossBackward>) average train loss tensor(1.2441, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6148933038999265 val_avg_loss: tensor(1.4202)\n",
      "epoch: 52 train_loss: tensor(0.8771, grad_fn=<NllLossBackward>) average train loss tensor(1.2424, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.613392200147167 val_avg_loss: tensor(1.4218)\n",
      "epoch: 53 train_loss: tensor(0.8672, grad_fn=<NllLossBackward>) average train loss tensor(1.2407, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6133333333333333 val_avg_loss: tensor(1.4230)\n",
      "epoch: 54 train_loss: tensor(0.8848, grad_fn=<NllLossBackward>) average train loss tensor(1.2387, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6127740986019131 val_avg_loss: tensor(1.4245)\n",
      "epoch: 55 train_loss: tensor(0.8961, grad_fn=<NllLossBackward>) average train loss tensor(1.2374, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6137748344370861 val_avg_loss: tensor(1.4257)\n",
      "epoch: 56 train_loss: tensor(0.8897, grad_fn=<NllLossBackward>) average train loss tensor(1.2394, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6137159676232524 val_avg_loss: tensor(1.4273)\n",
      "epoch: 57 train_loss: tensor(0.8865, grad_fn=<NllLossBackward>) average train loss tensor(1.2328, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6121559970566594 val_avg_loss: tensor(1.4270)\n",
      "epoch: 58 train_loss: tensor(0.8405, grad_fn=<NllLossBackward>) average train loss tensor(1.2313, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6121265636497425 val_avg_loss: tensor(1.4292)\n",
      "epoch: 59 train_loss: tensor(0.8760, grad_fn=<NllLossBackward>) average train loss tensor(1.2326, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6126857983811627 val_avg_loss: tensor(1.4298)\n"
     ]
    }
   ],
   "source": [
    "trivial_model = torch_models.TrivialModel()\n",
    "optimizer = optim.Adam(trivial_model.parameters())\n",
    "writer = SummaryWriter('runs/trivial_bs2048_rs42_')\n",
    "\n",
    "EPOCHS = 60\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    trivial_model.train()\n",
    "    \n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "    \n",
    "    for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "        trivial_model.zero_grad()\n",
    "        output = trivial_model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "        loss.backward()\n",
    "            \n",
    "        loss_sum += loss\n",
    "        loss_count += 1\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum/loss_count)\n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    writer.add_scalar('avg_train_loss', loss_sum/loss_count, epoch)\n",
    "\n",
    "    trivial_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "            output = trivial_model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "            loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y_cur, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print('val_acc:', correct/total, 'val_avg_loss:', loss_sum/loss_count)\n",
    "    writer.add_scalar('val_acc', correct/total, epoch)\n",
    "    writer.add_scalar('val_avg_loss', loss_sum/loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(1.5632, grad_fn=<NllLossBackward>) average train loss tensor(1.9788, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5917880794701986 val_avg_loss: tensor(1.5810)\n",
      "epoch: 1 train_loss: tensor(1.3921, grad_fn=<NllLossBackward>) average train loss tensor(1.4969, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6093009565857248 val_avg_loss: tensor(1.5033)\n",
      "epoch: 2 train_loss: tensor(1.3086, grad_fn=<NllLossBackward>) average train loss tensor(1.4280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.612420897718911 val_avg_loss: tensor(1.4785)\n",
      "epoch: 3 train_loss: tensor(1.2520, grad_fn=<NllLossBackward>) average train loss tensor(1.3898, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6140397350993377 val_avg_loss: tensor(1.4662)\n",
      "epoch: 4 train_loss: tensor(1.2084, grad_fn=<NllLossBackward>) average train loss tensor(1.3629, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6152170713760118 val_avg_loss: tensor(1.4590)\n",
      "epoch: 5 train_loss: tensor(1.1726, grad_fn=<NllLossBackward>) average train loss tensor(1.3420, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6153642384105961 val_avg_loss: tensor(1.4546)\n",
      "epoch: 6 train_loss: tensor(1.1422, grad_fn=<NllLossBackward>) average train loss tensor(1.3249, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6151582045621781 val_avg_loss: tensor(1.4517)\n",
      "epoch: 7 train_loss: tensor(1.1158, grad_fn=<NllLossBackward>) average train loss tensor(1.3105, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.614186902133922 val_avg_loss: tensor(1.4498)\n",
      "epoch: 8 train_loss: tensor(1.0926, grad_fn=<NllLossBackward>) average train loss tensor(1.2979, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6138337012509197 val_avg_loss: tensor(1.4486)\n",
      "epoch: 9 train_loss: tensor(1.0719, grad_fn=<NllLossBackward>) average train loss tensor(1.2869, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6139220014716703 val_avg_loss: tensor(1.4478)\n",
      "epoch: 10 train_loss: tensor(1.0533, grad_fn=<NllLossBackward>) average train loss tensor(1.2770, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6142163355408389 val_avg_loss: tensor(1.4474)\n",
      "epoch: 11 train_loss: tensor(1.0364, grad_fn=<NllLossBackward>) average train loss tensor(1.2680, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6139220014716703 val_avg_loss: tensor(1.4472)\n",
      "epoch: 12 train_loss: tensor(1.0210, grad_fn=<NllLossBackward>) average train loss tensor(1.2598, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6140986019131714 val_avg_loss: tensor(1.4472)\n",
      "epoch: 13 train_loss: tensor(1.0069, grad_fn=<NllLossBackward>) average train loss tensor(1.2523, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6135688005886681 val_avg_loss: tensor(1.4473)\n",
      "epoch: 14 train_loss: tensor(0.9939, grad_fn=<NllLossBackward>) average train loss tensor(1.2453, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6133333333333333 val_avg_loss: tensor(1.4475)\n",
      "epoch: 15 train_loss: tensor(0.9818, grad_fn=<NllLossBackward>) average train loss tensor(1.2388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6129801324503311 val_avg_loss: tensor(1.4478)\n",
      "epoch: 16 train_loss: tensor(0.9706, grad_fn=<NllLossBackward>) average train loss tensor(1.2327, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6124797645327447 val_avg_loss: tensor(1.4481)\n",
      "epoch: 17 train_loss: tensor(0.9601, grad_fn=<NllLossBackward>) average train loss tensor(1.2270, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6118322295805739 val_avg_loss: tensor(1.4486)\n",
      "epoch: 18 train_loss: tensor(0.9504, grad_fn=<NllLossBackward>) average train loss tensor(1.2217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6118027961736571 val_avg_loss: tensor(1.4490)\n",
      "epoch: 19 train_loss: tensor(0.9412, grad_fn=<NllLossBackward>) average train loss tensor(1.2166, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6115378955114055 val_avg_loss: tensor(1.4495)\n",
      "epoch: 20 train_loss: tensor(0.9326, grad_fn=<NllLossBackward>) average train loss tensor(1.2118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6112435614422369 val_avg_loss: tensor(1.4501)\n",
      "epoch: 21 train_loss: tensor(0.9245, grad_fn=<NllLossBackward>) average train loss tensor(1.2073, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6107726269315673 val_avg_loss: tensor(1.4506)\n",
      "epoch: 22 train_loss: tensor(0.9169, grad_fn=<NllLossBackward>) average train loss tensor(1.2030, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6105665930831494 val_avg_loss: tensor(1.4512)\n",
      "epoch: 23 train_loss: tensor(0.9096, grad_fn=<NllLossBackward>) average train loss tensor(1.1989, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6103311258278146 val_avg_loss: tensor(1.4519)\n",
      "epoch: 24 train_loss: tensor(0.9028, grad_fn=<NllLossBackward>) average train loss tensor(1.1949, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6094481236203091 val_avg_loss: tensor(1.4525)\n",
      "epoch: 25 train_loss: tensor(0.8963, grad_fn=<NllLossBackward>) average train loss tensor(1.1912, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6088005886681384 val_avg_loss: tensor(1.4532)\n",
      "epoch: 26 train_loss: tensor(0.8901, grad_fn=<NllLossBackward>) average train loss tensor(1.1877, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6085356880058866 val_avg_loss: tensor(1.4539)\n",
      "epoch: 27 train_loss: tensor(0.8842, grad_fn=<NllLossBackward>) average train loss tensor(1.1842, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6078292862398823 val_avg_loss: tensor(1.4547)\n",
      "epoch: 28 train_loss: tensor(0.8786, grad_fn=<NllLossBackward>) average train loss tensor(1.1810, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6077115526122149 val_avg_loss: tensor(1.4554)\n",
      "epoch: 29 train_loss: tensor(0.8732, grad_fn=<NllLossBackward>) average train loss tensor(1.1779, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6077409860191317 val_avg_loss: tensor(1.4562)\n",
      "epoch: 30 train_loss: tensor(0.8681, grad_fn=<NllLossBackward>) average train loss tensor(1.1749, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6075643855776306 val_avg_loss: tensor(1.4571)\n",
      "epoch: 31 train_loss: tensor(0.8632, grad_fn=<NllLossBackward>) average train loss tensor(1.1720, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6072700515084621 val_avg_loss: tensor(1.4579)\n",
      "epoch: 32 train_loss: tensor(0.8585, grad_fn=<NllLossBackward>) average train loss tensor(1.1692, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6069462840323767 val_avg_loss: tensor(1.4588)\n",
      "epoch: 33 train_loss: tensor(0.8541, grad_fn=<NllLossBackward>) average train loss tensor(1.1666, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6066519499632083 val_avg_loss: tensor(1.4596)\n",
      "epoch: 34 train_loss: tensor(0.8497, grad_fn=<NllLossBackward>) average train loss tensor(1.1640, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.606504782928624 val_avg_loss: tensor(1.4606)\n",
      "epoch: 35 train_loss: tensor(0.8456, grad_fn=<NllLossBackward>) average train loss tensor(1.1616, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6060338484179544 val_avg_loss: tensor(1.4615)\n",
      "epoch: 36 train_loss: tensor(0.8416, grad_fn=<NllLossBackward>) average train loss tensor(1.1593, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6054746136865342 val_avg_loss: tensor(1.4625)\n",
      "epoch: 37 train_loss: tensor(0.8378, grad_fn=<NllLossBackward>) average train loss tensor(1.1570, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6053568800588668 val_avg_loss: tensor(1.4634)\n",
      "epoch: 38 train_loss: tensor(0.8342, grad_fn=<NllLossBackward>) average train loss tensor(1.1548, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.605121412803532 val_avg_loss: tensor(1.4644)\n",
      "epoch: 39 train_loss: tensor(0.8306, grad_fn=<NllLossBackward>) average train loss tensor(1.1527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6047387785136129 val_avg_loss: tensor(1.4655)\n",
      "epoch: 40 train_loss: tensor(0.8272, grad_fn=<NllLossBackward>) average train loss tensor(1.1507, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6044444444444445 val_avg_loss: tensor(1.4665)\n",
      "epoch: 41 train_loss: tensor(0.8240, grad_fn=<NllLossBackward>) average train loss tensor(1.1488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6039735099337749 val_avg_loss: tensor(1.4676)\n",
      "epoch: 42 train_loss: tensor(0.8208, grad_fn=<NllLossBackward>) average train loss tensor(1.1469, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.60373804267844 val_avg_loss: tensor(1.4687)\n",
      "epoch: 43 train_loss: tensor(0.8178, grad_fn=<NllLossBackward>) average train loss tensor(1.1451, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6035320088300221 val_avg_loss: tensor(1.4698)\n",
      "epoch: 44 train_loss: tensor(0.8148, grad_fn=<NllLossBackward>) average train loss tensor(1.1434, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6031788079470198 val_avg_loss: tensor(1.4709)\n",
      "epoch: 45 train_loss: tensor(0.8120, grad_fn=<NllLossBackward>) average train loss tensor(1.1417, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6029139072847682 val_avg_loss: tensor(1.4720)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.8092, grad_fn=<NllLossBackward>) average train loss tensor(1.1401, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6028844738778514 val_avg_loss: tensor(1.4732)\n",
      "epoch: 47 train_loss: tensor(0.8066, grad_fn=<NllLossBackward>) average train loss tensor(1.1386, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6025901398086828 val_avg_loss: tensor(1.4743)\n",
      "epoch: 48 train_loss: tensor(0.8040, grad_fn=<NllLossBackward>) average train loss tensor(1.1371, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6022958057395144 val_avg_loss: tensor(1.4755)\n",
      "epoch: 49 train_loss: tensor(0.8015, grad_fn=<NllLossBackward>) average train loss tensor(1.1357, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6018837380426785 val_avg_loss: tensor(1.4767)\n",
      "epoch: 50 train_loss: tensor(0.7992, grad_fn=<NllLossBackward>) average train loss tensor(1.1343, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6017071376011773 val_avg_loss: tensor(1.4779)\n",
      "epoch: 51 train_loss: tensor(0.7968, grad_fn=<NllLossBackward>) average train loss tensor(1.1329, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6014422369389257 val_avg_loss: tensor(1.4791)\n",
      "epoch: 52 train_loss: tensor(0.7946, grad_fn=<NllLossBackward>) average train loss tensor(1.1316, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6013245033112583 val_avg_loss: tensor(1.4803)\n",
      "epoch: 53 train_loss: tensor(0.7924, grad_fn=<NllLossBackward>) average train loss tensor(1.1304, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6009124356144224 val_avg_loss: tensor(1.4816)\n",
      "epoch: 54 train_loss: tensor(0.7903, grad_fn=<NllLossBackward>) average train loss tensor(1.1292, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6007652685798381 val_avg_loss: tensor(1.4828)\n",
      "epoch: 55 train_loss: tensor(0.7883, grad_fn=<NllLossBackward>) average train loss tensor(1.1280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6005003679175864 val_avg_loss: tensor(1.4841)\n",
      "epoch: 56 train_loss: tensor(0.7863, grad_fn=<NllLossBackward>) average train loss tensor(1.1269, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5999705665930831 val_avg_loss: tensor(1.4853)\n",
      "epoch: 57 train_loss: tensor(0.7844, grad_fn=<NllLossBackward>) average train loss tensor(1.1258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5995290654893304 val_avg_loss: tensor(1.4866)\n",
      "epoch: 58 train_loss: tensor(0.7825, grad_fn=<NllLossBackward>) average train loss tensor(1.1247, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5994701986754967 val_avg_loss: tensor(1.4878)\n",
      "epoch: 59 train_loss: tensor(0.7807, grad_fn=<NllLossBackward>) average train loss tensor(1.1237, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.599411331861663 val_avg_loss: tensor(1.4891)\n"
     ]
    }
   ],
   "source": [
    "extreme_trivial_model = torch_models.ExtremeTrivialModel()\n",
    "optimizer = optim.Adam(extreme_trivial_model.parameters())\n",
    "writer = SummaryWriter('runs/extreme_trivial_bs2048_rs42')\n",
    "\n",
    "EPOCHS = 60\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "        extreme_trivial_model.zero_grad()\n",
    "        output = extreme_trivial_model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "        loss.backward()\n",
    "            \n",
    "        loss_sum += loss\n",
    "        loss_count += 1\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum/loss_count)\n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    writer.add_scalar('avg_train_loss', loss_sum/loss_count, epoch)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "            output = extreme_trivial_model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "            loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y_cur, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print('val_acc:', correct/total, 'val_avg_loss:', loss_sum/loss_count)\n",
    "    writer.add_scalar('val_acc', correct/total, epoch)\n",
    "    writer.add_scalar('val_avg_loss', loss_sum/loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_model = torch_models.TrivialModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(trivial_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6595, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5165, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4773, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4376, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4104, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3552, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3528, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3566, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3425, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3599, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        trivial_model.zero_grad()\n",
    "        output = trivial_model(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = trivial_model(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    trivial_writer.add_scalar('trivial/accuracy/val', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_sm = torch_models.NormModelSM()\n",
    "optimizer = optim.Adam(norm_model_sm.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model.zero_grad()\n",
    "        output = norm_model(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = cross_entropy_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    norm_writer.add_scalar('accuracy/val/norm_sm', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model = torch_models.NormModel()\n",
    "optimizer = optim.Adam(norm_model.parameters(), lr=1e-3)\n",
    "norm_writer = SummaryWriter('runs/adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model.zero_grad()\n",
    "        output = norm_model(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    norm_writer.add_scalar('train_loss', loss, epoch)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    norm_writer.add_scalar('val_acc', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_loss_history)), train_loss_history)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train loss')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(val_acc_history)), val_acc_history)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('val acc')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm model without and with glorot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(1.7752, grad_fn=<NllLossBackward>) average train loss tensor(2.4701, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5220897718910964 val_avg_loss: tensor(1.7794)\n",
      "epoch: 1 train_loss: tensor(1.5299, grad_fn=<NllLossBackward>) average train loss tensor(1.6370, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5727152317880795 val_avg_loss: tensor(1.6000)\n",
      "epoch: 2 train_loss: tensor(1.4072, grad_fn=<NllLossBackward>) average train loss tensor(1.5169, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5837527593818984 val_avg_loss: tensor(1.5512)\n",
      "epoch: 3 train_loss: tensor(1.3170, grad_fn=<NllLossBackward>) average train loss tensor(1.4603, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5924944812362031 val_avg_loss: tensor(1.5152)\n",
      "epoch: 4 train_loss: tensor(1.2620, grad_fn=<NllLossBackward>) average train loss tensor(1.4157, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5956732891832229 val_avg_loss: tensor(1.5054)\n",
      "epoch: 5 train_loss: tensor(1.1793, grad_fn=<NllLossBackward>) average train loss tensor(1.3825, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5959087564385578 val_avg_loss: tensor(1.4945)\n",
      "epoch: 6 train_loss: tensor(1.1229, grad_fn=<NllLossBackward>) average train loss tensor(1.3514, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5996762325239147 val_avg_loss: tensor(1.4872)\n",
      "epoch: 7 train_loss: tensor(1.1153, grad_fn=<NllLossBackward>) average train loss tensor(1.3215, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6016188373804268 val_avg_loss: tensor(1.4912)\n",
      "epoch: 8 train_loss: tensor(1.0497, grad_fn=<NllLossBackward>) average train loss tensor(1.2922, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6041795437821927 val_avg_loss: tensor(1.4782)\n",
      "epoch: 9 train_loss: tensor(1.0275, grad_fn=<NllLossBackward>) average train loss tensor(1.2736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6046210448859456 val_avg_loss: tensor(1.4838)\n",
      "epoch: 10 train_loss: tensor(0.9929, grad_fn=<NllLossBackward>) average train loss tensor(1.2540, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5997350993377484 val_avg_loss: tensor(1.4926)\n",
      "epoch: 11 train_loss: tensor(0.9319, grad_fn=<NllLossBackward>) average train loss tensor(1.2314, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.601972038263429 val_avg_loss: tensor(1.4920)\n",
      "epoch: 12 train_loss: tensor(0.8997, grad_fn=<NllLossBackward>) average train loss tensor(1.2128, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6016777041942605 val_avg_loss: tensor(1.5046)\n",
      "epoch: 13 train_loss: tensor(0.8678, grad_fn=<NllLossBackward>) average train loss tensor(1.1947, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6041795437821927 val_avg_loss: tensor(1.5038)\n",
      "epoch: 14 train_loss: tensor(0.8421, grad_fn=<NllLossBackward>) average train loss tensor(1.1779, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6034142752023547 val_avg_loss: tensor(1.5119)\n",
      "epoch: 15 train_loss: tensor(0.8130, grad_fn=<NllLossBackward>) average train loss tensor(1.1573, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5982045621780722 val_avg_loss: tensor(1.5199)\n",
      "epoch: 16 train_loss: tensor(0.8034, grad_fn=<NllLossBackward>) average train loss tensor(1.1415, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6000294334069168 val_avg_loss: tensor(1.5323)\n",
      "epoch: 17 train_loss: tensor(0.7293, grad_fn=<NllLossBackward>) average train loss tensor(1.1262, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6009418690213392 val_avg_loss: tensor(1.5393)\n",
      "epoch: 18 train_loss: tensor(0.7750, grad_fn=<NllLossBackward>) average train loss tensor(1.1119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.594466519499632 val_avg_loss: tensor(1.5541)\n",
      "epoch: 19 train_loss: tensor(0.7351, grad_fn=<NllLossBackward>) average train loss tensor(1.0962, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5982339955849889 val_avg_loss: tensor(1.5568)\n",
      "epoch: 20 train_loss: tensor(0.6894, grad_fn=<NllLossBackward>) average train loss tensor(1.0832, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.597439293598234 val_avg_loss: tensor(1.5673)\n",
      "epoch: 21 train_loss: tensor(0.6798, grad_fn=<NllLossBackward>) average train loss tensor(1.0683, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.59467255334805 val_avg_loss: tensor(1.5897)\n",
      "epoch: 22 train_loss: tensor(0.6539, grad_fn=<NllLossBackward>) average train loss tensor(1.0530, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5954083885209713 val_avg_loss: tensor(1.5961)\n",
      "epoch: 23 train_loss: tensor(0.6248, grad_fn=<NllLossBackward>) average train loss tensor(1.0422, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.591140544518028 val_avg_loss: tensor(1.6095)\n",
      "epoch: 24 train_loss: tensor(0.6044, grad_fn=<NllLossBackward>) average train loss tensor(1.0293, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.590728476821192 val_avg_loss: tensor(1.6322)\n",
      "epoch: 25 train_loss: tensor(0.5955, grad_fn=<NllLossBackward>) average train loss tensor(1.0155, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5923473142016188 val_avg_loss: tensor(1.6264)\n",
      "epoch: 26 train_loss: tensor(0.6300, grad_fn=<NllLossBackward>) average train loss tensor(1.0072, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5931420161883738 val_avg_loss: tensor(1.6391)\n",
      "epoch: 27 train_loss: tensor(0.5809, grad_fn=<NllLossBackward>) average train loss tensor(0.9930, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5899043414275202 val_avg_loss: tensor(1.6569)\n",
      "epoch: 28 train_loss: tensor(0.5724, grad_fn=<NllLossBackward>) average train loss tensor(0.9835, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5907579102281089 val_avg_loss: tensor(1.6506)\n",
      "epoch: 29 train_loss: tensor(0.5681, grad_fn=<NllLossBackward>) average train loss tensor(0.9774, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5890507726269316 val_avg_loss: tensor(1.6497)\n",
      "epoch: 30 train_loss: tensor(0.5426, grad_fn=<NllLossBackward>) average train loss tensor(0.9650, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5903164091243561 val_avg_loss: tensor(1.6743)\n",
      "epoch: 31 train_loss: tensor(0.5299, grad_fn=<NllLossBackward>) average train loss tensor(0.9534, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5813686534216336 val_avg_loss: tensor(1.7047)\n",
      "epoch: 32 train_loss: tensor(0.5012, grad_fn=<NllLossBackward>) average train loss tensor(0.9445, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.582075055187638 val_avg_loss: tensor(1.7144)\n",
      "epoch: 33 train_loss: tensor(0.4966, grad_fn=<NllLossBackward>) average train loss tensor(0.9331, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5861074319352465 val_avg_loss: tensor(1.7083)\n",
      "epoch: 34 train_loss: tensor(0.4908, grad_fn=<NllLossBackward>) average train loss tensor(0.9206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5821339220014716 val_avg_loss: tensor(1.7456)\n",
      "epoch: 35 train_loss: tensor(0.4577, grad_fn=<NllLossBackward>) average train loss tensor(0.9181, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5837527593818984 val_avg_loss: tensor(1.7429)\n",
      "epoch: 36 train_loss: tensor(0.5026, grad_fn=<NllLossBackward>) average train loss tensor(0.9103, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5860191317144959 val_avg_loss: tensor(1.7246)\n",
      "epoch: 37 train_loss: tensor(0.4646, grad_fn=<NllLossBackward>) average train loss tensor(0.8959, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5813686534216336 val_avg_loss: tensor(1.7643)\n",
      "epoch: 38 train_loss: tensor(0.4632, grad_fn=<NllLossBackward>) average train loss tensor(0.8933, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5837821927888153 val_avg_loss: tensor(1.7638)\n",
      "epoch: 39 train_loss: tensor(0.4627, grad_fn=<NllLossBackward>) average train loss tensor(0.8863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5792200147167035 val_avg_loss: tensor(1.8039)\n",
      "epoch: 40 train_loss: tensor(0.5003, grad_fn=<NllLossBackward>) average train loss tensor(0.8817, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5806622516556291 val_avg_loss: tensor(1.7868)\n",
      "epoch: 41 train_loss: tensor(0.4605, grad_fn=<NllLossBackward>) average train loss tensor(0.8680, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5812214863870493 val_avg_loss: tensor(1.8270)\n",
      "epoch: 42 train_loss: tensor(0.4500, grad_fn=<NllLossBackward>) average train loss tensor(0.8638, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.581074319352465 val_avg_loss: tensor(1.8084)\n",
      "epoch: 43 train_loss: tensor(0.4234, grad_fn=<NllLossBackward>) average train loss tensor(0.8541, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5791317144959529 val_avg_loss: tensor(1.8317)\n",
      "epoch: 44 train_loss: tensor(0.3932, grad_fn=<NllLossBackward>) average train loss tensor(0.8498, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5807799852832966 val_avg_loss: tensor(1.8447)\n",
      "epoch: 45 train_loss: tensor(0.4308, grad_fn=<NllLossBackward>) average train loss tensor(0.8391, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5782781456953643 val_avg_loss: tensor(1.8735)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.4211, grad_fn=<NllLossBackward>) average train loss tensor(0.8343, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5754231052244297 val_avg_loss: tensor(1.8778)\n",
      "epoch: 47 train_loss: tensor(0.4011, grad_fn=<NllLossBackward>) average train loss tensor(0.8253, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5758351729212656 val_avg_loss: tensor(1.8808)\n",
      "epoch: 48 train_loss: tensor(0.4084, grad_fn=<NllLossBackward>) average train loss tensor(0.8225, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5801324503311258 val_avg_loss: tensor(1.9113)\n",
      "epoch: 49 train_loss: tensor(0.4165, grad_fn=<NllLossBackward>) average train loss tensor(0.8198, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5775717439293598 val_avg_loss: tensor(1.8919)\n",
      "epoch: 50 train_loss: tensor(0.3899, grad_fn=<NllLossBackward>) average train loss tensor(0.8116, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5785430463576159 val_avg_loss: tensor(1.8943)\n",
      "epoch: 51 train_loss: tensor(0.3849, grad_fn=<NllLossBackward>) average train loss tensor(0.8036, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5762766740250184 val_avg_loss: tensor(1.9256)\n",
      "epoch: 52 train_loss: tensor(0.3843, grad_fn=<NllLossBackward>) average train loss tensor(0.7974, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5744812362030906 val_avg_loss: tensor(1.9011)\n",
      "epoch: 53 train_loss: tensor(0.3582, grad_fn=<NllLossBackward>) average train loss tensor(0.7929, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5746284032376747 val_avg_loss: tensor(1.9394)\n",
      "epoch: 54 train_loss: tensor(0.3767, grad_fn=<NllLossBackward>) average train loss tensor(0.7821, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5758646063281825 val_avg_loss: tensor(1.9362)\n",
      "epoch: 55 train_loss: tensor(0.3781, grad_fn=<NllLossBackward>) average train loss tensor(0.7829, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5759234731420162 val_avg_loss: tensor(1.9478)\n",
      "epoch: 56 train_loss: tensor(0.3864, grad_fn=<NllLossBackward>) average train loss tensor(0.7725, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5744223693892568 val_avg_loss: tensor(1.9490)\n",
      "epoch: 57 train_loss: tensor(0.3726, grad_fn=<NllLossBackward>) average train loss tensor(0.7701, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5735099337748344 val_avg_loss: tensor(1.9652)\n",
      "epoch: 58 train_loss: tensor(0.3790, grad_fn=<NllLossBackward>) average train loss tensor(0.7700, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5776306107431936 val_avg_loss: tensor(1.9626)\n",
      "epoch: 59 train_loss: tensor(0.3563, grad_fn=<NllLossBackward>) average train loss tensor(0.7582, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5752759381898455 val_avg_loss: tensor(1.9718)\n"
     ]
    }
   ],
   "source": [
    "norm_model = torch_models.NormModel()\n",
    "optimizer = optim.Adam(norm_model.parameters())\n",
    "writer = SummaryWriter('runs/norm_bs2048_rs42')\n",
    "\n",
    "EPOCHS = 60\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "        norm_model.zero_grad()\n",
    "        output = norm_model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "        loss.backward()\n",
    "            \n",
    "        loss_sum += loss\n",
    "        loss_count += 1\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum/loss_count)\n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    writer.add_scalar('avg_train_loss', loss_sum/loss_count, epoch)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "            output = norm_model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "            loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y_cur, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print('val_acc:', correct/total, 'val_avg_loss:', loss_sum/loss_count)\n",
    "    writer.add_scalar('val_acc', correct/total, epoch)\n",
    "    writer.add_scalar('val_avg_loss', loss_sum/loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(1.7957, grad_fn=<NllLossBackward>) average train loss tensor(2.4653, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.557645327446652 val_avg_loss: tensor(1.6393)\n",
      "epoch: 1 train_loss: tensor(1.5437, grad_fn=<NllLossBackward>) average train loss tensor(1.6360, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.600794701986755 val_avg_loss: tensor(1.4760)\n",
      "epoch: 2 train_loss: tensor(1.4197, grad_fn=<NllLossBackward>) average train loss tensor(1.5206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6118322295805739 val_avg_loss: tensor(1.4222)\n",
      "epoch: 3 train_loss: tensor(1.3667, grad_fn=<NllLossBackward>) average train loss tensor(1.4615, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6181898454746136 val_avg_loss: tensor(1.3941)\n",
      "epoch: 4 train_loss: tensor(1.3017, grad_fn=<NllLossBackward>) average train loss tensor(1.4181, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6222222222222222 val_avg_loss: tensor(1.3750)\n",
      "epoch: 5 train_loss: tensor(1.2260, grad_fn=<NllLossBackward>) average train loss tensor(1.3819, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6238999264164827 val_avg_loss: tensor(1.3642)\n",
      "epoch: 6 train_loss: tensor(1.1355, grad_fn=<NllLossBackward>) average train loss tensor(1.3509, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6275202354672553 val_avg_loss: tensor(1.3584)\n",
      "epoch: 7 train_loss: tensor(1.1145, grad_fn=<NllLossBackward>) average train loss tensor(1.3248, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6279323031640912 val_avg_loss: tensor(1.3513)\n",
      "epoch: 8 train_loss: tensor(1.0630, grad_fn=<NllLossBackward>) average train loss tensor(1.3028, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.629168506254599 val_avg_loss: tensor(1.3484)\n",
      "epoch: 9 train_loss: tensor(1.0124, grad_fn=<NllLossBackward>) average train loss tensor(1.2784, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6296394407652686 val_avg_loss: tensor(1.3423)\n",
      "epoch: 10 train_loss: tensor(0.9507, grad_fn=<NllLossBackward>) average train loss tensor(1.2565, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6323767476085357 val_avg_loss: tensor(1.3430)\n",
      "epoch: 11 train_loss: tensor(0.9508, grad_fn=<NllLossBackward>) average train loss tensor(1.2363, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6316997792494481 val_avg_loss: tensor(1.3438)\n",
      "epoch: 12 train_loss: tensor(0.9164, grad_fn=<NllLossBackward>) average train loss tensor(1.2146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6321412803532008 val_avg_loss: tensor(1.3462)\n",
      "epoch: 13 train_loss: tensor(0.8666, grad_fn=<NllLossBackward>) average train loss tensor(1.1952, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6348491537895511 val_avg_loss: tensor(1.3465)\n",
      "epoch: 14 train_loss: tensor(0.8684, grad_fn=<NllLossBackward>) average train loss tensor(1.1767, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6331714495952907 val_avg_loss: tensor(1.3495)\n",
      "epoch: 15 train_loss: tensor(0.8071, grad_fn=<NllLossBackward>) average train loss tensor(1.1612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6332008830022076 val_avg_loss: tensor(1.3562)\n",
      "epoch: 16 train_loss: tensor(0.7878, grad_fn=<NllLossBackward>) average train loss tensor(1.1426, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6313171449595291 val_avg_loss: tensor(1.3562)\n",
      "epoch: 17 train_loss: tensor(0.7471, grad_fn=<NllLossBackward>) average train loss tensor(1.1296, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324061810154525 val_avg_loss: tensor(1.3635)\n",
      "epoch: 18 train_loss: tensor(0.7628, grad_fn=<NllLossBackward>) average train loss tensor(1.1167, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6322295805739514 val_avg_loss: tensor(1.3774)\n",
      "epoch: 19 train_loss: tensor(0.7121, grad_fn=<NllLossBackward>) average train loss tensor(1.1040, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6315526122148639 val_avg_loss: tensor(1.3843)\n",
      "epoch: 20 train_loss: tensor(0.7017, grad_fn=<NllLossBackward>) average train loss tensor(1.0866, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6321707137601177 val_avg_loss: tensor(1.3803)\n",
      "epoch: 21 train_loss: tensor(0.6609, grad_fn=<NllLossBackward>) average train loss tensor(1.0721, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6336423841059603 val_avg_loss: tensor(1.3799)\n",
      "epoch: 22 train_loss: tensor(0.6542, grad_fn=<NllLossBackward>) average train loss tensor(1.0605, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6312582781456954 val_avg_loss: tensor(1.3977)\n",
      "epoch: 23 train_loss: tensor(0.6337, grad_fn=<NllLossBackward>) average train loss tensor(1.0454, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6319941133186167 val_avg_loss: tensor(1.3927)\n",
      "epoch: 24 train_loss: tensor(0.6358, grad_fn=<NllLossBackward>) average train loss tensor(1.0319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.630728476821192 val_avg_loss: tensor(1.4132)\n",
      "epoch: 25 train_loss: tensor(0.6324, grad_fn=<NllLossBackward>) average train loss tensor(1.0230, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6292568064753495 val_avg_loss: tensor(1.4116)\n",
      "epoch: 26 train_loss: tensor(0.6040, grad_fn=<NllLossBackward>) average train loss tensor(1.0099, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6304635761589404 val_avg_loss: tensor(1.4218)\n",
      "epoch: 27 train_loss: tensor(0.6206, grad_fn=<NllLossBackward>) average train loss tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6281972038263429 val_avg_loss: tensor(1.4265)\n",
      "epoch: 28 train_loss: tensor(0.5516, grad_fn=<NllLossBackward>) average train loss tensor(0.9874, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6295217071376011 val_avg_loss: tensor(1.4360)\n",
      "epoch: 29 train_loss: tensor(0.5569, grad_fn=<NllLossBackward>) average train loss tensor(0.9783, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6294039735099338 val_avg_loss: tensor(1.4485)\n",
      "epoch: 30 train_loss: tensor(0.5359, grad_fn=<NllLossBackward>) average train loss tensor(0.9708, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6292273730684327 val_avg_loss: tensor(1.4467)\n",
      "epoch: 31 train_loss: tensor(0.5567, grad_fn=<NllLossBackward>) average train loss tensor(0.9615, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6282266372332598 val_avg_loss: tensor(1.4541)\n",
      "epoch: 32 train_loss: tensor(0.5291, grad_fn=<NllLossBackward>) average train loss tensor(0.9523, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6275496688741722 val_avg_loss: tensor(1.4569)\n",
      "epoch: 33 train_loss: tensor(0.5005, grad_fn=<NllLossBackward>) average train loss tensor(0.9390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6278440029433406 val_avg_loss: tensor(1.4681)\n",
      "epoch: 34 train_loss: tensor(0.5125, grad_fn=<NllLossBackward>) average train loss tensor(0.9259, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268432671081677 val_avg_loss: tensor(1.4773)\n",
      "epoch: 35 train_loss: tensor(0.5184, grad_fn=<NllLossBackward>) average train loss tensor(0.9206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261074319352465 val_avg_loss: tensor(1.4727)\n",
      "epoch: 36 train_loss: tensor(0.4981, grad_fn=<NllLossBackward>) average train loss tensor(0.9137, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.627579102281089 val_avg_loss: tensor(1.4786)\n",
      "epoch: 37 train_loss: tensor(0.4696, grad_fn=<NllLossBackward>) average train loss tensor(0.9046, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272847682119206 val_avg_loss: tensor(1.4958)\n",
      "epoch: 38 train_loss: tensor(0.4949, grad_fn=<NllLossBackward>) average train loss tensor(0.8917, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264311994113319 val_avg_loss: tensor(1.5019)\n",
      "epoch: 39 train_loss: tensor(0.4590, grad_fn=<NllLossBackward>) average train loss tensor(0.8852, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6255776306107432 val_avg_loss: tensor(1.5101)\n",
      "epoch: 40 train_loss: tensor(0.4613, grad_fn=<NllLossBackward>) average train loss tensor(0.8813, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626607799852833 val_avg_loss: tensor(1.5184)\n",
      "epoch: 41 train_loss: tensor(0.4521, grad_fn=<NllLossBackward>) average train loss tensor(0.8724, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626784400294334 val_avg_loss: tensor(1.5165)\n",
      "epoch: 42 train_loss: tensor(0.4841, grad_fn=<NllLossBackward>) average train loss tensor(0.8679, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6243414275202355 val_avg_loss: tensor(1.5271)\n",
      "epoch: 43 train_loss: tensor(0.4590, grad_fn=<NllLossBackward>) average train loss tensor(0.8603, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6248417954378219 val_avg_loss: tensor(1.5391)\n",
      "epoch: 44 train_loss: tensor(0.4744, grad_fn=<NllLossBackward>) average train loss tensor(0.8534, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242531272994849 val_avg_loss: tensor(1.5458)\n",
      "epoch: 45 train_loss: tensor(0.4362, grad_fn=<NllLossBackward>) average train loss tensor(0.8484, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6236938925680647 val_avg_loss: tensor(1.5416)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.4172, grad_fn=<NllLossBackward>) average train loss tensor(0.8394, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6233406916850626 val_avg_loss: tensor(1.5579)\n",
      "epoch: 47 train_loss: tensor(0.4006, grad_fn=<NllLossBackward>) average train loss tensor(0.8335, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6228108903605593 val_avg_loss: tensor(1.5577)\n",
      "epoch: 48 train_loss: tensor(0.4100, grad_fn=<NllLossBackward>) average train loss tensor(0.8283, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6227520235467255 val_avg_loss: tensor(1.5711)\n",
      "epoch: 49 train_loss: tensor(0.4124, grad_fn=<NllLossBackward>) average train loss tensor(0.8236, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6206328182487123 val_avg_loss: tensor(1.5631)\n",
      "epoch: 50 train_loss: tensor(0.4134, grad_fn=<NllLossBackward>) average train loss tensor(0.8104, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6222222222222222 val_avg_loss: tensor(1.5811)\n",
      "epoch: 51 train_loss: tensor(0.3769, grad_fn=<NllLossBackward>) average train loss tensor(0.8054, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6203384841795437 val_avg_loss: tensor(1.5887)\n",
      "epoch: 52 train_loss: tensor(0.3970, grad_fn=<NllLossBackward>) average train loss tensor(0.8021, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6226048565121413 val_avg_loss: tensor(1.5870)\n",
      "epoch: 53 train_loss: tensor(0.3785, grad_fn=<NllLossBackward>) average train loss tensor(0.7967, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6214863870493009 val_avg_loss: tensor(1.6001)\n",
      "epoch: 54 train_loss: tensor(0.3946, grad_fn=<NllLossBackward>) average train loss tensor(0.7941, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6203090507726269 val_avg_loss: tensor(1.5950)\n",
      "epoch: 55 train_loss: tensor(0.3827, grad_fn=<NllLossBackward>) average train loss tensor(0.7868, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6216041206769684 val_avg_loss: tensor(1.5919)\n",
      "epoch: 56 train_loss: tensor(0.3843, grad_fn=<NllLossBackward>) average train loss tensor(0.7801, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6230757910228109 val_avg_loss: tensor(1.5980)\n",
      "epoch: 57 train_loss: tensor(0.3594, grad_fn=<NllLossBackward>) average train loss tensor(0.7750, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6230169242089771 val_avg_loss: tensor(1.6117)\n",
      "epoch: 58 train_loss: tensor(0.3717, grad_fn=<NllLossBackward>) average train loss tensor(0.7714, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6217512877115526 val_avg_loss: tensor(1.6128)\n",
      "epoch: 59 train_loss: tensor(0.3739, grad_fn=<NllLossBackward>) average train loss tensor(0.7609, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6213097866077999 val_avg_loss: tensor(1.6251)\n"
     ]
    }
   ],
   "source": [
    "model = torch_models.NormModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "writer = SummaryWriter('runs/norm_bs2048_rs42_te')\n",
    "\n",
    "EPOCHS = 60\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "        model.zero_grad()\n",
    "        output = model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "        loss.backward()\n",
    "            \n",
    "        loss_sum += loss\n",
    "        loss_count += 1\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum/loss_count)\n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    writer.add_scalar('avg_train_loss', loss_sum/loss_count, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "            output = model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "            loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y_cur, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print('val_acc:', correct/total, 'val_avg_loss:', loss_sum/loss_count)\n",
    "    writer.add_scalar('val_acc', correct/total, epoch)\n",
    "    writer.add_scalar('val_avg_loss', loss_sum/loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pytorch.torch_models failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 300, in update_instances\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 300, in <genexpr>\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(1.8598, grad_fn=<NllLossBackward>) average train loss tensor(2.4385, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5201471670345843 val_avg_loss: tensor(1.8433)\n",
      "epoch: 1 train_loss: tensor(1.6297, grad_fn=<NllLossBackward>) average train loss tensor(1.7092, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.560794701986755 val_avg_loss: tensor(1.6661)\n",
      "epoch: 2 train_loss: tensor(1.4839, grad_fn=<NllLossBackward>) average train loss tensor(1.5836, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.572214863870493 val_avg_loss: tensor(1.6083)\n",
      "epoch: 3 train_loss: tensor(1.3660, grad_fn=<NllLossBackward>) average train loss tensor(1.5142, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5838116261957321 val_avg_loss: tensor(1.5732)\n",
      "epoch: 4 train_loss: tensor(1.3545, grad_fn=<NllLossBackward>) average train loss tensor(1.4656, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5886975717439293 val_avg_loss: tensor(1.5499)\n",
      "epoch: 5 train_loss: tensor(1.2384, grad_fn=<NllLossBackward>) average train loss tensor(1.4241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5901398086828551 val_avg_loss: tensor(1.5364)\n",
      "epoch: 6 train_loss: tensor(1.1927, grad_fn=<NllLossBackward>) average train loss tensor(1.3891, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5953495217071376 val_avg_loss: tensor(1.5323)\n",
      "epoch: 7 train_loss: tensor(1.1933, grad_fn=<NllLossBackward>) average train loss tensor(1.3686, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5949668874172186 val_avg_loss: tensor(1.5239)\n",
      "epoch: 8 train_loss: tensor(1.1141, grad_fn=<NllLossBackward>) average train loss tensor(1.3384, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.594878587196468 val_avg_loss: tensor(1.5218)\n",
      "epoch: 9 train_loss: tensor(1.0929, grad_fn=<NllLossBackward>) average train loss tensor(1.3141, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5954378219278882 val_avg_loss: tensor(1.5154)\n",
      "epoch: 10 train_loss: tensor(1.0177, grad_fn=<NllLossBackward>) average train loss tensor(1.2906, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.596644591611479 val_avg_loss: tensor(1.5183)\n",
      "epoch: 11 train_loss: tensor(0.9900, grad_fn=<NllLossBackward>) average train loss tensor(1.2706, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5989992641648271 val_avg_loss: tensor(1.5123)\n",
      "epoch: 12 train_loss: tensor(0.9891, grad_fn=<NllLossBackward>) average train loss tensor(1.2535, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5984988962472406 val_avg_loss: tensor(1.5233)\n",
      "epoch: 13 train_loss: tensor(0.9129, grad_fn=<NllLossBackward>) average train loss tensor(1.2344, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5974981604120677 val_avg_loss: tensor(1.5219)\n",
      "epoch: 14 train_loss: tensor(0.9060, grad_fn=<NllLossBackward>) average train loss tensor(1.2174, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5972038263428991 val_avg_loss: tensor(1.5247)\n",
      "epoch: 15 train_loss: tensor(0.8711, grad_fn=<NllLossBackward>) average train loss tensor(1.2011, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.600794701986755 val_avg_loss: tensor(1.5285)\n",
      "epoch: 16 train_loss: tensor(0.8310, grad_fn=<NllLossBackward>) average train loss tensor(1.1863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5987049300956586 val_avg_loss: tensor(1.5257)\n",
      "epoch: 17 train_loss: tensor(0.8078, grad_fn=<NllLossBackward>) average train loss tensor(1.1711, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5989109639440765 val_avg_loss: tensor(1.5398)\n",
      "epoch: 18 train_loss: tensor(0.7997, grad_fn=<NllLossBackward>) average train loss tensor(1.1528, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5967034584253127 val_avg_loss: tensor(1.5438)\n",
      "epoch: 19 train_loss: tensor(0.8101, grad_fn=<NllLossBackward>) average train loss tensor(1.1413, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5959970566593084 val_avg_loss: tensor(1.5550)\n",
      "epoch: 20 train_loss: tensor(0.7648, grad_fn=<NllLossBackward>) average train loss tensor(1.1311, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5971449595290655 val_avg_loss: tensor(1.5590)\n",
      "epoch: 21 train_loss: tensor(0.7192, grad_fn=<NllLossBackward>) average train loss tensor(1.1160, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5950257542310522 val_avg_loss: tensor(1.5842)\n",
      "epoch: 22 train_loss: tensor(0.7221, grad_fn=<NllLossBackward>) average train loss tensor(1.0984, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5941427520235467 val_avg_loss: tensor(1.5752)\n",
      "epoch: 23 train_loss: tensor(0.6927, grad_fn=<NllLossBackward>) average train loss tensor(1.0912, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5945548197203826 val_avg_loss: tensor(1.5911)\n",
      "epoch: 24 train_loss: tensor(0.7042, grad_fn=<NllLossBackward>) average train loss tensor(1.0765, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5942016188373804 val_avg_loss: tensor(1.5892)\n",
      "epoch: 25 train_loss: tensor(0.6837, grad_fn=<NllLossBackward>) average train loss tensor(1.0614, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.592906548933039 val_avg_loss: tensor(1.6071)\n",
      "epoch: 26 train_loss: tensor(0.6743, grad_fn=<NllLossBackward>) average train loss tensor(1.0536, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5942604856512141 val_avg_loss: tensor(1.6138)\n",
      "epoch: 27 train_loss: tensor(0.6084, grad_fn=<NllLossBackward>) average train loss tensor(1.0413, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5930242825607064 val_avg_loss: tensor(1.6138)\n",
      "epoch: 28 train_loss: tensor(0.6302, grad_fn=<NllLossBackward>) average train loss tensor(1.0333, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5951434878587196 val_avg_loss: tensor(1.6248)\n",
      "epoch: 29 train_loss: tensor(0.5878, grad_fn=<NllLossBackward>) average train loss tensor(1.0202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5899926416482708 val_avg_loss: tensor(1.6303)\n",
      "epoch: 30 train_loss: tensor(0.5877, grad_fn=<NllLossBackward>) average train loss tensor(1.0103, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5901103752759382 val_avg_loss: tensor(1.6555)\n",
      "epoch: 31 train_loss: tensor(0.5963, grad_fn=<NllLossBackward>) average train loss tensor(1.0026, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5916703458425313 val_avg_loss: tensor(1.6536)\n",
      "epoch: 32 train_loss: tensor(0.6146, grad_fn=<NllLossBackward>) average train loss tensor(0.9941, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5918175128771155 val_avg_loss: tensor(1.6617)\n",
      "epoch: 33 train_loss: tensor(0.5544, grad_fn=<NllLossBackward>) average train loss tensor(0.9844, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5886975717439293 val_avg_loss: tensor(1.6738)\n",
      "epoch: 34 train_loss: tensor(0.5399, grad_fn=<NllLossBackward>) average train loss tensor(0.9730, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5888153053715968 val_avg_loss: tensor(1.6841)\n",
      "epoch: 35 train_loss: tensor(0.5651, grad_fn=<NllLossBackward>) average train loss tensor(0.9670, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5899043414275202 val_avg_loss: tensor(1.6766)\n",
      "epoch: 36 train_loss: tensor(0.5083, grad_fn=<NllLossBackward>) average train loss tensor(0.9565, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.586813833701251 val_avg_loss: tensor(1.6926)\n",
      "epoch: 37 train_loss: tensor(0.5400, grad_fn=<NllLossBackward>) average train loss tensor(0.9506, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5851949963208242 val_avg_loss: tensor(1.7209)\n",
      "epoch: 38 train_loss: tensor(0.5090, grad_fn=<NllLossBackward>) average train loss tensor(0.9442, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5898749080206034 val_avg_loss: tensor(1.7126)\n",
      "epoch: 39 train_loss: tensor(0.5172, grad_fn=<NllLossBackward>) average train loss tensor(0.9329, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.586813833701251 val_avg_loss: tensor(1.7051)\n",
      "epoch: 40 train_loss: tensor(0.5221, grad_fn=<NllLossBackward>) average train loss tensor(0.9240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5859896983075791 val_avg_loss: tensor(1.7270)\n",
      "epoch: 41 train_loss: tensor(0.5207, grad_fn=<NllLossBackward>) average train loss tensor(0.9196, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5878145695364239 val_avg_loss: tensor(1.7299)\n",
      "epoch: 42 train_loss: tensor(0.4996, grad_fn=<NllLossBackward>) average train loss tensor(0.9101, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.580691685062546 val_avg_loss: tensor(1.7545)\n",
      "epoch: 43 train_loss: tensor(0.4998, grad_fn=<NllLossBackward>) average train loss tensor(0.9039, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5817218543046357 val_avg_loss: tensor(1.7715)\n",
      "epoch: 44 train_loss: tensor(0.4768, grad_fn=<NllLossBackward>) average train loss tensor(0.8942, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5799558498896247 val_avg_loss: tensor(1.7599)\n",
      "epoch: 45 train_loss: tensor(0.4797, grad_fn=<NllLossBackward>) average train loss tensor(0.8851, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5828991905813098 val_avg_loss: tensor(1.7768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.4804, grad_fn=<NllLossBackward>) average train loss tensor(0.8800, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5796026490066225 val_avg_loss: tensor(1.8004)\n",
      "epoch: 47 train_loss: tensor(0.4793, grad_fn=<NllLossBackward>) average train loss tensor(0.8779, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5827225901398086 val_avg_loss: tensor(1.7879)\n",
      "epoch: 48 train_loss: tensor(0.4605, grad_fn=<NllLossBackward>) average train loss tensor(0.8664, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5828991905813098 val_avg_loss: tensor(1.7934)\n",
      "epoch: 49 train_loss: tensor(0.4310, grad_fn=<NllLossBackward>) average train loss tensor(0.8632, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5838116261957321 val_avg_loss: tensor(1.7948)\n",
      "epoch: 50 train_loss: tensor(0.4320, grad_fn=<NllLossBackward>) average train loss tensor(0.8557, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5816924208977189 val_avg_loss: tensor(1.8043)\n",
      "epoch: 51 train_loss: tensor(0.4372, grad_fn=<NllLossBackward>) average train loss tensor(0.8503, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5776600441501104 val_avg_loss: tensor(1.8351)\n",
      "epoch: 52 train_loss: tensor(0.4180, grad_fn=<NllLossBackward>) average train loss tensor(0.8447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5810448859455482 val_avg_loss: tensor(1.8270)\n",
      "epoch: 53 train_loss: tensor(0.4547, grad_fn=<NllLossBackward>) average train loss tensor(0.8407, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.581074319352465 val_avg_loss: tensor(1.8334)\n",
      "epoch: 54 train_loss: tensor(0.4224, grad_fn=<NllLossBackward>) average train loss tensor(0.8338, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5794849153789551 val_avg_loss: tensor(1.8541)\n",
      "epoch: 55 train_loss: tensor(0.3914, grad_fn=<NllLossBackward>) average train loss tensor(0.8261, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5796615158204562 val_avg_loss: tensor(1.8313)\n",
      "epoch: 56 train_loss: tensor(0.4059, grad_fn=<NllLossBackward>) average train loss tensor(0.8212, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5777189109639441 val_avg_loss: tensor(1.8633)\n",
      "epoch: 57 train_loss: tensor(0.4137, grad_fn=<NllLossBackward>) average train loss tensor(0.8146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5787490802060339 val_avg_loss: tensor(1.8408)\n",
      "epoch: 58 train_loss: tensor(0.4085, grad_fn=<NllLossBackward>) average train loss tensor(0.8081, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5764532744665195 val_avg_loss: tensor(1.8757)\n",
      "epoch: 59 train_loss: tensor(0.4010, grad_fn=<NllLossBackward>) average train loss tensor(0.8082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5791611479028698 val_avg_loss: tensor(1.8666)\n"
     ]
    }
   ],
   "source": [
    "norm_model_glorot = torch_models.NormModelGlorot()\n",
    "optimizer = optim.Adam(norm_model_glorot.parameters())\n",
    "writer = SummaryWriter('runs/glorot_bs2048_rs42')\n",
    "\n",
    "EPOCHS = 60\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "        norm_model_glorot.zero_grad()\n",
    "        output = norm_model_glorot(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "        loss.backward()\n",
    "            \n",
    "        loss_sum += loss\n",
    "        loss_count += 1\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum/loss_count)\n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    writer.add_scalar('avg_train_loss', loss_sum/loss_count, epoch)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "            output = norm_model_glorot(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "            loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y_cur, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print('val_acc:', correct/total, 'val_avg_loss:', loss_sum/loss_count)\n",
    "    writer.add_scalar('val_acc', correct/total, epoch)\n",
    "    writer.add_scalar('val_avg_loss', loss_sum/loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_4 = torch_models.NormModel()\n",
    "optimizer = optim.Adam(norm_model_4.parameters(), lr=1e-4)\n",
    "norm_4_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_4.zero_grad()\n",
    "        output = norm_model_4(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_4(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    norm_4_writer.add_scalar('/accuracy/val/norm_4', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_2 = torch_models.NormModel()\n",
    "optimizer = optim.Adam(norm_model_2.parameters(), lr=1e-2)\n",
    "norm_2_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_2.zero_grad()\n",
    "        output = norm_model_2(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_2(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    norm_2_writer.add_scalar('accuracy/val/norm_2', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_s = torch_models.NormModel()\n",
    "optimizer = optim.Adam(norm_model_s.parameters(), lr=1e-3)\n",
    "cos_shed = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000) \n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_s.zero_grad()\n",
    "        output = norm_model_s(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cos_shed.step()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_s(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    writer.add_scalar('accuracy/val/norm_s', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_cs = torch_models.NormModel()\n",
    "optimizer = optim.Adam(norm_model_cs.parameters(), lr=1e-3)\n",
    "cyclic_shed = optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=1e-2, cycle_momentum=False) \n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_cs.zero_grad()\n",
    "        output = norm_model_cs(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cyclic_shed.step()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_cs(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    writer.add_scalar('accuracy/val/norm_cs', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5671376011773362\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x_img, x_txt, y in val_loader:\n",
    "        output = norm_model_cs(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectified ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_radam = torch_models.NormModel()\n",
    "optimizer = radam.RAdam(norm_model_radam.parameters())\n",
    "writer = SummaryWriter('runs/radam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_radam.zero_grad()\n",
    "        output = norm_model_radam(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_radam(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    writer.add_scalar('val_acc', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pytorch.torch_models failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 860, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 791, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/dmitry/Desktop/Thesis/topics_ds/pytorch/torch_models.py\", line 14\n",
      "    class NormModel(nn.Module):\n",
      "        ^\n",
      "IndentationError: expected an indented block\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.3168, grad_fn=<NllLossBackward>) average train loss tensor(3.7594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20559234731420162 val_avg_loss: tensor(3.2530)\n",
      "epoch: 1 train_loss: tensor(2.1050, grad_fn=<NllLossBackward>) average train loss tensor(2.5946, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48562178072111845 val_avg_loss: tensor(1.9317)\n",
      "epoch: 2 train_loss: tensor(1.7373, grad_fn=<NllLossBackward>) average train loss tensor(1.8748, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5659455481972038 val_avg_loss: tensor(1.6185)\n",
      "epoch: 3 train_loss: tensor(1.5961, grad_fn=<NllLossBackward>) average train loss tensor(1.6674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5930537159676232 val_avg_loss: tensor(1.5093)\n",
      "epoch: 4 train_loss: tensor(1.4828, grad_fn=<NllLossBackward>) average train loss tensor(1.5734, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6037086092715231 val_avg_loss: tensor(1.4619)\n",
      "epoch: 5 train_loss: tensor(1.4484, grad_fn=<NllLossBackward>) average train loss tensor(1.5199, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6107431935246505 val_avg_loss: tensor(1.4312)\n",
      "epoch: 6 train_loss: tensor(1.3970, grad_fn=<NllLossBackward>) average train loss tensor(1.4772, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6156291390728477 val_avg_loss: tensor(1.4121)\n",
      "epoch: 7 train_loss: tensor(1.3475, grad_fn=<NllLossBackward>) average train loss tensor(1.4467, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.619896983075791 val_avg_loss: tensor(1.3949)\n",
      "epoch: 8 train_loss: tensor(1.2619, grad_fn=<NllLossBackward>) average train loss tensor(1.4142, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6218395879323032 val_avg_loss: tensor(1.3823)\n",
      "epoch: 9 train_loss: tensor(1.2423, grad_fn=<NllLossBackward>) average train loss tensor(1.3918, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6254010301692421 val_avg_loss: tensor(1.3720)\n",
      "epoch: 10 train_loss: tensor(1.2044, grad_fn=<NllLossBackward>) average train loss tensor(1.3648, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264311994113319 val_avg_loss: tensor(1.3664)\n",
      "epoch: 11 train_loss: tensor(1.1507, grad_fn=<NllLossBackward>) average train loss tensor(1.3453, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6256953642384105 val_avg_loss: tensor(1.3590)\n",
      "epoch: 12 train_loss: tensor(1.1396, grad_fn=<NllLossBackward>) average train loss tensor(1.3271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280794701986755 val_avg_loss: tensor(1.3528)\n",
      "epoch: 13 train_loss: tensor(1.1015, grad_fn=<NllLossBackward>) average train loss tensor(1.3071, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6285209713024282 val_avg_loss: tensor(1.3520)\n",
      "epoch: 14 train_loss: tensor(1.0034, grad_fn=<NllLossBackward>) average train loss tensor(1.2856, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6279028697571744 val_avg_loss: tensor(1.3568)\n",
      "epoch: 15 train_loss: tensor(1.0082, grad_fn=<NllLossBackward>) average train loss tensor(1.2701, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.628579838116262 val_avg_loss: tensor(1.3477)\n",
      "epoch: 16 train_loss: tensor(0.9641, grad_fn=<NllLossBackward>) average train loss tensor(1.2543, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6297277409860191 val_avg_loss: tensor(1.3515)\n",
      "epoch: 17 train_loss: tensor(0.9576, grad_fn=<NllLossBackward>) average train loss tensor(1.2335, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6295805739514349 val_avg_loss: tensor(1.3548)\n",
      "epoch: 18 train_loss: tensor(0.9187, grad_fn=<NllLossBackward>) average train loss tensor(1.2178, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6312582781456954 val_avg_loss: tensor(1.3586)\n",
      "epoch: 19 train_loss: tensor(0.8738, grad_fn=<NllLossBackward>) average train loss tensor(1.2017, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6300515084621044 val_avg_loss: tensor(1.3544)\n",
      "epoch: 20 train_loss: tensor(0.8873, grad_fn=<NllLossBackward>) average train loss tensor(1.1853, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6290507726269315 val_avg_loss: tensor(1.3586)\n",
      "epoch: 21 train_loss: tensor(0.8175, grad_fn=<NllLossBackward>) average train loss tensor(1.1712, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.630345842531273 val_avg_loss: tensor(1.3636)\n",
      "epoch: 22 train_loss: tensor(0.7970, grad_fn=<NllLossBackward>) average train loss tensor(1.1558, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6288447387785137 val_avg_loss: tensor(1.3634)\n",
      "epoch: 23 train_loss: tensor(0.8054, grad_fn=<NllLossBackward>) average train loss tensor(1.1427, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6305813097866078 val_avg_loss: tensor(1.3685)\n",
      "epoch: 24 train_loss: tensor(0.7666, grad_fn=<NllLossBackward>) average train loss tensor(1.1278, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6282855040470935 val_avg_loss: tensor(1.3698)\n",
      "epoch: 25 train_loss: tensor(0.7473, grad_fn=<NllLossBackward>) average train loss tensor(1.1131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6306990434142752 val_avg_loss: tensor(1.3800)\n",
      "epoch: 26 train_loss: tensor(0.7376, grad_fn=<NllLossBackward>) average train loss tensor(1.1015, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6296688741721854 val_avg_loss: tensor(1.3857)\n",
      "epoch: 27 train_loss: tensor(0.7138, grad_fn=<NllLossBackward>) average train loss tensor(1.0863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6294334069168507 val_avg_loss: tensor(1.3918)\n",
      "epoch: 28 train_loss: tensor(0.6803, grad_fn=<NllLossBackward>) average train loss tensor(1.0740, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6282560706401766 val_avg_loss: tensor(1.3943)\n",
      "epoch: 29 train_loss: tensor(0.6535, grad_fn=<NllLossBackward>) average train loss tensor(1.0631, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270493009565857 val_avg_loss: tensor(1.3982)\n",
      "epoch: 30 train_loss: tensor(0.6845, grad_fn=<NllLossBackward>) average train loss tensor(1.0473, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6266372332597498 val_avg_loss: tensor(1.4119)\n",
      "epoch: 31 train_loss: tensor(0.6494, grad_fn=<NllLossBackward>) average train loss tensor(1.0381, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280794701986755 val_avg_loss: tensor(1.4179)\n",
      "epoch: 32 train_loss: tensor(0.6452, grad_fn=<NllLossBackward>) average train loss tensor(1.0263, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6277557027225902 val_avg_loss: tensor(1.4209)\n",
      "epoch: 33 train_loss: tensor(0.6286, grad_fn=<NllLossBackward>) average train loss tensor(1.0162, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264311994113319 val_avg_loss: tensor(1.4318)\n",
      "epoch: 34 train_loss: tensor(0.6041, grad_fn=<NllLossBackward>) average train loss tensor(1.0016, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269021339220014 val_avg_loss: tensor(1.4273)\n",
      "epoch: 35 train_loss: tensor(0.5692, grad_fn=<NllLossBackward>) average train loss tensor(0.9901, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626019131714496 val_avg_loss: tensor(1.4434)\n",
      "epoch: 36 train_loss: tensor(0.5876, grad_fn=<NllLossBackward>) average train loss tensor(0.9801, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6244591611479029 val_avg_loss: tensor(1.4458)\n",
      "epoch: 37 train_loss: tensor(0.5645, grad_fn=<NllLossBackward>) average train loss tensor(0.9739, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6263428991905813 val_avg_loss: tensor(1.4555)\n",
      "epoch: 38 train_loss: tensor(0.5430, grad_fn=<NllLossBackward>) average train loss tensor(0.9612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6276674025018396 val_avg_loss: tensor(1.4510)\n",
      "epoch: 39 train_loss: tensor(0.5330, grad_fn=<NllLossBackward>) average train loss tensor(0.9524, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6255187637969095 val_avg_loss: tensor(1.4667)\n",
      "epoch: 40 train_loss: tensor(0.5379, grad_fn=<NllLossBackward>) average train loss tensor(0.9407, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6248417954378219 val_avg_loss: tensor(1.4686)\n",
      "epoch: 41 train_loss: tensor(0.5194, grad_fn=<NllLossBackward>) average train loss tensor(0.9324, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6235172921265637 val_avg_loss: tensor(1.4830)\n",
      "epoch: 42 train_loss: tensor(0.5209, grad_fn=<NllLossBackward>) average train loss tensor(0.9267, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6231935246504783 val_avg_loss: tensor(1.4936)\n",
      "epoch: 43 train_loss: tensor(0.5063, grad_fn=<NllLossBackward>) average train loss tensor(0.9120, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6236938925680647 val_avg_loss: tensor(1.4957)\n",
      "epoch: 44 train_loss: tensor(0.4882, grad_fn=<NllLossBackward>) average train loss tensor(0.9060, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6239882266372333 val_avg_loss: tensor(1.5096)\n",
      "epoch: 45 train_loss: tensor(0.4615, grad_fn=<NllLossBackward>) average train loss tensor(0.8971, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6205739514348786 val_avg_loss: tensor(1.5176)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.4846, grad_fn=<NllLossBackward>) average train loss tensor(0.8897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6238704930095659 val_avg_loss: tensor(1.5161)\n",
      "epoch: 47 train_loss: tensor(0.4630, grad_fn=<NllLossBackward>) average train loss tensor(0.8815, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6214569536423841 val_avg_loss: tensor(1.5247)\n",
      "epoch: 48 train_loss: tensor(0.4678, grad_fn=<NllLossBackward>) average train loss tensor(0.8729, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6202501839587933 val_avg_loss: tensor(1.5314)\n",
      "epoch: 49 train_loss: tensor(0.4596, grad_fn=<NllLossBackward>) average train loss tensor(0.8637, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.622869757174393 val_avg_loss: tensor(1.5483)\n",
      "epoch: 50 train_loss: tensor(0.4563, grad_fn=<NllLossBackward>) average train loss tensor(0.8621, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6211037527593819 val_avg_loss: tensor(1.5472)\n",
      "epoch: 51 train_loss: tensor(0.4353, grad_fn=<NllLossBackward>) average train loss tensor(0.8485, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6196026490066225 val_avg_loss: tensor(1.5608)\n",
      "epoch: 52 train_loss: tensor(0.4387, grad_fn=<NllLossBackward>) average train loss tensor(0.8459, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6220456217807211 val_avg_loss: tensor(1.5508)\n",
      "epoch: 53 train_loss: tensor(0.4066, grad_fn=<NllLossBackward>) average train loss tensor(0.8376, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6193671817512877 val_avg_loss: tensor(1.5731)\n",
      "epoch: 54 train_loss: tensor(0.4216, grad_fn=<NllLossBackward>) average train loss tensor(0.8345, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6196320824135394 val_avg_loss: tensor(1.5798)\n",
      "epoch: 55 train_loss: tensor(0.4199, grad_fn=<NllLossBackward>) average train loss tensor(0.8256, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6173951434878587 val_avg_loss: tensor(1.5840)\n",
      "epoch: 56 train_loss: tensor(0.4064, grad_fn=<NllLossBackward>) average train loss tensor(0.8197, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6177777777777778 val_avg_loss: tensor(1.5936)\n",
      "epoch: 57 train_loss: tensor(0.3689, grad_fn=<NllLossBackward>) average train loss tensor(0.8042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6165121412803533 val_avg_loss: tensor(1.5976)\n",
      "epoch: 58 train_loss: tensor(0.4187, grad_fn=<NllLossBackward>) average train loss tensor(0.8025, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6186607799852833 val_avg_loss: tensor(1.6027)\n",
      "epoch: 59 train_loss: tensor(0.3923, grad_fn=<NllLossBackward>) average train loss tensor(0.7945, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6187490802060338 val_avg_loss: tensor(1.6263)\n"
     ]
    }
   ],
   "source": [
    "model = torch_models.NormModel()\n",
    "optimizer = radam.RAdam(model.parameters())\n",
    "writer = SummaryWriter('runs/norm_radam_bs2048_rs42_te')\n",
    "\n",
    "EPOCHS = 60\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "        model.zero_grad()\n",
    "        output = model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "        loss.backward()\n",
    "            \n",
    "        loss_sum += loss\n",
    "        loss_count += 1\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum/loss_count)\n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    writer.add_scalar('avg_train_loss', loss_sum/loss_count, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0.0\n",
    "    loss_count = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "            output = model(x_img_cur.view(-1, IMG_LEN).float(), x_txt_cur.view(-1, TXT_LEN).float())\n",
    "            loss = F.nll_loss(output, torch.argmax(y_cur, dim=1))\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y_cur, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    print('val_acc:', correct/total, 'val_avg_loss:', loss_sum/loss_count)\n",
    "    writer.add_scalar('val_acc', correct/total, epoch)\n",
    "    writer.add_scalar('val_avg_loss', loss_sum/loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch' : 40,\n",
    "    'model_state_dict' : norm_model_radam.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),    \n",
    "}, 'saved_models/torch/radam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain RADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_plain_radam = torch_models.NormModel()\n",
    "optimizer = radam.PlainRAdam(norm_model_radam.parameters())\n",
    "writer = SummaryWriter('runs/plain_radam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_plain_radam.zero_grad()\n",
    "        output = norm_model_plain_radam(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_plain_radam(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    writer.add_scalar('val_acc', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch' : 40,\n",
    "    'model_state_dict' : norm_model_plain_radam.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),    \n",
    "}, 'saved_models/torch/radam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model_adamw = torch_models.NormModel()\n",
    "optimizer = radam.AdamW(norm_model_adamw.parameters())\n",
    "writer = SummaryWriter('runs/adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    for x_img, x_txt, y in train_loader:\n",
    "        norm_model_adamw.zero_grad()\n",
    "        output = norm_model_adamw(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "        loss = F.nll_loss(output, torch.argmax(y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    writer.add_scalar('train_loss', loss, epoch)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_img, x_txt, y in val_loader:\n",
    "            output = norm_model_adamw(x_img.view(-1, IMG_LEN).float(), x_txt.view(-1, TXT_LEN).float())\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == torch.argmax(y, dim=1)[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    writer.add_scalar('val_acc', correct/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch' : 40,\n",
    "    'model_state_dict' : norm_model_adamw.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),    \n",
    "}, 'saved_models/torch/adamw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
