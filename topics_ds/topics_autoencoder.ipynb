{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from struct import unpack\n",
    "from base64 import b64decode\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, concatenate, BatchNormalization, Multiply, Add\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from functools import partial\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Activation, Multiply, Add, Lambda, Layer\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dmitry/Downloads/topics_dataset.json\"\n",
    "df = pd.read_json(filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpck(l, x):\n",
    "    return unpack('%df' % l, b64decode(x.encode('utf-8')))\n",
    "\n",
    "unpck_img = partial(unpck, IMG_LEN)\n",
    "unpck_txt = partial(unpck, TXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = df.sample(frac=0.25)\n",
    "x_img_q = np.stack(df_q['x1'].map(unpck_img), axis=0)\n",
    "x_txt_q = np.stack(df_q['x2'].map(unpck_txt), axis=0)\n",
    "y_q = to_categorical(np.array(df_q['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(x_img_q, x_txt_q, y_q, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_autoencoder():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "\n",
    "    concat = concatenate([inp_img, inp_txt])\n",
    "    encoded = Dense(512, activation='relu')(concat)\n",
    "    \n",
    "    out_img = Dense(IMG_LEN)(encoded)\n",
    "    out_txt = Dense(TXT_LEN)(encoded)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=30, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 18s 482us/sample - loss: 0.7945 - dense_12_loss: 0.6168 - dense_13_loss: 0.1777 - val_loss: 0.6616 - val_dense_12_loss: 0.5618 - val_dense_13_loss: 0.1000\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 19s 500us/sample - loss: 0.6184 - dense_12_loss: 0.5411 - dense_13_loss: 0.0772 - val_loss: 0.5908 - val_dense_12_loss: 0.5281 - val_dense_13_loss: 0.0628\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 16s 429us/sample - loss: 0.5740 - dense_12_loss: 0.5182 - dense_13_loss: 0.0559 - val_loss: 0.5616 - val_dense_12_loss: 0.5103 - val_dense_13_loss: 0.0514\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 18s 484us/sample - loss: 0.5501 - dense_12_loss: 0.5008 - dense_13_loss: 0.0493 - val_loss: 0.5404 - val_dense_12_loss: 0.4920 - val_dense_13_loss: 0.0485\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 19s 487us/sample - loss: 0.5288 - dense_12_loss: 0.4802 - dense_13_loss: 0.0486 - val_loss: 0.5180 - val_dense_12_loss: 0.4686 - val_dense_13_loss: 0.0495\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 18s 475us/sample - loss: 0.5041 - dense_12_loss: 0.4535 - dense_13_loss: 0.0506 - val_loss: 0.4904 - val_dense_12_loss: 0.4384 - val_dense_13_loss: 0.0521\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 19s 493us/sample - loss: 0.4734 - dense_12_loss: 0.4208 - dense_13_loss: 0.0526 - val_loss: 0.4567 - val_dense_12_loss: 0.4035 - val_dense_13_loss: 0.0532\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 20s 527us/sample - loss: 0.4380 - dense_12_loss: 0.3857 - dense_13_loss: 0.0523 - val_loss: 0.4204 - val_dense_12_loss: 0.3692 - val_dense_13_loss: 0.0513\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 18s 465us/sample - loss: 0.4030 - dense_12_loss: 0.3539 - dense_13_loss: 0.0491 - val_loss: 0.3875 - val_dense_12_loss: 0.3406 - val_dense_13_loss: 0.0470\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 18s 463us/sample - loss: 0.3736 - dense_12_loss: 0.3291 - dense_13_loss: 0.0446 - val_loss: 0.3618 - val_dense_12_loss: 0.3194 - val_dense_13_loss: 0.0425\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 18s 477us/sample - loss: 0.3516 - dense_12_loss: 0.3112 - dense_13_loss: 0.0404 - val_loss: 0.3432 - val_dense_12_loss: 0.3046 - val_dense_13_loss: 0.0387\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 18s 482us/sample - loss: 0.3357 - dense_12_loss: 0.2987 - dense_13_loss: 0.0370 - val_loss: 0.3297 - val_dense_12_loss: 0.2942 - val_dense_13_loss: 0.0356\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 20s 511us/sample - loss: 0.3242 - dense_12_loss: 0.2900 - dense_13_loss: 0.0342 - val_loss: 0.3199 - val_dense_12_loss: 0.2869 - val_dense_13_loss: 0.0330\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 18s 467us/sample - loss: 0.3156 - dense_12_loss: 0.2838 - dense_13_loss: 0.0318 - val_loss: 0.3125 - val_dense_12_loss: 0.2818 - val_dense_13_loss: 0.0308\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 18s 463us/sample - loss: 0.3092 - dense_12_loss: 0.2794 - dense_13_loss: 0.0297 - val_loss: 0.3069 - val_dense_12_loss: 0.2781 - val_dense_13_loss: 0.0288\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 18s 462us/sample - loss: 0.3042 - dense_12_loss: 0.2763 - dense_13_loss: 0.0279 - val_loss: 0.3025 - val_dense_12_loss: 0.2755 - val_dense_13_loss: 0.0271\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 18s 464us/sample - loss: 0.3003 - dense_12_loss: 0.2739 - dense_13_loss: 0.0263 - val_loss: 0.2990 - val_dense_12_loss: 0.2735 - val_dense_13_loss: 0.0256\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 18s 463us/sample - loss: 0.2971 - dense_12_loss: 0.2722 - dense_13_loss: 0.0249 - val_loss: 0.2961 - val_dense_12_loss: 0.2719 - val_dense_13_loss: 0.0242\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 18s 465us/sample - loss: 0.2944 - dense_12_loss: 0.2709 - dense_13_loss: 0.0236 - val_loss: 0.2937 - val_dense_12_loss: 0.2708 - val_dense_13_loss: 0.0230\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 18s 468us/sample - loss: 0.2922 - dense_12_loss: 0.2698 - dense_13_loss: 0.0225 - val_loss: 0.2917 - val_dense_12_loss: 0.2698 - val_dense_13_loss: 0.0220\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 18s 465us/sample - loss: 0.2904 - dense_12_loss: 0.2689 - dense_13_loss: 0.0215 - val_loss: 0.2900 - val_dense_12_loss: 0.2690 - val_dense_13_loss: 0.0210\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 18s 461us/sample - loss: 0.2888 - dense_12_loss: 0.2682 - dense_13_loss: 0.0206 - val_loss: 0.2885 - val_dense_12_loss: 0.2683 - val_dense_13_loss: 0.0202\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 18s 464us/sample - loss: 0.2874 - dense_12_loss: 0.2676 - dense_13_loss: 0.0198 - val_loss: 0.2872 - val_dense_12_loss: 0.2678 - val_dense_13_loss: 0.0194\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 18s 465us/sample - loss: 0.2861 - dense_12_loss: 0.2670 - dense_13_loss: 0.0191 - val_loss: 0.2860 - val_dense_12_loss: 0.2673 - val_dense_13_loss: 0.0188\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 18s 470us/sample - loss: 0.2851 - dense_12_loss: 0.2666 - dense_13_loss: 0.0185 - val_loss: 0.2850 - val_dense_12_loss: 0.2669 - val_dense_13_loss: 0.0182\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 18s 468us/sample - loss: 0.2841 - dense_12_loss: 0.2662 - dense_13_loss: 0.0179 - val_loss: 0.2841 - val_dense_12_loss: 0.2665 - val_dense_13_loss: 0.0176\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 18s 471us/sample - loss: 0.2832 - dense_12_loss: 0.2658 - dense_13_loss: 0.0174 - val_loss: 0.2832 - val_dense_12_loss: 0.2661 - val_dense_13_loss: 0.0171\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 18s 475us/sample - loss: 0.2824 - dense_12_loss: 0.2655 - dense_13_loss: 0.0169 - val_loss: 0.2824 - val_dense_12_loss: 0.2658 - val_dense_13_loss: 0.0166\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 18s 475us/sample - loss: 0.2816 - dense_12_loss: 0.2652 - dense_13_loss: 0.0164 - val_loss: 0.2817 - val_dense_12_loss: 0.2655 - val_dense_13_loss: 0.0162\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 18s 468us/sample - loss: 0.2809 - dense_12_loss: 0.2649 - dense_13_loss: 0.0160 - val_loss: 0.2810 - val_dense_12_loss: 0.2652 - val_dense_13_loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "encoder = get_simple_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder_1():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "\n",
    "    concat = concatenate([inp_img, inp_txt])\n",
    "    encoded = Dense(512, activation='relu')(concat)\n",
    "    \n",
    "    out_img = Dense(IMG_LEN, activation='sigmoid', name='img')(encoded)\n",
    "    out_txt = Dense(TXT_LEN, activation='sigmoid', name='txt')(encoded)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse', loss_weights={'img':1, 'txt':0.2})\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=30, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 23s 609us/sample - loss: 0.3775 - img_loss: 0.3235 - txt_loss: 0.2698 - val_loss: 0.3755 - val_img_loss: 0.3225 - val_txt_loss: 0.2652\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 18s 474us/sample - loss: 0.3737 - img_loss: 0.3216 - txt_loss: 0.2610 - val_loss: 0.3720 - val_img_loss: 0.3207 - val_txt_loss: 0.2569\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 17s 449us/sample - loss: 0.3706 - img_loss: 0.3199 - txt_loss: 0.2532 - val_loss: 0.3691 - val_img_loss: 0.3192 - val_txt_loss: 0.2496\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 22s 577us/sample - loss: 0.3678 - img_loss: 0.3186 - txt_loss: 0.2462 - val_loss: 0.3665 - val_img_loss: 0.3180 - val_txt_loss: 0.2430\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 19s 497us/sample - loss: 0.3654 - img_loss: 0.3174 - txt_loss: 0.2399 - val_loss: 0.3642 - val_img_loss: 0.3169 - val_txt_loss: 0.2369\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 23s 600us/sample - loss: 0.3632 - img_loss: 0.3164 - txt_loss: 0.2341 - val_loss: 0.3621 - val_img_loss: 0.3159 - val_txt_loss: 0.2312\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 18s 478us/sample - loss: 0.3612 - img_loss: 0.3154 - txt_loss: 0.2285 - val_loss: 0.3602 - val_img_loss: 0.3150 - val_txt_loss: 0.2259\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 19s 491us/sample - loss: 0.3593 - img_loss: 0.3146 - txt_loss: 0.2233 - val_loss: 0.3583 - val_img_loss: 0.3142 - val_txt_loss: 0.2207\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 18s 473us/sample - loss: 0.3575 - img_loss: 0.3138 - txt_loss: 0.2181 - val_loss: 0.3566 - val_img_loss: 0.3135 - val_txt_loss: 0.2156\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 20s 532us/sample - loss: 0.3557 - img_loss: 0.3131 - txt_loss: 0.2131 - val_loss: 0.3548 - val_img_loss: 0.3128 - val_txt_loss: 0.2106\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 24s 621us/sample - loss: 0.3540 - img_loss: 0.3124 - txt_loss: 0.2081 - val_loss: 0.3531 - val_img_loss: 0.3121 - val_txt_loss: 0.2055\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 23s 612us/sample - loss: 0.3523 - img_loss: 0.3117 - txt_loss: 0.2031 - val_loss: 0.3515 - val_img_loss: 0.3114 - val_txt_loss: 0.2005\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 20s 524us/sample - loss: 0.3507 - img_loss: 0.3110 - txt_loss: 0.1980 - val_loss: 0.3498 - val_img_loss: 0.3107 - val_txt_loss: 0.1955\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 16s 420us/sample - loss: 0.3490 - img_loss: 0.3104 - txt_loss: 0.1930 - val_loss: 0.3481 - val_img_loss: 0.3101 - val_txt_loss: 0.1904\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 20s 523us/sample - loss: 0.3473 - img_loss: 0.3097 - txt_loss: 0.1878 - val_loss: 0.3464 - val_img_loss: 0.3094 - val_txt_loss: 0.1852\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 21s 556us/sample - loss: 0.3456 - img_loss: 0.3091 - txt_loss: 0.1826 - val_loss: 0.3447 - val_img_loss: 0.3088 - val_txt_loss: 0.1799\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 19s 491us/sample - loss: 0.3439 - img_loss: 0.3084 - txt_loss: 0.1773 - val_loss: 0.3430 - val_img_loss: 0.3081 - val_txt_loss: 0.1746\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 19s 506us/sample - loss: 0.3421 - img_loss: 0.3077 - txt_loss: 0.1720 - val_loss: 0.3413 - val_img_loss: 0.3075 - val_txt_loss: 0.1693\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 20s 527us/sample - loss: 0.3404 - img_loss: 0.3071 - txt_loss: 0.1666 - val_loss: 0.3395 - val_img_loss: 0.3068 - val_txt_loss: 0.1639\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 19s 510us/sample - loss: 0.3386 - img_loss: 0.3064 - txt_loss: 0.1612 - val_loss: 0.3378 - val_img_loss: 0.3061 - val_txt_loss: 0.1584\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 20s 521us/sample - loss: 0.3368 - img_loss: 0.3057 - txt_loss: 0.1557 - val_loss: 0.3360 - val_img_loss: 0.3054 - val_txt_loss: 0.1529\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 23s 610us/sample - loss: 0.3351 - img_loss: 0.3050 - txt_loss: 0.1503 - val_loss: 0.3342 - val_img_loss: 0.3047 - val_txt_loss: 0.1475\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 21s 560us/sample - loss: 0.3333 - img_loss: 0.3043 - txt_loss: 0.1448 - val_loss: 0.3324 - val_img_loss: 0.3040 - val_txt_loss: 0.1420\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 21s 540us/sample - loss: 0.3315 - img_loss: 0.3036 - txt_loss: 0.1393 - val_loss: 0.3306 - val_img_loss: 0.3033 - val_txt_loss: 0.1366\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 21s 552us/sample - loss: 0.3297 - img_loss: 0.3029 - txt_loss: 0.1339 - val_loss: 0.3289 - val_img_loss: 0.3026 - val_txt_loss: 0.1312\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 25s 654us/sample - loss: 0.3279 - img_loss: 0.3022 - txt_loss: 0.1286 - val_loss: 0.3271 - val_img_loss: 0.3020 - val_txt_loss: 0.1259\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 20s 519us/sample - loss: 0.3262 - img_loss: 0.3015 - txt_loss: 0.1234 - val_loss: 0.3254 - val_img_loss: 0.3013 - val_txt_loss: 0.1207\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 19s 510us/sample - loss: 0.3244 - img_loss: 0.3008 - txt_loss: 0.1182 - val_loss: 0.3237 - val_img_loss: 0.3006 - val_txt_loss: 0.1156\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 19s 505us/sample - loss: 0.3228 - img_loss: 0.3001 - txt_loss: 0.1132 - val_loss: 0.3220 - val_img_loss: 0.2999 - val_txt_loss: 0.1107\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 20s 520us/sample - loss: 0.3211 - img_loss: 0.2994 - txt_loss: 0.1083 - val_loss: 0.3204 - val_img_loss: 0.2992 - val_txt_loss: 0.1059\n"
     ]
    }
   ],
   "source": [
    "encoder_1 = get_autoencoder_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1324)         0           input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 512)          678400      concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 678,400\n",
      "Trainable params: 678,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = encoder.predict([x_img_train, x_txt_train])\n",
    "test_e = encoder.predict([x_img_test, x_txt_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42468, 512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(512,))\n",
    "    x = Dense(512, activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 6s 164us/sample - loss: 3.4458 - accuracy: 0.1243 - val_loss: 3.0151 - val_accuracy: 0.2437\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 6s 150us/sample - loss: 3.0504 - accuracy: 0.2208 - val_loss: 2.8126 - val_accuracy: 0.2861\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 146us/sample - loss: 2.9124 - accuracy: 0.2537 - val_loss: 2.7067 - val_accuracy: 0.3063\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 6s 152us/sample - loss: 2.8222 - accuracy: 0.2709 - val_loss: 2.6727 - val_accuracy: 0.3193\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 6s 151us/sample - loss: 2.7781 - accuracy: 0.2847 - val_loss: 2.6448 - val_accuracy: 0.3153\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 6s 148us/sample - loss: 2.7433 - accuracy: 0.2882 - val_loss: 2.5969 - val_accuracy: 0.3308\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 6s 155us/sample - loss: 2.7135 - accuracy: 0.2960 - val_loss: 2.6162 - val_accuracy: 0.3280\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 7s 174us/sample - loss: 2.6861 - accuracy: 0.3041 - val_loss: 2.5882 - val_accuracy: 0.3412\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 6s 159us/sample - loss: 2.6637 - accuracy: 0.3096 - val_loss: 2.5560 - val_accuracy: 0.3435\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 6s 160us/sample - loss: 2.6413 - accuracy: 0.3145 - val_loss: 2.5880 - val_accuracy: 0.3336\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 6s 162us/sample - loss: 2.6276 - accuracy: 0.3162 - val_loss: 2.5557 - val_accuracy: 0.3485\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 6s 150us/sample - loss: 2.6072 - accuracy: 0.3199 - val_loss: 2.5556 - val_accuracy: 0.3398\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 10s 261us/sample - loss: 2.5895 - accuracy: 0.3259 - val_loss: 2.5376 - val_accuracy: 0.3558\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 10s 252us/sample - loss: 2.5823 - accuracy: 0.3254 - val_loss: 2.5417 - val_accuracy: 0.3454\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 7s 180us/sample - loss: 2.5733 - accuracy: 0.3279 - val_loss: 2.5403 - val_accuracy: 0.3490\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 7s 176us/sample - loss: 2.5571 - accuracy: 0.3321 - val_loss: 2.5327 - val_accuracy: 0.3513\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 6s 153us/sample - loss: 2.5452 - accuracy: 0.3343 - val_loss: 2.5367 - val_accuracy: 0.3497\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 5s 143us/sample - loss: 2.5381 - accuracy: 0.3373 - val_loss: 2.5396 - val_accuracy: 0.3492\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 6s 147us/sample - loss: 2.5247 - accuracy: 0.3372 - val_loss: 2.5371 - val_accuracy: 0.3490\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 5s 143us/sample - loss: 2.5090 - accuracy: 0.3426 - val_loss: 2.5302 - val_accuracy: 0.3506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a06b790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(train_e, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 7s 182us/sample - loss: 3.0136 - accuracy: 0.2319 - val_loss: 2.5085 - val_accuracy: 0.3551\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 6s 160us/sample - loss: 2.6394 - accuracy: 0.3188 - val_loss: 2.3875 - val_accuracy: 0.3932\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 160us/sample - loss: 2.5354 - accuracy: 0.3435 - val_loss: 2.3025 - val_accuracy: 0.3993\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 7s 179us/sample - loss: 2.4800 - accuracy: 0.3547 - val_loss: 2.2831 - val_accuracy: 0.4125\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 7s 195us/sample - loss: 2.4458 - accuracy: 0.3641 - val_loss: 2.2725 - val_accuracy: 0.4045\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 7s 185us/sample - loss: 2.4075 - accuracy: 0.3721 - val_loss: 2.2590 - val_accuracy: 0.4125\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 8s 198us/sample - loss: 2.3753 - accuracy: 0.3798 - val_loss: 2.2363 - val_accuracy: 0.4184\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 7s 182us/sample - loss: 2.3580 - accuracy: 0.3824 - val_loss: 2.2230 - val_accuracy: 0.4205\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 6s 155us/sample - loss: 2.3446 - accuracy: 0.3842 - val_loss: 2.2277 - val_accuracy: 0.4154\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 7s 193us/sample - loss: 2.3249 - accuracy: 0.3908 - val_loss: 2.2309 - val_accuracy: 0.4222\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 7s 184us/sample - loss: 2.3162 - accuracy: 0.3949 - val_loss: 2.2138 - val_accuracy: 0.4161\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 7s 175us/sample - loss: 2.2937 - accuracy: 0.3949 - val_loss: 2.2095 - val_accuracy: 0.4210\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 6s 167us/sample - loss: 2.2839 - accuracy: 0.3981 - val_loss: 2.2165 - val_accuracy: 0.4278\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 7s 183us/sample - loss: 2.2709 - accuracy: 0.4016 - val_loss: 2.1873 - val_accuracy: 0.4314\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 9s 224us/sample - loss: 2.2622 - accuracy: 0.4044 - val_loss: 2.2035 - val_accuracy: 0.4236\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 7s 193us/sample - loss: 2.2518 - accuracy: 0.4067 - val_loss: 2.2053 - val_accuracy: 0.4300\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 7s 196us/sample - loss: 2.2390 - accuracy: 0.4069 - val_loss: 2.1930 - val_accuracy: 0.4342\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 8s 197us/sample - loss: 2.2316 - accuracy: 0.4093 - val_loss: 2.1904 - val_accuracy: 0.4255\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 7s 195us/sample - loss: 2.2252 - accuracy: 0.4139 - val_loss: 2.1825 - val_accuracy: 0.4330\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 8s 214us/sample - loss: 2.2147 - accuracy: 0.4152 - val_loss: 2.2034 - val_accuracy: 0.4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ef5e0d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_e_1 = encoder_1.predict([x_img_train, x_txt_train])\n",
    "model_1 = get_model()\n",
    "model_1.fit(train_e_1, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder_2():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "\n",
    "    concat = concatenate([inp_img, inp_txt])\n",
    "    hidden_1 = Dense(512, activation='relu')(concat)\n",
    "    \n",
    "    hidden_2 = Dropout(0.5)(hidden_1)\n",
    "    hidden_2 = Dense(512, activation='relu')(hidden_2)\n",
    "    \n",
    "    hidden_3 = Dropout(0.5)(hidden_2)\n",
    "    hidden_3 = Dense(512, activation='relu')(hidden_3)\n",
    "    \n",
    "    out_img = Dense(IMG_LEN, activation='sigmoid', name='img')(hidden_3)\n",
    "    out_txt = Dense(TXT_LEN, activation='sigmoid', name='txt')(hidden_3)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse', loss_weights={'img':1, 'txt':0.2})\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=30, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=hidden_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 52s 1ms/sample - loss: 0.3781 - img_loss: 0.3244 - txt_loss: 0.2686 - val_loss: 0.3659 - val_img_loss: 0.3156 - val_txt_loss: 0.2517\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 39s 1ms/sample - loss: 0.3750 - img_loss: 0.3225 - txt_loss: 0.2626 - val_loss: 0.3644 - val_img_loss: 0.3148 - val_txt_loss: 0.2484\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 57s 1ms/sample - loss: 0.3725 - img_loss: 0.3210 - txt_loss: 0.2577 - val_loss: 0.3633 - val_img_loss: 0.3142 - val_txt_loss: 0.2458\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 45s 1ms/sample - loss: 0.3706 - img_loss: 0.3199 - txt_loss: 0.2537 - val_loss: 0.3624 - val_img_loss: 0.3137 - val_txt_loss: 0.2437\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 38s 1000us/sample - loss: 0.3690 - img_loss: 0.3189 - txt_loss: 0.2503 - val_loss: 0.3617 - val_img_loss: 0.3133 - val_txt_loss: 0.2418\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 34s 882us/sample - loss: 0.3676 - img_loss: 0.3181 - txt_loss: 0.2472 - val_loss: 0.3610 - val_img_loss: 0.3130 - val_txt_loss: 0.2402\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 42s 1ms/sample - loss: 0.3663 - img_loss: 0.3174 - txt_loss: 0.2445 - val_loss: 0.3605 - val_img_loss: 0.3127 - val_txt_loss: 0.2387\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 33s 852us/sample - loss: 0.3652 - img_loss: 0.3168 - txt_loss: 0.2420 - val_loss: 0.3599 - val_img_loss: 0.3125 - val_txt_loss: 0.2373\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 31s 822us/sample - loss: 0.3642 - img_loss: 0.3163 - txt_loss: 0.2396 - val_loss: 0.3594 - val_img_loss: 0.3123 - val_txt_loss: 0.2360\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 32s 849us/sample - loss: 0.3633 - img_loss: 0.3158 - txt_loss: 0.2375 - val_loss: 0.3590 - val_img_loss: 0.3121 - val_txt_loss: 0.2346\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 39s 1ms/sample - loss: 0.3625 - img_loss: 0.3155 - txt_loss: 0.2353 - val_loss: 0.3585 - val_img_loss: 0.3119 - val_txt_loss: 0.2333\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 0.3617 - img_loss: 0.3151 - txt_loss: 0.2332 - val_loss: 0.3581 - val_img_loss: 0.3117 - val_txt_loss: 0.2320\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 35s 911us/sample - loss: 0.3610 - img_loss: 0.3147 - txt_loss: 0.2312 - val_loss: 0.3576 - val_img_loss: 0.3115 - val_txt_loss: 0.2306\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 38s 998us/sample - loss: 0.3602 - img_loss: 0.3144 - txt_loss: 0.2291 - val_loss: 0.3571 - val_img_loss: 0.3113 - val_txt_loss: 0.2292\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 30s 786us/sample - loss: 0.3595 - img_loss: 0.3141 - txt_loss: 0.2271 - val_loss: 0.3567 - val_img_loss: 0.3112 - val_txt_loss: 0.2277\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 33s 857us/sample - loss: 0.3588 - img_loss: 0.3138 - txt_loss: 0.2251 - val_loss: 0.3562 - val_img_loss: 0.3110 - val_txt_loss: 0.2261\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 30s 781us/sample - loss: 0.3581 - img_loss: 0.3135 - txt_loss: 0.2230 - val_loss: 0.3556 - val_img_loss: 0.3108 - val_txt_loss: 0.2245\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 35s 909us/sample - loss: 0.3574 - img_loss: 0.3133 - txt_loss: 0.2208 - val_loss: 0.3551 - val_img_loss: 0.3106 - val_txt_loss: 0.2228\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 34s 895us/sample - loss: 0.3567 - img_loss: 0.3130 - txt_loss: 0.2186 - val_loss: 0.3545 - val_img_loss: 0.3104 - val_txt_loss: 0.2209\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 35s 912us/sample - loss: 0.3560 - img_loss: 0.3128 - txt_loss: 0.2163 - val_loss: 0.3539 - val_img_loss: 0.3102 - val_txt_loss: 0.2190\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 30s 781us/sample - loss: 0.3553 - img_loss: 0.3125 - txt_loss: 0.2139 - val_loss: 0.3533 - val_img_loss: 0.3100 - val_txt_loss: 0.2169\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 36s 930us/sample - loss: 0.3545 - img_loss: 0.3122 - txt_loss: 0.2114 - val_loss: 0.3526 - val_img_loss: 0.3097 - val_txt_loss: 0.2147\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 35s 914us/sample - loss: 0.3538 - img_loss: 0.3120 - txt_loss: 0.2088 - val_loss: 0.3519 - val_img_loss: 0.3095 - val_txt_loss: 0.2123\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 30s 798us/sample - loss: 0.3530 - img_loss: 0.3118 - txt_loss: 0.2061 - val_loss: 0.3511 - val_img_loss: 0.3092 - val_txt_loss: 0.2097\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 32s 829us/sample - loss: 0.3522 - img_loss: 0.3115 - txt_loss: 0.2032 - val_loss: 0.3503 - val_img_loss: 0.3090 - val_txt_loss: 0.2070\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 35s 913us/sample - loss: 0.3513 - img_loss: 0.3113 - txt_loss: 0.2002 - val_loss: 0.3495 - val_img_loss: 0.3087 - val_txt_loss: 0.2041\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 30s 774us/sample - loss: 0.3504 - img_loss: 0.3110 - txt_loss: 0.1970 - val_loss: 0.3485 - val_img_loss: 0.3084 - val_txt_loss: 0.2010\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 30s 779us/sample - loss: 0.3495 - img_loss: 0.3108 - txt_loss: 0.1935 - val_loss: 0.3475 - val_img_loss: 0.3081 - val_txt_loss: 0.1976\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 36s 947us/sample - loss: 0.3485 - img_loss: 0.3105 - txt_loss: 0.1901 - val_loss: 0.3465 - val_img_loss: 0.3077 - val_txt_loss: 0.1941\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 34s 890us/sample - loss: 0.3475 - img_loss: 0.3102 - txt_loss: 0.1864 - val_loss: 0.3454 - val_img_loss: 0.3074 - val_txt_loss: 0.1904\n"
     ]
    }
   ],
   "source": [
    "encoder_2 = get_autoencoder_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 8s 211us/sample - loss: 2.9431 - accuracy: 0.2522 - val_loss: 2.4769 - val_accuracy: 0.3600\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 7s 177us/sample - loss: 2.5965 - accuracy: 0.3273 - val_loss: 2.3708 - val_accuracy: 0.3866\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 7s 188us/sample - loss: 2.4999 - accuracy: 0.3506 - val_loss: 2.3067 - val_accuracy: 0.3998\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 7s 182us/sample - loss: 2.4446 - accuracy: 0.3643 - val_loss: 2.3007 - val_accuracy: 0.3991\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 7s 176us/sample - loss: 2.4009 - accuracy: 0.3729 - val_loss: 2.2868 - val_accuracy: 0.4055\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 7s 189us/sample - loss: 2.3700 - accuracy: 0.3805 - val_loss: 2.2625 - val_accuracy: 0.4052\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 7s 195us/sample - loss: 2.3433 - accuracy: 0.3859 - val_loss: 2.2462 - val_accuracy: 0.4095\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 7s 181us/sample - loss: 2.3120 - accuracy: 0.3901 - val_loss: 2.2438 - val_accuracy: 0.4081\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 7s 189us/sample - loss: 2.2866 - accuracy: 0.3965 - val_loss: 2.2270 - val_accuracy: 0.4083\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 7s 172us/sample - loss: 2.2686 - accuracy: 0.3998 - val_loss: 2.2411 - val_accuracy: 0.4118\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 7s 179us/sample - loss: 2.2538 - accuracy: 0.4046 - val_loss: 2.2130 - val_accuracy: 0.4198\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 2.2272 - accuracy: 0.4085 - val_loss: 2.2155 - val_accuracy: 0.4161\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 7s 178us/sample - loss: 2.2160 - accuracy: 0.4106 - val_loss: 2.2086 - val_accuracy: 0.4165\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 7s 184us/sample - loss: 2.2000 - accuracy: 0.4151 - val_loss: 2.2254 - val_accuracy: 0.4118\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 8s 211us/sample - loss: 2.1868 - accuracy: 0.4187 - val_loss: 2.2250 - val_accuracy: 0.4255\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 7s 172us/sample - loss: 2.1698 - accuracy: 0.4224 - val_loss: 2.2076 - val_accuracy: 0.4245\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 7s 183us/sample - loss: 2.1578 - accuracy: 0.4216 - val_loss: 2.2107 - val_accuracy: 0.4271\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 7s 188us/sample - loss: 2.1488 - accuracy: 0.4231 - val_loss: 2.2015 - val_accuracy: 0.4203\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 7s 176us/sample - loss: 2.1317 - accuracy: 0.4268 - val_loss: 2.2243 - val_accuracy: 0.4194\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 7s 192us/sample - loss: 2.1222 - accuracy: 0.4281 - val_loss: 2.2053 - val_accuracy: 0.4205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13de8d150>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_e_2 = encoder_2.predict([x_img_train, x_txt_train])\n",
    "model_2 = get_model()\n",
    "model_2.fit(train_e_2, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1324)         0           input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 512)          678400      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 256)          131328      dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 809,728\n",
      "Trainable params: 809,728\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(encoder_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder_2():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    encoded_img = Dense(1024)(inp_img)\n",
    "    encoded_img = Dropout(0.5)(encoded_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "    encoded_txt = Dense(512)(inp_txt)\n",
    "    encoded_txt = Dropout(0.5)(encoded_txt)\n",
    "    \n",
    "    concat = concatenate([inp_img, inp_txt])\n",
    "    encoded = Dense(512, activation='relu')(concat)\n",
    "    \n",
    "    decoded_img = Dense(1024)(encoded)\n",
    "    decoded_img = Dropout(0.5)(decoded_img)\n",
    "    out_img = Dense(IMG_LEN, activation='sigmoid', name='img')(decoded_img)\n",
    "    \n",
    "    decoded_txt = Dense(512)(encoded)\n",
    "    decoded_txt = Dropout(0.5)(decoded_txt)\n",
    "    out_txt = Dense(TXT_LEN, activation='sigmoid', name='txt')(decoded_img)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse', loss_weights={'img':1, 'txt':0.2})\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=30, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 36s 935us/sample - loss: 0.3858 - img_loss: 0.3312 - txt_loss: 0.2729 - val_loss: 0.3714 - val_img_loss: 0.3207 - val_txt_loss: 0.2536\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 36s 939us/sample - loss: 0.3795 - img_loss: 0.3275 - txt_loss: 0.2601 - val_loss: 0.3668 - val_img_loss: 0.3183 - val_txt_loss: 0.2429\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 33s 863us/sample - loss: 0.3747 - img_loss: 0.3247 - txt_loss: 0.2501 - val_loss: 0.3632 - val_img_loss: 0.3164 - val_txt_loss: 0.2344\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 35s 911us/sample - loss: 0.3711 - img_loss: 0.3227 - txt_loss: 0.2420 - val_loss: 0.3603 - val_img_loss: 0.3149 - val_txt_loss: 0.2273\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 0.3681 - img_loss: 0.3210 - txt_loss: 0.2351 - val_loss: 0.3579 - val_img_loss: 0.3137 - val_txt_loss: 0.2210\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 39s 1ms/sample - loss: 0.3655 - img_loss: 0.3197 - txt_loss: 0.2291 - val_loss: 0.3557 - val_img_loss: 0.3127 - val_txt_loss: 0.2154\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 32s 850us/sample - loss: 0.3633 - img_loss: 0.3186 - txt_loss: 0.2236 - val_loss: 0.3537 - val_img_loss: 0.3117 - val_txt_loss: 0.2100\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 37s 974us/sample - loss: 0.3613 - img_loss: 0.3176 - txt_loss: 0.2183 - val_loss: 0.3518 - val_img_loss: 0.3109 - val_txt_loss: 0.2049\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 30s 789us/sample - loss: 0.3595 - img_loss: 0.3169 - txt_loss: 0.2134 - val_loss: 0.3500 - val_img_loss: 0.3101 - val_txt_loss: 0.1998\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 33s 857us/sample - loss: 0.3578 - img_loss: 0.3161 - txt_loss: 0.2085 - val_loss: 0.3482 - val_img_loss: 0.3093 - val_txt_loss: 0.1947\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 31s 813us/sample - loss: 0.3561 - img_loss: 0.3154 - txt_loss: 0.2036 - val_loss: 0.3464 - val_img_loss: 0.3086 - val_txt_loss: 0.1896\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 35s 904us/sample - loss: 0.3545 - img_loss: 0.3148 - txt_loss: 0.1987 - val_loss: 0.3447 - val_img_loss: 0.3078 - val_txt_loss: 0.1845\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 37s 965us/sample - loss: 0.3530 - img_loss: 0.3142 - txt_loss: 0.1939 - val_loss: 0.3429 - val_img_loss: 0.3071 - val_txt_loss: 0.1792\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 35s 921us/sample - loss: 0.3515 - img_loss: 0.3136 - txt_loss: 0.1890 - val_loss: 0.3411 - val_img_loss: 0.3064 - val_txt_loss: 0.1739\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 34s 892us/sample - loss: 0.3499 - img_loss: 0.3131 - txt_loss: 0.1841 - val_loss: 0.3393 - val_img_loss: 0.3056 - val_txt_loss: 0.1686\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 34s 887us/sample - loss: 0.3484 - img_loss: 0.3126 - txt_loss: 0.1791 - val_loss: 0.3375 - val_img_loss: 0.3049 - val_txt_loss: 0.1632\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 34s 889us/sample - loss: 0.3469 - img_loss: 0.3121 - txt_loss: 0.1741 - val_loss: 0.3357 - val_img_loss: 0.3042 - val_txt_loss: 0.1577\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 34s 888us/sample - loss: 0.3455 - img_loss: 0.3116 - txt_loss: 0.1691 - val_loss: 0.3339 - val_img_loss: 0.3035 - val_txt_loss: 0.1523\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 34s 886us/sample - loss: 0.3440 - img_loss: 0.3112 - txt_loss: 0.1642 - val_loss: 0.3321 - val_img_loss: 0.3028 - val_txt_loss: 0.1469\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 30s 772us/sample - loss: 0.3426 - img_loss: 0.3108 - txt_loss: 0.1592 - val_loss: 0.3304 - val_img_loss: 0.3021 - val_txt_loss: 0.1416\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 29s 760us/sample - loss: 0.3412 - img_loss: 0.3103 - txt_loss: 0.1544 - val_loss: 0.3286 - val_img_loss: 0.3014 - val_txt_loss: 0.1363\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 35s 904us/sample - loss: 0.3398 - img_loss: 0.3099 - txt_loss: 0.1496 - val_loss: 0.3269 - val_img_loss: 0.3007 - val_txt_loss: 0.1312\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 36s 947us/sample - loss: 0.3385 - img_loss: 0.3095 - txt_loss: 0.1450 - val_loss: 0.3252 - val_img_loss: 0.3000 - val_txt_loss: 0.1262\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 34s 885us/sample - loss: 0.3372 - img_loss: 0.3091 - txt_loss: 0.1404 - val_loss: 0.3236 - val_img_loss: 0.2993 - val_txt_loss: 0.1213\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 38s 987us/sample - loss: 0.3359 - img_loss: 0.3087 - txt_loss: 0.1360 - val_loss: 0.3220 - val_img_loss: 0.2987 - val_txt_loss: 0.1166\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 36s 937us/sample - loss: 0.3347 - img_loss: 0.3084 - txt_loss: 0.1316 - val_loss: 0.3205 - val_img_loss: 0.2981 - val_txt_loss: 0.1121\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 36s 946us/sample - loss: 0.3335 - img_loss: 0.3080 - txt_loss: 0.1276 - val_loss: 0.3190 - val_img_loss: 0.2975 - val_txt_loss: 0.1078\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 36s 948us/sample - loss: 0.3324 - img_loss: 0.3076 - txt_loss: 0.1236 - val_loss: 0.3176 - val_img_loss: 0.2969 - val_txt_loss: 0.1037\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 39s 1ms/sample - loss: 0.3313 - img_loss: 0.3074 - txt_loss: 0.1197 - val_loss: 0.3162 - val_img_loss: 0.2963 - val_txt_loss: 0.0997\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 38s 990us/sample - loss: 0.3302 - img_loss: 0.3070 - txt_loss: 0.1161 - val_loss: 0.3149 - val_img_loss: 0.2957 - val_txt_loss: 0.0960\n"
     ]
    }
   ],
   "source": [
    "encoder_2 = get_autoencoder_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 6s 169us/sample - loss: 2.8997 - accuracy: 0.2604 - val_loss: 2.3908 - val_accuracy: 0.3781\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 6s 167us/sample - loss: 2.5550 - accuracy: 0.3387 - val_loss: 2.3074 - val_accuracy: 0.3996\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 156us/sample - loss: 2.4606 - accuracy: 0.3610 - val_loss: 2.2601 - val_accuracy: 0.4090\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 6s 167us/sample - loss: 2.3999 - accuracy: 0.3778 - val_loss: 2.2374 - val_accuracy: 0.4123\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 2.3633 - accuracy: 0.3821 - val_loss: 2.2136 - val_accuracy: 0.4194\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 6s 158us/sample - loss: 2.3262 - accuracy: 0.3947 - val_loss: 2.1877 - val_accuracy: 0.4227\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 2.3012 - accuracy: 0.3947 - val_loss: 2.1993 - val_accuracy: 0.4292\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 2.2703 - accuracy: 0.4026 - val_loss: 2.1873 - val_accuracy: 0.4259\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 6s 163us/sample - loss: 2.2530 - accuracy: 0.4057 - val_loss: 2.1948 - val_accuracy: 0.4281\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 2.2241 - accuracy: 0.4123 - val_loss: 2.1752 - val_accuracy: 0.4375\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 2.2042 - accuracy: 0.4181 - val_loss: 2.1630 - val_accuracy: 0.4349\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 6s 168us/sample - loss: 2.1887 - accuracy: 0.4249 - val_loss: 2.1703 - val_accuracy: 0.4344\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 6s 162us/sample - loss: 2.1638 - accuracy: 0.4229 - val_loss: 2.1538 - val_accuracy: 0.4384\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 2.1605 - accuracy: 0.4262 - val_loss: 2.1523 - val_accuracy: 0.4427\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 6s 166us/sample - loss: 2.1440 - accuracy: 0.4274 - val_loss: 2.1449 - val_accuracy: 0.4424\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 7s 175us/sample - loss: 2.1304 - accuracy: 0.4303 - val_loss: 2.1562 - val_accuracy: 0.4377\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 6s 170us/sample - loss: 2.1177 - accuracy: 0.4331 - val_loss: 2.1637 - val_accuracy: 0.4389\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 7s 171us/sample - loss: 2.1023 - accuracy: 0.4351 - val_loss: 2.1565 - val_accuracy: 0.4424\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 7s 193us/sample - loss: 2.0891 - accuracy: 0.4376 - val_loss: 2.1473 - val_accuracy: 0.4410\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 7s 193us/sample - loss: 2.0826 - accuracy: 0.4399 - val_loss: 2.1505 - val_accuracy: 0.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1524ba650>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_e_2 = encoder_2.predict([x_img_train, x_txt_train])\n",
    "model_2 = get_model()\n",
    "model_2.fit(train_e_2, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 2.9016 - accuracy: 0.2591 - val_loss: 2.4447 - val_accuracy: 0.3574\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 2.5675 - accuracy: 0.3376 - val_loss: 2.3212 - val_accuracy: 0.3935\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 152us/sample - loss: 2.4732 - accuracy: 0.3575 - val_loss: 2.2811 - val_accuracy: 0.4048\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 6s 162us/sample - loss: 2.4080 - accuracy: 0.3750 - val_loss: 2.2329 - val_accuracy: 0.4158\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 6s 154us/sample - loss: 2.3624 - accuracy: 0.3838 - val_loss: 2.2076 - val_accuracy: 0.4168\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 2.3314 - accuracy: 0.3911 - val_loss: 2.1982 - val_accuracy: 0.4198\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 6s 157us/sample - loss: 2.2962 - accuracy: 0.3995 - val_loss: 2.1847 - val_accuracy: 0.4309\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 6s 159us/sample - loss: 2.2721 - accuracy: 0.4009 - val_loss: 2.1808 - val_accuracy: 0.4269\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 2.2528 - accuracy: 0.4069 - val_loss: 2.1828 - val_accuracy: 0.4295\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 7s 178us/sample - loss: 2.2267 - accuracy: 0.4130 - val_loss: 2.1781 - val_accuracy: 0.4335\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 6s 168us/sample - loss: 2.2057 - accuracy: 0.4127 - val_loss: 2.1548 - val_accuracy: 0.4401\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 2.1868 - accuracy: 0.4209 - val_loss: 2.1428 - val_accuracy: 0.4372\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 7s 177us/sample - loss: 2.1790 - accuracy: 0.4217 - val_loss: 2.1618 - val_accuracy: 0.4372\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 7s 176us/sample - loss: 2.1618 - accuracy: 0.4237 - val_loss: 2.1502 - val_accuracy: 0.4349\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 2.1410 - accuracy: 0.4294 - val_loss: 2.1545 - val_accuracy: 0.4377\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 7s 191us/sample - loss: 2.1312 - accuracy: 0.4293 - val_loss: 2.1587 - val_accuracy: 0.4325\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 6s 169us/sample - loss: 2.1225 - accuracy: 0.4334 - val_loss: 2.1444 - val_accuracy: 0.4408\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 7s 180us/sample - loss: 2.1077 - accuracy: 0.4331 - val_loss: 2.1534 - val_accuracy: 0.4389\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 5s 131us/sample - loss: 2.0957 - accuracy: 0.4376 - val_loss: 2.1584 - val_accuracy: 0.4375\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 5s 131us/sample - loss: 2.0839 - accuracy: 0.4389 - val_loss: 2.1583 - val_accuracy: 0.4354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x157192f10>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12 = get_model()\n",
    "model_12.fit(train_e_2, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1938919574022293"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(x_txt_train[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (    10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   relu/prelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      highway  residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leaky relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder_4():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "\n",
    "    concat = concatenate([inp_img, inp_txt])\n",
    "    encoded = Dense(512, activation='relu')(concat)\n",
    "    \n",
    "    out_img = Dense(IMG_LEN, activation='sigmoid', name='img')(encoded)\n",
    "    out_txt = Dense(TXT_LEN, activation='sigmoid', name='txt')(encoded)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse', loss_weights={'img':2, 'txt':0.2})\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=30, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 28s 726us/sample - loss: 0.6966 - img_loss: 0.3215 - txt_loss: 0.2680 - val_loss: 0.6926 - val_img_loss: 0.3200 - val_txt_loss: 0.2633\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 24s 623us/sample - loss: 0.6888 - img_loss: 0.3185 - txt_loss: 0.2592 - val_loss: 0.6857 - val_img_loss: 0.3174 - val_txt_loss: 0.2554\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 21s 540us/sample - loss: 0.6827 - img_loss: 0.3161 - txt_loss: 0.2520 - val_loss: 0.6802 - val_img_loss: 0.3153 - val_txt_loss: 0.2487\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 23s 591us/sample - loss: 0.6776 - img_loss: 0.3142 - txt_loss: 0.2457 - val_loss: 0.6755 - val_img_loss: 0.3135 - val_txt_loss: 0.2428\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 18s 481us/sample - loss: 0.6732 - img_loss: 0.3126 - txt_loss: 0.2400 - val_loss: 0.6713 - val_img_loss: 0.3120 - val_txt_loss: 0.2373\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 23s 610us/sample - loss: 0.6693 - img_loss: 0.3112 - txt_loss: 0.2347 - val_loss: 0.6676 - val_img_loss: 0.3106 - val_txt_loss: 0.2321\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 21s 551us/sample - loss: 0.6656 - img_loss: 0.3098 - txt_loss: 0.2297 - val_loss: 0.6640 - val_img_loss: 0.3093 - val_txt_loss: 0.2271\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 19s 488us/sample - loss: 0.6621 - img_loss: 0.3086 - txt_loss: 0.2246 - val_loss: 0.6606 - val_img_loss: 0.3081 - val_txt_loss: 0.2221\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 19s 486us/sample - loss: 0.6588 - img_loss: 0.3074 - txt_loss: 0.2196 - val_loss: 0.6573 - val_img_loss: 0.3070 - val_txt_loss: 0.2170\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 19s 500us/sample - loss: 0.6554 - img_loss: 0.3063 - txt_loss: 0.2146 - val_loss: 0.6540 - val_img_loss: 0.3059 - val_txt_loss: 0.2119\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 20s 519us/sample - loss: 0.6521 - img_loss: 0.3051 - txt_loss: 0.2094 - val_loss: 0.6508 - val_img_loss: 0.3047 - val_txt_loss: 0.2067\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 26s 680us/sample - loss: 0.6489 - img_loss: 0.3040 - txt_loss: 0.2042 - val_loss: 0.6475 - val_img_loss: 0.3037 - val_txt_loss: 0.2014\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 19s 490us/sample - loss: 0.6456 - img_loss: 0.3029 - txt_loss: 0.1988 - val_loss: 0.6443 - val_img_loss: 0.3026 - val_txt_loss: 0.1959\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 19s 489us/sample - loss: 0.6423 - img_loss: 0.3018 - txt_loss: 0.1933 - val_loss: 0.6410 - val_img_loss: 0.3015 - val_txt_loss: 0.1904\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 19s 491us/sample - loss: 0.6391 - img_loss: 0.3008 - txt_loss: 0.1876 - val_loss: 0.6378 - val_img_loss: 0.3005 - val_txt_loss: 0.1847\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 18s 472us/sample - loss: 0.6358 - img_loss: 0.2997 - txt_loss: 0.1819 - val_loss: 0.6346 - val_img_loss: 0.2994 - val_txt_loss: 0.1789\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 19s 485us/sample - loss: 0.6326 - img_loss: 0.2987 - txt_loss: 0.1761 - val_loss: 0.6314 - val_img_loss: 0.2985 - val_txt_loss: 0.1730\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 19s 491us/sample - loss: 0.6295 - img_loss: 0.2977 - txt_loss: 0.1701 - val_loss: 0.6283 - val_img_loss: 0.2975 - val_txt_loss: 0.1671\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 18s 483us/sample - loss: 0.6264 - img_loss: 0.2968 - txt_loss: 0.1642 - val_loss: 0.6253 - val_img_loss: 0.2966 - val_txt_loss: 0.1611\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 18s 481us/sample - loss: 0.6233 - img_loss: 0.2959 - txt_loss: 0.1582 - val_loss: 0.6223 - val_img_loss: 0.2957 - val_txt_loss: 0.1551\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 22s 583us/sample - loss: 0.6204 - img_loss: 0.2949 - txt_loss: 0.1522 - val_loss: 0.6194 - val_img_loss: 0.2948 - val_txt_loss: 0.1491\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 18s 480us/sample - loss: 0.6175 - img_loss: 0.2941 - txt_loss: 0.1462 - val_loss: 0.6166 - val_img_loss: 0.2940 - val_txt_loss: 0.1431\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 18s 472us/sample - loss: 0.6147 - img_loss: 0.2933 - txt_loss: 0.1403 - val_loss: 0.6138 - val_img_loss: 0.2932 - val_txt_loss: 0.1372\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 18s 470us/sample - loss: 0.6120 - img_loss: 0.2926 - txt_loss: 0.1345 - val_loss: 0.6112 - val_img_loss: 0.2925 - val_txt_loss: 0.1315\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 18s 464us/sample - loss: 0.6094 - img_loss: 0.2918 - txt_loss: 0.1287 - val_loss: 0.6087 - val_img_loss: 0.2918 - val_txt_loss: 0.1258\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 20s 533us/sample - loss: 0.6069 - img_loss: 0.2912 - txt_loss: 0.1231 - val_loss: 0.6063 - val_img_loss: 0.2912 - val_txt_loss: 0.1203\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 22s 566us/sample - loss: 0.6046 - img_loss: 0.2905 - txt_loss: 0.1176 - val_loss: 0.6040 - val_img_loss: 0.2906 - val_txt_loss: 0.1149\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 20s 526us/sample - loss: 0.6023 - img_loss: 0.2899 - txt_loss: 0.1124 - val_loss: 0.6018 - val_img_loss: 0.2900 - val_txt_loss: 0.1097\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 20s 519us/sample - loss: 0.6002 - img_loss: 0.2894 - txt_loss: 0.1073 - val_loss: 0.5998 - val_img_loss: 0.2894 - val_txt_loss: 0.1047\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 22s 567us/sample - loss: 0.5982 - img_loss: 0.2888 - txt_loss: 0.1024 - val_loss: 0.5978 - val_img_loss: 0.2889 - val_txt_loss: 0.0999\n"
     ]
    }
   ],
   "source": [
    "encoder_4 = get_autoencoder_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_encoder():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "    \n",
    "    encoded = concatenate([inp_img, inp_txt])\n",
    "    encoded = Dense(512, activation='relu')(inp_img)\n",
    "    \n",
    "    out_img = Dense(IMG_LEN, activation='relu', name='img')(encoded)\n",
    "    out_txt = Dense(TXT_LEN, activation='sigmoid', name='txt')(encoded)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=10, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_encoder_1():\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    encoded_img = Dense(1024, activation='relu')(inp_img)\n",
    "#     encoded_img = Dropout(0.5)(encoded_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "    encoded_txt = Dense(512, activation='relu')(inp_txt)\n",
    "#     encoded_txt = Dropout(0.5)(encoded_txt)\n",
    "    \n",
    "    encoded = concatenate([encoded_img, encoded_txt])\n",
    "    encoded = Dense(512, activation='relu')(inp_img)\n",
    "    \n",
    "    decoded_img = Dense(1024, activation='relu')(encoded)\n",
    "#     decoded_img = Dropout(0.5)(decoded_img)\n",
    "    \n",
    "    decoded_txt = Dense(512, activation='relu')(encoded)\n",
    "#     decoded_txt = Dropout(0.5)(decoded_txt)\n",
    "    \n",
    "    out_img = Dense(IMG_LEN, activation='relu', name='img')(decoded_img)\n",
    "    out_txt = Dense(TXT_LEN, activation='sigmoid', name='txt')(decoded_txt)\n",
    "    \n",
    "    autoencoder = Model(inputs=[inp_img, inp_txt], outputs=[out_img, out_txt])\n",
    "    autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "    \n",
    "    autoencoder.fit([x_img_train, x_txt_train], [x_img_train, x_txt_train], epochs=3, validation_split=0.1)\n",
    "    return Model(inputs=[inp_img, inp_txt], outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/10\n",
      "38221/38221 [==============================] - 18s 483us/sample - loss: 0.0303 - img_loss: 0.0156 - txt_loss: 0.0147 - val_loss: 0.0304 - val_img_loss: 0.0156 - val_txt_loss: 0.0148\n",
      "Epoch 2/10\n",
      "38221/38221 [==============================] - 28s 729us/sample - loss: 0.0303 - img_loss: 0.0156 - txt_loss: 0.0147 - val_loss: 0.0303 - val_img_loss: 0.0156 - val_txt_loss: 0.0147\n",
      "Epoch 3/10\n",
      "38221/38221 [==============================] - 25s 641us/sample - loss: 0.0302 - img_loss: 0.0156 - txt_loss: 0.0147 - val_loss: 0.0303 - val_img_loss: 0.0156 - val_txt_loss: 0.0147\n",
      "Epoch 4/10\n",
      "38221/38221 [==============================] - 27s 713us/sample - loss: 0.0302 - img_loss: 0.0156 - txt_loss: 0.0147 - val_loss: 0.0303 - val_img_loss: 0.0155 - val_txt_loss: 0.0147\n",
      "Epoch 5/10\n",
      "38221/38221 [==============================] - 27s 696us/sample - loss: 0.0302 - img_loss: 0.0155 - txt_loss: 0.0146 - val_loss: 0.0302 - val_img_loss: 0.0155 - val_txt_loss: 0.0147\n",
      "Epoch 6/10\n",
      "38221/38221 [==============================] - 22s 565us/sample - loss: 0.0301 - img_loss: 0.0155 - txt_loss: 0.0146 - val_loss: 0.0302 - val_img_loss: 0.0155 - val_txt_loss: 0.0147\n",
      "Epoch 7/10\n",
      "38221/38221 [==============================] - 21s 538us/sample - loss: 0.0301 - img_loss: 0.0155 - txt_loss: 0.0146 - val_loss: 0.0301 - val_img_loss: 0.0155 - val_txt_loss: 0.0147\n",
      "Epoch 8/10\n",
      "38221/38221 [==============================] - 18s 472us/sample - loss: 0.0300 - img_loss: 0.0155 - txt_loss: 0.0146 - val_loss: 0.0301 - val_img_loss: 0.0154 - val_txt_loss: 0.0146\n",
      "Epoch 9/10\n",
      "38221/38221 [==============================] - 26s 676us/sample - loss: 0.0300 - img_loss: 0.0154 - txt_loss: 0.0146 - val_loss: 0.0300 - val_img_loss: 0.0154 - val_txt_loss: 0.0146\n",
      "Epoch 10/10\n",
      "38221/38221 [==============================] - 19s 497us/sample - loss: 0.0300 - img_loss: 0.0154 - txt_loss: 0.0146 - val_loss: 0.0300 - val_img_loss: 0.0154 - val_txt_loss: 0.0146\n"
     ]
    }
   ],
   "source": [
    "img_encoder = get_relu_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/3\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 0.0301 - img_loss: 0.0158 - txt_loss: 0.0142 - val_loss: 0.0301 - val_img_loss: 0.0158 - val_txt_loss: 0.0143\n",
      "Epoch 2/3\n",
      "38221/38221 [==============================] - 43s 1ms/sample - loss: 0.0300 - img_loss: 0.0158 - txt_loss: 0.0142 - val_loss: 0.0301 - val_img_loss: 0.0158 - val_txt_loss: 0.0143\n",
      "Epoch 3/3\n",
      "38221/38221 [==============================] - 44s 1ms/sample - loss: 0.0300 - img_loss: 0.0157 - txt_loss: 0.0142 - val_loss: 0.0300 - val_img_loss: 0.0157 - val_txt_loss: 0.0143\n"
     ]
    }
   ],
   "source": [
    "relu_encoder_1 = get_relu_encoder_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "norm_x_img_q = normalize(x_img_q)\n",
    "img_scaler = MinMaxScaler()\n",
    "img_scaler.fit(norm_x_img_q)\n",
    "scaled_x_img_q = img_scaler.transform(norm_x_img_q)\n",
    "\n",
    "norm_x_txt_q = normalize(x_txt_q)\n",
    "txt_scaler = MinMaxScaler()\n",
    "txt_scaler.fit(norm_x_txt_q)\n",
    "scaled_x_txt_q = txt_scaler.transform(norm_x_txt_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(scaled_x_img_q, scaled_x_txt_q, y_q, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(max([max(e) for e in x_img_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 14s 364us/sample - loss: 2.8712 - accuracy: 0.2620 - val_loss: 2.3990 - val_accuracy: 0.3687\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 11s 290us/sample - loss: 2.4943 - accuracy: 0.3447 - val_loss: 2.2984 - val_accuracy: 0.3946\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 10s 272us/sample - loss: 2.4074 - accuracy: 0.3650 - val_loss: 2.2788 - val_accuracy: 0.3918\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 11s 292us/sample - loss: 2.3635 - accuracy: 0.3766 - val_loss: 2.2361 - val_accuracy: 0.4033\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 11s 296us/sample - loss: 2.3246 - accuracy: 0.3853 - val_loss: 2.2213 - val_accuracy: 0.4040\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 11s 289us/sample - loss: 2.2940 - accuracy: 0.3932 - val_loss: 2.2045 - val_accuracy: 0.4121\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 12s 325us/sample - loss: 2.2720 - accuracy: 0.3952 - val_loss: 2.1963 - val_accuracy: 0.4121\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 13s 334us/sample - loss: 2.2375 - accuracy: 0.4051 - val_loss: 2.1880 - val_accuracy: 0.4102\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 10s 270us/sample - loss: 2.2167 - accuracy: 0.4094 - val_loss: 2.1789 - val_accuracy: 0.4144\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 11s 277us/sample - loss: 2.1925 - accuracy: 0.4145 - val_loss: 2.1836 - val_accuracy: 0.4128\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 11s 290us/sample - loss: 2.1722 - accuracy: 0.4174 - val_loss: 2.1785 - val_accuracy: 0.4128\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 10s 261us/sample - loss: 2.1575 - accuracy: 0.4185 - val_loss: 2.1844 - val_accuracy: 0.4128\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 14s 359us/sample - loss: 2.1357 - accuracy: 0.4234 - val_loss: 2.1675 - val_accuracy: 0.4168\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 13s 345us/sample - loss: 2.1241 - accuracy: 0.4261 - val_loss: 2.1723 - val_accuracy: 0.4236\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 13s 341us/sample - loss: 2.0966 - accuracy: 0.4310 - val_loss: 2.1743 - val_accuracy: 0.4139\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 13s 345us/sample - loss: 2.0909 - accuracy: 0.4329 - val_loss: 2.1676 - val_accuracy: 0.4179\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 13s 343us/sample - loss: 2.0735 - accuracy: 0.4366 - val_loss: 2.1879 - val_accuracy: 0.4154\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 13s 335us/sample - loss: 2.0565 - accuracy: 0.4374 - val_loss: 2.1753 - val_accuracy: 0.4135\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 11s 297us/sample - loss: 2.0456 - accuracy: 0.4414 - val_loss: 2.1723 - val_accuracy: 0.4139\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 13s 335us/sample - loss: 2.0312 - accuracy: 0.4468 - val_loss: 2.1701 - val_accuracy: 0.4215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cd82c50>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_e_relu = img_encoder.predict([x_img_train, x_txt_train])\n",
    "model = get_model()\n",
    "model.fit(train_e_relu, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_13():\n",
    "    inp = Input(shape=(512,))\n",
    "    x = Dense(512, activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 25s 662us/sample - loss: 2.9389 - accuracy: 0.2389 - val_loss: 2.4804 - val_accuracy: 0.3464\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 20s 521us/sample - loss: 2.5918 - accuracy: 0.3172 - val_loss: 2.3742 - val_accuracy: 0.3753\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 20s 535us/sample - loss: 2.5115 - accuracy: 0.3406 - val_loss: 2.3303 - val_accuracy: 0.3866\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 18s 459us/sample - loss: 2.4546 - accuracy: 0.3560 - val_loss: 2.2991 - val_accuracy: 0.3885\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 17s 453us/sample - loss: 2.4147 - accuracy: 0.3662 - val_loss: 2.2717 - val_accuracy: 0.3939\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 19s 498us/sample - loss: 2.3833 - accuracy: 0.3739 - val_loss: 2.2747 - val_accuracy: 0.3972\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 17s 452us/sample - loss: 2.3633 - accuracy: 0.3785 - val_loss: 2.2405 - val_accuracy: 0.4062\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 17s 440us/sample - loss: 2.3426 - accuracy: 0.3831 - val_loss: 2.2381 - val_accuracy: 0.4036\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 17s 441us/sample - loss: 2.3322 - accuracy: 0.3843 - val_loss: 2.2365 - val_accuracy: 0.4024\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 18s 467us/sample - loss: 2.3125 - accuracy: 0.3915 - val_loss: 2.2246 - val_accuracy: 0.4031\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 19s 502us/sample - loss: 2.2939 - accuracy: 0.3935 - val_loss: 2.2345 - val_accuracy: 0.4031\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 18s 479us/sample - loss: 2.2867 - accuracy: 0.3968 - val_loss: 2.2348 - val_accuracy: 0.4005\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 19s 496us/sample - loss: 2.2759 - accuracy: 0.3985 - val_loss: 2.2159 - val_accuracy: 0.4073\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 17s 454us/sample - loss: 2.2656 - accuracy: 0.4002 - val_loss: 2.2319 - val_accuracy: 0.4026\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 18s 476us/sample - loss: 2.2553 - accuracy: 0.4015 - val_loss: 2.2158 - val_accuracy: 0.4040\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 21s 553us/sample - loss: 2.2549 - accuracy: 0.4047 - val_loss: 2.2150 - val_accuracy: 0.4050\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 20s 517us/sample - loss: 2.2383 - accuracy: 0.4083 - val_loss: 2.2127 - val_accuracy: 0.4076\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 20s 511us/sample - loss: 2.2288 - accuracy: 0.4059 - val_loss: 2.2257 - val_accuracy: 0.4090\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 18s 473us/sample - loss: 2.2209 - accuracy: 0.4128 - val_loss: 2.2150 - val_accuracy: 0.4095\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 17s 451us/sample - loss: 2.2145 - accuracy: 0.4107 - val_loss: 2.2126 - val_accuracy: 0.4135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1561db650>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_13()\n",
    "model.fit(train_e_relu, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_model(encoder, model):\n",
    "    inp_img = Input(shape=(IMG_LEN,))\n",
    "    inp_txt = Input(shape=(TXT_LEN,))\n",
    "    \n",
    "    output_e = encoder([inp_img, inp_txt])\n",
    "    output_m = model(output_e)\n",
    "    \n",
    "    return Model([inp_img, inp_txt], output_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = get_combined_model(img_encoder, model)\n",
    "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2489103235699446, 0.403598]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 16s 413us/sample - loss: 2.7878 - accuracy: 0.2865 - val_loss: 2.4970 - val_accuracy: 0.3645\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 15s 405us/sample - loss: 2.6210 - accuracy: 0.3245 - val_loss: 2.4475 - val_accuracy: 0.3546\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 17s 435us/sample - loss: 2.5425 - accuracy: 0.3414 - val_loss: 2.4003 - val_accuracy: 0.3744\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 20s 514us/sample - loss: 2.4934 - accuracy: 0.3531 - val_loss: 2.3637 - val_accuracy: 0.3958\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 16s 412us/sample - loss: 2.4510 - accuracy: 0.3664 - val_loss: 2.3418 - val_accuracy: 0.3951\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 15s 386us/sample - loss: 2.4306 - accuracy: 0.3710 - val_loss: 2.3179 - val_accuracy: 0.3932\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 15s 388us/sample - loss: 2.4044 - accuracy: 0.3771 - val_loss: 2.3353 - val_accuracy: 0.3958\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 14s 374us/sample - loss: 2.3842 - accuracy: 0.3829 - val_loss: 2.3039 - val_accuracy: 0.3951\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 15s 381us/sample - loss: 2.3726 - accuracy: 0.3877 - val_loss: 2.3573 - val_accuracy: 0.3869\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 18s 476us/sample - loss: 2.3445 - accuracy: 0.3932 - val_loss: 2.3011 - val_accuracy: 0.4038\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 17s 452us/sample - loss: 2.3209 - accuracy: 0.3985 - val_loss: 2.2701 - val_accuracy: 0.4003\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 15s 405us/sample - loss: 2.3163 - accuracy: 0.3986 - val_loss: 2.2717 - val_accuracy: 0.4095\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 16s 408us/sample - loss: 2.3016 - accuracy: 0.4026 - val_loss: 2.2686 - val_accuracy: 0.4036\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 16s 423us/sample - loss: 2.2913 - accuracy: 0.4051 - val_loss: 2.2876 - val_accuracy: 0.4113\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 16s 412us/sample - loss: 2.2726 - accuracy: 0.4092 - val_loss: 2.2836 - val_accuracy: 0.4057\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 15s 383us/sample - loss: 2.2588 - accuracy: 0.4102 - val_loss: 2.2649 - val_accuracy: 0.4092\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 16s 409us/sample - loss: 2.2595 - accuracy: 0.4145 - val_loss: 2.2749 - val_accuracy: 0.4055\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 16s 422us/sample - loss: 2.2462 - accuracy: 0.4136 - val_loss: 2.2724 - val_accuracy: 0.4090\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 16s 416us/sample - loss: 2.2338 - accuracy: 0.4180 - val_loss: 2.2643 - val_accuracy: 0.4083\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 19s 504us/sample - loss: 2.2258 - accuracy: 0.4225 - val_loss: 2.2775 - val_accuracy: 0.4073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15b678ed0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 8s 213us/sample - loss: 2.8639 - accuracy: 0.2604 - val_loss: 2.4127 - val_accuracy: 0.3659\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 8s 202us/sample - loss: 2.4906 - accuracy: 0.3480 - val_loss: 2.2960 - val_accuracy: 0.3859\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 8s 209us/sample - loss: 2.4077 - accuracy: 0.3677 - val_loss: 2.2594 - val_accuracy: 0.4036\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 7s 187us/sample - loss: 2.3527 - accuracy: 0.3815 - val_loss: 2.2357 - val_accuracy: 0.4005\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 8s 200us/sample - loss: 2.3235 - accuracy: 0.3899 - val_loss: 2.2165 - val_accuracy: 0.4132\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 7s 188us/sample - loss: 2.2869 - accuracy: 0.3956 - val_loss: 2.2158 - val_accuracy: 0.4092\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 7s 189us/sample - loss: 2.2544 - accuracy: 0.4006 - val_loss: 2.1945 - val_accuracy: 0.4130\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 7s 196us/sample - loss: 2.2319 - accuracy: 0.4083 - val_loss: 2.1825 - val_accuracy: 0.4184\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 7s 193us/sample - loss: 2.2054 - accuracy: 0.4101 - val_loss: 2.1828 - val_accuracy: 0.4165\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 7s 185us/sample - loss: 2.1801 - accuracy: 0.4148 - val_loss: 2.1820 - val_accuracy: 0.4139\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 6s 162us/sample - loss: 2.1614 - accuracy: 0.4203 - val_loss: 2.1750 - val_accuracy: 0.4179\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 6s 159us/sample - loss: 2.1431 - accuracy: 0.4241 - val_loss: 2.1624 - val_accuracy: 0.4252\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 6s 153us/sample - loss: 2.1163 - accuracy: 0.4299 - val_loss: 2.1610 - val_accuracy: 0.4229\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 6s 166us/sample - loss: 2.1051 - accuracy: 0.4302 - val_loss: 2.1599 - val_accuracy: 0.4205\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 7s 196us/sample - loss: 2.0941 - accuracy: 0.4332 - val_loss: 2.1618 - val_accuracy: 0.4224\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 8s 204us/sample - loss: 2.0658 - accuracy: 0.4377 - val_loss: 2.1648 - val_accuracy: 0.4269\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 6s 159us/sample - loss: 2.0499 - accuracy: 0.4430 - val_loss: 2.1531 - val_accuracy: 0.4252\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 6s 167us/sample - loss: 2.0383 - accuracy: 0.4436 - val_loss: 2.1647 - val_accuracy: 0.4252\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 2.0168 - accuracy: 0.4463 - val_loss: 2.1693 - val_accuracy: 0.4208\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 2.0054 - accuracy: 0.4517 - val_loss: 2.1583 - val_accuracy: 0.4241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a1dd6d0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_e_relu_1 = relu_encoder_1.predict([x_img_train, x_txt_train])\n",
    "model = get_model()\n",
    "model.fit(train_e_relu_1, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
