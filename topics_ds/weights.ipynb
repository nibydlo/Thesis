{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from data import data\n",
    "from pytorch import torch_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50\n",
    "BATCH_SIZE = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img, x_txt, y = data.get_unpacked_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(\n",
    "    x_img, \n",
    "    x_txt, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "x_img_train, x_img_val, x_txt_train, x_txt_val, y_train, y_val = train_test_split(\n",
    "    x_img_train,\n",
    "    x_txt_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sscaler = StandardScaler()\n",
    "img_sscaler.fit(x_img_train)\n",
    "\n",
    "x_img_train = img_sscaler.transform(x_img_train)\n",
    "x_img_val = img_sscaler.transform(x_img_val)\n",
    "x_img_test = img_sscaler.transform(x_img_test)\n",
    "\n",
    "txt_sscaler = StandardScaler()\n",
    "txt_sscaler.fit(x_txt_train)\n",
    "\n",
    "x_txt_train = txt_sscaler.transform(x_txt_train)\n",
    "x_txt_val = txt_sscaler.transform(x_txt_val)\n",
    "x_txt_test = txt_sscaler.transform(x_txt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train_t = torch.tensor(x_img_train).float()\n",
    "x_img_val_t = torch.tensor(x_img_val).float()\n",
    "x_img_test_t = torch.tensor(x_img_test).float()\n",
    "\n",
    "x_txt_train_t = torch.tensor(x_txt_train).float()\n",
    "x_txt_val_t = torch.tensor(x_txt_val).float()\n",
    "x_txt_test_t = torch.tensor(x_txt_test).float()\n",
    "\n",
    "y_train_t = torch.tensor(y_train).float()\n",
    "y_val_t = torch.tensor(y_val).float()\n",
    "y_test_t = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_img_train_t, x_txt_train_t, y_train_t)\n",
    "val_ds = TensorDataset(x_img_val_t, x_txt_val_t, y_val_t)\n",
    "test_ds = TensorDataset(x_img_test_t, x_txt_test_t, y_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_topics_trident_model_with_weights(\n",
    "    model, \n",
    "    optimizer, \n",
    "    train_loader, \n",
    "    val_loader=None, \n",
    "    scheduler=None, \n",
    "    writer=None, \n",
    "    epochs=1,\n",
    "    weight=None\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_sum = 0.0\n",
    "        loss_common_sum = 0.0\n",
    "        loss_img_sum = 0.0\n",
    "        loss_txt_sum = 0.0\n",
    "        loss_count = 0\n",
    "\n",
    "        for x_img_cur, x_txt_cur, y_cur in train_loader:\n",
    "            model.zero_grad()\n",
    "            out_common, out_img, out_txt = model(x_img_cur, x_txt_cur)\n",
    "            target = torch.argmax(y_cur, dim=1)\n",
    "            loss_common = F.nll_loss(out_common, target, weight=weight)\n",
    "            loss_img = F.nll_loss(out_img, target, weight=weight)\n",
    "            loss_txt = F.nll_loss(out_txt, target, weight=weight)\n",
    "            loss = (loss_common + loss_img + loss_txt) / 3.0\n",
    "            loss.backward()\n",
    "\n",
    "            loss_common_sum += loss_common\n",
    "            loss_img_sum += loss_img\n",
    "            loss_txt_sum += loss_txt\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        print('epoch:', epoch, 'train_loss:', loss, 'average train loss', loss_sum / loss_count)\n",
    "        print( \n",
    "            'avg common loss:', loss_common_sum / loss_count, \n",
    "            'avg img loss:', loss_img_sum / loss_count,\n",
    "            'avg txt loss:', loss_txt_sum / loss_count\n",
    "        )\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('train_loss', loss, epoch)\n",
    "            writer.add_scalar('avg_train_loss', loss_sum / loss_count, epoch)\n",
    "            writer.add_scalar('avg_train_loss_common', loss_common_sum / loss_count, epoch)\n",
    "            writer.add_scalar('avg_train_loss_img', loss_img_sum / loss_count, epoch)\n",
    "            writer.add_scalar('avg_train_loss_txt', loss_txt_sum / loss_count, epoch)\n",
    "\n",
    "\n",
    "\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "\n",
    "            correct_common = 0\n",
    "            correct_img = 0\n",
    "            correct_txt = 0\n",
    "            total = 0\n",
    "            loss_common_sum = 0.0\n",
    "            loss_img_sum = 0.0\n",
    "            loss_txt_sum = 0.0\n",
    "            loss_sum = 0.0\n",
    "            loss_count = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for x_img_cur, x_txt_cur, y_cur in val_loader:\n",
    "                    out_common, out_img, out_txt = model(x_img_cur, x_txt_cur)\n",
    "                    target = torch.argmax(y_cur, dim=1)\n",
    "                    loss_common = F.nll_loss(out_common, target, weight=weight)\n",
    "                    loss_img = F.nll_loss(out_img, target, weight=weight)\n",
    "                    loss_txt = F.nll_loss(out_txt, target, weight=weight)\n",
    "                    \n",
    "                    loss = (loss_common + loss_img + loss_txt) / 3.0\n",
    "                    \n",
    "                    loss_common_sum += loss_common\n",
    "                    loss_img_sum += loss_img\n",
    "                    loss_txt_sum += loss_txt\n",
    "                    loss_sum += loss\n",
    "                    \n",
    "                    loss_count += 1\n",
    "                    for idx, i in enumerate(out_common):\n",
    "                        if torch.argmax(i) == target[idx]:\n",
    "                            correct_common += weight[target[idx]]\n",
    "                        total += weight[target[idx]]\n",
    "                    \n",
    "                    for idx, i in enumerate(out_img):\n",
    "                        if torch.argmax(i) == target[idx]:\n",
    "                            correct_img += weight[target[idx]]\n",
    "                           \n",
    "                    for idx, i in enumerate(out_txt):\n",
    "                        if torch.argmax(i) == target[idx]:\n",
    "                            correct_txt += weight[target[idx]]\n",
    "                    \n",
    "            print(\n",
    "                'val common acc:', correct_common / total,\n",
    "                'val img acc:', correct_img / total,\n",
    "                'val txt acc:', correct_txt / total,\n",
    "                'val_avg_loss:', loss_sum / loss_count)\n",
    "            print( \n",
    "                'avg common val loss:', loss_common_sum / loss_count, \n",
    "                'avg img val loss:', loss_img_sum / loss_count,\n",
    "                'avg txt val loss:', loss_txt_sum / loss_count\n",
    "            )\n",
    "            if writer is not None:\n",
    "                writer.add_scalar('val_acc', correct_common / total, epoch)\n",
    "                writer.add_scalar('val_img_acc', correct_img / total, epoch)\n",
    "                writer.add_scalar('val_txt_acc', correct_txt / total, epoch)\n",
    "                writer.add_scalar('val_avg_loss', loss_sum / loss_count, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_non_cat = np.argmax(y_train, axis=1)\n",
    "y_train_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_non_cat),\n",
    "    y=y_train_non_cat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49916253,  0.5604    ,  3.96779562,  0.48804812,  2.87308668,\n",
       "        1.24333943,  0.7834938 ,  1.5602411 ,  1.69342056,  0.93916379,\n",
       "        0.64867303,  0.75039757,  0.68324284,  0.84224977,  1.03857088,\n",
       "        1.65123937,  0.45841457,  1.1400755 ,  1.04656912,  1.09506044,\n",
       "        0.83092021,  1.54340716,  1.45812232,  0.61940292,  0.78462471,\n",
       "        0.88330842,  0.59892904,  0.82411765,  0.41820896,  1.01340045,\n",
       "        1.18068636,  0.8171798 ,  0.41406764,  1.77179922,  1.35558105,\n",
       "        2.47310282,  1.92625089,  3.21269504,  4.90602888,  3.83348378,\n",
       "        8.44080745,  1.5141727 , 20.28313433,  0.81035778,  4.20083462,\n",
       "        1.08284462,  4.04455357,  8.44080745,  0.35668504,  2.14687204])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(2.3515, grad_fn=<DivBackward0>) average train loss tensor(2.9298, grad_fn=<DivBackward0>)\n",
      "avg common loss: tensor(2.9602, grad_fn=<DivBackward0>) avg img loss: tensor(2.8974, grad_fn=<DivBackward0>) avg txt loss: tensor(2.9318, grad_fn=<DivBackward0>)\n",
      "val common acc: tensor(0.4905) val img acc: tensor(0.3671) val txt acc: tensor(0.4266) val_avg_loss: tensor(2.2432)\n",
      "avg common val loss: tensor(1.9872) avg img val loss: tensor(2.4622) avg txt val loss: tensor(2.2803)\n"
     ]
    }
   ],
   "source": [
    "model = torch_models.NormModelTridentBN(drop=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "writer = SummaryWriter('runs/trident_bn_bs2048_rs42_d128_wd0005_drop05_weighted')\n",
    "\n",
    "fit_topics_trident_model_with_weights(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    epochs=1,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    weight=torch.tensor(y_train_weights).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
