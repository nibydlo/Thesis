{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from struct import unpack\n",
    "from base64 import b64decode\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, concatenate, BatchNormalization, Multiply, Add, Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dmitry/Downloads/topics_dataset.json\"\n",
    "df = pd.read_json(filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def unpck(l, x):\n",
    "    return unpack('%df' % l, b64decode(x.encode('utf-8')))\n",
    "\n",
    "unpck_img = partial(unpck, IMG_LEN)\n",
    "unpck_txt = partial(unpck, TXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = np.stack(df['x1'].map(unpck_img), axis=0)\n",
    "x_txt = np.stack(df['x2'].map(unpck_txt), axis=0)\n",
    "y = to_categorical(np.array(df['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(\n",
    "    x_img, \n",
    "    x_txt, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_val, x_txt_train, x_txt_val, y_train, y_val = train_test_split(\n",
    "    x_img_train,\n",
    "    x_txt_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sscaler = StandardScaler()\n",
    "img_sscaler.fit(x_img_train)\n",
    "\n",
    "x_img_train = img_sscaler.transform(x_img_train)\n",
    "x_img_val = img_sscaler.transform(x_img_val)\n",
    "x_img_test = img_sscaler.transform(x_img_test)\n",
    "\n",
    "txt_sscaler = StandardScaler()\n",
    "txt_sscaler.fit(x_txt_train)\n",
    "\n",
    "x_txt_train = txt_sscaler.transform(x_txt_train)\n",
    "x_txt_val = txt_sscaler.transform(x_txt_val)\n",
    "x_txt_test = txt_sscaler.transform(x_txt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting 47th class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_47 = y_train[:, 47]\n",
    "y_val_47 = y_val[:, 47]\n",
    "y_test_47 = y_test[:, 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stat(y):\n",
    "    stat = {}\n",
    "    for i in range(y.shape[0]):\n",
    "        p = np.argmax(y[i])\n",
    "        if p in test_stat:\n",
    "            test_stat[p] += 1\n",
    "        else:\n",
    "            test_stat[p] = 1\n",
    "        \n",
    "    for key, value in sorted(test_stat.items()):\n",
    "        print(\"{} : {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 135897\n",
      "    Positive: 340 (0.25% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_train, pos_train = np.bincount(y_train_47.astype(np.int))\n",
    "total_train = neg_train + pos_train\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_train, pos_train, 100 * pos_train / total_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 33975\n",
      "    Positive: 65 (0.19% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_val, pos_val = np.bincount(y_val_47.astype(np.int))\n",
    "total_val = neg_val + pos_val\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_val, pos_val, 100 * pos_val / total_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 42468\n",
      "    Positive: 98 (0.23% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_test, pos_test = np.bincount(y_test_47.astype(np.int))\n",
    "total_test = neg_test + pos_test\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_test, pos_test, 100 * pos_test / total_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([3, 4, 5])[np.array([1, 0, 1]).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 47th rows\n",
    "x_img_train_47 = x_img_train[y_train_47.astype(bool)]\n",
    "x_txt_train_47 = x_txt_train[y_train_47.astype(bool)]\n",
    "\n",
    "x_img_train_others = x_img_train[(y_train_47 - 1).astype(bool)]\n",
    "x_txt_train_others = x_txt_train[(y_train_47 - 1).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations_47 = np.std(x_img_train_47, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations_others = np.std(x_img_train_others, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96118451, 0.91084354, 0.98085979, ..., 0.98485636, 1.00395001,\n",
       "       0.93173016])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00009247, 1.0002125 , 1.00003889, ..., 1.00003222, 0.99998996,\n",
       "       1.00016476])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations_difs = np.abs(deviations_47 - deviations_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(deviations_difs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38178755483435567"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviations_difs[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50 = np.argpartition(deviations_difs, -50, axis=0)[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train_top_50 = x_img_train[:, top_50]\n",
    "x_img_val_top_50 = x_img_val[:, top_50]\n",
    "x_img_test_top_50 = x_img_test[:, top_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135897, 50)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train_top_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_img():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x = Dense(64, activation='relu')(inp_img)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs = inp_img, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/60\n",
      "135897/135897 [==============================] - 11s 79us/sample - loss: 0.0187 - tp: 25.0000 - fp: 7794.0000 - tn: 127763.0000 - fn: 315.0000 - accuracy: 0.9403 - precision: 0.0032 - recall: 0.0735 - auc: 0.5308 - val_loss: 0.0085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6148\n",
      "Epoch 2/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0122 - tp: 7.0000 - fp: 1428.0000 - tn: 134129.0000 - fn: 333.0000 - accuracy: 0.9870 - precision: 0.0049 - recall: 0.0206 - auc: 0.6073 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6357\n",
      "Epoch 3/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0111 - tp: 5.0000 - fp: 729.0000 - tn: 134828.0000 - fn: 335.0000 - accuracy: 0.9922 - precision: 0.0068 - recall: 0.0147 - auc: 0.6556 - val_loss: 0.0083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6472\n",
      "Epoch 4/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0104 - tp: 6.0000 - fp: 438.0000 - tn: 135119.0000 - fn: 334.0000 - accuracy: 0.9943 - precision: 0.0135 - recall: 0.0176 - auc: 0.6838 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6509\n",
      "Epoch 5/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0098 - tp: 6.0000 - fp: 374.0000 - tn: 135183.0000 - fn: 334.0000 - accuracy: 0.9948 - precision: 0.0158 - recall: 0.0176 - auc: 0.7165 - val_loss: 0.0083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6384\n",
      "Epoch 6/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0094 - tp: 11.0000 - fp: 292.0000 - tn: 135265.0000 - fn: 329.0000 - accuracy: 0.9954 - precision: 0.0363 - recall: 0.0324 - auc: 0.7430 - val_loss: 0.0083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6370\n",
      "Epoch 7/60\n",
      "135897/135897 [==============================] - 3s 24us/sample - loss: 0.0089 - tp: 6.0000 - fp: 187.0000 - tn: 135370.0000 - fn: 334.0000 - accuracy: 0.9962 - precision: 0.0311 - recall: 0.0176 - auc: 0.7671 - val_loss: 0.0085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6219\n",
      "Epoch 8/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0089 - tp: 3.0000 - fp: 199.0000 - tn: 135358.0000 - fn: 337.0000 - accuracy: 0.9961 - precision: 0.0149 - recall: 0.0088 - auc: 0.7733 - val_loss: 0.0085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6277\n",
      "Epoch 9/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0085 - tp: 2.0000 - fp: 151.0000 - tn: 135406.0000 - fn: 338.0000 - accuracy: 0.9964 - precision: 0.0131 - recall: 0.0059 - auc: 0.7936 - val_loss: 0.0085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6253\n",
      "Epoch 10/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0081 - tp: 8.0000 - fp: 126.0000 - tn: 135431.0000 - fn: 332.0000 - accuracy: 0.9966 - precision: 0.0597 - recall: 0.0235 - auc: 0.8156 - val_loss: 0.0086 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6308\n",
      "Epoch 11/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0079 - tp: 12.0000 - fp: 122.0000 - tn: 135435.0000 - fn: 328.0000 - accuracy: 0.9967 - precision: 0.0896 - recall: 0.0353 - auc: 0.8251 - val_loss: 0.0088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6372\n",
      "Epoch 12/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0075 - tp: 8.0000 - fp: 128.0000 - tn: 135429.0000 - fn: 332.0000 - accuracy: 0.9966 - precision: 0.0588 - recall: 0.0235 - auc: 0.8540 - val_loss: 0.0089 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6123\n",
      "Epoch 13/60\n",
      "135897/135897 [==============================] - 3s 25us/sample - loss: 0.0072 - tp: 17.0000 - fp: 182.0000 - tn: 135375.0000 - fn: 323.0000 - accuracy: 0.9963 - precision: 0.0854 - recall: 0.0500 - auc: 0.8625 - val_loss: 0.0091 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6181\n",
      "Epoch 14/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0070 - tp: 28.0000 - fp: 223.0000 - tn: 135334.0000 - fn: 312.0000 - accuracy: 0.9961 - precision: 0.1116 - recall: 0.0824 - auc: 0.8751 - val_loss: 0.0092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6246\n",
      "Epoch 15/60\n",
      "135897/135897 [==============================] - 3s 24us/sample - loss: 0.0067 - tp: 31.0000 - fp: 274.0000 - tn: 135283.0000 - fn: 309.0000 - accuracy: 0.9957 - precision: 0.1016 - recall: 0.0912 - auc: 0.8902 - val_loss: 0.0094 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 65.0000 - val_accuracy: 0.9980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6144\n",
      "Epoch 16/60\n",
      "135897/135897 [==============================] - 3s 24us/sample - loss: 0.0065 - tp: 47.0000 - fp: 308.0000 - tn: 135249.0000 - fn: 293.0000 - accuracy: 0.9956 - precision: 0.1324 - recall: 0.1382 - auc: 0.9007 - val_loss: 0.0100 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 65.0000 - val_accuracy: 0.9980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6008\n",
      "Epoch 17/60\n",
      "135897/135897 [==============================] - 3s 24us/sample - loss: 0.0065 - tp: 43.0000 - fp: 384.0000 - tn: 135173.0000 - fn: 297.0000 - accuracy: 0.9950 - precision: 0.1007 - recall: 0.1265 - auc: 0.8984 - val_loss: 0.0096 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 65.0000 - val_accuracy: 0.9980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6296\n",
      "Epoch 18/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0058 - tp: 58.0000 - fp: 383.0000 - tn: 135174.0000 - fn: 282.0000 - accuracy: 0.9951 - precision: 0.1315 - recall: 0.1706 - auc: 0.9274 - val_loss: 0.0102 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 65.0000 - val_accuracy: 0.9979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6065\n",
      "Epoch 19/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0055 - tp: 93.0000 - fp: 546.0000 - tn: 135011.0000 - fn: 247.0000 - accuracy: 0.9942 - precision: 0.1455 - recall: 0.2735 - auc: 0.9291 - val_loss: 0.0110 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 65.0000 - val_accuracy: 0.9980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5640\n",
      "Epoch 20/60\n",
      "135897/135897 [==============================] - 4s 29us/sample - loss: 0.0055 - tp: 89.0000 - fp: 623.0000 - tn: 134934.0000 - fn: 251.0000 - accuracy: 0.9936 - precision: 0.1250 - recall: 0.2618 - auc: 0.9303 - val_loss: 0.0111 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 33898.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0769 - val_recall: 0.0154 - val_auc: 0.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60\n",
      "135897/135897 [==============================] - 3s 24us/sample - loss: 0.0054 - tp: 92.0000 - fp: 690.0000 - tn: 134867.0000 - fn: 248.0000 - accuracy: 0.9931 - precision: 0.1176 - recall: 0.2706 - auc: 0.9339 - val_loss: 0.0114 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5489\n",
      "Epoch 22/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0049 - tp: 112.0000 - fp: 678.0000 - tn: 134879.0000 - fn: 228.0000 - accuracy: 0.9933 - precision: 0.1418 - recall: 0.3294 - auc: 0.9476 - val_loss: 0.0119 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5614\n",
      "Epoch 23/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0047 - tp: 133.0000 - fp: 687.0000 - tn: 134870.0000 - fn: 207.0000 - accuracy: 0.9934 - precision: 0.1622 - recall: 0.3912 - auc: 0.9490 - val_loss: 0.0124 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5479\n",
      "Epoch 24/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0049 - tp: 135.0000 - fp: 707.0000 - tn: 134850.0000 - fn: 205.0000 - accuracy: 0.9933 - precision: 0.1603 - recall: 0.3971 - auc: 0.9437 - val_loss: 0.0122 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 33897.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0714 - val_recall: 0.0154 - val_auc: 0.5811\n",
      "Epoch 25/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0045 - tp: 143.0000 - fp: 668.0000 - tn: 134889.0000 - fn: 197.0000 - accuracy: 0.9936 - precision: 0.1763 - recall: 0.4206 - auc: 0.9564 - val_loss: 0.0134 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5507\n",
      "Epoch 26/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0044 - tp: 165.0000 - fp: 691.0000 - tn: 134866.0000 - fn: 175.0000 - accuracy: 0.9936 - precision: 0.1928 - recall: 0.4853 - auc: 0.9498 - val_loss: 0.0133 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 33897.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0714 - val_recall: 0.0154 - val_auc: 0.5295\n",
      "Epoch 27/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0040 - tp: 163.0000 - fp: 766.0000 - tn: 134791.0000 - fn: 177.0000 - accuracy: 0.9931 - precision: 0.1755 - recall: 0.4794 - auc: 0.9672 - val_loss: 0.0146 - val_tp: 1.0000 - val_fp: 17.0000 - val_tn: 33893.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0556 - val_recall: 0.0154 - val_auc: 0.5594\n",
      "Epoch 28/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0043 - tp: 177.0000 - fp: 746.0000 - tn: 134811.0000 - fn: 163.0000 - accuracy: 0.9933 - precision: 0.1918 - recall: 0.5206 - auc: 0.9517 - val_loss: 0.0142 - val_tp: 1.0000 - val_fp: 20.0000 - val_tn: 33890.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0476 - val_recall: 0.0154 - val_auc: 0.5314\n",
      "Epoch 29/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0041 - tp: 185.0000 - fp: 817.0000 - tn: 134740.0000 - fn: 155.0000 - accuracy: 0.9928 - precision: 0.1846 - recall: 0.5441 - auc: 0.9633 - val_loss: 0.0144 - val_tp: 1.0000 - val_fp: 22.0000 - val_tn: 33888.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0435 - val_recall: 0.0154 - val_auc: 0.5491\n",
      "Epoch 30/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0041 - tp: 172.0000 - fp: 817.0000 - tn: 134740.0000 - fn: 168.0000 - accuracy: 0.9928 - precision: 0.1739 - recall: 0.5059 - auc: 0.9568 - val_loss: 0.0151 - val_tp: 1.0000 - val_fp: 16.0000 - val_tn: 33894.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0588 - val_recall: 0.0154 - val_auc: 0.5252\n",
      "Epoch 31/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0036 - tp: 193.0000 - fp: 729.0000 - tn: 134828.0000 - fn: 147.0000 - accuracy: 0.9936 - precision: 0.2093 - recall: 0.5676 - auc: 0.9675 - val_loss: 0.0157 - val_tp: 1.0000 - val_fp: 16.0000 - val_tn: 33894.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0588 - val_recall: 0.0154 - val_auc: 0.5363\n",
      "Epoch 32/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0036 - tp: 206.0000 - fp: 726.0000 - tn: 134831.0000 - fn: 134.0000 - accuracy: 0.9937 - precision: 0.2210 - recall: 0.6059 - auc: 0.9673 - val_loss: 0.0163 - val_tp: 1.0000 - val_fp: 14.0000 - val_tn: 33896.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0667 - val_recall: 0.0154 - val_auc: 0.5428\n",
      "Epoch 33/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0033 - tp: 207.0000 - fp: 644.0000 - tn: 134913.0000 - fn: 133.0000 - accuracy: 0.9943 - precision: 0.2432 - recall: 0.6088 - auc: 0.9713 - val_loss: 0.0165 - val_tp: 1.0000 - val_fp: 20.0000 - val_tn: 33890.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0476 - val_recall: 0.0154 - val_auc: 0.5084\n",
      "Epoch 34/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0032 - tp: 229.0000 - fp: 771.0000 - tn: 134786.0000 - fn: 111.0000 - accuracy: 0.9935 - precision: 0.2290 - recall: 0.6735 - auc: 0.9789 - val_loss: 0.0175 - val_tp: 1.0000 - val_fp: 26.0000 - val_tn: 33884.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0370 - val_recall: 0.0154 - val_auc: 0.5351\n",
      "Epoch 35/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0034 - tp: 223.0000 - fp: 825.0000 - tn: 134732.0000 - fn: 117.0000 - accuracy: 0.9931 - precision: 0.2128 - recall: 0.6559 - auc: 0.9685 - val_loss: 0.0186 - val_tp: 1.0000 - val_fp: 15.0000 - val_tn: 33895.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0625 - val_recall: 0.0154 - val_auc: 0.4990\n",
      "Epoch 36/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0030 - tp: 228.0000 - fp: 653.0000 - tn: 134904.0000 - fn: 112.0000 - accuracy: 0.9944 - precision: 0.2588 - recall: 0.6706 - auc: 0.9740 - val_loss: 0.0183 - val_tp: 2.0000 - val_fp: 24.0000 - val_tn: 33886.0000 - val_fn: 63.0000 - val_accuracy: 0.9974 - val_precision: 0.0769 - val_recall: 0.0308 - val_auc: 0.4887\n",
      "Epoch 37/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0030 - tp: 234.0000 - fp: 677.0000 - tn: 134880.0000 - fn: 106.0000 - accuracy: 0.9942 - precision: 0.2569 - recall: 0.6882 - auc: 0.9770 - val_loss: 0.0191 - val_tp: 2.0000 - val_fp: 15.0000 - val_tn: 33895.0000 - val_fn: 63.0000 - val_accuracy: 0.9977 - val_precision: 0.1176 - val_recall: 0.0308 - val_auc: 0.5115\n",
      "Epoch 38/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0027 - tp: 241.0000 - fp: 689.0000 - tn: 134868.0000 - fn: 99.0000 - accuracy: 0.9942 - precision: 0.2591 - recall: 0.7088 - auc: 0.9801 - val_loss: 0.0209 - val_tp: 2.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 63.0000 - val_accuracy: 0.9979 - val_precision: 0.1667 - val_recall: 0.0308 - val_auc: 0.5041\n",
      "Epoch 39/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0030 - tp: 236.0000 - fp: 714.0000 - tn: 134843.0000 - fn: 104.0000 - accuracy: 0.9940 - precision: 0.2484 - recall: 0.6941 - auc: 0.9726 - val_loss: 0.0198 - val_tp: 2.0000 - val_fp: 18.0000 - val_tn: 33892.0000 - val_fn: 63.0000 - val_accuracy: 0.9976 - val_precision: 0.1000 - val_recall: 0.0308 - val_auc: 0.5548\n",
      "Epoch 40/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0027 - tp: 256.0000 - fp: 693.0000 - tn: 134864.0000 - fn: 84.0000 - accuracy: 0.9943 - precision: 0.2698 - recall: 0.7529 - auc: 0.9801 - val_loss: 0.0208 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 33897.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0714 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0027 - tp: 249.0000 - fp: 691.0000 - tn: 134866.0000 - fn: 91.0000 - accuracy: 0.9942 - precision: 0.2649 - recall: 0.7324 - auc: 0.9790 - val_loss: 0.0211 - val_tp: 1.0000 - val_fp: 14.0000 - val_tn: 33896.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0667 - val_recall: 0.0154 - val_auc: 0.5057\n",
      "Epoch 42/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0026 - tp: 255.0000 - fp: 712.0000 - tn: 134845.0000 - fn: 85.0000 - accuracy: 0.9941 - precision: 0.2637 - recall: 0.7500 - auc: 0.9792 - val_loss: 0.0217 - val_tp: 1.0000 - val_fp: 14.0000 - val_tn: 33896.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0667 - val_recall: 0.0154 - val_auc: 0.4733\n",
      "Epoch 43/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0024 - tp: 261.0000 - fp: 562.0000 - tn: 134995.0000 - fn: 79.0000 - accuracy: 0.9953 - precision: 0.3171 - recall: 0.7676 - auc: 0.9807 - val_loss: 0.0225 - val_tp: 1.0000 - val_fp: 20.0000 - val_tn: 33890.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0476 - val_recall: 0.0154 - val_auc: 0.5198\n",
      "Epoch 44/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0024 - tp: 262.0000 - fp: 633.0000 - tn: 134924.0000 - fn: 78.0000 - accuracy: 0.9948 - precision: 0.2927 - recall: 0.7706 - auc: 0.9817 - val_loss: 0.0222 - val_tp: 2.0000 - val_fp: 16.0000 - val_tn: 33894.0000 - val_fn: 63.0000 - val_accuracy: 0.9977 - val_precision: 0.1111 - val_recall: 0.0308 - val_auc: 0.5349\n",
      "Epoch 45/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0025 - tp: 255.0000 - fp: 687.0000 - tn: 134870.0000 - fn: 85.0000 - accuracy: 0.9943 - precision: 0.2707 - recall: 0.7500 - auc: 0.9771 - val_loss: 0.0223 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 33898.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0769 - val_recall: 0.0154 - val_auc: 0.4899\n",
      "Epoch 46/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0024 - tp: 267.0000 - fp: 636.0000 - tn: 134921.0000 - fn: 73.0000 - accuracy: 0.9948 - precision: 0.2957 - recall: 0.7853 - auc: 0.9818 - val_loss: 0.0231 - val_tp: 1.0000 - val_fp: 33.0000 - val_tn: 33877.0000 - val_fn: 64.0000 - val_accuracy: 0.9971 - val_precision: 0.0294 - val_recall: 0.0154 - val_auc: 0.4920\n",
      "Epoch 47/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0022 - tp: 270.0000 - fp: 628.0000 - tn: 134929.0000 - fn: 70.0000 - accuracy: 0.9949 - precision: 0.3007 - recall: 0.7941 - auc: 0.9847 - val_loss: 0.0240 - val_tp: 1.0000 - val_fp: 19.0000 - val_tn: 33891.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0500 - val_recall: 0.0154 - val_auc: 0.4829\n",
      "Epoch 48/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0027 - tp: 267.0000 - fp: 736.0000 - tn: 134821.0000 - fn: 73.0000 - accuracy: 0.9940 - precision: 0.2662 - recall: 0.7853 - auc: 0.9761 - val_loss: 0.0227 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.4886\n",
      "Epoch 49/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0023 - tp: 268.0000 - fp: 536.0000 - tn: 135021.0000 - fn: 72.0000 - accuracy: 0.9955 - precision: 0.3333 - recall: 0.7882 - auc: 0.9816 - val_loss: 0.0233 - val_tp: 1.0000 - val_fp: 14.0000 - val_tn: 33896.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0667 - val_recall: 0.0154 - val_auc: 0.5098\n",
      "Epoch 50/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0023 - tp: 271.0000 - fp: 601.0000 - tn: 134956.0000 - fn: 69.0000 - accuracy: 0.9951 - precision: 0.3108 - recall: 0.7971 - auc: 0.9787 - val_loss: 0.0242 - val_tp: 1.0000 - val_fp: 17.0000 - val_tn: 33893.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0556 - val_recall: 0.0154 - val_auc: 0.5143\n",
      "Epoch 51/60\n",
      "135897/135897 [==============================] - 3s 21us/sample - loss: 0.0022 - tp: 281.0000 - fp: 633.0000 - tn: 134924.0000 - fn: 59.0000 - accuracy: 0.9949 - precision: 0.3074 - recall: 0.8265 - auc: 0.9835 - val_loss: 0.0251 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 33898.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0769 - val_recall: 0.0154 - val_auc: 0.5174\n",
      "Epoch 52/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0020 - tp: 271.0000 - fp: 597.0000 - tn: 134960.0000 - fn: 69.0000 - accuracy: 0.9951 - precision: 0.3122 - recall: 0.7971 - auc: 0.9908 - val_loss: 0.0262 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5145\n",
      "Epoch 53/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0021 - tp: 286.0000 - fp: 537.0000 - tn: 135020.0000 - fn: 54.0000 - accuracy: 0.9957 - precision: 0.3475 - recall: 0.8412 - auc: 0.9831 - val_loss: 0.0249 - val_tp: 1.0000 - val_fp: 16.0000 - val_tn: 33894.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0588 - val_recall: 0.0154 - val_auc: 0.5270\n",
      "Epoch 54/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0022 - tp: 277.0000 - fp: 595.0000 - tn: 134962.0000 - fn: 63.0000 - accuracy: 0.9952 - precision: 0.3177 - recall: 0.8147 - auc: 0.9850 - val_loss: 0.0251 - val_tp: 1.0000 - val_fp: 15.0000 - val_tn: 33895.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0625 - val_recall: 0.0154 - val_auc: 0.5189\n",
      "Epoch 55/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0024 - tp: 263.0000 - fp: 663.0000 - tn: 134894.0000 - fn: 77.0000 - accuracy: 0.9946 - precision: 0.2840 - recall: 0.7735 - auc: 0.9814 - val_loss: 0.0241 - val_tp: 1.0000 - val_fp: 16.0000 - val_tn: 33894.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0588 - val_recall: 0.0154 - val_auc: 0.5273\n",
      "Epoch 56/60\n",
      "135897/135897 [==============================] - 3s 22us/sample - loss: 0.0022 - tp: 277.0000 - fp: 606.0000 - tn: 134951.0000 - fn: 63.0000 - accuracy: 0.9951 - precision: 0.3137 - recall: 0.8147 - auc: 0.9838 - val_loss: 0.0247 - val_tp: 1.0000 - val_fp: 14.0000 - val_tn: 33896.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0667 - val_recall: 0.0154 - val_auc: 0.5195\n",
      "Epoch 57/60\n",
      "135897/135897 [==============================] - 4s 26us/sample - loss: 0.0020 - tp: 283.0000 - fp: 547.0000 - tn: 135010.0000 - fn: 57.0000 - accuracy: 0.9956 - precision: 0.3410 - recall: 0.8324 - auc: 0.9851 - val_loss: 0.0259 - val_tp: 1.0000 - val_fp: 22.0000 - val_tn: 33888.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0435 - val_recall: 0.0154 - val_auc: 0.4774\n",
      "Epoch 58/60\n",
      "135897/135897 [==============================] - 3s 20us/sample - loss: 0.0018 - tp: 291.0000 - fp: 554.0000 - tn: 135003.0000 - fn: 49.0000 - accuracy: 0.9956 - precision: 0.3444 - recall: 0.8559 - auc: 0.9861 - val_loss: 0.0277 - val_tp: 1.0000 - val_fp: 15.0000 - val_tn: 33895.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0625 - val_recall: 0.0154 - val_auc: 0.4814\n",
      "Epoch 59/60\n",
      "135897/135897 [==============================] - 3s 23us/sample - loss: 0.0020 - tp: 281.0000 - fp: 571.0000 - tn: 134986.0000 - fn: 59.0000 - accuracy: 0.9954 - precision: 0.3298 - recall: 0.8265 - auc: 0.9839 - val_loss: 0.0277 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 33898.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0769 - val_recall: 0.0154 - val_auc: 0.4841\n",
      "Epoch 60/60\n",
      "135897/135897 [==============================] - 3s 20us/sample - loss: 0.0019 - tp: 287.0000 - fp: 553.0000 - tn: 135004.0000 - fn: 53.0000 - accuracy: 0.9955 - precision: 0.3417 - recall: 0.8441 - auc: 0.9902 - val_loss: 0.0285 - val_tp: 1.0000 - val_fp: 18.0000 - val_tn: 33892.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0526 - val_recall: 0.0154 - val_auc: 0.5325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x187954210>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_img = get_model_img()\n",
    "model_img.fit(\n",
    "    x_img_train, \n",
    "    y_train_47, \n",
    "    validation_data=(x_img_val, y_val_47), \n",
    "    class_weight={0: 0.05, 1: 0.95}, \n",
    "    epochs=60,\n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_txt():\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x = Dense(64, activation='relu')(inp_txt)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs = inp_txt, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/60\n",
      "135897/135897 [==============================] - 5s 36us/sample - loss: 0.0177 - tp: 15.0000 - fp: 6862.0000 - tn: 128695.0000 - fn: 325.0000 - accuracy: 0.9471 - precision: 0.0022 - recall: 0.0441 - auc: 0.5249 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6297\n",
      "Epoch 2/60\n",
      "135897/135897 [==============================] - 2s 15us/sample - loss: 0.0119 - tp: 3.0000 - fp: 1047.0000 - tn: 134510.0000 - fn: 337.0000 - accuracy: 0.9898 - precision: 0.0029 - recall: 0.0088 - auc: 0.6113 - val_loss: 0.0079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6663\n",
      "Epoch 3/60\n",
      "135897/135897 [==============================] - 2s 15us/sample - loss: 0.0107 - tp: 3.0000 - fp: 533.0000 - tn: 135024.0000 - fn: 337.0000 - accuracy: 0.9936 - precision: 0.0056 - recall: 0.0088 - auc: 0.6558 - val_loss: 0.0078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6630\n",
      "Epoch 4/60\n",
      "135897/135897 [==============================] - 2s 14us/sample - loss: 0.0100 - tp: 2.0000 - fp: 317.0000 - tn: 135240.0000 - fn: 338.0000 - accuracy: 0.9952 - precision: 0.0063 - recall: 0.0059 - auc: 0.6975 - val_loss: 0.0078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6827\n",
      "Epoch 5/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0095 - tp: 1.0000 - fp: 206.0000 - tn: 135351.0000 - fn: 339.0000 - accuracy: 0.9960 - precision: 0.0048 - recall: 0.0029 - auc: 0.7281 - val_loss: 0.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6860\n",
      "Epoch 6/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0092 - tp: 0.0000e+00 - fp: 176.0000 - tn: 135381.0000 - fn: 340.0000 - accuracy: 0.9962 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7436 - val_loss: 0.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6957\n",
      "Epoch 7/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0086 - tp: 4.0000 - fp: 97.0000 - tn: 135460.0000 - fn: 336.0000 - accuracy: 0.9968 - precision: 0.0396 - recall: 0.0118 - auc: 0.7780 - val_loss: 0.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7018\n",
      "Epoch 8/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0083 - tp: 4.0000 - fp: 110.0000 - tn: 135447.0000 - fn: 336.0000 - accuracy: 0.9967 - precision: 0.0351 - recall: 0.0118 - auc: 0.8047 - val_loss: 0.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7155\n",
      "Epoch 9/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0084 - tp: 7.0000 - fp: 122.0000 - tn: 135435.0000 - fn: 333.0000 - accuracy: 0.9967 - precision: 0.0543 - recall: 0.0206 - auc: 0.7987 - val_loss: 0.0078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6958\n",
      "Epoch 10/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0081 - tp: 5.0000 - fp: 101.0000 - tn: 135456.0000 - fn: 335.0000 - accuracy: 0.9968 - precision: 0.0472 - recall: 0.0147 - auc: 0.8133 - val_loss: 0.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7061\n",
      "Epoch 11/60\n",
      "135897/135897 [==============================] - 2s 16us/sample - loss: 0.0078 - tp: 8.0000 - fp: 94.0000 - tn: 135463.0000 - fn: 332.0000 - accuracy: 0.9969 - precision: 0.0784 - recall: 0.0235 - auc: 0.8393 - val_loss: 0.0077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7150\n",
      "Epoch 12/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0076 - tp: 10.0000 - fp: 94.0000 - tn: 135463.0000 - fn: 330.0000 - accuracy: 0.9969 - precision: 0.0962 - recall: 0.0294 - auc: 0.8416 - val_loss: 0.0078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7163\n",
      "Epoch 13/60\n",
      "135897/135897 [==============================] - 2s 14us/sample - loss: 0.0072 - tp: 20.0000 - fp: 154.0000 - tn: 135403.0000 - fn: 320.0000 - accuracy: 0.9965 - precision: 0.1149 - recall: 0.0588 - auc: 0.8622 - val_loss: 0.0079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7147\n",
      "Epoch 14/60\n",
      "135897/135897 [==============================] - 2s 14us/sample - loss: 0.0069 - tp: 16.0000 - fp: 164.0000 - tn: 135393.0000 - fn: 324.0000 - accuracy: 0.9964 - precision: 0.0889 - recall: 0.0471 - auc: 0.8797 - val_loss: 0.0080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7191\n",
      "Epoch 15/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0068 - tp: 23.0000 - fp: 184.0000 - tn: 135373.0000 - fn: 317.0000 - accuracy: 0.9963 - precision: 0.1111 - recall: 0.0676 - auc: 0.8842 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7030\n",
      "Epoch 16/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0067 - tp: 27.0000 - fp: 230.0000 - tn: 135327.0000 - fn: 313.0000 - accuracy: 0.9960 - precision: 0.1051 - recall: 0.0794 - auc: 0.8881 - val_loss: 0.0083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6986\n",
      "Epoch 17/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0065 - tp: 38.0000 - fp: 329.0000 - tn: 135228.0000 - fn: 302.0000 - accuracy: 0.9954 - precision: 0.1035 - recall: 0.1118 - auc: 0.8961 - val_loss: 0.0085 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 65.0000 - val_accuracy: 0.9980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6909\n",
      "Epoch 18/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0062 - tp: 43.0000 - fp: 297.0000 - tn: 135260.0000 - fn: 297.0000 - accuracy: 0.9956 - precision: 0.1265 - recall: 0.1265 - auc: 0.9095 - val_loss: 0.0087 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 65.0000 - val_accuracy: 0.9980 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6767\n",
      "Epoch 19/60\n",
      "135897/135897 [==============================] - 2s 14us/sample - loss: 0.0059 - tp: 62.0000 - fp: 328.0000 - tn: 135229.0000 - fn: 278.0000 - accuracy: 0.9955 - precision: 0.1590 - recall: 0.1824 - auc: 0.9237 - val_loss: 0.0091 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 65.0000 - val_accuracy: 0.9979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6717\n",
      "Epoch 20/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0057 - tp: 65.0000 - fp: 339.0000 - tn: 135218.0000 - fn: 275.0000 - accuracy: 0.9955 - precision: 0.1609 - recall: 0.1912 - auc: 0.9234 - val_loss: 0.0094 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 65.0000 - val_accuracy: 0.9979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60\n",
      "135897/135897 [==============================] - 2s 13us/sample - loss: 0.0055 - tp: 86.0000 - fp: 418.0000 - tn: 135139.0000 - fn: 254.0000 - accuracy: 0.9951 - precision: 0.1706 - recall: 0.2529 - auc: 0.9330 - val_loss: 0.0097 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 65.0000 - val_accuracy: 0.9979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6527\n",
      "Epoch 22/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0054 - tp: 88.0000 - fp: 405.0000 - tn: 135152.0000 - fn: 252.0000 - accuracy: 0.9952 - precision: 0.1785 - recall: 0.2588 - auc: 0.9375 - val_loss: 0.0102 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.6412\n",
      "Epoch 23/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0054 - tp: 89.0000 - fp: 466.0000 - tn: 135091.0000 - fn: 251.0000 - accuracy: 0.9947 - precision: 0.1604 - recall: 0.2618 - auc: 0.9349 - val_loss: 0.0101 - val_tp: 1.0000 - val_fp: 11.0000 - val_tn: 33899.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0833 - val_recall: 0.0154 - val_auc: 0.6720\n",
      "Epoch 24/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0052 - tp: 105.0000 - fp: 517.0000 - tn: 135040.0000 - fn: 235.0000 - accuracy: 0.9945 - precision: 0.1688 - recall: 0.3088 - auc: 0.9427 - val_loss: 0.0103 - val_tp: 1.0000 - val_fp: 28.0000 - val_tn: 33882.0000 - val_fn: 64.0000 - val_accuracy: 0.9973 - val_precision: 0.0345 - val_recall: 0.0154 - val_auc: 0.6480\n",
      "Epoch 25/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0049 - tp: 119.0000 - fp: 559.0000 - tn: 134998.0000 - fn: 221.0000 - accuracy: 0.9943 - precision: 0.1755 - recall: 0.3500 - auc: 0.9441 - val_loss: 0.0112 - val_tp: 1.0000 - val_fp: 9.0000 - val_tn: 33901.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1000 - val_recall: 0.0154 - val_auc: 0.6256\n",
      "Epoch 26/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0048 - tp: 137.0000 - fp: 533.0000 - tn: 135024.0000 - fn: 203.0000 - accuracy: 0.9946 - precision: 0.2045 - recall: 0.4029 - auc: 0.9492 - val_loss: 0.0110 - val_tp: 1.0000 - val_fp: 18.0000 - val_tn: 33892.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0526 - val_recall: 0.0154 - val_auc: 0.6433\n",
      "Epoch 27/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0048 - tp: 133.0000 - fp: 592.0000 - tn: 134965.0000 - fn: 207.0000 - accuracy: 0.9941 - precision: 0.1834 - recall: 0.3912 - auc: 0.9500 - val_loss: 0.0121 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 33897.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0714 - val_recall: 0.0154 - val_auc: 0.6122\n",
      "Epoch 28/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0043 - tp: 143.0000 - fp: 556.0000 - tn: 135001.0000 - fn: 197.0000 - accuracy: 0.9945 - precision: 0.2046 - recall: 0.4206 - auc: 0.9604 - val_loss: 0.0124 - val_tp: 1.0000 - val_fp: 19.0000 - val_tn: 33891.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0500 - val_recall: 0.0154 - val_auc: 0.6072\n",
      "Epoch 29/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0043 - tp: 157.0000 - fp: 532.0000 - tn: 135025.0000 - fn: 183.0000 - accuracy: 0.9947 - precision: 0.2279 - recall: 0.4618 - auc: 0.9533 - val_loss: 0.0125 - val_tp: 1.0000 - val_fp: 18.0000 - val_tn: 33892.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0526 - val_recall: 0.0154 - val_auc: 0.6190\n",
      "Epoch 30/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0044 - tp: 166.0000 - fp: 579.0000 - tn: 134978.0000 - fn: 174.0000 - accuracy: 0.9945 - precision: 0.2228 - recall: 0.4882 - auc: 0.9487 - val_loss: 0.0129 - val_tp: 1.0000 - val_fp: 19.0000 - val_tn: 33891.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0500 - val_recall: 0.0154 - val_auc: 0.6062\n",
      "Epoch 31/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0043 - tp: 169.0000 - fp: 545.0000 - tn: 135012.0000 - fn: 171.0000 - accuracy: 0.9947 - precision: 0.2367 - recall: 0.4971 - auc: 0.9513 - val_loss: 0.0132 - val_tp: 1.0000 - val_fp: 25.0000 - val_tn: 33885.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0385 - val_recall: 0.0154 - val_auc: 0.5972\n",
      "Epoch 32/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0041 - tp: 177.0000 - fp: 592.0000 - tn: 134965.0000 - fn: 163.0000 - accuracy: 0.9944 - precision: 0.2302 - recall: 0.5206 - auc: 0.9607 - val_loss: 0.0133 - val_tp: 2.0000 - val_fp: 27.0000 - val_tn: 33883.0000 - val_fn: 63.0000 - val_accuracy: 0.9974 - val_precision: 0.0690 - val_recall: 0.0308 - val_auc: 0.6054\n",
      "Epoch 33/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0039 - tp: 187.0000 - fp: 570.0000 - tn: 134987.0000 - fn: 153.0000 - accuracy: 0.9947 - precision: 0.2470 - recall: 0.5500 - auc: 0.9606 - val_loss: 0.0142 - val_tp: 1.0000 - val_fp: 18.0000 - val_tn: 33892.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0526 - val_recall: 0.0154 - val_auc: 0.5748\n",
      "Epoch 34/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0039 - tp: 187.0000 - fp: 601.0000 - tn: 134956.0000 - fn: 153.0000 - accuracy: 0.9945 - precision: 0.2373 - recall: 0.5500 - auc: 0.9640 - val_loss: 0.0145 - val_tp: 1.0000 - val_fp: 27.0000 - val_tn: 33883.0000 - val_fn: 64.0000 - val_accuracy: 0.9973 - val_precision: 0.0357 - val_recall: 0.0154 - val_auc: 0.5859\n",
      "Epoch 35/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0040 - tp: 188.0000 - fp: 680.0000 - tn: 134877.0000 - fn: 152.0000 - accuracy: 0.9939 - precision: 0.2166 - recall: 0.5529 - auc: 0.9607 - val_loss: 0.0148 - val_tp: 1.0000 - val_fp: 23.0000 - val_tn: 33887.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0417 - val_recall: 0.0154 - val_auc: 0.5744\n",
      "Epoch 36/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0038 - tp: 200.0000 - fp: 641.0000 - tn: 134916.0000 - fn: 140.0000 - accuracy: 0.9943 - precision: 0.2378 - recall: 0.5882 - auc: 0.9659 - val_loss: 0.0158 - val_tp: 1.0000 - val_fp: 30.0000 - val_tn: 33880.0000 - val_fn: 64.0000 - val_accuracy: 0.9972 - val_precision: 0.0323 - val_recall: 0.0154 - val_auc: 0.5869\n",
      "Epoch 37/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0036 - tp: 203.0000 - fp: 554.0000 - tn: 135003.0000 - fn: 137.0000 - accuracy: 0.9949 - precision: 0.2682 - recall: 0.5971 - auc: 0.9680 - val_loss: 0.0159 - val_tp: 1.0000 - val_fp: 35.0000 - val_tn: 33875.0000 - val_fn: 64.0000 - val_accuracy: 0.9971 - val_precision: 0.0278 - val_recall: 0.0154 - val_auc: 0.5753\n",
      "Epoch 38/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0038 - tp: 198.0000 - fp: 670.0000 - tn: 134887.0000 - fn: 142.0000 - accuracy: 0.9940 - precision: 0.2281 - recall: 0.5824 - auc: 0.9613 - val_loss: 0.0159 - val_tp: 1.0000 - val_fp: 35.0000 - val_tn: 33875.0000 - val_fn: 64.0000 - val_accuracy: 0.9971 - val_precision: 0.0278 - val_recall: 0.0154 - val_auc: 0.5893\n",
      "Epoch 39/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0038 - tp: 217.0000 - fp: 786.0000 - tn: 134771.0000 - fn: 123.0000 - accuracy: 0.9933 - precision: 0.2164 - recall: 0.6382 - auc: 0.9659 - val_loss: 0.0160 - val_tp: 1.0000 - val_fp: 32.0000 - val_tn: 33878.0000 - val_fn: 64.0000 - val_accuracy: 0.9972 - val_precision: 0.0303 - val_recall: 0.0154 - val_auc: 0.5676\n",
      "Epoch 40/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0034 - tp: 219.0000 - fp: 586.0000 - tn: 134971.0000 - fn: 121.0000 - accuracy: 0.9948 - precision: 0.2720 - recall: 0.6441 - auc: 0.9723 - val_loss: 0.0171 - val_tp: 3.0000 - val_fp: 28.0000 - val_tn: 33882.0000 - val_fn: 62.0000 - val_accuracy: 0.9974 - val_precision: 0.0968 - val_recall: 0.0462 - val_auc: 0.5868\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0033 - tp: 211.0000 - fp: 634.0000 - tn: 134923.0000 - fn: 129.0000 - accuracy: 0.9944 - precision: 0.2497 - recall: 0.6206 - auc: 0.9737 - val_loss: 0.0177 - val_tp: 1.0000 - val_fp: 20.0000 - val_tn: 33890.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0476 - val_recall: 0.0154 - val_auc: 0.5524\n",
      "Epoch 42/60\n",
      "135897/135897 [==============================] - 1s 10us/sample - loss: 0.0032 - tp: 241.0000 - fp: 607.0000 - tn: 134950.0000 - fn: 99.0000 - accuracy: 0.9948 - precision: 0.2842 - recall: 0.7088 - auc: 0.9745 - val_loss: 0.0187 - val_tp: 1.0000 - val_fp: 19.0000 - val_tn: 33891.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0500 - val_recall: 0.0154 - val_auc: 0.5536\n",
      "Epoch 43/60\n",
      "135897/135897 [==============================] - 1s 10us/sample - loss: 0.0033 - tp: 236.0000 - fp: 602.0000 - tn: 134955.0000 - fn: 104.0000 - accuracy: 0.9948 - precision: 0.2816 - recall: 0.6941 - auc: 0.9682 - val_loss: 0.0187 - val_tp: 2.0000 - val_fp: 24.0000 - val_tn: 33886.0000 - val_fn: 63.0000 - val_accuracy: 0.9974 - val_precision: 0.0769 - val_recall: 0.0308 - val_auc: 0.5480\n",
      "Epoch 44/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0033 - tp: 233.0000 - fp: 521.0000 - tn: 135036.0000 - fn: 107.0000 - accuracy: 0.9954 - precision: 0.3090 - recall: 0.6853 - auc: 0.9673 - val_loss: 0.0193 - val_tp: 2.0000 - val_fp: 26.0000 - val_tn: 33884.0000 - val_fn: 63.0000 - val_accuracy: 0.9974 - val_precision: 0.0714 - val_recall: 0.0308 - val_auc: 0.5399\n",
      "Epoch 45/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0032 - tp: 238.0000 - fp: 577.0000 - tn: 134980.0000 - fn: 102.0000 - accuracy: 0.9950 - precision: 0.2920 - recall: 0.7000 - auc: 0.9727 - val_loss: 0.0196 - val_tp: 1.0000 - val_fp: 26.0000 - val_tn: 33884.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0370 - val_recall: 0.0154 - val_auc: 0.5487\n",
      "Epoch 46/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0032 - tp: 238.0000 - fp: 612.0000 - tn: 134945.0000 - fn: 102.0000 - accuracy: 0.9947 - precision: 0.2800 - recall: 0.7000 - auc: 0.9676 - val_loss: 0.0201 - val_tp: 1.0000 - val_fp: 19.0000 - val_tn: 33891.0000 - val_fn: 64.0000 - val_accuracy: 0.9976 - val_precision: 0.0500 - val_recall: 0.0154 - val_auc: 0.5231\n",
      "Epoch 47/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0031 - tp: 242.0000 - fp: 593.0000 - tn: 134964.0000 - fn: 98.0000 - accuracy: 0.9949 - precision: 0.2898 - recall: 0.7118 - auc: 0.9703 - val_loss: 0.0202 - val_tp: 1.0000 - val_fp: 24.0000 - val_tn: 33886.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0400 - val_recall: 0.0154 - val_auc: 0.5326\n",
      "Epoch 48/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0033 - tp: 236.0000 - fp: 595.0000 - tn: 134962.0000 - fn: 104.0000 - accuracy: 0.9949 - precision: 0.2840 - recall: 0.6941 - auc: 0.9695 - val_loss: 0.0212 - val_tp: 1.0000 - val_fp: 21.0000 - val_tn: 33889.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0455 - val_recall: 0.0154 - val_auc: 0.5356\n",
      "Epoch 49/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0033 - tp: 240.0000 - fp: 575.0000 - tn: 134982.0000 - fn: 100.0000 - accuracy: 0.9950 - precision: 0.2945 - recall: 0.7059 - auc: 0.9614 - val_loss: 0.0205 - val_tp: 1.0000 - val_fp: 23.0000 - val_tn: 33887.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0417 - val_recall: 0.0154 - val_auc: 0.5269\n",
      "Epoch 50/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0029 - tp: 247.0000 - fp: 582.0000 - tn: 134975.0000 - fn: 93.0000 - accuracy: 0.9950 - precision: 0.2979 - recall: 0.7265 - auc: 0.9764 - val_loss: 0.0209 - val_tp: 1.0000 - val_fp: 25.0000 - val_tn: 33885.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0385 - val_recall: 0.0154 - val_auc: 0.5341\n",
      "Epoch 51/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0029 - tp: 248.0000 - fp: 566.0000 - tn: 134991.0000 - fn: 92.0000 - accuracy: 0.9952 - precision: 0.3047 - recall: 0.7294 - auc: 0.9769 - val_loss: 0.0220 - val_tp: 1.0000 - val_fp: 21.0000 - val_tn: 33889.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0455 - val_recall: 0.0154 - val_auc: 0.5285\n",
      "Epoch 52/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0031 - tp: 239.0000 - fp: 605.0000 - tn: 134952.0000 - fn: 101.0000 - accuracy: 0.9948 - precision: 0.2832 - recall: 0.7029 - auc: 0.9758 - val_loss: 0.0215 - val_tp: 2.0000 - val_fp: 36.0000 - val_tn: 33874.0000 - val_fn: 63.0000 - val_accuracy: 0.9971 - val_precision: 0.0526 - val_recall: 0.0308 - val_auc: 0.5430\n",
      "Epoch 53/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0029 - tp: 241.0000 - fp: 535.0000 - tn: 135022.0000 - fn: 99.0000 - accuracy: 0.9953 - precision: 0.3106 - recall: 0.7088 - auc: 0.9808 - val_loss: 0.0223 - val_tp: 1.0000 - val_fp: 25.0000 - val_tn: 33885.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0385 - val_recall: 0.0154 - val_auc: 0.5420\n",
      "Epoch 54/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0030 - tp: 249.0000 - fp: 553.0000 - tn: 135004.0000 - fn: 91.0000 - accuracy: 0.9953 - precision: 0.3105 - recall: 0.7324 - auc: 0.9766 - val_loss: 0.0231 - val_tp: 1.0000 - val_fp: 28.0000 - val_tn: 33882.0000 - val_fn: 64.0000 - val_accuracy: 0.9973 - val_precision: 0.0345 - val_recall: 0.0154 - val_auc: 0.5284\n",
      "Epoch 55/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0030 - tp: 249.0000 - fp: 593.0000 - tn: 134964.0000 - fn: 91.0000 - accuracy: 0.9950 - precision: 0.2957 - recall: 0.7324 - auc: 0.9772 - val_loss: 0.0230 - val_tp: 1.0000 - val_fp: 29.0000 - val_tn: 33881.0000 - val_fn: 64.0000 - val_accuracy: 0.9973 - val_precision: 0.0333 - val_recall: 0.0154 - val_auc: 0.5258\n",
      "Epoch 56/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0030 - tp: 249.0000 - fp: 649.0000 - tn: 134908.0000 - fn: 91.0000 - accuracy: 0.9946 - precision: 0.2773 - recall: 0.7324 - auc: 0.9702 - val_loss: 0.0231 - val_tp: 1.0000 - val_fp: 45.0000 - val_tn: 33865.0000 - val_fn: 64.0000 - val_accuracy: 0.9968 - val_precision: 0.0217 - val_recall: 0.0154 - val_auc: 0.5201\n",
      "Epoch 57/60\n",
      "135897/135897 [==============================] - 2s 11us/sample - loss: 0.0030 - tp: 248.0000 - fp: 579.0000 - tn: 134978.0000 - fn: 92.0000 - accuracy: 0.9951 - precision: 0.2999 - recall: 0.7294 - auc: 0.9768 - val_loss: 0.0231 - val_tp: 1.0000 - val_fp: 27.0000 - val_tn: 33883.0000 - val_fn: 64.0000 - val_accuracy: 0.9973 - val_precision: 0.0357 - val_recall: 0.0154 - val_auc: 0.5165\n",
      "Epoch 58/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0030 - tp: 253.0000 - fp: 602.0000 - tn: 134955.0000 - fn: 87.0000 - accuracy: 0.9949 - precision: 0.2959 - recall: 0.7441 - auc: 0.9749 - val_loss: 0.0234 - val_tp: 1.0000 - val_fp: 22.0000 - val_tn: 33888.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0435 - val_recall: 0.0154 - val_auc: 0.5216\n",
      "Epoch 59/60\n",
      "135897/135897 [==============================] - 2s 12us/sample - loss: 0.0029 - tp: 256.0000 - fp: 553.0000 - tn: 135004.0000 - fn: 84.0000 - accuracy: 0.9953 - precision: 0.3164 - recall: 0.7529 - auc: 0.9723 - val_loss: 0.0238 - val_tp: 1.0000 - val_fp: 56.0000 - val_tn: 33854.0000 - val_fn: 64.0000 - val_accuracy: 0.9965 - val_precision: 0.0175 - val_recall: 0.0154 - val_auc: 0.5348\n",
      "Epoch 60/60\n",
      "135897/135897 [==============================] - 1s 11us/sample - loss: 0.0031 - tp: 253.0000 - fp: 609.0000 - tn: 134948.0000 - fn: 87.0000 - accuracy: 0.9949 - precision: 0.2935 - recall: 0.7441 - auc: 0.9690 - val_loss: 0.0243 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 33897.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0714 - val_recall: 0.0154 - val_auc: 0.5233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17e71a250>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_txt = get_model_txt()\n",
    "model_txt.fit(\n",
    "    x_txt_train, \n",
    "    y_train_47, \n",
    "    validation_data=(x_txt_val, y_val_47), \n",
    "    class_weight={0: 0.05, 1: 0.95}, \n",
    "    epochs=60,\n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_img_top_50():\n",
    "    inp_img = Input(shape=(50,))\n",
    "    x = Dense(64, activation='relu')(inp_img)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs = inp_img, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/20\n",
      "135897/135897 [==============================] - 4s 27us/sample - loss: 0.0162 - tp: 9.0000 - fp: 5211.0000 - tn: 130346.0000 - fn: 331.0000 - accuracy: 0.9592 - precision: 0.0017 - recall: 0.0265 - auc: 0.4956 - val_loss: 0.0086 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5373\n",
      "Epoch 2/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0121 - tp: 0.0000e+00 - fp: 474.0000 - tn: 135083.0000 - fn: 340.0000 - accuracy: 0.9940 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5442 - val_loss: 0.0084 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5504\n",
      "Epoch 3/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0116 - tp: 1.0000 - fp: 265.0000 - tn: 135292.0000 - fn: 339.0000 - accuracy: 0.9956 - precision: 0.0038 - recall: 0.0029 - auc: 0.5628 - val_loss: 0.0083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5544\n",
      "Epoch 4/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0113 - tp: 0.0000e+00 - fp: 160.0000 - tn: 135397.0000 - fn: 340.0000 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5637 - val_loss: 0.0083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5609\n",
      "Epoch 5/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0110 - tp: 0.0000e+00 - fp: 64.0000 - tn: 135493.0000 - fn: 340.0000 - accuracy: 0.9970 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5736 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5612\n",
      "Epoch 6/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0106 - tp: 1.0000 - fp: 47.0000 - tn: 135510.0000 - fn: 339.0000 - accuracy: 0.9972 - precision: 0.0208 - recall: 0.0029 - auc: 0.5931 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5734\n",
      "Epoch 7/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0107 - tp: 0.0000e+00 - fp: 28.0000 - tn: 135529.0000 - fn: 340.0000 - accuracy: 0.9973 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5708 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5797\n",
      "Epoch 8/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0102 - tp: 1.0000 - fp: 16.0000 - tn: 135541.0000 - fn: 339.0000 - accuracy: 0.9974 - precision: 0.0588 - recall: 0.0029 - auc: 0.6239 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5857\n",
      "Epoch 9/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0102 - tp: 0.0000e+00 - fp: 18.0000 - tn: 135539.0000 - fn: 340.0000 - accuracy: 0.9974 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6151 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5888\n",
      "Epoch 10/20\n",
      "135897/135897 [==============================] - 1s 7us/sample - loss: 0.0101 - tp: 0.0000e+00 - fp: 8.0000 - tn: 135549.0000 - fn: 340.0000 - accuracy: 0.9974 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6161 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5860\n",
      "Epoch 11/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0100 - tp: 0.0000e+00 - fp: 5.0000 - tn: 135552.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6397 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5823\n",
      "Epoch 12/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0101 - tp: 0.0000e+00 - fp: 5.0000 - tn: 135552.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6157 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5759\n",
      "Epoch 13/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0098 - tp: 0.0000e+00 - fp: 2.0000 - tn: 135555.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6390 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5805\n",
      "Epoch 14/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0097 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 135557.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6529 - val_loss: 0.0082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5821\n",
      "Epoch 15/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 135557.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6712 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5825\n",
      "Epoch 16/20\n",
      "135897/135897 [==============================] - 1s 9us/sample - loss: 0.0095 - tp: 0.0000e+00 - fp: 1.0000 - tn: 135556.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6624 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5838\n",
      "Epoch 17/20\n",
      "135897/135897 [==============================] - 1s 8us/sample - loss: 0.0095 - tp: 0.0000e+00 - fp: 1.0000 - tn: 135556.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6591 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5871\n",
      "Epoch 18/20\n",
      "135897/135897 [==============================] - 1s 6us/sample - loss: 0.0095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 135557.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6740 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5828\n",
      "Epoch 19/20\n",
      "135897/135897 [==============================] - 1s 6us/sample - loss: 0.0093 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 135557.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6955 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5879\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135897/135897 [==============================] - 1s 6us/sample - loss: 0.0095 - tp: 0.0000e+00 - fp: 1.0000 - tn: 135556.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6701 - val_loss: 0.0081 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17e482390>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_img_top_50 = get_model_img_top_50()\n",
    "model_img_top_50.fit(\n",
    "    x_img_train_top_50, \n",
    "    y_train_47, \n",
    "    validation_data=(x_img_val_top_50, y_val_47), \n",
    "    class_weight={0: 0.05, 1: 0.95}, \n",
    "    epochs=20,\n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS_NAMES = [\n",
    "    'tp',\n",
    "    'fp',\n",
    "    'tn',\n",
    "    'fn',\n",
    "    'accuracy',\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'auc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_class_47():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x_img = Dense(512, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "135897/135897 [==============================] - 19s 143us/sample - loss: 0.0823 - tp: 6.0000 - fp: 1880.0000 - tn: 133677.0000 - fn: 334.0000 - accuracy: 0.9837 - precision: 0.0032 - recall: 0.0176 - auc: 0.5044 - val_loss: 0.0425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 2/30\n",
      "135897/135897 [==============================] - 8s 57us/sample - loss: 0.0407 - tp: 0.0000e+00 - fp: 4.0000 - tn: 135553.0000 - fn: 340.0000 - accuracy: 0.9975 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.0245 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5263\n",
      "Epoch 3/30\n",
      "135897/135897 [==============================] - 8s 55us/sample - loss: 0.0249 - tp: 0.0000e+00 - fp: 45.0000 - tn: 135512.0000 - fn: 340.0000 - accuracy: 0.9972 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5746 - val_loss: 0.0187 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5394\n",
      "Epoch 4/30\n",
      "135897/135897 [==============================] - 10s 77us/sample - loss: 0.0201 - tp: 2.0000 - fp: 31.0000 - tn: 135526.0000 - fn: 338.0000 - accuracy: 0.9973 - precision: 0.0606 - recall: 0.0059 - auc: 0.6566 - val_loss: 0.0171 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5229\n",
      "Epoch 5/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0182 - tp: 4.0000 - fp: 18.0000 - tn: 135539.0000 - fn: 336.0000 - accuracy: 0.9974 - precision: 0.1818 - recall: 0.0118 - auc: 0.6713 - val_loss: 0.0164 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5395\n",
      "Epoch 6/30\n",
      "135897/135897 [==============================] - 8s 61us/sample - loss: 0.0165 - tp: 1.0000 - fp: 17.0000 - tn: 135540.0000 - fn: 339.0000 - accuracy: 0.9974 - precision: 0.0556 - recall: 0.0029 - auc: 0.7246 - val_loss: 0.0164 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5396\n",
      "Epoch 7/30\n",
      "135897/135897 [==============================] - 9s 65us/sample - loss: 0.0163 - tp: 2.0000 - fp: 19.0000 - tn: 135538.0000 - fn: 338.0000 - accuracy: 0.9974 - precision: 0.0952 - recall: 0.0059 - auc: 0.7318 - val_loss: 0.0158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5432\n",
      "Epoch 8/30\n",
      "135897/135897 [==============================] - 10s 73us/sample - loss: 0.0147 - tp: 5.0000 - fp: 14.0000 - tn: 135543.0000 - fn: 335.0000 - accuracy: 0.9974 - precision: 0.2632 - recall: 0.0147 - auc: 0.7843 - val_loss: 0.0156 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5593\n",
      "Epoch 9/30\n",
      "135897/135897 [==============================] - 9s 69us/sample - loss: 0.0140 - tp: 5.0000 - fp: 13.0000 - tn: 135544.0000 - fn: 335.0000 - accuracy: 0.9974 - precision: 0.2778 - recall: 0.0147 - auc: 0.8109 - val_loss: 0.0161 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5369\n",
      "Epoch 10/30\n",
      "135897/135897 [==============================] - 10s 75us/sample - loss: 0.0132 - tp: 7.0000 - fp: 12.0000 - tn: 135545.0000 - fn: 333.0000 - accuracy: 0.9975 - precision: 0.3684 - recall: 0.0206 - auc: 0.8286 - val_loss: 0.0162 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5447\n",
      "Epoch 11/30\n",
      "135897/135897 [==============================] - 10s 77us/sample - loss: 0.0123 - tp: 17.0000 - fp: 15.0000 - tn: 135542.0000 - fn: 323.0000 - accuracy: 0.9975 - precision: 0.5312 - recall: 0.0500 - auc: 0.8523 - val_loss: 0.0159 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5495\n",
      "Epoch 12/30\n",
      "135897/135897 [==============================] - 12s 88us/sample - loss: 0.0117 - tp: 27.0000 - fp: 20.0000 - tn: 135537.0000 - fn: 313.0000 - accuracy: 0.9975 - precision: 0.5745 - recall: 0.0794 - auc: 0.8649 - val_loss: 0.0170 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5398\n",
      "Epoch 13/30\n",
      "135897/135897 [==============================] - 10s 74us/sample - loss: 0.0116 - tp: 27.0000 - fp: 19.0000 - tn: 135538.0000 - fn: 313.0000 - accuracy: 0.9976 - precision: 0.5870 - recall: 0.0794 - auc: 0.8727 - val_loss: 0.0165 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5593\n",
      "Epoch 14/30\n",
      "135897/135897 [==============================] - 9s 69us/sample - loss: 0.0103 - tp: 38.0000 - fp: 8.0000 - tn: 135549.0000 - fn: 302.0000 - accuracy: 0.9977 - precision: 0.8261 - recall: 0.1118 - auc: 0.8974 - val_loss: 0.0169 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5441\n",
      "Epoch 15/30\n",
      "135897/135897 [==============================] - 10s 70us/sample - loss: 0.0096 - tp: 62.0000 - fp: 17.0000 - tn: 135540.0000 - fn: 278.0000 - accuracy: 0.9978 - precision: 0.7848 - recall: 0.1824 - auc: 0.9129 - val_loss: 0.0178 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5389\n",
      "Epoch 16/30\n",
      "135897/135897 [==============================] - 11s 79us/sample - loss: 0.0094 - tp: 60.0000 - fp: 21.0000 - tn: 135536.0000 - fn: 280.0000 - accuracy: 0.9978 - precision: 0.7407 - recall: 0.1765 - auc: 0.9218 - val_loss: 0.0179 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5465\n",
      "Epoch 17/30\n",
      "135897/135897 [==============================] - 11s 82us/sample - loss: 0.0082 - tp: 82.0000 - fp: 18.0000 - tn: 135539.0000 - fn: 258.0000 - accuracy: 0.9980 - precision: 0.8200 - recall: 0.2412 - auc: 0.9381 - val_loss: 0.0182 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5390\n",
      "Epoch 18/30\n",
      "135897/135897 [==============================] - 11s 79us/sample - loss: 0.0077 - tp: 113.0000 - fp: 26.0000 - tn: 135531.0000 - fn: 227.0000 - accuracy: 0.9981 - precision: 0.8129 - recall: 0.3324 - auc: 0.9447 - val_loss: 0.0195 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5337\n",
      "Epoch 19/30\n",
      "135897/135897 [==============================] - 9s 66us/sample - loss: 0.0077 - tp: 105.0000 - fp: 28.0000 - tn: 135529.0000 - fn: 235.0000 - accuracy: 0.9981 - precision: 0.7895 - recall: 0.3088 - auc: 0.9396 - val_loss: 0.0199 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5346\n",
      "Epoch 20/30\n",
      "135897/135897 [==============================] - 10s 72us/sample - loss: 0.0068 - tp: 126.0000 - fp: 22.0000 - tn: 135535.0000 - fn: 214.0000 - accuracy: 0.9983 - precision: 0.8514 - recall: 0.3706 - auc: 0.9575 - val_loss: 0.0202 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0059 - tp: 149.0000 - fp: 23.0000 - tn: 135534.0000 - fn: 191.0000 - accuracy: 0.9984 - precision: 0.8663 - recall: 0.4382 - auc: 0.9568 - val_loss: 0.0205 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5416\n",
      "Epoch 22/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0061 - tp: 143.0000 - fp: 36.0000 - tn: 135521.0000 - fn: 197.0000 - accuracy: 0.9983 - precision: 0.7989 - recall: 0.4206 - auc: 0.9537 - val_loss: 0.0216 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5267\n",
      "Epoch 23/30\n",
      "135897/135897 [==============================] - 9s 66us/sample - loss: 0.0054 - tp: 170.0000 - fp: 23.0000 - tn: 135534.0000 - fn: 170.0000 - accuracy: 0.9986 - precision: 0.8808 - recall: 0.5000 - auc: 0.9663 - val_loss: 0.0221 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5345\n",
      "Epoch 24/30\n",
      "135897/135897 [==============================] - 9s 65us/sample - loss: 0.0049 - tp: 188.0000 - fp: 29.0000 - tn: 135528.0000 - fn: 152.0000 - accuracy: 0.9987 - precision: 0.8664 - recall: 0.5529 - auc: 0.9713 - val_loss: 0.0229 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5350\n",
      "Epoch 25/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0049 - tp: 191.0000 - fp: 29.0000 - tn: 135528.0000 - fn: 149.0000 - accuracy: 0.9987 - precision: 0.8682 - recall: 0.5618 - auc: 0.9685 - val_loss: 0.0236 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5359\n",
      "Epoch 26/30\n",
      "135897/135897 [==============================] - 9s 64us/sample - loss: 0.0043 - tp: 210.0000 - fp: 24.0000 - tn: 135533.0000 - fn: 130.0000 - accuracy: 0.9989 - precision: 0.8974 - recall: 0.6176 - auc: 0.9691 - val_loss: 0.0254 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5286\n",
      "Epoch 27/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0045 - tp: 210.0000 - fp: 41.0000 - tn: 135516.0000 - fn: 130.0000 - accuracy: 0.9987 - precision: 0.8367 - recall: 0.6176 - auc: 0.9718 - val_loss: 0.0249 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5281\n",
      "Epoch 28/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0045 - tp: 218.0000 - fp: 37.0000 - tn: 135520.0000 - fn: 122.0000 - accuracy: 0.9988 - precision: 0.8549 - recall: 0.6412 - auc: 0.9675 - val_loss: 0.0262 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5211\n",
      "Epoch 29/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0042 - tp: 207.0000 - fp: 30.0000 - tn: 135527.0000 - fn: 133.0000 - accuracy: 0.9988 - precision: 0.8734 - recall: 0.6088 - auc: 0.9752 - val_loss: 0.0264 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5289\n",
      "Epoch 30/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0037 - tp: 229.0000 - fp: 30.0000 - tn: 135527.0000 - fn: 111.0000 - accuracy: 0.9990 - precision: 0.8842 - recall: 0.6735 - auc: 0.9782 - val_loss: 0.0262 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21919e4d0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_47 = get_model_class_47()\n",
    "model_47.fit(\n",
    "    [x_img_train, x_txt_train], \n",
    "    y_train_47, \n",
    "    epochs=30, \n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47), \n",
    "    batch_size=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     42468\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00     42468\n",
      "   macro avg       0.50      0.50      0.50     42468\n",
      "weighted avg       1.00      1.00      1.00     42468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_47 = model_47.predict([x_img_test, x_txt_test])\n",
    "print(classification_report(np.argmax(y_pred_47, axis=1), y_test_class_47))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9885339], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_pred_47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8265843e-04, 2.2479892e-04, 2.3168325e-04, ..., 9.7869611e-01,\n",
       "       9.8012865e-01, 9.8853391e-01], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred_47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_47 = (y_pred_47 < 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     42468\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00     42468\n",
      "   macro avg       0.50      0.50      0.50     42468\n",
      "weighted avg       1.00      1.00      1.00     42468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(labels_47, axis=1), y_test_class_47))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3381])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((labels_47 == 0).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = model_47.evaluate([x_img_test, x_txt_test], y_test_class_47, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tp', 'fp', 'tn', 'fn', 'accuracy', 'precision', 'recall', 'auc']\n"
     ]
    }
   ],
   "source": [
    "print(METRICS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.027148785302560777, 1.0, 64.0, 42305.0, 98.0, 0.99618536, 0.015384615, 0.01010101, 0.5595725]\n"
     ]
    }
   ],
   "source": [
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 169872\n",
      "    Positive: 404 (0.24% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(y_train_class_47.astype(np.int))\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.bincount(y_train_class_47.astype(np.int))[1]\n",
    "neg = len(y_train) - pos\n",
    "init_bias = np.log([pos / neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.03900452])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_class_47_1():\n",
    "    output_bias = tf.keras.initializers.Constant(init_bias)\n",
    "    \n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x_img = Dense(512, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid',  bias_initializer=output_bias)(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "135897/135897 [==============================] - 22s 163us/sample - loss: 0.0542 - tp: 1.0000 - fp: 271.0000 - tn: 135286.0000 - fn: 339.0000 - accuracy: 0.9955 - precision: 0.0037 - recall: 0.0029 - auc: 0.4989 - val_loss: 0.0280 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5053\n",
      "Epoch 2/30\n",
      "135897/135897 [==============================] - 9s 65us/sample - loss: 0.0252 - tp: 0.0000e+00 - fp: 64.0000 - tn: 135493.0000 - fn: 340.0000 - accuracy: 0.9970 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5524 - val_loss: 0.0159 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5275\n",
      "Epoch 3/30\n",
      "135897/135897 [==============================] - 7s 51us/sample - loss: 0.0197 - tp: 4.0000 - fp: 32.0000 - tn: 135525.0000 - fn: 336.0000 - accuracy: 0.9973 - precision: 0.1111 - recall: 0.0118 - auc: 0.6121 - val_loss: 0.0158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5273\n",
      "Epoch 4/30\n",
      "135897/135897 [==============================] - 8s 56us/sample - loss: 0.0179 - tp: 3.0000 - fp: 24.0000 - tn: 135533.0000 - fn: 337.0000 - accuracy: 0.9973 - precision: 0.1111 - recall: 0.0088 - auc: 0.6601 - val_loss: 0.0150 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5332\n",
      "Epoch 5/30\n",
      "135897/135897 [==============================] - 9s 66us/sample - loss: 0.0181 - tp: 4.0000 - fp: 37.0000 - tn: 135520.0000 - fn: 336.0000 - accuracy: 0.9973 - precision: 0.0976 - recall: 0.0118 - auc: 0.6608 - val_loss: 0.0158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5400\n",
      "Epoch 6/30\n",
      "135897/135897 [==============================] - 9s 69us/sample - loss: 0.0169 - tp: 6.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 334.0000 - accuracy: 0.9973 - precision: 0.1364 - recall: 0.0176 - auc: 0.7104 - val_loss: 0.0157 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5486\n",
      "Epoch 7/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0154 - tp: 11.0000 - fp: 40.0000 - tn: 135517.0000 - fn: 329.0000 - accuracy: 0.9973 - precision: 0.2157 - recall: 0.0324 - auc: 0.7591 - val_loss: 0.0164 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5278\n",
      "Epoch 8/30\n",
      "135897/135897 [==============================] - 9s 63us/sample - loss: 0.0141 - tp: 14.0000 - fp: 40.0000 - tn: 135517.0000 - fn: 326.0000 - accuracy: 0.9973 - precision: 0.2593 - recall: 0.0412 - auc: 0.7934 - val_loss: 0.0154 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5769\n",
      "Epoch 9/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0138 - tp: 26.0000 - fp: 37.0000 - tn: 135520.0000 - fn: 314.0000 - accuracy: 0.9974 - precision: 0.4127 - recall: 0.0765 - auc: 0.8013 - val_loss: 0.0172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5432\n",
      "Epoch 10/30\n",
      "135897/135897 [==============================] - 9s 64us/sample - loss: 0.0123 - tp: 45.0000 - fp: 26.0000 - tn: 135531.0000 - fn: 295.0000 - accuracy: 0.9976 - precision: 0.6338 - recall: 0.1324 - auc: 0.8394 - val_loss: 0.0176 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5582\n",
      "Epoch 11/30\n",
      "135897/135897 [==============================] - 9s 65us/sample - loss: 0.0115 - tp: 48.0000 - fp: 48.0000 - tn: 135509.0000 - fn: 292.0000 - accuracy: 0.9975 - precision: 0.5000 - recall: 0.1412 - auc: 0.8602 - val_loss: 0.0181 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5505\n",
      "Epoch 12/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0103 - tp: 60.0000 - fp: 40.0000 - tn: 135517.0000 - fn: 280.0000 - accuracy: 0.9976 - precision: 0.6000 - recall: 0.1765 - auc: 0.8949 - val_loss: 0.0186 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5501\n",
      "Epoch 13/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0093 - tp: 89.0000 - fp: 47.0000 - tn: 135510.0000 - fn: 251.0000 - accuracy: 0.9978 - precision: 0.6544 - recall: 0.2618 - auc: 0.8922 - val_loss: 0.0185 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5501\n",
      "Epoch 14/30\n",
      "135897/135897 [==============================] - 10s 77us/sample - loss: 0.0091 - tp: 91.0000 - fp: 49.0000 - tn: 135508.0000 - fn: 249.0000 - accuracy: 0.9978 - precision: 0.6500 - recall: 0.2676 - auc: 0.9071 - val_loss: 0.0204 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5209\n",
      "Epoch 15/30\n",
      "135897/135897 [==============================] - 8s 61us/sample - loss: 0.0080 - tp: 120.0000 - fp: 50.0000 - tn: 135507.0000 - fn: 220.0000 - accuracy: 0.9980 - precision: 0.7059 - recall: 0.3529 - auc: 0.9352 - val_loss: 0.0213 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5288\n",
      "Epoch 16/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0076 - tp: 130.0000 - fp: 50.0000 - tn: 135507.0000 - fn: 210.0000 - accuracy: 0.9981 - precision: 0.7222 - recall: 0.3824 - auc: 0.9325 - val_loss: 0.0229 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5213\n",
      "Epoch 17/30\n",
      "135897/135897 [==============================] - 12s 90us/sample - loss: 0.0068 - tp: 147.0000 - fp: 40.0000 - tn: 135517.0000 - fn: 193.0000 - accuracy: 0.9983 - precision: 0.7861 - recall: 0.4324 - auc: 0.9432 - val_loss: 0.0234 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5295\n",
      "Epoch 18/30\n",
      "135897/135897 [==============================] - 10s 75us/sample - loss: 0.0066 - tp: 162.0000 - fp: 47.0000 - tn: 135510.0000 - fn: 178.0000 - accuracy: 0.9983 - precision: 0.7751 - recall: 0.4765 - auc: 0.9466 - val_loss: 0.0237 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5293\n",
      "Epoch 19/30\n",
      "135897/135897 [==============================] - 10s 73us/sample - loss: 0.0062 - tp: 157.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 183.0000 - accuracy: 0.9983 - precision: 0.7772 - recall: 0.4618 - auc: 0.9543 - val_loss: 0.0233 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5360\n",
      "Epoch 20/30\n",
      "135897/135897 [==============================] - 10s 73us/sample - loss: 0.0058 - tp: 187.0000 - fp: 40.0000 - tn: 135517.0000 - fn: 153.0000 - accuracy: 0.9986 - precision: 0.8238 - recall: 0.5500 - auc: 0.9548 - val_loss: 0.0253 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "135897/135897 [==============================] - 10s 72us/sample - loss: 0.0055 - tp: 185.0000 - fp: 44.0000 - tn: 135513.0000 - fn: 155.0000 - accuracy: 0.9985 - precision: 0.8079 - recall: 0.5441 - auc: 0.9555 - val_loss: 0.0247 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5359\n",
      "Epoch 22/30\n",
      "135897/135897 [==============================] - 9s 69us/sample - loss: 0.0047 - tp: 207.0000 - fp: 46.0000 - tn: 135511.0000 - fn: 133.0000 - accuracy: 0.9987 - precision: 0.8182 - recall: 0.6088 - auc: 0.9733 - val_loss: 0.0266 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5369\n",
      "Epoch 23/30\n",
      "135897/135897 [==============================] - 10s 73us/sample - loss: 0.0049 - tp: 197.0000 - fp: 43.0000 - tn: 135514.0000 - fn: 143.0000 - accuracy: 0.9986 - precision: 0.8208 - recall: 0.5794 - auc: 0.9630 - val_loss: 0.0264 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5368\n",
      "Epoch 24/30\n",
      "135897/135897 [==============================] - 10s 77us/sample - loss: 0.0045 - tp: 211.0000 - fp: 50.0000 - tn: 135507.0000 - fn: 129.0000 - accuracy: 0.9987 - precision: 0.8084 - recall: 0.6206 - auc: 0.9734 - val_loss: 0.0260 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5368\n",
      "Epoch 25/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0043 - tp: 225.0000 - fp: 46.0000 - tn: 135511.0000 - fn: 115.0000 - accuracy: 0.9988 - precision: 0.8303 - recall: 0.6618 - auc: 0.9679 - val_loss: 0.0270 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5366\n",
      "Epoch 26/30\n",
      "135897/135897 [==============================] - 10s 74us/sample - loss: 0.0041 - tp: 233.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 107.0000 - accuracy: 0.9989 - precision: 0.8566 - recall: 0.6853 - auc: 0.9695 - val_loss: 0.0274 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5370\n",
      "Epoch 27/30\n",
      "135897/135897 [==============================] - 9s 69us/sample - loss: 0.0041 - tp: 210.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 130.0000 - accuracy: 0.9988 - precision: 0.8468 - recall: 0.6176 - auc: 0.9770 - val_loss: 0.0281 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5350\n",
      "Epoch 28/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0036 - tp: 239.0000 - fp: 41.0000 - tn: 135516.0000 - fn: 101.0000 - accuracy: 0.9990 - precision: 0.8536 - recall: 0.7029 - auc: 0.9742 - val_loss: 0.0297 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5371\n",
      "Epoch 29/30\n",
      "135897/135897 [==============================] - 10s 74us/sample - loss: 0.0033 - tp: 248.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 92.0000 - accuracy: 0.9990 - precision: 0.8671 - recall: 0.7294 - auc: 0.9729 - val_loss: 0.0316 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5224\n",
      "Epoch 30/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0028 - tp: 254.0000 - fp: 23.0000 - tn: 135534.0000 - fn: 86.0000 - accuracy: 0.9992 - precision: 0.9170 - recall: 0.7471 - auc: 0.9818 - val_loss: 0.0310 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5144\n"
     ]
    }
   ],
   "source": [
    "model_47_1 = get_model_class_47_1()\n",
    "history_1 = model_47_1.fit(\n",
    "    [x_img_train, x_txt_train], \n",
    "    y_train_47, \n",
    "    epochs=30, \n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47), \n",
    "    batch_size=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "135897/135897 [==============================] - 8s 59us/sample - loss: 0.0027 - tp: 265.0000 - fp: 34.0000 - tn: 135523.0000 - fn: 75.0000 - accuracy: 0.9992 - precision: 0.8863 - recall: 0.7794 - auc: 0.9804 - val_loss: 0.0319 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5296\n",
      "Epoch 2/30\n",
      "135897/135897 [==============================] - 7s 55us/sample - loss: 0.0027 - tp: 270.0000 - fp: 34.0000 - tn: 135523.0000 - fn: 70.0000 - accuracy: 0.9992 - precision: 0.8882 - recall: 0.7941 - auc: 0.9790 - val_loss: 0.0323 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 3/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0025 - tp: 271.0000 - fp: 28.0000 - tn: 135529.0000 - fn: 69.0000 - accuracy: 0.9993 - precision: 0.9064 - recall: 0.7971 - auc: 0.9849 - val_loss: 0.0342 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5221\n",
      "Epoch 4/30\n",
      "135897/135897 [==============================] - 10s 70us/sample - loss: 0.0023 - tp: 268.0000 - fp: 25.0000 - tn: 135532.0000 - fn: 72.0000 - accuracy: 0.9993 - precision: 0.9147 - recall: 0.7882 - auc: 0.9894 - val_loss: 0.0345 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5300\n",
      "Epoch 5/30\n",
      "135897/135897 [==============================] - 9s 63us/sample - loss: 0.0032 - tp: 260.0000 - fp: 27.0000 - tn: 135530.0000 - fn: 80.0000 - accuracy: 0.9992 - precision: 0.9059 - recall: 0.7647 - auc: 0.9716 - val_loss: 0.0336 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5220\n",
      "Epoch 6/30\n",
      "135897/135897 [==============================] - 10s 76us/sample - loss: 0.0033 - tp: 263.0000 - fp: 34.0000 - tn: 135523.0000 - fn: 77.0000 - accuracy: 0.9992 - precision: 0.8855 - recall: 0.7735 - auc: 0.9730 - val_loss: 0.0334 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5068\n",
      "Epoch 7/30\n",
      "135897/135897 [==============================] - 11s 82us/sample - loss: 0.0025 - tp: 273.0000 - fp: 26.0000 - tn: 135531.0000 - fn: 67.0000 - accuracy: 0.9993 - precision: 0.9130 - recall: 0.8029 - auc: 0.9835 - val_loss: 0.0336 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5145\n",
      "Epoch 8/30\n",
      "135897/135897 [==============================] - 11s 79us/sample - loss: 0.0022 - tp: 271.0000 - fp: 28.0000 - tn: 135529.0000 - fn: 69.0000 - accuracy: 0.9993 - precision: 0.9064 - recall: 0.7971 - auc: 0.9864 - val_loss: 0.0344 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5144\n",
      "Epoch 9/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0023 - tp: 273.0000 - fp: 32.0000 - tn: 135525.0000 - fn: 67.0000 - accuracy: 0.9993 - precision: 0.8951 - recall: 0.8029 - auc: 0.9894 - val_loss: 0.0357 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5302\n",
      "Epoch 10/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0021 - tp: 277.0000 - fp: 19.0000 - tn: 135538.0000 - fn: 63.0000 - accuracy: 0.9994 - precision: 0.9358 - recall: 0.8147 - auc: 0.9895 - val_loss: 0.0357 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 11/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0023 - tp: 275.0000 - fp: 23.0000 - tn: 135534.0000 - fn: 65.0000 - accuracy: 0.9994 - precision: 0.9228 - recall: 0.8088 - auc: 0.9879 - val_loss: 0.0334 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5295\n",
      "Epoch 12/30\n",
      "135897/135897 [==============================] - 10s 70us/sample - loss: 0.0024 - tp: 282.0000 - fp: 31.0000 - tn: 135526.0000 - fn: 58.0000 - accuracy: 0.9993 - precision: 0.9010 - recall: 0.8294 - auc: 0.9820 - val_loss: 0.0357 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5222\n",
      "Epoch 13/30\n",
      "135897/135897 [==============================] - 10s 72us/sample - loss: 0.0020 - tp: 279.0000 - fp: 17.0000 - tn: 135540.0000 - fn: 61.0000 - accuracy: 0.9994 - precision: 0.9426 - recall: 0.8206 - auc: 0.9924 - val_loss: 0.0359 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5301\n",
      "Epoch 14/30\n",
      "135897/135897 [==============================] - 10s 75us/sample - loss: 0.0023 - tp: 282.0000 - fp: 25.0000 - tn: 135532.0000 - fn: 58.0000 - accuracy: 0.9994 - precision: 0.9186 - recall: 0.8294 - auc: 0.9864 - val_loss: 0.0356 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5068\n",
      "Epoch 15/30\n",
      "135897/135897 [==============================] - 11s 80us/sample - loss: 0.0019 - tp: 285.0000 - fp: 24.0000 - tn: 135533.0000 - fn: 55.0000 - accuracy: 0.9994 - precision: 0.9223 - recall: 0.8382 - auc: 0.9895 - val_loss: 0.0375 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 16/30\n",
      "135897/135897 [==============================] - 12s 88us/sample - loss: 0.0019 - tp: 286.0000 - fp: 21.0000 - tn: 135536.0000 - fn: 54.0000 - accuracy: 0.9994 - precision: 0.9316 - recall: 0.8412 - auc: 0.9880 - val_loss: 0.0371 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 17/30\n",
      "135897/135897 [==============================] - 10s 73us/sample - loss: 0.0025 - tp: 277.0000 - fp: 31.0000 - tn: 135526.0000 - fn: 63.0000 - accuracy: 0.9993 - precision: 0.8994 - recall: 0.8147 - auc: 0.9894 - val_loss: 0.0381 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5149\n",
      "Epoch 18/30\n",
      "135897/135897 [==============================] - 10s 73us/sample - loss: 0.0026 - tp: 281.0000 - fp: 29.0000 - tn: 135528.0000 - fn: 59.0000 - accuracy: 0.9994 - precision: 0.9065 - recall: 0.8265 - auc: 0.9821 - val_loss: 0.0384 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 19/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0016 - tp: 293.0000 - fp: 22.0000 - tn: 135535.0000 - fn: 47.0000 - accuracy: 0.9995 - precision: 0.9302 - recall: 0.8618 - auc: 0.9939 - val_loss: 0.0369 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 20/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0015 - tp: 295.0000 - fp: 15.0000 - tn: 135542.0000 - fn: 45.0000 - accuracy: 0.9996 - precision: 0.9516 - recall: 0.8676 - auc: 0.9969 - val_loss: 0.0381 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5223\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0016 - tp: 294.0000 - fp: 21.0000 - tn: 135536.0000 - fn: 46.0000 - accuracy: 0.9995 - precision: 0.9333 - recall: 0.8647 - auc: 0.9881 - val_loss: 0.0387 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5223\n",
      "Epoch 22/30\n",
      "135897/135897 [==============================] - 9s 70us/sample - loss: 0.0017 - tp: 295.0000 - fp: 17.0000 - tn: 135540.0000 - fn: 45.0000 - accuracy: 0.9995 - precision: 0.9455 - recall: 0.8676 - auc: 0.9910 - val_loss: 0.0379 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5222\n",
      "Epoch 23/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0015 - tp: 297.0000 - fp: 16.0000 - tn: 135541.0000 - fn: 43.0000 - accuracy: 0.9996 - precision: 0.9489 - recall: 0.8735 - auc: 0.9925 - val_loss: 0.0390 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5225\n",
      "Epoch 24/30\n",
      "135897/135897 [==============================] - 10s 70us/sample - loss: 0.0018 - tp: 299.0000 - fp: 17.0000 - tn: 135540.0000 - fn: 41.0000 - accuracy: 0.9996 - precision: 0.9462 - recall: 0.8794 - auc: 0.9896 - val_loss: 0.0391 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5223\n",
      "Epoch 25/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0017 - tp: 297.0000 - fp: 25.0000 - tn: 135532.0000 - fn: 43.0000 - accuracy: 0.9995 - precision: 0.9224 - recall: 0.8735 - auc: 0.9954 - val_loss: 0.0401 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 26/30\n",
      "135897/135897 [==============================] - 10s 70us/sample - loss: 0.0015 - tp: 297.0000 - fp: 21.0000 - tn: 135536.0000 - fn: 43.0000 - accuracy: 0.9995 - precision: 0.9340 - recall: 0.8735 - auc: 0.9940 - val_loss: 0.0399 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5227\n",
      "Epoch 27/30\n",
      "135897/135897 [==============================] - 9s 68us/sample - loss: 0.0016 - tp: 300.0000 - fp: 17.0000 - tn: 135540.0000 - fn: 40.0000 - accuracy: 0.9996 - precision: 0.9464 - recall: 0.8824 - auc: 0.9896 - val_loss: 0.0394 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5225\n",
      "Epoch 28/30\n",
      "135897/135897 [==============================] - 9s 66us/sample - loss: 0.0016 - tp: 302.0000 - fp: 12.0000 - tn: 135545.0000 - fn: 38.0000 - accuracy: 0.9996 - precision: 0.9618 - recall: 0.8882 - auc: 0.9881 - val_loss: 0.0400 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5222\n",
      "Epoch 29/30\n",
      "135897/135897 [==============================] - 10s 71us/sample - loss: 0.0021 - tp: 286.0000 - fp: 26.0000 - tn: 135531.0000 - fn: 54.0000 - accuracy: 0.9994 - precision: 0.9167 - recall: 0.8412 - auc: 0.9924 - val_loss: 0.0401 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5150\n",
      "Epoch 30/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0023 - tp: 277.0000 - fp: 29.0000 - tn: 135528.0000 - fn: 63.0000 - accuracy: 0.9993 - precision: 0.9052 - recall: 0.8147 - auc: 0.9835 - val_loss: 0.0409 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5222\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_47_1.fit(\n",
    "    [x_img_train, x_txt_train], \n",
    "    y_train_47, \n",
    "    epochs=30, \n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47), \n",
    "    batch_size=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0342 - tp: 2.0000 - fp: 123.0000 - tn: 135434.0000 - fn: 338.0000 - accuracy: 0.9966 - precision: 0.0160 - recall: 0.0059 - auc: 0.5264 - val_loss: 0.0158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5194\n",
      "Epoch 2/30\n",
      "135897/135897 [==============================] - 8s 58us/sample - loss: 0.0214 - tp: 1.0000 - fp: 31.0000 - tn: 135526.0000 - fn: 339.0000 - accuracy: 0.9973 - precision: 0.0312 - recall: 0.0029 - auc: 0.5802 - val_loss: 0.0146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5362\n",
      "Epoch 3/30\n",
      "135897/135897 [==============================] - 8s 61us/sample - loss: 0.0194 - tp: 0.0000e+00 - fp: 31.0000 - tn: 135526.0000 - fn: 340.0000 - accuracy: 0.9973 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6244 - val_loss: 0.0153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5419\n",
      "Epoch 4/30\n",
      "135897/135897 [==============================] - 9s 67us/sample - loss: 0.0171 - tp: 6.0000 - fp: 27.0000 - tn: 135530.0000 - fn: 334.0000 - accuracy: 0.9973 - precision: 0.1818 - recall: 0.0176 - auc: 0.6764 - val_loss: 0.0151 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5323\n",
      "Epoch 5/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0161 - tp: 10.0000 - fp: 14.0000 - tn: 135543.0000 - fn: 330.0000 - accuracy: 0.9975 - precision: 0.4167 - recall: 0.0294 - auc: 0.7261 - val_loss: 0.0147 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5582\n",
      "Epoch 6/30\n",
      "135897/135897 [==============================] - 14s 103us/sample - loss: 0.0148 - tp: 6.0000 - fp: 35.0000 - tn: 135522.0000 - fn: 334.0000 - accuracy: 0.9973 - precision: 0.1463 - recall: 0.0176 - auc: 0.7576 - val_loss: 0.0147 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5562\n",
      "Epoch 7/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0139 - tp: 16.0000 - fp: 27.0000 - tn: 135530.0000 - fn: 324.0000 - accuracy: 0.9974 - precision: 0.3721 - recall: 0.0471 - auc: 0.7967 - val_loss: 0.0159 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5309\n",
      "Epoch 8/30\n",
      "135897/135897 [==============================] - 11s 84us/sample - loss: 0.0120 - tp: 25.0000 - fp: 24.0000 - tn: 135533.0000 - fn: 315.0000 - accuracy: 0.9975 - precision: 0.5102 - recall: 0.0735 - auc: 0.8541 - val_loss: 0.0155 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5500\n",
      "Epoch 9/30\n",
      "135897/135897 [==============================] - 13s 93us/sample - loss: 0.0110 - tp: 44.0000 - fp: 27.0000 - tn: 135530.0000 - fn: 296.0000 - accuracy: 0.9976 - precision: 0.6197 - recall: 0.1294 - auc: 0.8792 - val_loss: 0.0168 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556\n",
      "Epoch 10/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0102 - tp: 67.0000 - fp: 32.0000 - tn: 135525.0000 - fn: 273.0000 - accuracy: 0.9978 - precision: 0.6768 - recall: 0.1971 - auc: 0.8817 - val_loss: 0.0168 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5609\n",
      "Epoch 11/30\n",
      "135897/135897 [==============================] - 12s 86us/sample - loss: 0.0092 - tp: 79.0000 - fp: 47.0000 - tn: 135510.0000 - fn: 261.0000 - accuracy: 0.9977 - precision: 0.6270 - recall: 0.2324 - auc: 0.9180 - val_loss: 0.0184 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5352\n",
      "Epoch 12/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0087 - tp: 82.0000 - fp: 48.0000 - tn: 135509.0000 - fn: 258.0000 - accuracy: 0.9977 - precision: 0.6308 - recall: 0.2412 - auc: 0.9166 - val_loss: 0.0186 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5186\n",
      "Epoch 13/30\n",
      "135897/135897 [==============================] - 11s 85us/sample - loss: 0.0072 - tp: 117.0000 - fp: 32.0000 - tn: 135525.0000 - fn: 223.0000 - accuracy: 0.9981 - precision: 0.7852 - recall: 0.3441 - auc: 0.9464 - val_loss: 0.0198 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5415\n",
      "Epoch 14/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0070 - tp: 135.0000 - fp: 59.0000 - tn: 135498.0000 - fn: 205.0000 - accuracy: 0.9981 - precision: 0.6959 - recall: 0.3971 - auc: 0.9425 - val_loss: 0.0208 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5260\n",
      "Epoch 15/30\n",
      "135897/135897 [==============================] - 15s 107us/sample - loss: 0.0068 - tp: 140.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 200.0000 - accuracy: 0.9982 - precision: 0.7865 - recall: 0.4118 - auc: 0.9418 - val_loss: 0.0208 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5262\n",
      "Epoch 16/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0059 - tp: 162.0000 - fp: 53.0000 - tn: 135504.0000 - fn: 178.0000 - accuracy: 0.9983 - precision: 0.7535 - recall: 0.4765 - auc: 0.9647 - val_loss: 0.0225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5055\n",
      "Epoch 17/30\n",
      "135897/135897 [==============================] - 11s 84us/sample - loss: 0.0057 - tp: 178.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 162.0000 - accuracy: 0.9985 - precision: 0.7982 - recall: 0.5235 - auc: 0.9594 - val_loss: 0.0226 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5279\n",
      "Epoch 18/30\n",
      "135897/135897 [==============================] - 12s 92us/sample - loss: 0.0048 - tp: 194.0000 - fp: 36.0000 - tn: 135521.0000 - fn: 146.0000 - accuracy: 0.9987 - precision: 0.8435 - recall: 0.5706 - auc: 0.9598 - val_loss: 0.0237 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5215\n",
      "Epoch 19/30\n",
      "135897/135897 [==============================] - 13s 97us/sample - loss: 0.0053 - tp: 194.0000 - fp: 44.0000 - tn: 135513.0000 - fn: 146.0000 - accuracy: 0.9986 - precision: 0.8151 - recall: 0.5706 - auc: 0.9494 - val_loss: 0.0223 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5349\n",
      "Epoch 20/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0044 - tp: 215.0000 - fp: 33.0000 - tn: 135524.0000 - fn: 125.0000 - accuracy: 0.9988 - precision: 0.8669 - recall: 0.6324 - auc: 0.9777 - val_loss: 0.0242 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "135897/135897 [==============================] - 11s 82us/sample - loss: 0.0043 - tp: 217.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 123.0000 - accuracy: 0.9988 - precision: 0.8477 - recall: 0.6382 - auc: 0.9707 - val_loss: 0.0253 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5196\n",
      "Epoch 22/30\n",
      "135897/135897 [==============================] - 11s 82us/sample - loss: 0.0035 - tp: 243.0000 - fp: 28.0000 - tn: 135529.0000 - fn: 97.0000 - accuracy: 0.9991 - precision: 0.8967 - recall: 0.7147 - auc: 0.9813 - val_loss: 0.0263 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5214\n",
      "Epoch 23/30\n",
      "135897/135897 [==============================] - 11s 81us/sample - loss: 0.0032 - tp: 252.0000 - fp: 26.0000 - tn: 135531.0000 - fn: 88.0000 - accuracy: 0.9992 - precision: 0.9065 - recall: 0.7412 - auc: 0.9802 - val_loss: 0.0256 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5277\n",
      "Epoch 24/30\n",
      "135897/135897 [==============================] - 11s 82us/sample - loss: 0.0034 - tp: 237.0000 - fp: 41.0000 - tn: 135516.0000 - fn: 103.0000 - accuracy: 0.9989 - precision: 0.8525 - recall: 0.6971 - auc: 0.9815 - val_loss: 0.0275 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5358\n",
      "Epoch 25/30\n",
      "135897/135897 [==============================] - 12s 87us/sample - loss: 0.0040 - tp: 235.0000 - fp: 37.0000 - tn: 135520.0000 - fn: 105.0000 - accuracy: 0.9990 - precision: 0.8640 - recall: 0.6912 - auc: 0.9683 - val_loss: 0.0282 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5143\n",
      "Epoch 26/30\n",
      "135897/135897 [==============================] - 11s 84us/sample - loss: 0.0033 - tp: 240.0000 - fp: 33.0000 - tn: 135524.0000 - fn: 100.0000 - accuracy: 0.9990 - precision: 0.8791 - recall: 0.7059 - auc: 0.9786 - val_loss: 0.0278 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5204\n",
      "Epoch 27/30\n",
      "135897/135897 [==============================] - 10s 77us/sample - loss: 0.0026 - tp: 262.0000 - fp: 27.0000 - tn: 135530.0000 - fn: 78.0000 - accuracy: 0.9992 - precision: 0.9066 - recall: 0.7706 - auc: 0.9818 - val_loss: 0.0305 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5138\n",
      "Epoch 28/30\n",
      "135897/135897 [==============================] - 11s 80us/sample - loss: 0.0033 - tp: 244.0000 - fp: 33.0000 - tn: 135524.0000 - fn: 96.0000 - accuracy: 0.9991 - precision: 0.8809 - recall: 0.7176 - auc: 0.9817 - val_loss: 0.0292 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5198\n",
      "Epoch 29/30\n",
      "135897/135897 [==============================] - 11s 79us/sample - loss: 0.0033 - tp: 253.0000 - fp: 37.0000 - tn: 135520.0000 - fn: 87.0000 - accuracy: 0.9991 - precision: 0.8724 - recall: 0.7441 - auc: 0.9787 - val_loss: 0.0301 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5281\n",
      "Epoch 30/30\n",
      "135897/135897 [==============================] - 11s 78us/sample - loss: 0.0028 - tp: 259.0000 - fp: 26.0000 - tn: 135531.0000 - fn: 81.0000 - accuracy: 0.9992 - precision: 0.9088 - recall: 0.7618 - auc: 0.9818 - val_loss: 0.0291 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5139\n"
     ]
    }
   ],
   "source": [
    "model_47_1_1 = get_model_class_47_1()\n",
    "history_1_1 = model_47_1_1.fit(\n",
    "    [x_img_train, x_txt_train], \n",
    "    y_train_47, \n",
    "    epochs=30, \n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47), \n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.python.keras.utils.generic_utils import to_list\n",
    "from  tensorflow.keras import regularizers \n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "class Highway(Layer):\n",
    "    \"\"\"Densely connected highway network.\n",
    "    Highway layers are a natural extension of LSTMs to feedforward networks.\n",
    "    # Arguments\n",
    "        init: name of initialization function for the weights of the layer\n",
    "            (see [initializations](../initializations.md)),\n",
    "            or alternatively, Theano function to use for weights\n",
    "            initialization. This parameter is only relevant\n",
    "            if you don't pass a `weights` argument.\n",
    "        activation: name of activation function to use\n",
    "            (see [activations](../activations.md)),\n",
    "            or alternatively, elementwise Theano function.\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: a(x) = x).\n",
    "        weights: list of Numpy arrays to set as initial weights.\n",
    "            The list should have 2 elements, of shape `(input_dim, output_dim)`\n",
    "            and (output_dim,) for weights and biases respectively.\n",
    "        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n",
    "            (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n",
    "            applied to the bias.\n",
    "        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n",
    "            applied to the network output.\n",
    "        W_constraint: instance of the [constraints](../constraints.md) module\n",
    "            (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "        b_constraint: instance of the [constraints](../constraints.md) module,\n",
    "            applied to the bias.\n",
    "        bias: whether to include a bias\n",
    "            (i.e. make the layer affine rather than linear).\n",
    "        input_dim: dimensionality of the input (integer). This argument\n",
    "            (or alternatively, the keyword argument `input_shape`)\n",
    "            is required when using this layer as the first layer in a model.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(nb_samples, input_dim)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(nb_samples, input_dim)`.\n",
    "    # References\n",
    "        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 init='glorot_uniform',\n",
    "                 activation=None,\n",
    "                 weights=None,\n",
    "                 W_regularizer=None,\n",
    "                 b_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 W_constraint=None,\n",
    "                 b_constraint=None,\n",
    "                 bias=True,\n",
    "                 input_dim=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        if 'transform_bias' in kwargs:\n",
    "            kwargs.pop('transform_bias')\n",
    "            warnings.warn('`transform_bias` argument is deprecated and '\n",
    "                          'has been removed.')\n",
    "        self.init = initializers.get(init)\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "        super(Highway, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(),\n",
    "                                    shape=(None, input_dim))\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_dim, input_dim),\n",
    "                                 initializer=self.init,\n",
    "                                 name='W',\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.W_carry = self.add_weight(shape=(input_dim, input_dim),\n",
    "                                       initializer=self.init,\n",
    "                                       name='W_carry')\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='b',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.b_carry = self.add_weight(shape=(input_dim,),\n",
    "                                           initializer='one',\n",
    "                                           name='b_carry')\n",
    "        else:\n",
    "            self.b_carry = None\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        y = K.dot(x, self.W_carry)\n",
    "        if self.bias:\n",
    "            y += self.b_carry\n",
    "        transform_weight = activations.sigmoid(y)\n",
    "        y = K.dot(x, self.W)\n",
    "        if self.bias:\n",
    "            y += self.b\n",
    "        act = self.activation(y)\n",
    "        act *= transform_weight\n",
    "        output = act + (1 - transform_weight) * x\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'init': initializers.serialize(self.init),\n",
    "                  'activation': activations.serialize(self.activation),\n",
    "                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n",
    "                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n",
    "                  'activity_regularizer':\n",
    "                      regularizers.serialize(self.activity_regularizer),\n",
    "                  'W_constraint': constraints.serialize(self.W_constraint),\n",
    "                  'b_constraint': constraints.serialize(self.b_constraint),\n",
    "                  'bias': self.bias,\n",
    "                  'input_dim': self.input_dim}\n",
    "        base_config = super(Highway, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_47_highway():\n",
    "    output_bias = tf.keras.initializers.Constant(init_bias)\n",
    "    \n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x_img = Dense(512, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Highway()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Highway()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid',  bias_initializer=output_bias)(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135897 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "135897/135897 [==============================] - 49s 363us/sample - loss: 0.0259 - tp: 0.0000e+00 - fp: 60.0000 - tn: 135497.0000 - fn: 340.0000 - accuracy: 0.9971 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5194 - val_loss: 0.0165 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5069\n",
      "Epoch 2/30\n",
      "135897/135897 [==============================] - 42s 307us/sample - loss: 0.0210 - tp: 0.0000e+00 - fp: 12.0000 - tn: 135545.0000 - fn: 340.0000 - accuracy: 0.9974 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5529 - val_loss: 0.0145 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5332\n",
      "Epoch 3/30\n",
      "135897/135897 [==============================] - 43s 319us/sample - loss: 0.0184 - tp: 0.0000e+00 - fp: 9.0000 - tn: 135548.0000 - fn: 340.0000 - accuracy: 0.9974 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6158 - val_loss: 0.0142 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5271\n",
      "Epoch 4/30\n",
      "135897/135897 [==============================] - 42s 310us/sample - loss: 0.0171 - tp: 1.0000 - fp: 1.0000 - tn: 135556.0000 - fn: 339.0000 - accuracy: 0.9975 - precision: 0.5000 - recall: 0.0029 - auc: 0.6662 - val_loss: 0.0143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5412\n",
      "Epoch 5/30\n",
      "135897/135897 [==============================] - 49s 361us/sample - loss: 0.0158 - tp: 3.0000 - fp: 8.0000 - tn: 135549.0000 - fn: 337.0000 - accuracy: 0.9975 - precision: 0.2727 - recall: 0.0088 - auc: 0.7205 - val_loss: 0.0145 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5465\n",
      "Epoch 6/30\n",
      "135897/135897 [==============================] - 46s 336us/sample - loss: 0.0139 - tp: 6.0000 - fp: 12.0000 - tn: 135545.0000 - fn: 334.0000 - accuracy: 0.9975 - precision: 0.3333 - recall: 0.0176 - auc: 0.7685 - val_loss: 0.0141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5793\n",
      "Epoch 7/30\n",
      "135897/135897 [==============================] - 45s 330us/sample - loss: 0.0133 - tp: 13.0000 - fp: 21.0000 - tn: 135536.0000 - fn: 327.0000 - accuracy: 0.9974 - precision: 0.3824 - recall: 0.0382 - auc: 0.8106 - val_loss: 0.0156 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5488\n",
      "Epoch 8/30\n",
      "135897/135897 [==============================] - 43s 319us/sample - loss: 0.0118 - tp: 36.0000 - fp: 25.0000 - tn: 135532.0000 - fn: 304.0000 - accuracy: 0.9976 - precision: 0.5902 - recall: 0.1059 - auc: 0.8469 - val_loss: 0.0150 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5554\n",
      "Epoch 9/30\n",
      "135897/135897 [==============================] - 41s 300us/sample - loss: 0.0104 - tp: 67.0000 - fp: 36.0000 - tn: 135521.0000 - fn: 273.0000 - accuracy: 0.9977 - precision: 0.6505 - recall: 0.1971 - auc: 0.8664 - val_loss: 0.0163 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5433\n",
      "Epoch 10/30\n",
      "135897/135897 [==============================] - 47s 343us/sample - loss: 0.0106 - tp: 66.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 274.0000 - accuracy: 0.9977 - precision: 0.6286 - recall: 0.1941 - auc: 0.8814 - val_loss: 0.0159 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5329\n",
      "Epoch 11/30\n",
      "135897/135897 [==============================] - 41s 302us/sample - loss: 0.0095 - tp: 90.0000 - fp: 52.0000 - tn: 135505.0000 - fn: 250.0000 - accuracy: 0.9978 - precision: 0.6338 - recall: 0.2647 - auc: 0.8899 - val_loss: 0.0173 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5200\n",
      "Epoch 12/30\n",
      "135897/135897 [==============================] - 38s 281us/sample - loss: 0.0091 - tp: 105.0000 - fp: 49.0000 - tn: 135508.0000 - fn: 235.0000 - accuracy: 0.9979 - precision: 0.6818 - recall: 0.3088 - auc: 0.8905 - val_loss: 0.0172 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5131\n",
      "Epoch 13/30\n",
      "135897/135897 [==============================] - 43s 316us/sample - loss: 0.0074 - tp: 146.0000 - fp: 42.0000 - tn: 135515.0000 - fn: 194.0000 - accuracy: 0.9983 - precision: 0.7766 - recall: 0.4294 - auc: 0.9144 - val_loss: 0.0176 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5279\n",
      "Epoch 14/30\n",
      "135897/135897 [==============================] - 42s 310us/sample - loss: 0.0076 - tp: 134.0000 - fp: 57.0000 - tn: 135500.0000 - fn: 206.0000 - accuracy: 0.9981 - precision: 0.7016 - recall: 0.3941 - auc: 0.9260 - val_loss: 0.0191 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5288\n",
      "Epoch 15/30\n",
      "135897/135897 [==============================] - 52s 379us/sample - loss: 0.0072 - tp: 157.0000 - fp: 49.0000 - tn: 135508.0000 - fn: 183.0000 - accuracy: 0.9983 - precision: 0.7621 - recall: 0.4618 - auc: 0.9253 - val_loss: 0.0178 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5282\n",
      "Epoch 16/30\n",
      "135897/135897 [==============================] - 44s 324us/sample - loss: 0.0070 - tp: 165.0000 - fp: 40.0000 - tn: 135517.0000 - fn: 175.0000 - accuracy: 0.9984 - precision: 0.8049 - recall: 0.4853 - auc: 0.9230 - val_loss: 0.0205 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5063\n",
      "Epoch 17/30\n",
      "135897/135897 [==============================] - 41s 304us/sample - loss: 0.0062 - tp: 182.0000 - fp: 44.0000 - tn: 135513.0000 - fn: 158.0000 - accuracy: 0.9985 - precision: 0.8053 - recall: 0.5353 - auc: 0.9341 - val_loss: 0.0236 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 18/30\n",
      "135897/135897 [==============================] - 42s 310us/sample - loss: 0.0057 - tp: 205.0000 - fp: 43.0000 - tn: 135514.0000 - fn: 135.0000 - accuracy: 0.9987 - precision: 0.8266 - recall: 0.6029 - auc: 0.9389 - val_loss: 0.0210 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5073\n",
      "Epoch 19/30\n",
      "135897/135897 [==============================] - 40s 293us/sample - loss: 0.0048 - tp: 219.0000 - fp: 37.0000 - tn: 135520.0000 - fn: 121.0000 - accuracy: 0.9988 - precision: 0.8555 - recall: 0.6441 - auc: 0.9528 - val_loss: 0.0230 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 20/30\n",
      "135897/135897 [==============================] - 39s 288us/sample - loss: 0.0048 - tp: 220.0000 - fp: 43.0000 - tn: 135514.0000 - fn: 120.0000 - accuracy: 0.9988 - precision: 0.8365 - recall: 0.6471 - auc: 0.9530 - val_loss: 0.0218 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "135897/135897 [==============================] - 39s 286us/sample - loss: 0.0056 - tp: 202.0000 - fp: 55.0000 - tn: 135502.0000 - fn: 138.0000 - accuracy: 0.9986 - precision: 0.7860 - recall: 0.5941 - auc: 0.9465 - val_loss: 0.0227 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5147\n",
      "Epoch 22/30\n",
      "135897/135897 [==============================] - 40s 292us/sample - loss: 0.0055 - tp: 216.0000 - fp: 44.0000 - tn: 135513.0000 - fn: 124.0000 - accuracy: 0.9988 - precision: 0.8308 - recall: 0.6353 - auc: 0.9481 - val_loss: 0.0238 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5227\n",
      "Epoch 23/30\n",
      "135897/135897 [==============================] - 39s 286us/sample - loss: 0.0057 - tp: 204.0000 - fp: 42.0000 - tn: 135515.0000 - fn: 136.0000 - accuracy: 0.9987 - precision: 0.8293 - recall: 0.6000 - auc: 0.9541 - val_loss: 0.0222 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 24/30\n",
      "135897/135897 [==============================] - 39s 284us/sample - loss: 0.0045 - tp: 237.0000 - fp: 35.0000 - tn: 135522.0000 - fn: 103.0000 - accuracy: 0.9990 - precision: 0.8713 - recall: 0.6971 - auc: 0.9516 - val_loss: 0.0246 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 25/30\n",
      "135897/135897 [==============================] - 44s 322us/sample - loss: 0.0041 - tp: 240.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 100.0000 - accuracy: 0.9990 - precision: 0.8633 - recall: 0.7059 - auc: 0.9652 - val_loss: 0.0231 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5149\n",
      "Epoch 26/30\n",
      "135897/135897 [==============================] - 42s 311us/sample - loss: 0.0042 - tp: 238.0000 - fp: 41.0000 - tn: 135516.0000 - fn: 102.0000 - accuracy: 0.9989 - precision: 0.8530 - recall: 0.7000 - auc: 0.9563 - val_loss: 0.0260 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5069\n",
      "Epoch 27/30\n",
      "135897/135897 [==============================] - 39s 289us/sample - loss: 0.0049 - tp: 229.0000 - fp: 52.0000 - tn: 135505.0000 - fn: 111.0000 - accuracy: 0.9988 - precision: 0.8149 - recall: 0.6735 - auc: 0.9472 - val_loss: 0.0280 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 28/30\n",
      "135897/135897 [==============================] - 39s 290us/sample - loss: 0.0053 - tp: 222.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 118.0000 - accuracy: 0.9988 - precision: 0.8315 - recall: 0.6529 - auc: 0.9411 - val_loss: 0.0269 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5073\n",
      "Epoch 29/30\n",
      "135897/135897 [==============================] - 40s 297us/sample - loss: 0.0039 - tp: 259.0000 - fp: 42.0000 - tn: 135515.0000 - fn: 81.0000 - accuracy: 0.9991 - precision: 0.8605 - recall: 0.7618 - auc: 0.9610 - val_loss: 0.0261 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 30/30\n",
      "135897/135897 [==============================] - 40s 294us/sample - loss: 0.0040 - tp: 236.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 104.0000 - accuracy: 0.9989 - precision: 0.8399 - recall: 0.6941 - auc: 0.9682 - val_loss: 0.0250 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5074\n"
     ]
    }
   ],
   "source": [
    "model_47_highway = get_model_47_highway()\n",
    "history_highway = model_47_highway.fit(\n",
    "    [x_img_train, x_txt_train], \n",
    "    y_train_47, \n",
    "    epochs=30, \n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47), \n",
    "    batch_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train_47 = x_img_train[y_train_47.astype(bool)]\n",
    "x_txt_train_47 = x_txt_train[y_train_47.astype(bool)]\n",
    "\n",
    "x_img_train_others = x_img_train[(y_train_47 - 1).astype(bool)]\n",
    "x_txt_train_others = x_txt_train[(y_train_47 - 1).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_47_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_coef = n_47_samples // x_img_train_47.shape[0]\n",
    "x_img_train_47_up = np.repeat(x_img_train_47, rep_coef, axis=0)\n",
    "x_txt_train_47_up = np.repeat(x_txt_train_47, rep_coef, axis=0)\n",
    "y_train_47_up = np.ones(x_img_train_47_up.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 1024)\n",
      "(4760, 1024)\n",
      "(4760, 300)\n",
      "(4760,)\n"
     ]
    }
   ],
   "source": [
    "print(x_img_train_47.shape)\n",
    "print(x_img_train_47_up.shape)\n",
    "print(x_txt_train_47_up.shape)\n",
    "print(y_train_47_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135557, 1024)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img_train_others.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train_up = np.concatenate((x_img_train_others, x_img_train_47_up))\n",
    "x_txt_train_up = np.concatenate((x_txt_train_others, x_txt_train_47_up))\n",
    "y_train_up = np.concatenate((np.zeros(x_img_train_others.shape[0]), y_train_47_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(y_train_up))\n",
    "x_img_train_up = x_img_train_up[perm]\n",
    "x_txt_train_up = x_txt_train_up[perm]\n",
    "y_train_up = y_train_up[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140317 samples, validate on 33975 samples\n",
      "Epoch 1/20\n",
      "140317/140317 [==============================] - 13s 91us/sample - loss: 0.1507 - tp: 744.0000 - fp: 1456.0000 - tn: 134101.0000 - fn: 4016.0000 - accuracy: 0.9610 - precision: 0.3382 - recall: 0.1563 - auc: 0.7788 - val_loss: 0.0178 - val_tp: 1.0000 - val_fp: 15.0000 - val_tn: 33895.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0625 - val_recall: 0.0154 - val_auc: 0.5969\n",
      "Epoch 2/20\n",
      "140317/140317 [==============================] - 8s 60us/sample - loss: 0.0639 - tp: 2564.0000 - fp: 822.0000 - tn: 134735.0000 - fn: 2196.0000 - accuracy: 0.9785 - precision: 0.7572 - recall: 0.5387 - auc: 0.9592 - val_loss: 0.0197 - val_tp: 1.0000 - val_fp: 22.0000 - val_tn: 33888.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0435 - val_recall: 0.0154 - val_auc: 0.5608\n",
      "Epoch 3/20\n",
      "140317/140317 [==============================] - 9s 62us/sample - loss: 0.0298 - tp: 3775.0000 - fp: 495.0000 - tn: 135062.0000 - fn: 985.0000 - accuracy: 0.9895 - precision: 0.8841 - recall: 0.7931 - auc: 0.9896 - val_loss: 0.0235 - val_tp: 1.0000 - val_fp: 15.0000 - val_tn: 33895.0000 - val_fn: 64.0000 - val_accuracy: 0.9977 - val_precision: 0.0625 - val_recall: 0.0154 - val_auc: 0.5546\n",
      "Epoch 4/20\n",
      "140317/140317 [==============================] - 9s 64us/sample - loss: 0.0197 - tp: 4156.0000 - fp: 356.0000 - tn: 135201.0000 - fn: 604.0000 - accuracy: 0.9932 - precision: 0.9211 - recall: 0.8731 - auc: 0.9941 - val_loss: 0.0255 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5319\n",
      "Epoch 5/20\n",
      "140317/140317 [==============================] - 8s 59us/sample - loss: 0.0132 - tp: 4352.0000 - fp: 256.0000 - tn: 135301.0000 - fn: 408.0000 - accuracy: 0.9953 - precision: 0.9444 - recall: 0.9143 - auc: 0.9975 - val_loss: 0.0295 - val_tp: 2.0000 - val_fp: 18.0000 - val_tn: 33892.0000 - val_fn: 63.0000 - val_accuracy: 0.9976 - val_precision: 0.1000 - val_recall: 0.0308 - val_auc: 0.5516\n",
      "Epoch 6/20\n",
      "140317/140317 [==============================] - 9s 62us/sample - loss: 0.0105 - tp: 4449.0000 - fp: 208.0000 - tn: 135349.0000 - fn: 311.0000 - accuracy: 0.9963 - precision: 0.9553 - recall: 0.9347 - auc: 0.9983 - val_loss: 0.0321 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 33898.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0769 - val_recall: 0.0154 - val_auc: 0.5261\n",
      "Epoch 7/20\n",
      "140317/140317 [==============================] - 9s 63us/sample - loss: 0.0085 - tp: 4515.0000 - fp: 182.0000 - tn: 135375.0000 - fn: 245.0000 - accuracy: 0.9970 - precision: 0.9613 - recall: 0.9485 - auc: 0.9992 - val_loss: 0.0360 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5274\n",
      "Epoch 8/20\n",
      "140317/140317 [==============================] - 9s 64us/sample - loss: 0.0082 - tp: 4514.0000 - fp: 151.0000 - tn: 135406.0000 - fn: 246.0000 - accuracy: 0.9972 - precision: 0.9676 - recall: 0.9483 - auc: 0.9983 - val_loss: 0.0395 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5200\n",
      "Epoch 9/20\n",
      "140317/140317 [==============================] - 11s 81us/sample - loss: 0.0072 - tp: 4583.0000 - fp: 137.0000 - tn: 135420.0000 - fn: 177.0000 - accuracy: 0.9978 - precision: 0.9710 - recall: 0.9628 - auc: 0.9986 - val_loss: 0.0393 - val_tp: 1.0000 - val_fp: 11.0000 - val_tn: 33899.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0833 - val_recall: 0.0154 - val_auc: 0.5205\n",
      "Epoch 10/20\n",
      "140317/140317 [==============================] - 13s 90us/sample - loss: 0.0071 - tp: 4570.0000 - fp: 140.0000 - tn: 135417.0000 - fn: 190.0000 - accuracy: 0.9976 - precision: 0.9703 - recall: 0.9601 - auc: 0.9985 - val_loss: 0.0411 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5285\n",
      "Epoch 11/20\n",
      "140317/140317 [==============================] - 13s 92us/sample - loss: 0.0050 - tp: 4628.0000 - fp: 99.0000 - tn: 135458.0000 - fn: 132.0000 - accuracy: 0.9984 - precision: 0.9791 - recall: 0.9723 - auc: 0.9989 - val_loss: 0.0422 - val_tp: 1.0000 - val_fp: 9.0000 - val_tn: 33901.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1000 - val_recall: 0.0154 - val_auc: 0.5135\n",
      "Epoch 12/20\n",
      "140317/140317 [==============================] - 13s 94us/sample - loss: 0.0054 - tp: 4627.0000 - fp: 110.0000 - tn: 135447.0000 - fn: 133.0000 - accuracy: 0.9983 - precision: 0.9768 - recall: 0.9721 - auc: 0.9988 - val_loss: 0.0460 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5065\n",
      "Epoch 13/20\n",
      "140317/140317 [==============================] - 11s 76us/sample - loss: 0.0045 - tp: 4641.0000 - fp: 89.0000 - tn: 135468.0000 - fn: 119.0000 - accuracy: 0.9985 - precision: 0.9812 - recall: 0.9750 - auc: 0.9996 - val_loss: 0.0482 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 14/20\n",
      "140317/140317 [==============================] - 10s 75us/sample - loss: 0.0037 - tp: 4669.0000 - fp: 75.0000 - tn: 135482.0000 - fn: 91.0000 - accuracy: 0.9988 - precision: 0.9842 - recall: 0.9809 - auc: 0.9993 - val_loss: 0.0490 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 15/20\n",
      "140317/140317 [==============================] - 10s 71us/sample - loss: 0.0041 - tp: 4658.0000 - fp: 76.0000 - tn: 135481.0000 - fn: 102.0000 - accuracy: 0.9987 - precision: 0.9839 - recall: 0.9786 - auc: 0.9994 - val_loss: 0.0474 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5144\n",
      "Epoch 16/20\n",
      "140317/140317 [==============================] - 10s 72us/sample - loss: 0.0041 - tp: 4663.0000 - fp: 82.0000 - tn: 135475.0000 - fn: 97.0000 - accuracy: 0.9987 - precision: 0.9827 - recall: 0.9796 - auc: 0.9996 - val_loss: 0.0497 - val_tp: 2.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 63.0000 - val_accuracy: 0.9979 - val_precision: 0.2000 - val_recall: 0.0308 - val_auc: 0.5290\n",
      "Epoch 17/20\n",
      "140317/140317 [==============================] - 12s 85us/sample - loss: 0.0034 - tp: 4687.0000 - fp: 64.0000 - tn: 135493.0000 - fn: 73.0000 - accuracy: 0.9990 - precision: 0.9865 - recall: 0.9847 - auc: 0.9996 - val_loss: 0.0497 - val_tp: 1.0000 - val_fp: 9.0000 - val_tn: 33901.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1000 - val_recall: 0.0154 - val_auc: 0.5292\n",
      "Epoch 18/20\n",
      "140317/140317 [==============================] - 13s 89us/sample - loss: 0.0038 - tp: 4665.0000 - fp: 75.0000 - tn: 135482.0000 - fn: 95.0000 - accuracy: 0.9988 - precision: 0.9842 - recall: 0.9800 - auc: 0.9993 - val_loss: 0.0511 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5145\n",
      "Epoch 19/20\n",
      "140317/140317 [==============================] - 13s 91us/sample - loss: 0.0032 - tp: 4665.0000 - fp: 59.0000 - tn: 135498.0000 - fn: 95.0000 - accuracy: 0.9989 - precision: 0.9875 - recall: 0.9800 - auc: 0.9994 - val_loss: 0.0515 - val_tp: 1.0000 - val_fp: 12.0000 - val_tn: 33898.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0769 - val_recall: 0.0154 - val_auc: 0.5124\n",
      "Epoch 20/20\n",
      "140317/140317 [==============================] - 12s 84us/sample - loss: 0.0040 - tp: 4679.0000 - fp: 71.0000 - tn: 135486.0000 - fn: 81.0000 - accuracy: 0.9989 - precision: 0.9851 - recall: 0.9830 - auc: 0.9993 - val_loss: 0.0535 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d91fd650>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_up = get_model_class_47_1()\n",
    "model_up.fit(\n",
    "    [x_img_train_up, x_txt_train_up],\n",
    "    y_train_up,\n",
    "    batch_size=2048,\n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47),\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140317 samples, validate on 33975 samples\n",
      "Epoch 1/20\n",
      "140317/140317 [==============================] - 12s 82us/sample - loss: 0.0035 - tp: 4680.0000 - fp: 66.0000 - tn: 135491.0000 - fn: 80.0000 - accuracy: 0.9990 - precision: 0.9861 - recall: 0.9832 - auc: 0.9996 - val_loss: 0.0540 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5069\n",
      "Epoch 2/20\n",
      "140317/140317 [==============================] - 10s 73us/sample - loss: 0.0033 - tp: 4682.0000 - fp: 64.0000 - tn: 135493.0000 - fn: 78.0000 - accuracy: 0.9990 - precision: 0.9865 - recall: 0.9836 - auc: 0.9990 - val_loss: 0.0564 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 3/20\n",
      "140317/140317 [==============================] - 11s 79us/sample - loss: 0.0033 - tp: 4693.0000 - fp: 54.0000 - tn: 135503.0000 - fn: 67.0000 - accuracy: 0.9991 - precision: 0.9886 - recall: 0.9859 - auc: 0.9991 - val_loss: 0.0538 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5070\n",
      "Epoch 4/20\n",
      "140317/140317 [==============================] - 9s 68us/sample - loss: 0.0033 - tp: 4694.0000 - fp: 66.0000 - tn: 135491.0000 - fn: 66.0000 - accuracy: 0.9991 - precision: 0.9861 - recall: 0.9861 - auc: 0.9994 - val_loss: 0.0566 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5226\n",
      "Epoch 5/20\n",
      "140317/140317 [==============================] - 10s 71us/sample - loss: 0.0031 - tp: 4695.0000 - fp: 53.0000 - tn: 135504.0000 - fn: 65.0000 - accuracy: 0.9992 - precision: 0.9888 - recall: 0.9863 - auc: 0.9997 - val_loss: 0.0529 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 6/20\n",
      "140317/140317 [==============================] - 10s 69us/sample - loss: 0.0034 - tp: 4693.0000 - fp: 56.0000 - tn: 135501.0000 - fn: 67.0000 - accuracy: 0.9991 - precision: 0.9882 - recall: 0.9859 - auc: 0.9996 - val_loss: 0.0562 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 7/20\n",
      "140317/140317 [==============================] - 11s 79us/sample - loss: 0.0030 - tp: 4699.0000 - fp: 47.0000 - tn: 135510.0000 - fn: 61.0000 - accuracy: 0.9992 - precision: 0.9901 - recall: 0.9872 - auc: 0.9994 - val_loss: 0.0522 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 8/20\n",
      "140317/140317 [==============================] - 10s 69us/sample - loss: 0.0026 - tp: 4702.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 58.0000 - accuracy: 0.9993 - precision: 0.9905 - recall: 0.9878 - auc: 0.9997 - val_loss: 0.0546 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5147\n",
      "Epoch 9/20\n",
      "140317/140317 [==============================] - 10s 71us/sample - loss: 0.0021 - tp: 4709.0000 - fp: 35.0000 - tn: 135522.0000 - fn: 51.0000 - accuracy: 0.9994 - precision: 0.9926 - recall: 0.9893 - auc: 0.9994 - val_loss: 0.0545 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 10/20\n",
      "140317/140317 [==============================] - 11s 80us/sample - loss: 0.0025 - tp: 4723.0000 - fp: 42.0000 - tn: 135515.0000 - fn: 37.0000 - accuracy: 0.9994 - precision: 0.9912 - recall: 0.9922 - auc: 0.9995 - val_loss: 0.0558 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 11/20\n",
      "140317/140317 [==============================] - 9s 67us/sample - loss: 0.0021 - tp: 4722.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 38.0000 - accuracy: 0.9995 - precision: 0.9920 - recall: 0.9920 - auc: 0.9992 - val_loss: 0.0541 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5224\n",
      "Epoch 12/20\n",
      "140317/140317 [==============================] - 9s 68us/sample - loss: 0.0027 - tp: 4707.0000 - fp: 41.0000 - tn: 135516.0000 - fn: 53.0000 - accuracy: 0.9993 - precision: 0.9914 - recall: 0.9889 - auc: 0.9997 - val_loss: 0.0548 - val_tp: 1.0000 - val_fp: 9.0000 - val_tn: 33901.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1000 - val_recall: 0.0154 - val_auc: 0.5299\n",
      "Epoch 13/20\n",
      "140317/140317 [==============================] - 12s 82us/sample - loss: 0.0024 - tp: 4712.0000 - fp: 41.0000 - tn: 135516.0000 - fn: 48.0000 - accuracy: 0.9994 - precision: 0.9914 - recall: 0.9899 - auc: 0.9999 - val_loss: 0.0556 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5375\n",
      "Epoch 14/20\n",
      "140317/140317 [==============================] - 11s 78us/sample - loss: 0.0026 - tp: 4693.0000 - fp: 44.0000 - tn: 135513.0000 - fn: 67.0000 - accuracy: 0.9992 - precision: 0.9907 - recall: 0.9859 - auc: 0.9992 - val_loss: 0.0516 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5219\n",
      "Epoch 15/20\n",
      "140317/140317 [==============================] - 10s 72us/sample - loss: 0.0024 - tp: 4722.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 38.0000 - accuracy: 0.9995 - precision: 0.9918 - recall: 0.9920 - auc: 0.9996 - val_loss: 0.0528 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 16/20\n",
      "140317/140317 [==============================] - 10s 75us/sample - loss: 0.0019 - tp: 4722.0000 - fp: 32.0000 - tn: 135525.0000 - fn: 38.0000 - accuracy: 0.9995 - precision: 0.9933 - recall: 0.9920 - auc: 0.9999 - val_loss: 0.0551 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5143\n",
      "Epoch 17/20\n",
      "140317/140317 [==============================] - 13s 92us/sample - loss: 0.0023 - tp: 4720.0000 - fp: 38.0000 - tn: 135519.0000 - fn: 40.0000 - accuracy: 0.9994 - precision: 0.9920 - recall: 0.9916 - auc: 0.9993 - val_loss: 0.0549 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5073\n",
      "Epoch 18/20\n",
      "140317/140317 [==============================] - 14s 103us/sample - loss: 0.0021 - tp: 4723.0000 - fp: 35.0000 - tn: 135522.0000 - fn: 37.0000 - accuracy: 0.9995 - precision: 0.9926 - recall: 0.9922 - auc: 0.9994 - val_loss: 0.0537 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 19/20\n",
      "140317/140317 [==============================] - 11s 75us/sample - loss: 0.0015 - tp: 4725.0000 - fp: 30.0000 - tn: 135527.0000 - fn: 35.0000 - accuracy: 0.9995 - precision: 0.9937 - recall: 0.9926 - auc: 0.9998 - val_loss: 0.0573 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 20/20\n",
      "140317/140317 [==============================] - 10s 71us/sample - loss: 0.0017 - tp: 4734.0000 - fp: 28.0000 - tn: 135529.0000 - fn: 26.0000 - accuracy: 0.9996 - precision: 0.9941 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0572 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18868fb50>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_up.fit(\n",
    "    [x_img_train_up, x_txt_train_up],\n",
    "    y_train_up,\n",
    "    batch_size=2048,\n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47),\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = model_up.evaluate([x_img_test, x_txt_test], y_test_47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.064368234744062, 0.0, 3.0, 42367.0, 98.0, 0.9976217, 0.0, 0.0, 0.50470144]\n"
     ]
    }
   ],
   "source": [
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 145417 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "145417/145417 [==============================] - 31s 215us/sample - loss: 0.2638 - tp: 2144.0000 - fp: 3483.0000 - tn: 132074.0000 - fn: 7716.0000 - accuracy: 0.9230 - precision: 0.3810 - recall: 0.2174 - auc: 0.7718 - val_loss: 0.0245 - val_tp: 2.0000 - val_fp: 44.0000 - val_tn: 33866.0000 - val_fn: 63.0000 - val_accuracy: 0.9969 - val_precision: 0.0435 - val_recall: 0.0308 - val_auc: 0.7066\n",
      "Epoch 2/30\n",
      "145417/145417 [==============================] - 13s 87us/sample - loss: 0.1061 - tp: 5771.0000 - fp: 1774.0000 - tn: 133783.0000 - fn: 4089.0000 - accuracy: 0.9597 - precision: 0.7649 - recall: 0.5853 - auc: 0.9620 - val_loss: 0.0207 - val_tp: 1.0000 - val_fp: 23.0000 - val_tn: 33887.0000 - val_fn: 64.0000 - val_accuracy: 0.9974 - val_precision: 0.0417 - val_recall: 0.0154 - val_auc: 0.5517\n",
      "Epoch 3/30\n",
      "145417/145417 [==============================] - 9s 59us/sample - loss: 0.0463 - tp: 8210.0000 - fp: 879.0000 - tn: 134678.0000 - fn: 1650.0000 - accuracy: 0.9826 - precision: 0.9033 - recall: 0.8327 - auc: 0.9927 - val_loss: 0.0212 - val_tp: 1.0000 - val_fp: 20.0000 - val_tn: 33890.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0476 - val_recall: 0.0154 - val_auc: 0.5476\n",
      "Epoch 4/30\n",
      "145417/145417 [==============================] - 11s 74us/sample - loss: 0.0245 - tp: 9038.0000 - fp: 480.0000 - tn: 135077.0000 - fn: 822.0000 - accuracy: 0.9910 - precision: 0.9496 - recall: 0.9166 - auc: 0.9981 - val_loss: 0.0252 - val_tp: 1.0000 - val_fp: 22.0000 - val_tn: 33888.0000 - val_fn: 64.0000 - val_accuracy: 0.9975 - val_precision: 0.0435 - val_recall: 0.0154 - val_auc: 0.5223\n",
      "Epoch 5/30\n",
      "145417/145417 [==============================] - 9s 60us/sample - loss: 0.0158 - tp: 9356.0000 - fp: 323.0000 - tn: 135234.0000 - fn: 504.0000 - accuracy: 0.9943 - precision: 0.9666 - recall: 0.9489 - auc: 0.9992 - val_loss: 0.0263 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5215\n",
      "Epoch 6/30\n",
      "145417/145417 [==============================] - 9s 62us/sample - loss: 0.0104 - tp: 9558.0000 - fp: 226.0000 - tn: 135331.0000 - fn: 302.0000 - accuracy: 0.9964 - precision: 0.9769 - recall: 0.9694 - auc: 0.9996 - val_loss: 0.0293 - val_tp: 1.0000 - val_fp: 9.0000 - val_tn: 33901.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1000 - val_recall: 0.0154 - val_auc: 0.5242\n",
      "Epoch 7/30\n",
      "145417/145417 [==============================] - 9s 65us/sample - loss: 0.0077 - tp: 9659.0000 - fp: 171.0000 - tn: 135386.0000 - fn: 201.0000 - accuracy: 0.9974 - precision: 0.9826 - recall: 0.9796 - auc: 0.9998 - val_loss: 0.0306 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5272\n",
      "Epoch 8/30\n",
      "145417/145417 [==============================] - 9s 63us/sample - loss: 0.0070 - tp: 9661.0000 - fp: 139.0000 - tn: 135418.0000 - fn: 199.0000 - accuracy: 0.9977 - precision: 0.9858 - recall: 0.9798 - auc: 0.9998 - val_loss: 0.0325 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5193\n",
      "Epoch 9/30\n",
      "145417/145417 [==============================] - 11s 74us/sample - loss: 0.0056 - tp: 9732.0000 - fp: 114.0000 - tn: 135443.0000 - fn: 128.0000 - accuracy: 0.9983 - precision: 0.9884 - recall: 0.9870 - auc: 0.9997 - val_loss: 0.0345 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5125\n",
      "Epoch 10/30\n",
      "145417/145417 [==============================] - 10s 67us/sample - loss: 0.0047 - tp: 9756.0000 - fp: 102.0000 - tn: 135455.0000 - fn: 104.0000 - accuracy: 0.9986 - precision: 0.9897 - recall: 0.9895 - auc: 0.9997 - val_loss: 0.0363 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5129\n",
      "Epoch 11/30\n",
      "145417/145417 [==============================] - 9s 65us/sample - loss: 0.0042 - tp: 9749.0000 - fp: 78.0000 - tn: 135479.0000 - fn: 111.0000 - accuracy: 0.9987 - precision: 0.9921 - recall: 0.9887 - auc: 0.9997 - val_loss: 0.0376 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5286\n",
      "Epoch 12/30\n",
      "145417/145417 [==============================] - 9s 64us/sample - loss: 0.0040 - tp: 9771.0000 - fp: 80.0000 - tn: 135477.0000 - fn: 89.0000 - accuracy: 0.9988 - precision: 0.9919 - recall: 0.9910 - auc: 0.9999 - val_loss: 0.0390 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5058\n",
      "Epoch 13/30\n",
      "145417/145417 [==============================] - 10s 67us/sample - loss: 0.0041 - tp: 9772.0000 - fp: 85.0000 - tn: 135472.0000 - fn: 88.0000 - accuracy: 0.9988 - precision: 0.9914 - recall: 0.9911 - auc: 0.9997 - val_loss: 0.0409 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5292\n",
      "Epoch 14/30\n",
      "145417/145417 [==============================] - 9s 63us/sample - loss: 0.0032 - tp: 9794.0000 - fp: 69.0000 - tn: 135488.0000 - fn: 66.0000 - accuracy: 0.9991 - precision: 0.9930 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0428 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5220\n",
      "Epoch 15/30\n",
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0036 - tp: 9791.0000 - fp: 73.0000 - tn: 135484.0000 - fn: 69.0000 - accuracy: 0.9990 - precision: 0.9926 - recall: 0.9930 - auc: 0.9999 - val_loss: 0.0448 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5134\n",
      "Epoch 16/30\n",
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0032 - tp: 9790.0000 - fp: 62.0000 - tn: 135495.0000 - fn: 70.0000 - accuracy: 0.9991 - precision: 0.9937 - recall: 0.9929 - auc: 0.9998 - val_loss: 0.0452 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5216\n",
      "Epoch 17/30\n",
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0037 - tp: 9782.0000 - fp: 73.0000 - tn: 135484.0000 - fn: 78.0000 - accuracy: 0.9990 - precision: 0.9926 - recall: 0.9921 - auc: 0.9998 - val_loss: 0.0454 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5142\n",
      "Epoch 18/30\n",
      "145417/145417 [==============================] - 10s 67us/sample - loss: 0.0042 - tp: 9776.0000 - fp: 78.0000 - tn: 135479.0000 - fn: 84.0000 - accuracy: 0.9989 - precision: 0.9921 - recall: 0.9915 - auc: 0.9997 - val_loss: 0.0454 - val_tp: 2.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 63.0000 - val_accuracy: 0.9979 - val_precision: 0.2222 - val_recall: 0.0308 - val_auc: 0.5293\n",
      "Epoch 19/30\n",
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0038 - tp: 9778.0000 - fp: 76.0000 - tn: 135481.0000 - fn: 82.0000 - accuracy: 0.9989 - precision: 0.9923 - recall: 0.9917 - auc: 0.9997 - val_loss: 0.0491 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5136\n",
      "Epoch 20/30\n",
      "145417/145417 [==============================] - 10s 65us/sample - loss: 0.0033 - tp: 9788.0000 - fp: 74.0000 - tn: 135483.0000 - fn: 72.0000 - accuracy: 0.9990 - precision: 0.9925 - recall: 0.9927 - auc: 0.9998 - val_loss: 0.0511 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5143\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0037 - tp: 9784.0000 - fp: 75.0000 - tn: 135482.0000 - fn: 76.0000 - accuracy: 0.9990 - precision: 0.9924 - recall: 0.9923 - auc: 0.9997 - val_loss: 0.0508 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5147\n",
      "Epoch 22/30\n",
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0036 - tp: 9793.0000 - fp: 67.0000 - tn: 135490.0000 - fn: 67.0000 - accuracy: 0.9991 - precision: 0.9932 - recall: 0.9932 - auc: 0.9998 - val_loss: 0.0517 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5069\n",
      "Epoch 23/30\n",
      "145417/145417 [==============================] - 9s 65us/sample - loss: 0.0042 - tp: 9769.0000 - fp: 89.0000 - tn: 135468.0000 - fn: 91.0000 - accuracy: 0.9988 - precision: 0.9910 - recall: 0.9908 - auc: 0.9997 - val_loss: 0.0512 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 33900.0000 - val_fn: 64.0000 - val_accuracy: 0.9978 - val_precision: 0.0909 - val_recall: 0.0154 - val_auc: 0.5142\n",
      "Epoch 24/30\n",
      "145417/145417 [==============================] - 10s 66us/sample - loss: 0.0037 - tp: 9772.0000 - fp: 84.0000 - tn: 135473.0000 - fn: 88.0000 - accuracy: 0.9988 - precision: 0.9915 - recall: 0.9911 - auc: 0.9997 - val_loss: 0.0530 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 33902.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1111 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 25/30\n",
      "145417/145417 [==============================] - 9s 64us/sample - loss: 0.0032 - tp: 9792.0000 - fp: 73.0000 - tn: 135484.0000 - fn: 68.0000 - accuracy: 0.9990 - precision: 0.9926 - recall: 0.9931 - auc: 0.9997 - val_loss: 0.0564 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 26/30\n",
      "145417/145417 [==============================] - 11s 74us/sample - loss: 0.0030 - tp: 9791.0000 - fp: 67.0000 - tn: 135490.0000 - fn: 69.0000 - accuracy: 0.9991 - precision: 0.9932 - recall: 0.9930 - auc: 0.9998 - val_loss: 0.0563 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5300\n",
      "Epoch 27/30\n",
      "145417/145417 [==============================] - 10s 67us/sample - loss: 0.0030 - tp: 9811.0000 - fp: 64.0000 - tn: 135493.0000 - fn: 49.0000 - accuracy: 0.9992 - precision: 0.9935 - recall: 0.9950 - auc: 0.9998 - val_loss: 0.0583 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5221\n",
      "Epoch 28/30\n",
      "145417/145417 [==============================] - 12s 80us/sample - loss: 0.0033 - tp: 9790.0000 - fp: 73.0000 - tn: 135484.0000 - fn: 70.0000 - accuracy: 0.9990 - precision: 0.9926 - recall: 0.9929 - auc: 0.9997 - val_loss: 0.0572 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5302\n",
      "Epoch 29/30\n",
      "145417/145417 [==============================] - 10s 67us/sample - loss: 0.0025 - tp: 9806.0000 - fp: 43.0000 - tn: 135514.0000 - fn: 54.0000 - accuracy: 0.9993 - precision: 0.9956 - recall: 0.9945 - auc: 0.9998 - val_loss: 0.0609 - val_tp: 1.0000 - val_fp: 6.0000 - val_tn: 33904.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1429 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 30/30\n",
      "145417/145417 [==============================] - 9s 63us/sample - loss: 0.0028 - tp: 9805.0000 - fp: 49.0000 - tn: 135508.0000 - fn: 55.0000 - accuracy: 0.9993 - precision: 0.9950 - recall: 0.9944 - auc: 0.9998 - val_loss: 0.0583 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df18f250>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_47_samples = 10000\n",
    "\n",
    "rep_coef = n_47_samples // x_img_train_47.shape[0]\n",
    "x_img_train_47_up = np.repeat(x_img_train_47, rep_coef, axis=0)\n",
    "x_txt_train_47_up = np.repeat(x_txt_train_47, rep_coef, axis=0)\n",
    "y_train_47_up = np.ones(x_img_train_47_up.shape[0])\n",
    "\n",
    "x_img_train_up = np.concatenate((x_img_train_others, x_img_train_47_up))\n",
    "x_txt_train_up = np.concatenate((x_txt_train_others, x_txt_train_47_up))\n",
    "y_train_up = np.concatenate((np.zeros(x_img_train_others.shape[0]), y_train_47_up))\n",
    "\n",
    "perm = np.random.permutation(len(y_train_up))\n",
    "x_img_train_up = x_img_train_up[perm]\n",
    "x_txt_train_up = x_txt_train_up[perm]\n",
    "y_train_up = y_train_up[perm]\n",
    "\n",
    "model_up_10000 = get_model_class_47_1()\n",
    "model_up_10000.fit(\n",
    "    [x_img_train_up, x_txt_train_up],\n",
    "    y_train_up,\n",
    "    batch_size=4096,\n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_47_2():\n",
    "    output_bias = tf.keras.initializers.Constant(init_bias)\n",
    "    \n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x_img = Dense(512, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(128)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid',  bias_initializer=output_bias)(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 145417 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "145417/145417 [==============================] - 21s 141us/sample - loss: 0.3137 - tp: 1012.0000 - fp: 3195.0000 - tn: 132362.0000 - fn: 8848.0000 - accuracy: 0.9172 - precision: 0.2406 - recall: 0.1026 - auc: 0.6672 - val_loss: 0.0191 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7074\n",
      "Epoch 2/30\n",
      "145417/145417 [==============================] - 17s 119us/sample - loss: 0.1538 - tp: 4175.0000 - fp: 2136.0000 - tn: 133421.0000 - fn: 5685.0000 - accuracy: 0.9462 - precision: 0.6615 - recall: 0.4234 - auc: 0.9162 - val_loss: 0.0154 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.6057\n",
      "Epoch 3/30\n",
      "145417/145417 [==============================] - 15s 103us/sample - loss: 0.0608 - tp: 7718.0000 - fp: 1159.0000 - tn: 134398.0000 - fn: 2142.0000 - accuracy: 0.9773 - precision: 0.8694 - recall: 0.7828 - auc: 0.9874 - val_loss: 0.0198 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5319\n",
      "Epoch 4/30\n",
      "145417/145417 [==============================] - 15s 105us/sample - loss: 0.0305 - tp: 8853.0000 - fp: 611.0000 - tn: 134946.0000 - fn: 1007.0000 - accuracy: 0.9889 - precision: 0.9354 - recall: 0.8979 - auc: 0.9963 - val_loss: 0.0241 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5136\n",
      "Epoch 5/30\n",
      "145417/145417 [==============================] - 17s 115us/sample - loss: 0.0189 - tp: 9257.0000 - fp: 393.0000 - tn: 135164.0000 - fn: 603.0000 - accuracy: 0.9932 - precision: 0.9593 - recall: 0.9388 - auc: 0.9984 - val_loss: 0.0283 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5070\n",
      "Epoch 6/30\n",
      "145417/145417 [==============================] - 17s 120us/sample - loss: 0.0144 - tp: 9462.0000 - fp: 300.0000 - tn: 135257.0000 - fn: 398.0000 - accuracy: 0.9952 - precision: 0.9693 - recall: 0.9596 - auc: 0.9987 - val_loss: 0.0297 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5070\n",
      "Epoch 7/30\n",
      "145417/145417 [==============================] - 16s 110us/sample - loss: 0.0118 - tp: 9509.0000 - fp: 241.0000 - tn: 135316.0000 - fn: 351.0000 - accuracy: 0.9959 - precision: 0.9753 - recall: 0.9644 - auc: 0.9987 - val_loss: 0.0323 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 8/30\n",
      "145417/145417 [==============================] - 13s 93us/sample - loss: 0.0095 - tp: 9596.0000 - fp: 207.0000 - tn: 135350.0000 - fn: 264.0000 - accuracy: 0.9968 - precision: 0.9789 - recall: 0.9732 - auc: 0.9991 - val_loss: 0.0344 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 9/30\n",
      "145417/145417 [==============================] - 15s 101us/sample - loss: 0.0094 - tp: 9592.0000 - fp: 172.0000 - tn: 135385.0000 - fn: 268.0000 - accuracy: 0.9970 - precision: 0.9824 - recall: 0.9728 - auc: 0.9993 - val_loss: 0.0335 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 10/30\n",
      "145417/145417 [==============================] - 13s 90us/sample - loss: 0.0084 - tp: 9633.0000 - fp: 163.0000 - tn: 135394.0000 - fn: 227.0000 - accuracy: 0.9973 - precision: 0.9834 - recall: 0.9770 - auc: 0.9993 - val_loss: 0.0344 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 11/30\n",
      "145417/145417 [==============================] - 16s 109us/sample - loss: 0.0066 - tp: 9695.0000 - fp: 146.0000 - tn: 135411.0000 - fn: 165.0000 - accuracy: 0.9979 - precision: 0.9852 - recall: 0.9833 - auc: 0.9995 - val_loss: 0.0361 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 12/30\n",
      "145417/145417 [==============================] - 15s 100us/sample - loss: 0.0059 - tp: 9714.0000 - fp: 119.0000 - tn: 135438.0000 - fn: 146.0000 - accuracy: 0.9982 - precision: 0.9879 - recall: 0.9852 - auc: 0.9995 - val_loss: 0.0375 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 13/30\n",
      "145417/145417 [==============================] - 16s 108us/sample - loss: 0.0050 - tp: 9738.0000 - fp: 93.0000 - tn: 135464.0000 - fn: 122.0000 - accuracy: 0.9985 - precision: 0.9905 - recall: 0.9876 - auc: 0.9997 - val_loss: 0.0383 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 14/30\n",
      "145417/145417 [==============================] - 15s 103us/sample - loss: 0.0054 - tp: 9723.0000 - fp: 101.0000 - tn: 135456.0000 - fn: 137.0000 - accuracy: 0.9984 - precision: 0.9897 - recall: 0.9861 - auc: 0.9997 - val_loss: 0.0380 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 15/30\n",
      "145417/145417 [==============================] - 15s 104us/sample - loss: 0.0056 - tp: 9747.0000 - fp: 92.0000 - tn: 135465.0000 - fn: 113.0000 - accuracy: 0.9986 - precision: 0.9906 - recall: 0.9885 - auc: 0.9997 - val_loss: 0.0391 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 16/30\n",
      "145417/145417 [==============================] - 15s 100us/sample - loss: 0.0042 - tp: 9757.0000 - fp: 91.0000 - tn: 135466.0000 - fn: 103.0000 - accuracy: 0.9987 - precision: 0.9908 - recall: 0.9896 - auc: 0.9998 - val_loss: 0.0391 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 17/30\n",
      "145417/145417 [==============================] - 15s 106us/sample - loss: 0.0040 - tp: 9757.0000 - fp: 74.0000 - tn: 135483.0000 - fn: 103.0000 - accuracy: 0.9988 - precision: 0.9925 - recall: 0.9896 - auc: 0.9995 - val_loss: 0.0396 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 18/30\n",
      "145417/145417 [==============================] - 15s 102us/sample - loss: 0.0038 - tp: 9781.0000 - fp: 82.0000 - tn: 135475.0000 - fn: 79.0000 - accuracy: 0.9989 - precision: 0.9917 - recall: 0.9920 - auc: 0.9998 - val_loss: 0.0413 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 19/30\n",
      "145417/145417 [==============================] - 19s 133us/sample - loss: 0.0037 - tp: 9775.0000 - fp: 74.0000 - tn: 135483.0000 - fn: 85.0000 - accuracy: 0.9989 - precision: 0.9925 - recall: 0.9914 - auc: 0.9996 - val_loss: 0.0431 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 20/30\n",
      "145417/145417 [==============================] - 16s 110us/sample - loss: 0.0038 - tp: 9781.0000 - fp: 75.0000 - tn: 135482.0000 - fn: 79.0000 - accuracy: 0.9989 - precision: 0.9924 - recall: 0.9920 - auc: 0.9996 - val_loss: 0.0424 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145417/145417 [==============================] - 17s 119us/sample - loss: 0.0035 - tp: 9782.0000 - fp: 69.0000 - tn: 135488.0000 - fn: 78.0000 - accuracy: 0.9990 - precision: 0.9930 - recall: 0.9921 - auc: 0.9997 - val_loss: 0.0420 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 22/30\n",
      "145417/145417 [==============================] - 15s 102us/sample - loss: 0.0032 - tp: 9781.0000 - fp: 57.0000 - tn: 135500.0000 - fn: 79.0000 - accuracy: 0.9991 - precision: 0.9942 - recall: 0.9920 - auc: 0.9998 - val_loss: 0.0418 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 23/30\n",
      "145417/145417 [==============================] - 15s 105us/sample - loss: 0.0032 - tp: 9792.0000 - fp: 63.0000 - tn: 135494.0000 - fn: 68.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9931 - auc: 0.9997 - val_loss: 0.0447 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 24/30\n",
      "145417/145417 [==============================] - 17s 114us/sample - loss: 0.0030 - tp: 9785.0000 - fp: 58.0000 - tn: 135499.0000 - fn: 75.0000 - accuracy: 0.9991 - precision: 0.9941 - recall: 0.9924 - auc: 0.9999 - val_loss: 0.0438 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 25/30\n",
      "145417/145417 [==============================] - 14s 98us/sample - loss: 0.0029 - tp: 9795.0000 - fp: 60.0000 - tn: 135497.0000 - fn: 65.0000 - accuracy: 0.9991 - precision: 0.9939 - recall: 0.9934 - auc: 0.9997 - val_loss: 0.0450 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 26/30\n",
      "145417/145417 [==============================] - 15s 102us/sample - loss: 0.0033 - tp: 9789.0000 - fp: 57.0000 - tn: 135500.0000 - fn: 71.0000 - accuracy: 0.9991 - precision: 0.9942 - recall: 0.9928 - auc: 0.9996 - val_loss: 0.0445 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 27/30\n",
      "145417/145417 [==============================] - 18s 123us/sample - loss: 0.0028 - tp: 9805.0000 - fp: 49.0000 - tn: 135508.0000 - fn: 55.0000 - accuracy: 0.9993 - precision: 0.9950 - recall: 0.9944 - auc: 0.9997 - val_loss: 0.0442 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 28/30\n",
      "145417/145417 [==============================] - 15s 105us/sample - loss: 0.0027 - tp: 9814.0000 - fp: 46.0000 - tn: 135511.0000 - fn: 46.0000 - accuracy: 0.9994 - precision: 0.9953 - recall: 0.9953 - auc: 0.9998 - val_loss: 0.0451 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 29/30\n",
      "145417/145417 [==============================] - 18s 122us/sample - loss: 0.0026 - tp: 9807.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 53.0000 - accuracy: 0.9994 - precision: 0.9960 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0437 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 30/30\n",
      "145417/145417 [==============================] - 16s 109us/sample - loss: 0.0024 - tp: 9812.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 48.0000 - accuracy: 0.9994 - precision: 0.9960 - recall: 0.9951 - auc: 0.9999 - val_loss: 0.0443 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n"
     ]
    }
   ],
   "source": [
    "model_2_up_10000 = get_model_47_2()\n",
    "history_2_10000 = model_2_up_10000.fit(\n",
    "    [x_img_train_up, x_txt_train_up],\n",
    "    y_train_up,\n",
    "    batch_size=4096,\n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def plot_loss(history):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "    plt.plot(history.epoch, history.history['loss'], color=colors[0], label='Train loss')\n",
    "    plt.plot(history.epoch, history.history['val_loss'], color=colors[1], label='Val loss')\n",
    "    plt.plot(history.epoch, history.history['precision'], color=colors[2], label='Train precision')\n",
    "    plt.plot(history.epoch, history.history['val_precision'], color=colors[3], label='Val precision')\n",
    "    plt.plot(history.epoch, history.history['recall'], color=colors[4], label='Train recall')\n",
    "    plt.plot(history.epoch, history.history['val_recall'], color=colors[5], label='Val recall')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "  \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_2_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_47_3():\n",
    "    output_bias = tf.keras.initializers.Constant(init_bias)\n",
    "    \n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x_img = Dense(512, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    \n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(128)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = concatenate([x, x_img, x_txt])\n",
    "    x = Dense(128)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid',  bias_initializer=output_bias)(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 145417 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "145417/145417 [==============================] - 18s 124us/sample - loss: 0.5335 - tp: 937.0000 - fp: 5772.0000 - tn: 129785.0000 - fn: 8923.0000 - accuracy: 0.8989 - precision: 0.1397 - recall: 0.0950 - auc: 0.6093 - val_loss: 0.0287 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7141\n",
      "Epoch 2/30\n",
      "145417/145417 [==============================] - 14s 95us/sample - loss: 0.2014 - tp: 1996.0000 - fp: 1963.0000 - tn: 133594.0000 - fn: 7864.0000 - accuracy: 0.9324 - precision: 0.5042 - recall: 0.2024 - auc: 0.8402 - val_loss: 0.0234 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.7076\n",
      "Epoch 3/30\n",
      "145417/145417 [==============================] - 16s 109us/sample - loss: 0.1224 - tp: 4803.0000 - fp: 1674.0000 - tn: 133883.0000 - fn: 5057.0000 - accuracy: 0.9537 - precision: 0.7415 - recall: 0.4871 - auc: 0.9494 - val_loss: 0.0172 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.6437\n",
      "Epoch 4/30\n",
      "145417/145417 [==============================] - 15s 105us/sample - loss: 0.0608 - tp: 7498.0000 - fp: 988.0000 - tn: 134569.0000 - fn: 2362.0000 - accuracy: 0.9770 - precision: 0.8836 - recall: 0.7604 - auc: 0.9885 - val_loss: 0.0176 - val_tp: 1.0000 - val_fp: 7.0000 - val_tn: 33903.0000 - val_fn: 64.0000 - val_accuracy: 0.9979 - val_precision: 0.1250 - val_recall: 0.0154 - val_auc: 0.5922\n",
      "Epoch 5/30\n",
      "145417/145417 [==============================] - 15s 106us/sample - loss: 0.0330 - tp: 8694.0000 - fp: 630.0000 - tn: 134927.0000 - fn: 1166.0000 - accuracy: 0.9876 - precision: 0.9324 - recall: 0.8817 - auc: 0.9967 - val_loss: 0.0199 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5520\n",
      "Epoch 6/30\n",
      "145417/145417 [==============================] - 17s 114us/sample - loss: 0.0202 - tp: 9193.0000 - fp: 400.0000 - tn: 135157.0000 - fn: 667.0000 - accuracy: 0.9927 - precision: 0.9583 - recall: 0.9324 - auc: 0.9986 - val_loss: 0.0234 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5264\n",
      "Epoch 7/30\n",
      "145417/145417 [==============================] - 18s 124us/sample - loss: 0.0137 - tp: 9449.0000 - fp: 284.0000 - tn: 135273.0000 - fn: 411.0000 - accuracy: 0.9952 - precision: 0.9708 - recall: 0.9583 - auc: 0.9993 - val_loss: 0.0261 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5278\n",
      "Epoch 8/30\n",
      "145417/145417 [==============================] - 17s 118us/sample - loss: 0.0115 - tp: 9515.0000 - fp: 219.0000 - tn: 135338.0000 - fn: 345.0000 - accuracy: 0.9961 - precision: 0.9775 - recall: 0.9650 - auc: 0.9994 - val_loss: 0.0275 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5208\n",
      "Epoch 9/30\n",
      "145417/145417 [==============================] - 18s 123us/sample - loss: 0.0106 - tp: 9545.0000 - fp: 229.0000 - tn: 135328.0000 - fn: 315.0000 - accuracy: 0.9963 - precision: 0.9766 - recall: 0.9681 - auc: 0.9993 - val_loss: 0.0291 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5130\n",
      "Epoch 10/30\n",
      "145417/145417 [==============================] - 16s 112us/sample - loss: 0.0088 - tp: 9610.0000 - fp: 197.0000 - tn: 135360.0000 - fn: 250.0000 - accuracy: 0.9969 - precision: 0.9799 - recall: 0.9746 - auc: 0.9994 - val_loss: 0.0314 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5068\n",
      "Epoch 11/30\n",
      "145417/145417 [==============================] - 17s 115us/sample - loss: 0.0068 - tp: 9655.0000 - fp: 136.0000 - tn: 135421.0000 - fn: 205.0000 - accuracy: 0.9977 - precision: 0.9861 - recall: 0.9792 - auc: 0.9996 - val_loss: 0.0313 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5214\n",
      "Epoch 12/30\n",
      "145417/145417 [==============================] - 18s 126us/sample - loss: 0.0060 - tp: 9691.0000 - fp: 123.0000 - tn: 135434.0000 - fn: 169.0000 - accuracy: 0.9980 - precision: 0.9875 - recall: 0.9829 - auc: 0.9998 - val_loss: 0.0329 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5067\n",
      "Epoch 13/30\n",
      "145417/145417 [==============================] - 17s 120us/sample - loss: 0.0054 - tp: 9730.0000 - fp: 99.0000 - tn: 135458.0000 - fn: 130.0000 - accuracy: 0.9984 - precision: 0.9899 - recall: 0.9868 - auc: 0.9998 - val_loss: 0.0354 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 14/30\n",
      "145417/145417 [==============================] - 17s 120us/sample - loss: 0.0051 - tp: 9736.0000 - fp: 89.0000 - tn: 135468.0000 - fn: 124.0000 - accuracy: 0.9985 - precision: 0.9909 - recall: 0.9874 - auc: 0.9997 - val_loss: 0.0359 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5071\n",
      "Epoch 15/30\n",
      "145417/145417 [==============================] - 23s 159us/sample - loss: 0.0048 - tp: 9735.0000 - fp: 95.0000 - tn: 135462.0000 - fn: 125.0000 - accuracy: 0.9985 - precision: 0.9903 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.0366 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 16/30\n",
      "145417/145417 [==============================] - 20s 134us/sample - loss: 0.0055 - tp: 9729.0000 - fp: 103.0000 - tn: 135454.0000 - fn: 131.0000 - accuracy: 0.9984 - precision: 0.9895 - recall: 0.9867 - auc: 0.9996 - val_loss: 0.0364 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5149\n",
      "Epoch 17/30\n",
      "145417/145417 [==============================] - 16s 113us/sample - loss: 0.0046 - tp: 9733.0000 - fp: 97.0000 - tn: 135460.0000 - fn: 127.0000 - accuracy: 0.9985 - precision: 0.9901 - recall: 0.9871 - auc: 0.9996 - val_loss: 0.0370 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5146\n",
      "Epoch 18/30\n",
      "145417/145417 [==============================] - 22s 149us/sample - loss: 0.0045 - tp: 9758.0000 - fp: 85.0000 - tn: 135472.0000 - fn: 102.0000 - accuracy: 0.9987 - precision: 0.9914 - recall: 0.9897 - auc: 0.9996 - val_loss: 0.0372 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5148\n",
      "Epoch 19/30\n",
      "145417/145417 [==============================] - 20s 138us/sample - loss: 0.0042 - tp: 9765.0000 - fp: 89.0000 - tn: 135468.0000 - fn: 95.0000 - accuracy: 0.9987 - precision: 0.9910 - recall: 0.9904 - auc: 0.9998 - val_loss: 0.0395 - val_tp: 1.0000 - val_fp: 5.0000 - val_tn: 33905.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.1667 - val_recall: 0.0154 - val_auc: 0.5073\n",
      "Epoch 20/30\n",
      "145417/145417 [==============================] - 20s 140us/sample - loss: 0.0044 - tp: 9754.0000 - fp: 83.0000 - tn: 135474.0000 - fn: 106.0000 - accuracy: 0.9987 - precision: 0.9916 - recall: 0.9892 - auc: 0.9996 - val_loss: 0.0390 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5072\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145417/145417 [==============================] - 20s 136us/sample - loss: 0.0035 - tp: 9767.0000 - fp: 76.0000 - tn: 135481.0000 - fn: 93.0000 - accuracy: 0.9988 - precision: 0.9923 - recall: 0.9906 - auc: 0.9997 - val_loss: 0.0395 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5149\n",
      "Epoch 22/30\n",
      "145417/145417 [==============================] - 16s 107us/sample - loss: 0.0033 - tp: 9788.0000 - fp: 63.0000 - tn: 135494.0000 - fn: 72.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9927 - auc: 0.9999 - val_loss: 0.0407 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 23/30\n",
      "145417/145417 [==============================] - 15s 106us/sample - loss: 0.0032 - tp: 9782.0000 - fp: 64.0000 - tn: 135493.0000 - fn: 78.0000 - accuracy: 0.9990 - precision: 0.9935 - recall: 0.9921 - auc: 0.9997 - val_loss: 0.0402 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 24/30\n",
      "145417/145417 [==============================] - 16s 112us/sample - loss: 0.0029 - tp: 9800.0000 - fp: 56.0000 - tn: 135501.0000 - fn: 60.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9939 - auc: 0.9999 - val_loss: 0.0421 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 25/30\n",
      "145417/145417 [==============================] - 17s 115us/sample - loss: 0.0032 - tp: 9789.0000 - fp: 54.0000 - tn: 135503.0000 - fn: 71.0000 - accuracy: 0.9991 - precision: 0.9945 - recall: 0.9928 - auc: 0.9998 - val_loss: 0.0414 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5150\n",
      "Epoch 26/30\n",
      "145417/145417 [==============================] - 15s 101us/sample - loss: 0.0029 - tp: 9793.0000 - fp: 57.0000 - tn: 135500.0000 - fn: 67.0000 - accuracy: 0.9991 - precision: 0.9942 - recall: 0.9932 - auc: 0.9998 - val_loss: 0.0422 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5073\n",
      "Epoch 27/30\n",
      "145417/145417 [==============================] - 17s 114us/sample - loss: 0.0028 - tp: 9789.0000 - fp: 63.0000 - tn: 135494.0000 - fn: 71.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9928 - auc: 0.9997 - val_loss: 0.0433 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 28/30\n",
      "145417/145417 [==============================] - 16s 109us/sample - loss: 0.0029 - tp: 9794.0000 - fp: 63.0000 - tn: 135494.0000 - fn: 66.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0426 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5152\n",
      "Epoch 29/30\n",
      "145417/145417 [==============================] - 16s 109us/sample - loss: 0.0043 - tp: 9773.0000 - fp: 74.0000 - tn: 135483.0000 - fn: 87.0000 - accuracy: 0.9989 - precision: 0.9925 - recall: 0.9912 - auc: 0.9996 - val_loss: 0.0424 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5151\n",
      "Epoch 30/30\n",
      "145417/145417 [==============================] - 15s 107us/sample - loss: 0.0031 - tp: 9796.0000 - fp: 68.0000 - tn: 135489.0000 - fn: 64.0000 - accuracy: 0.9991 - precision: 0.9931 - recall: 0.9935 - auc: 0.9998 - val_loss: 0.0436 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5075\n"
     ]
    }
   ],
   "source": [
    "model_3_up_10000 = get_model_47_3()\n",
    "history_3_10000 = model_3_up_10000.fit(\n",
    "    [x_img_train_up, x_txt_train_up],\n",
    "    y_train_up,\n",
    "    batch_size=4096,\n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_3_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_47_4():\n",
    "    output_bias = tf.keras.initializers.Constant(init_bias)\n",
    "    \n",
    "    inp_img = Input(shape=(1024,))\n",
    "    x_img = Dense(512, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    \n",
    "    relu = Dense(512, activation='relu')(x_img)\n",
    "    sigmoid = Dense(512, activation='sigmoid')(x_img)\n",
    "    mult_1 = Multiply()([x_img, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x_img = Add()([mult_2, mult_1])\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "                                    \n",
    "    \n",
    "    inp_txt = Input(shape=(300,))\n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    relu = Dense(256, activation='relu')(x_txt)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x_txt)\n",
    "    mult_1 = Multiply()([x_txt, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x_txt = Add()([mult_2, mult_1])\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    relu = Dense(256, activation='relu')(x)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x)\n",
    "    mult_1 = Multiply()([x, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x = Add()([mult_2, mult_1])\n",
    "    x = Dense(128)(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(1, activation='sigmoid',  bias_initializer=output_bias)(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3), loss='binary_crossentropy', metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 145417 samples, validate on 33975 samples\n",
      "Epoch 1/30\n",
      "145417/145417 [==============================] - 32s 221us/sample - loss: 0.2620 - tp: 528.0000 - fp: 1235.0000 - tn: 134322.0000 - fn: 9332.0000 - accuracy: 0.9273 - precision: 0.2995 - recall: 0.0535 - auc: 0.6504 - val_loss: 0.0217 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7066\n",
      "Epoch 2/30\n",
      "145417/145417 [==============================] - 24s 163us/sample - loss: 0.1502 - tp: 3342.0000 - fp: 1050.0000 - tn: 134507.0000 - fn: 6518.0000 - accuracy: 0.9480 - precision: 0.7609 - recall: 0.3389 - auc: 0.9132 - val_loss: 0.0137 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 65.0000 - val_accuracy: 0.9981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5827\n",
      "Epoch 3/30\n",
      "145417/145417 [==============================] - 24s 165us/sample - loss: 0.0666 - tp: 7421.0000 - fp: 843.0000 - tn: 134714.0000 - fn: 2439.0000 - accuracy: 0.9774 - precision: 0.8980 - recall: 0.7526 - auc: 0.9850 - val_loss: 0.0137 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5363\n",
      "Epoch 4/30\n",
      "145417/145417 [==============================] - 27s 188us/sample - loss: 0.0350 - tp: 8711.0000 - fp: 539.0000 - tn: 135018.0000 - fn: 1149.0000 - accuracy: 0.9884 - precision: 0.9417 - recall: 0.8835 - auc: 0.9957 - val_loss: 0.0148 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5074\n",
      "Epoch 5/30\n",
      "145417/145417 [==============================] - 27s 186us/sample - loss: 0.0214 - tp: 9196.0000 - fp: 350.0000 - tn: 135207.0000 - fn: 664.0000 - accuracy: 0.9930 - precision: 0.9633 - recall: 0.9327 - auc: 0.9985 - val_loss: 0.0166 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 6/30\n",
      "145417/145417 [==============================] - 25s 175us/sample - loss: 0.0145 - tp: 9418.0000 - fp: 268.0000 - tn: 135289.0000 - fn: 442.0000 - accuracy: 0.9951 - precision: 0.9723 - recall: 0.9552 - auc: 0.9993 - val_loss: 0.0182 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5073\n",
      "Epoch 7/30\n",
      "145417/145417 [==============================] - 25s 175us/sample - loss: 0.0112 - tp: 9523.0000 - fp: 206.0000 - tn: 135351.0000 - fn: 337.0000 - accuracy: 0.9963 - precision: 0.9788 - recall: 0.9658 - auc: 0.9992 - val_loss: 0.0196 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 33910.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 1.0000 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 8/30\n",
      "145417/145417 [==============================] - 25s 173us/sample - loss: 0.0096 - tp: 9603.0000 - fp: 173.0000 - tn: 135384.0000 - fn: 257.0000 - accuracy: 0.9970 - precision: 0.9823 - recall: 0.9739 - auc: 0.9994 - val_loss: 0.0212 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5075\n",
      "Epoch 9/30\n",
      "145417/145417 [==============================] - 26s 179us/sample - loss: 0.0084 - tp: 9635.0000 - fp: 169.0000 - tn: 135388.0000 - fn: 225.0000 - accuracy: 0.9973 - precision: 0.9828 - recall: 0.9772 - auc: 0.9995 - val_loss: 0.0213 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 10/30\n",
      "145417/145417 [==============================] - 30s 205us/sample - loss: 0.0059 - tp: 9671.0000 - fp: 123.0000 - tn: 135434.0000 - fn: 189.0000 - accuracy: 0.9979 - precision: 0.9874 - recall: 0.9808 - auc: 0.9998 - val_loss: 0.0230 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 11/30\n",
      "145417/145417 [==============================] - 25s 173us/sample - loss: 0.0058 - tp: 9696.0000 - fp: 108.0000 - tn: 135449.0000 - fn: 164.0000 - accuracy: 0.9981 - precision: 0.9890 - recall: 0.9834 - auc: 0.9996 - val_loss: 0.0243 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 12/30\n",
      "145417/145417 [==============================] - 25s 171us/sample - loss: 0.0052 - tp: 9723.0000 - fp: 100.0000 - tn: 135457.0000 - fn: 137.0000 - accuracy: 0.9984 - precision: 0.9898 - recall: 0.9861 - auc: 0.9997 - val_loss: 0.0245 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 13/30\n",
      "145417/145417 [==============================] - 26s 178us/sample - loss: 0.0054 - tp: 9726.0000 - fp: 112.0000 - tn: 135445.0000 - fn: 134.0000 - accuracy: 0.9983 - precision: 0.9886 - recall: 0.9864 - auc: 0.9997 - val_loss: 0.0259 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 14/30\n",
      "145417/145417 [==============================] - 33s 226us/sample - loss: 0.0047 - tp: 9744.0000 - fp: 91.0000 - tn: 135466.0000 - fn: 116.0000 - accuracy: 0.9986 - precision: 0.9907 - recall: 0.9882 - auc: 0.9997 - val_loss: 0.0266 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 15/30\n",
      "145417/145417 [==============================] - 29s 200us/sample - loss: 0.0038 - tp: 9756.0000 - fp: 82.0000 - tn: 135475.0000 - fn: 104.0000 - accuracy: 0.9987 - precision: 0.9917 - recall: 0.9895 - auc: 0.9997 - val_loss: 0.0272 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 16/30\n",
      "145417/145417 [==============================] - 39s 268us/sample - loss: 0.0041 - tp: 9760.0000 - fp: 85.0000 - tn: 135472.0000 - fn: 100.0000 - accuracy: 0.9987 - precision: 0.9914 - recall: 0.9899 - auc: 0.9998 - val_loss: 0.0290 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5153\n",
      "Epoch 17/30\n",
      "145417/145417 [==============================] - 31s 214us/sample - loss: 0.0037 - tp: 9761.0000 - fp: 73.0000 - tn: 135484.0000 - fn: 99.0000 - accuracy: 0.9988 - precision: 0.9926 - recall: 0.9900 - auc: 0.9999 - val_loss: 0.0296 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 18/30\n",
      "145417/145417 [==============================] - 26s 178us/sample - loss: 0.0035 - tp: 9776.0000 - fp: 74.0000 - tn: 135483.0000 - fn: 84.0000 - accuracy: 0.9989 - precision: 0.9925 - recall: 0.9915 - auc: 0.9998 - val_loss: 0.0300 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 19/30\n",
      "145417/145417 [==============================] - 22s 153us/sample - loss: 0.0029 - tp: 9791.0000 - fp: 56.0000 - tn: 135501.0000 - fn: 69.0000 - accuracy: 0.9991 - precision: 0.9943 - recall: 0.9930 - auc: 1.0000 - val_loss: 0.0324 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5153\n",
      "Epoch 20/30\n",
      "145417/145417 [==============================] - 22s 151us/sample - loss: 0.0031 - tp: 9787.0000 - fp: 72.0000 - tn: 135485.0000 - fn: 73.0000 - accuracy: 0.9990 - precision: 0.9927 - recall: 0.9926 - auc: 0.9999 - val_loss: 0.0327 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145417/145417 [==============================] - 22s 150us/sample - loss: 0.0034 - tp: 9781.0000 - fp: 64.0000 - tn: 135493.0000 - fn: 79.0000 - accuracy: 0.9990 - precision: 0.9935 - recall: 0.9920 - auc: 0.9998 - val_loss: 0.0332 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 22/30\n",
      "145417/145417 [==============================] - 22s 153us/sample - loss: 0.0032 - tp: 9784.0000 - fp: 63.0000 - tn: 135494.0000 - fn: 76.0000 - accuracy: 0.9990 - precision: 0.9936 - recall: 0.9923 - auc: 0.9998 - val_loss: 0.0341 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 33909.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.5000 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 23/30\n",
      "145417/145417 [==============================] - 22s 152us/sample - loss: 0.0032 - tp: 9795.0000 - fp: 58.0000 - tn: 135499.0000 - fn: 65.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9934 - auc: 0.9999 - val_loss: 0.0342 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 24/30\n",
      "145417/145417 [==============================] - 22s 149us/sample - loss: 0.0024 - tp: 9801.0000 - fp: 51.0000 - tn: 135506.0000 - fn: 59.0000 - accuracy: 0.9992 - precision: 0.9948 - recall: 0.9940 - auc: 0.9999 - val_loss: 0.0380 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5153\n",
      "Epoch 25/30\n",
      "145417/145417 [==============================] - 21s 147us/sample - loss: 0.0020 - tp: 9816.0000 - fp: 42.0000 - tn: 135515.0000 - fn: 44.0000 - accuracy: 0.9994 - precision: 0.9957 - recall: 0.9955 - auc: 1.0000 - val_loss: 0.0390 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5153\n",
      "Epoch 26/30\n",
      "145417/145417 [==============================] - 21s 147us/sample - loss: 0.0027 - tp: 9802.0000 - fp: 59.0000 - tn: 135498.0000 - fn: 58.0000 - accuracy: 0.9992 - precision: 0.9940 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.0370 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 33908.0000 - val_fn: 64.0000 - val_accuracy: 0.9981 - val_precision: 0.3333 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 27/30\n",
      "145417/145417 [==============================] - 21s 146us/sample - loss: 0.0024 - tp: 9811.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 49.0000 - accuracy: 0.9994 - precision: 0.9954 - recall: 0.9950 - auc: 0.9998 - val_loss: 0.0363 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5153\n",
      "Epoch 28/30\n",
      "145417/145417 [==============================] - 21s 148us/sample - loss: 0.0022 - tp: 9813.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 47.0000 - accuracy: 0.9994 - precision: 0.9954 - recall: 0.9952 - auc: 0.9999 - val_loss: 0.0374 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5076\n",
      "Epoch 29/30\n",
      "145417/145417 [==============================] - 21s 145us/sample - loss: 0.0023 - tp: 9812.0000 - fp: 45.0000 - tn: 135512.0000 - fn: 48.0000 - accuracy: 0.9994 - precision: 0.9954 - recall: 0.9951 - auc: 1.0000 - val_loss: 0.0385 - val_tp: 1.0000 - val_fp: 3.0000 - val_tn: 33907.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2500 - val_recall: 0.0154 - val_auc: 0.5153\n",
      "Epoch 30/30\n",
      "145417/145417 [==============================] - 21s 146us/sample - loss: 0.0020 - tp: 9817.0000 - fp: 39.0000 - tn: 135518.0000 - fn: 43.0000 - accuracy: 0.9994 - precision: 0.9960 - recall: 0.9956 - auc: 1.0000 - val_loss: 0.0405 - val_tp: 1.0000 - val_fp: 4.0000 - val_tn: 33906.0000 - val_fn: 64.0000 - val_accuracy: 0.9980 - val_precision: 0.2000 - val_recall: 0.0154 - val_auc: 0.5153\n"
     ]
    }
   ],
   "source": [
    "model_4_up_10000 = get_model_47_4()\n",
    "history_4_10000 = model_4_up_10000.fit(\n",
    "    [x_img_train_up, x_txt_train_up],\n",
    "    y_train_up,\n",
    "    batch_size=4096,\n",
    "    validation_data=([x_img_val, x_txt_val], y_val_47),\n",
    "    epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_4_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
