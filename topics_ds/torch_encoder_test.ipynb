{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img, x_txt, y = data.get_unpacked_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(\n",
    "    x_img, \n",
    "    x_txt, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "x_img_train, x_img_val, x_txt_train, x_txt_val, y_train, y_val = train_test_split(\n",
    "    x_img_train,\n",
    "    x_txt_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "img_sscaler = StandardScaler()\n",
    "img_sscaler.fit(x_img_train)\n",
    "\n",
    "x_img_train = img_sscaler.transform(x_img_train)\n",
    "x_img_val = img_sscaler.transform(x_img_val)\n",
    "x_img_test = img_sscaler.transform(x_img_test)\n",
    "\n",
    "txt_sscaler = StandardScaler()\n",
    "txt_sscaler.fit(x_txt_train)\n",
    "\n",
    "x_txt_train = txt_sscaler.transform(x_txt_train)\n",
    "x_txt_val = txt_sscaler.transform(x_txt_val)\n",
    "x_txt_test = txt_sscaler.transform(x_txt_test)\n",
    "\n",
    "x_img_train_t = torch.tensor(x_img_train).float()\n",
    "x_img_val_t = torch.tensor(x_img_val).float()\n",
    "x_img_test_t = torch.tensor(x_img_test).float()\n",
    "\n",
    "x_txt_train_t = torch.tensor(x_txt_train).float()\n",
    "x_txt_val_t = torch.tensor(x_txt_val).float()\n",
    "x_txt_test_t = torch.tensor(x_txt_test).float()\n",
    "\n",
    "y_train_t = torch.tensor(y_train).float()\n",
    "y_val_t = torch.tensor(y_val).float()\n",
    "y_test_t = torch.tensor(y_test).float()\n",
    "\n",
    "train_ds = TensorDataset(x_img_train_t, x_txt_train_t, y_train_t)\n",
    "val_ds = TensorDataset(x_img_val_t, x_txt_val_t, y_val_t)\n",
    "test_ds = TensorDataset(x_img_test_t, x_txt_test_t, y_test_t)\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(IMG_LEN, d)\n",
    "        self.fc_txt = nn.Linear(TXT_LEN, d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x_img = self.fc_img(inp_img)\n",
    "        x_txt = self.fc_txt(inp_txt)\n",
    "        \n",
    "        x = torch.cat((x_img, x_txt), 1)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(2 * d, IMG_LEN)\n",
    "        self.fc_txt = nn.Linear(2 * d, TXT_LEN)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_img = self.fc_img(x)\n",
    "        x_txt = self.fc_txt(x)\n",
    "        return x_img, x_txt\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d)\n",
    "        self.decoder = Decoder(d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x_img, x_txt = self.decoder(x)\n",
    "        return x_img, x_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderConcat(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(IMG_LEN, d)\n",
    "        self.fc_txt = nn.Linear(TXT_LEN, d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x_img = self.fc_img(inp_img)\n",
    "        x_txt = self.fc_txt(inp_txt)\n",
    "        \n",
    "        x = torch.cat((x_img, x_txt), 1)\n",
    "        return x\n",
    "    \n",
    "class DecoderConcat(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(2 * d, IMG_LEN)\n",
    "        self.fc_txt = nn.Linear(2 * d, TXT_LEN)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_img = self.fc_img(x)\n",
    "        x_txt = self.fc_txt(x)\n",
    "        return x_img, x_txt\n",
    "\n",
    "class AutoencoderConcat(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderConcat(d)\n",
    "        self.decoder = DecoderConcat(d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x_img, x_txt = self.decoder(x)\n",
    "        return x_img, x_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderFixed(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(IMG_LEN, d)\n",
    "        self.fc_txt = nn.Linear(TXT_LEN, d)\n",
    "        self.fc = nn.Linear(2 * d, 2 * d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x_img = self.fc_img(inp_img)\n",
    "        x_txt = self.fc_txt(inp_txt)\n",
    "        \n",
    "        x = self.fc(torch.cat((x_img, x_txt), 1))\n",
    "        return x\n",
    "    \n",
    "class DecoderFixed(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(2 * d, IMG_LEN)\n",
    "        self.fc_txt = nn.Linear(2 * d, TXT_LEN)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_img = self.fc_img(x)\n",
    "        x_txt = self.fc_txt(x)\n",
    "        return x_img, x_txt\n",
    "\n",
    "class AutoencoderFixed(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderFixed(d)\n",
    "        self.decoder = DecoderFixed(d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x_img, x_txt = self.decoder(x)\n",
    "        return x_img, x_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRelu(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(IMG_LEN, d)\n",
    "        self.fc_txt = nn.Linear(TXT_LEN, d)\n",
    "        self.fc = nn.Linear(2 * d, 2 * d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x_img = F.relu(self.fc_img(inp_img))\n",
    "        x_txt = F.relu(self.fc_txt(inp_txt))\n",
    "        x = F.relu(self.fc(torch.cat((x_img, x_txt), 1)))\n",
    "        return x\n",
    "    \n",
    "class DecoderRelu(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.fc_img = nn.Linear(2 * d, IMG_LEN)\n",
    "        self.fc_txt = nn.Linear(2 * d, TXT_LEN)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_img = self.fc_img(x)\n",
    "        x_txt = self.fc_txt(x)\n",
    "        return x_img, x_txt\n",
    "\n",
    "class AutoencoderRelu(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderRelu(d)\n",
    "        self.decoder = DecoderRelu(d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x_img, x_txt = self.decoder(x)\n",
    "        return x_img, x_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def fit_autoencoder(autoencoder, optimizer, epochs, X_train, X_val, verbose=1):\n",
    "    \n",
    "    x_img_train, x_txt_train = X_train[0], X_train[1]\n",
    "    x_img_val, x_txt_val = X_val[0], X_val[1]\n",
    "    \n",
    "    x_img_train_t = torch.tensor(x_img_train).float()\n",
    "    x_img_val_t = torch.tensor(x_img_val).float()\n",
    "\n",
    "    x_txt_train_t = torch.tensor(x_txt_train).float()\n",
    "    x_txt_val_t = torch.tensor(x_txt_val).float()\n",
    "    \n",
    "    train_ds = TensorDataset(x_img_train_t, x_txt_train_t)\n",
    "    val_ds = TensorDataset(x_img_val_t, x_txt_val_t)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    train_img_loss_history = []\n",
    "    train_txt_loss_history = []\n",
    "    \n",
    "    val_img_loss_history = []\n",
    "    val_txt_loss_history = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        autoencoder.train()\n",
    "    \n",
    "        loss_img_sum = 0.0\n",
    "        loss_txt_sum = 0.0\n",
    "        loss_sum = 0.0\n",
    "        loss_count = 0\n",
    "    \n",
    "        for x_img_cur, x_txt_cur in train_loader:\n",
    "            autoencoder.zero_grad()\n",
    "            out_img, out_txt = autoencoder(inp_img=x_img_cur, inp_txt=x_txt_cur)\n",
    "            loss_img = criterion(out_img, x_img_cur)\n",
    "            loss_txt = criterion(out_txt, x_txt_cur)\n",
    "            loss = loss_img + loss_txt\n",
    "        \n",
    "            loss_img_sum += loss_img\n",
    "            loss_txt_sum += loss_txt\n",
    "            loss_sum += loss\n",
    "            loss_count += 1\n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "         \n",
    "        if verbose != 0:\n",
    "            print(\n",
    "                'train img loss:', \"%.3f\" % (loss_img_sum/loss_count).item(), \n",
    "                'txt_loss:', \"%.3f\" % (loss_txt_sum/loss_count).item(), \n",
    "                'img + txt loss', \"%.3f\" % (loss_sum/loss_count).item()\n",
    "            )\n",
    "        train_img_loss_history.append((loss_img_sum/loss_count).item())\n",
    "        train_txt_loss_history.append((loss_txt_sum/loss_count).item())\n",
    "        \n",
    "        autoencoder.eval()\n",
    "    \n",
    "        val_loss_img_sum = 0.0\n",
    "        val_loss_txt_sum = 0.0\n",
    "        val_loss_sum = 0.0\n",
    "        val_loss_count = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for x_img_cur, x_txt_cur in val_loader:\n",
    "                out_img, out_txt = autoencoder(x_img_cur, x_txt_cur)\n",
    "                loss_img = criterion(out_img, x_img_cur)\n",
    "                loss_txt = criterion(out_txt, x_txt_cur)\n",
    "                loss = loss_img + loss_txt\n",
    "            \n",
    "                val_loss_img_sum += loss_img\n",
    "                val_loss_txt_sum += loss_txt\n",
    "                val_loss_sum += loss\n",
    "                val_loss_count += 1\n",
    "        \n",
    "        if verbose != 0:\n",
    "            print(\n",
    "                'val img loss:', \"%.3f\" % (val_loss_img_sum/val_loss_count).item(), \n",
    "                'val txt_loss:', \"%.3f\" % (val_loss_txt_sum/val_loss_count).item(), \n",
    "                'img + txt loss', \"%.3f\" % (val_loss_sum/val_loss_count).item()\n",
    "            )\n",
    "        val_img_loss_history.append((val_loss_img_sum/val_loss_count).item())\n",
    "        val_txt_loss_history.append((val_loss_txt_sum/val_loss_count).item())\n",
    "        \n",
    "    operation_time = time.time() - start_time\n",
    "    \n",
    "    if verbose != 0:\n",
    "        print('autoencoder fitting finished for', operation_time, 'seconds')\n",
    "        \n",
    "    return train_img_loss_history, train_txt_loss_history, val_img_loss_history, val_txt_loss_history, operation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trivial_autoencoder(d):\n",
    "    print('TESTING WITH d = ', d)\n",
    "    autoencoder = Autoencoder(d=d)\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "\n",
    "    stat = fit_autoencoder(autoencoder, optimizer, EPOCHS, [x_img_train, x_txt_train], [x_img_val, x_txt_val])\n",
    "    pickle.dump(stat, open( \"autoencoder_stat/trivial_\" + str(d) + \".pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  8\n",
      "train img loss: 1.010 txt_loss: 1.006 img + txt loss 2.016\n",
      "val img loss: 0.245 val txt_loss: 0.245 img + txt loss 0.490\n",
      "train img loss: 0.918 txt_loss: 0.917 img + txt loss 1.835\n",
      "val img loss: 0.223 val txt_loss: 0.223 img + txt loss 0.446\n",
      "train img loss: 0.856 txt_loss: 0.849 img + txt loss 1.706\n",
      "val img loss: 0.211 val txt_loss: 0.209 img + txt loss 0.421\n",
      "train img loss: 0.816 txt_loss: 0.806 img + txt loss 1.622\n",
      "val img loss: 0.203 val txt_loss: 0.201 img + txt loss 0.403\n",
      "train img loss: 0.786 txt_loss: 0.780 img + txt loss 1.566\n",
      "val img loss: 0.196 val txt_loss: 0.195 img + txt loss 0.392\n",
      "train img loss: 0.765 txt_loss: 0.764 img + txt loss 1.529\n",
      "val img loss: 0.192 val txt_loss: 0.192 img + txt loss 0.384\n",
      "train img loss: 0.749 txt_loss: 0.754 img + txt loss 1.503\n",
      "val img loss: 0.188 val txt_loss: 0.190 img + txt loss 0.378\n",
      "train img loss: 0.737 txt_loss: 0.746 img + txt loss 1.483\n",
      "val img loss: 0.186 val txt_loss: 0.188 img + txt loss 0.374\n",
      "train img loss: 0.728 txt_loss: 0.740 img + txt loss 1.468\n",
      "val img loss: 0.184 val txt_loss: 0.187 img + txt loss 0.371\n",
      "train img loss: 0.721 txt_loss: 0.735 img + txt loss 1.457\n",
      "val img loss: 0.182 val txt_loss: 0.186 img + txt loss 0.368\n",
      "train img loss: 0.716 txt_loss: 0.731 img + txt loss 1.447\n",
      "val img loss: 0.181 val txt_loss: 0.185 img + txt loss 0.366\n",
      "train img loss: 0.711 txt_loss: 0.726 img + txt loss 1.438\n",
      "val img loss: 0.180 val txt_loss: 0.184 img + txt loss 0.363\n",
      "train img loss: 0.707 txt_loss: 0.722 img + txt loss 1.429\n",
      "val img loss: 0.179 val txt_loss: 0.183 img + txt loss 0.361\n",
      "train img loss: 0.704 txt_loss: 0.719 img + txt loss 1.422\n",
      "val img loss: 0.178 val txt_loss: 0.182 img + txt loss 0.360\n",
      "train img loss: 0.701 txt_loss: 0.716 img + txt loss 1.417\n",
      "val img loss: 0.177 val txt_loss: 0.181 img + txt loss 0.359\n",
      "train img loss: 0.699 txt_loss: 0.714 img + txt loss 1.413\n",
      "val img loss: 0.177 val txt_loss: 0.181 img + txt loss 0.358\n",
      "train img loss: 0.697 txt_loss: 0.713 img + txt loss 1.410\n",
      "val img loss: 0.177 val txt_loss: 0.181 img + txt loss 0.357\n",
      "train img loss: 0.696 txt_loss: 0.712 img + txt loss 1.407\n",
      "val img loss: 0.176 val txt_loss: 0.180 img + txt loss 0.356\n",
      "train img loss: 0.695 txt_loss: 0.711 img + txt loss 1.405\n",
      "val img loss: 0.176 val txt_loss: 0.180 img + txt loss 0.356\n",
      "train img loss: 0.694 txt_loss: 0.710 img + txt loss 1.404\n",
      "val img loss: 0.176 val txt_loss: 0.180 img + txt loss 0.356\n",
      "train img loss: 0.693 txt_loss: 0.709 img + txt loss 1.402\n",
      "val img loss: 0.176 val txt_loss: 0.180 img + txt loss 0.355\n",
      "train img loss: 0.692 txt_loss: 0.709 img + txt loss 1.401\n",
      "val img loss: 0.175 val txt_loss: 0.180 img + txt loss 0.355\n",
      "train img loss: 0.692 txt_loss: 0.708 img + txt loss 1.400\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.355\n",
      "train img loss: 0.691 txt_loss: 0.708 img + txt loss 1.399\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.355\n",
      "train img loss: 0.691 txt_loss: 0.707 img + txt loss 1.398\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.690 txt_loss: 0.707 img + txt loss 1.397\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.690 txt_loss: 0.707 img + txt loss 1.397\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.690 txt_loss: 0.706 img + txt loss 1.396\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.690 txt_loss: 0.706 img + txt loss 1.396\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.689 txt_loss: 0.706 img + txt loss 1.395\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.689 txt_loss: 0.706 img + txt loss 1.395\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.689 txt_loss: 0.706 img + txt loss 1.395\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.354\n",
      "train img loss: 0.689 txt_loss: 0.706 img + txt loss 1.394\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.689 txt_loss: 0.705 img + txt loss 1.394\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.689 txt_loss: 0.705 img + txt loss 1.394\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.394\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.175 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.393\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.705 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.179 img + txt loss 0.353\n",
      "train img loss: 0.688 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.392\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "train img loss: 0.687 txt_loss: 0.704 img + txt loss 1.391\n",
      "val img loss: 0.174 val txt_loss: 0.178 img + txt loss 0.353\n",
      "finished for 597.5979850292206 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  16\n",
      "train img loss: 0.963 txt_loss: 0.960 img + txt loss 1.923\n",
      "val img loss: 0.222 val txt_loss: 0.221 img + txt loss 0.443\n",
      "train img loss: 0.820 txt_loss: 0.812 img + txt loss 1.632\n",
      "val img loss: 0.195 val txt_loss: 0.194 img + txt loss 0.389\n",
      "train img loss: 0.735 txt_loss: 0.736 img + txt loss 1.471\n",
      "val img loss: 0.179 val txt_loss: 0.181 img + txt loss 0.360\n",
      "train img loss: 0.686 txt_loss: 0.699 img + txt loss 1.385\n",
      "val img loss: 0.169 val txt_loss: 0.174 img + txt loss 0.344\n",
      "train img loss: 0.655 txt_loss: 0.679 img + txt loss 1.334\n",
      "val img loss: 0.163 val txt_loss: 0.170 img + txt loss 0.333\n",
      "train img loss: 0.637 txt_loss: 0.666 img + txt loss 1.303\n",
      "val img loss: 0.160 val txt_loss: 0.167 img + txt loss 0.327\n",
      "train img loss: 0.626 txt_loss: 0.657 img + txt loss 1.284\n",
      "val img loss: 0.158 val txt_loss: 0.166 img + txt loss 0.324\n",
      "train img loss: 0.620 txt_loss: 0.651 img + txt loss 1.271\n",
      "val img loss: 0.156 val txt_loss: 0.164 img + txt loss 0.321\n",
      "train img loss: 0.614 txt_loss: 0.646 img + txt loss 1.260\n",
      "val img loss: 0.155 val txt_loss: 0.163 img + txt loss 0.318\n",
      "train img loss: 0.610 txt_loss: 0.641 img + txt loss 1.251\n",
      "val img loss: 0.154 val txt_loss: 0.162 img + txt loss 0.316\n",
      "train img loss: 0.606 txt_loss: 0.636 img + txt loss 1.242\n",
      "val img loss: 0.153 val txt_loss: 0.160 img + txt loss 0.314\n",
      "train img loss: 0.602 txt_loss: 0.631 img + txt loss 1.233\n",
      "val img loss: 0.152 val txt_loss: 0.159 img + txt loss 0.311\n",
      "train img loss: 0.599 txt_loss: 0.627 img + txt loss 1.226\n",
      "val img loss: 0.151 val txt_loss: 0.158 img + txt loss 0.310\n",
      "train img loss: 0.595 txt_loss: 0.624 img + txt loss 1.220\n",
      "val img loss: 0.151 val txt_loss: 0.158 img + txt loss 0.308\n",
      "train img loss: 0.593 txt_loss: 0.622 img + txt loss 1.215\n",
      "val img loss: 0.150 val txt_loss: 0.157 img + txt loss 0.307\n",
      "train img loss: 0.590 txt_loss: 0.621 img + txt loss 1.211\n",
      "val img loss: 0.149 val txt_loss: 0.157 img + txt loss 0.307\n",
      "train img loss: 0.589 txt_loss: 0.620 img + txt loss 1.209\n",
      "val img loss: 0.149 val txt_loss: 0.157 img + txt loss 0.306\n",
      "train img loss: 0.587 txt_loss: 0.619 img + txt loss 1.206\n",
      "val img loss: 0.149 val txt_loss: 0.157 img + txt loss 0.305\n",
      "train img loss: 0.586 txt_loss: 0.618 img + txt loss 1.205\n",
      "val img loss: 0.149 val txt_loss: 0.157 img + txt loss 0.305\n",
      "train img loss: 0.585 txt_loss: 0.618 img + txt loss 1.203\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.305\n",
      "train img loss: 0.585 txt_loss: 0.617 img + txt loss 1.202\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.304\n",
      "train img loss: 0.584 txt_loss: 0.617 img + txt loss 1.201\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.304\n",
      "train img loss: 0.584 txt_loss: 0.617 img + txt loss 1.200\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.304\n",
      "train img loss: 0.583 txt_loss: 0.616 img + txt loss 1.200\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.304\n",
      "train img loss: 0.583 txt_loss: 0.616 img + txt loss 1.199\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.304\n",
      "train img loss: 0.583 txt_loss: 0.616 img + txt loss 1.198\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.304\n",
      "train img loss: 0.582 txt_loss: 0.616 img + txt loss 1.198\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.582 txt_loss: 0.615 img + txt loss 1.198\n",
      "val img loss: 0.148 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.582 txt_loss: 0.615 img + txt loss 1.197\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.582 txt_loss: 0.615 img + txt loss 1.197\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.582 txt_loss: 0.615 img + txt loss 1.197\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.615 img + txt loss 1.196\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.615 img + txt loss 1.196\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.615 img + txt loss 1.196\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.615 img + txt loss 1.196\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.581 txt_loss: 0.614 img + txt loss 1.195\n",
      "val img loss: 0.147 val txt_loss: 0.156 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.614 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.303\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.194\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "train img loss: 0.580 txt_loss: 0.613 img + txt loss 1.193\n",
      "val img loss: 0.147 val txt_loss: 0.155 img + txt loss 0.302\n",
      "finished for 644.74431681633 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  32\n",
      "train img loss: 0.903 txt_loss: 0.890 img + txt loss 1.793\n",
      "val img loss: 0.198 val txt_loss: 0.193 img + txt loss 0.391\n",
      "train img loss: 0.711 txt_loss: 0.700 img + txt loss 1.411\n",
      "val img loss: 0.165 val txt_loss: 0.166 img + txt loss 0.331\n",
      "train img loss: 0.613 txt_loss: 0.630 img + txt loss 1.243\n",
      "val img loss: 0.147 val txt_loss: 0.154 img + txt loss 0.301\n",
      "train img loss: 0.559 txt_loss: 0.593 img + txt loss 1.152\n",
      "val img loss: 0.137 val txt_loss: 0.147 img + txt loss 0.284\n",
      "train img loss: 0.529 txt_loss: 0.573 img + txt loss 1.102\n",
      "val img loss: 0.132 val txt_loss: 0.143 img + txt loss 0.275\n",
      "train img loss: 0.513 txt_loss: 0.561 img + txt loss 1.074\n",
      "val img loss: 0.129 val txt_loss: 0.141 img + txt loss 0.270\n",
      "train img loss: 0.503 txt_loss: 0.553 img + txt loss 1.055\n",
      "val img loss: 0.126 val txt_loss: 0.139 img + txt loss 0.265\n",
      "train img loss: 0.495 txt_loss: 0.545 img + txt loss 1.040\n",
      "val img loss: 0.125 val txt_loss: 0.137 img + txt loss 0.262\n",
      "train img loss: 0.488 txt_loss: 0.538 img + txt loss 1.027\n",
      "val img loss: 0.123 val txt_loss: 0.136 img + txt loss 0.259\n",
      "train img loss: 0.483 txt_loss: 0.532 img + txt loss 1.015\n",
      "val img loss: 0.122 val txt_loss: 0.134 img + txt loss 0.256\n",
      "train img loss: 0.479 txt_loss: 0.526 img + txt loss 1.005\n",
      "val img loss: 0.121 val txt_loss: 0.133 img + txt loss 0.254\n",
      "train img loss: 0.476 txt_loss: 0.522 img + txt loss 0.998\n",
      "val img loss: 0.120 val txt_loss: 0.132 img + txt loss 0.252\n",
      "train img loss: 0.473 txt_loss: 0.519 img + txt loss 0.992\n",
      "val img loss: 0.120 val txt_loss: 0.131 img + txt loss 0.251\n",
      "train img loss: 0.471 txt_loss: 0.516 img + txt loss 0.987\n",
      "val img loss: 0.119 val txt_loss: 0.131 img + txt loss 0.250\n",
      "train img loss: 0.469 txt_loss: 0.515 img + txt loss 0.984\n",
      "val img loss: 0.119 val txt_loss: 0.130 img + txt loss 0.249\n",
      "train img loss: 0.467 txt_loss: 0.514 img + txt loss 0.981\n",
      "val img loss: 0.118 val txt_loss: 0.130 img + txt loss 0.248\n",
      "train img loss: 0.466 txt_loss: 0.513 img + txt loss 0.979\n",
      "val img loss: 0.118 val txt_loss: 0.130 img + txt loss 0.248\n",
      "train img loss: 0.465 txt_loss: 0.512 img + txt loss 0.977\n",
      "val img loss: 0.118 val txt_loss: 0.130 img + txt loss 0.247\n",
      "train img loss: 0.464 txt_loss: 0.512 img + txt loss 0.975\n",
      "val img loss: 0.117 val txt_loss: 0.130 img + txt loss 0.247\n",
      "train img loss: 0.463 txt_loss: 0.511 img + txt loss 0.974\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.247\n",
      "train img loss: 0.462 txt_loss: 0.511 img + txt loss 0.973\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.247\n",
      "train img loss: 0.462 txt_loss: 0.510 img + txt loss 0.972\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.246\n",
      "train img loss: 0.461 txt_loss: 0.510 img + txt loss 0.971\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.246\n",
      "train img loss: 0.461 txt_loss: 0.510 img + txt loss 0.971\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.246\n",
      "train img loss: 0.460 txt_loss: 0.510 img + txt loss 0.970\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.246\n",
      "train img loss: 0.460 txt_loss: 0.510 img + txt loss 0.969\n",
      "val img loss: 0.117 val txt_loss: 0.129 img + txt loss 0.246\n",
      "train img loss: 0.459 txt_loss: 0.509 img + txt loss 0.969\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.459 txt_loss: 0.509 img + txt loss 0.968\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.459 txt_loss: 0.509 img + txt loss 0.968\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.459 txt_loss: 0.509 img + txt loss 0.968\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.458 txt_loss: 0.509 img + txt loss 0.967\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.458 txt_loss: 0.509 img + txt loss 0.967\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.458 txt_loss: 0.509 img + txt loss 0.967\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.458 txt_loss: 0.509 img + txt loss 0.966\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.458 txt_loss: 0.508 img + txt loss 0.966\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.966\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.966\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.245\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.457 txt_loss: 0.508 img + txt loss 0.965\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.964\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.508 img + txt loss 0.963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.129 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.116 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.456 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "train img loss: 0.455 txt_loss: 0.507 img + txt loss 0.963\n",
      "val img loss: 0.115 val txt_loss: 0.128 img + txt loss 0.244\n",
      "finished for 721.2419471740723 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  64\n",
      "train img loss: 0.811 txt_loss: 0.802 img + txt loss 1.613\n",
      "val img loss: 0.164 val txt_loss: 0.164 img + txt loss 0.328\n",
      "train img loss: 0.568 txt_loss: 0.583 img + txt loss 1.151\n",
      "val img loss: 0.128 val txt_loss: 0.136 img + txt loss 0.263\n",
      "train img loss: 0.465 txt_loss: 0.509 img + txt loss 0.974\n",
      "val img loss: 0.110 val txt_loss: 0.124 img + txt loss 0.233\n",
      "train img loss: 0.412 txt_loss: 0.475 img + txt loss 0.887\n",
      "val img loss: 0.100 val txt_loss: 0.118 img + txt loss 0.218\n",
      "train img loss: 0.385 txt_loss: 0.457 img + txt loss 0.842\n",
      "val img loss: 0.096 val txt_loss: 0.114 img + txt loss 0.210\n",
      "train img loss: 0.370 txt_loss: 0.444 img + txt loss 0.815\n",
      "val img loss: 0.093 val txt_loss: 0.111 img + txt loss 0.204\n",
      "train img loss: 0.360 txt_loss: 0.434 img + txt loss 0.794\n",
      "val img loss: 0.090 val txt_loss: 0.109 img + txt loss 0.199\n",
      "train img loss: 0.351 txt_loss: 0.425 img + txt loss 0.776\n",
      "val img loss: 0.088 val txt_loss: 0.107 img + txt loss 0.195\n",
      "train img loss: 0.345 txt_loss: 0.416 img + txt loss 0.761\n",
      "val img loss: 0.087 val txt_loss: 0.105 img + txt loss 0.191\n",
      "train img loss: 0.339 txt_loss: 0.408 img + txt loss 0.748\n",
      "val img loss: 0.086 val txt_loss: 0.103 img + txt loss 0.188\n",
      "train img loss: 0.335 txt_loss: 0.402 img + txt loss 0.737\n",
      "val img loss: 0.085 val txt_loss: 0.101 img + txt loss 0.186\n",
      "train img loss: 0.332 txt_loss: 0.397 img + txt loss 0.729\n",
      "val img loss: 0.084 val txt_loss: 0.100 img + txt loss 0.184\n",
      "train img loss: 0.329 txt_loss: 0.393 img + txt loss 0.722\n",
      "val img loss: 0.083 val txt_loss: 0.099 img + txt loss 0.183\n",
      "train img loss: 0.327 txt_loss: 0.391 img + txt loss 0.718\n",
      "val img loss: 0.083 val txt_loss: 0.099 img + txt loss 0.182\n",
      "train img loss: 0.325 txt_loss: 0.389 img + txt loss 0.715\n",
      "val img loss: 0.082 val txt_loss: 0.099 img + txt loss 0.181\n",
      "train img loss: 0.324 txt_loss: 0.388 img + txt loss 0.712\n",
      "val img loss: 0.082 val txt_loss: 0.098 img + txt loss 0.180\n",
      "train img loss: 0.323 txt_loss: 0.387 img + txt loss 0.710\n",
      "val img loss: 0.082 val txt_loss: 0.098 img + txt loss 0.180\n",
      "train img loss: 0.322 txt_loss: 0.386 img + txt loss 0.708\n",
      "val img loss: 0.082 val txt_loss: 0.098 img + txt loss 0.180\n",
      "train img loss: 0.321 txt_loss: 0.385 img + txt loss 0.707\n",
      "val img loss: 0.082 val txt_loss: 0.098 img + txt loss 0.179\n",
      "train img loss: 0.321 txt_loss: 0.385 img + txt loss 0.706\n",
      "val img loss: 0.081 val txt_loss: 0.098 img + txt loss 0.179\n",
      "train img loss: 0.320 txt_loss: 0.385 img + txt loss 0.705\n",
      "val img loss: 0.081 val txt_loss: 0.098 img + txt loss 0.179\n",
      "train img loss: 0.320 txt_loss: 0.384 img + txt loss 0.704\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.179\n",
      "train img loss: 0.319 txt_loss: 0.384 img + txt loss 0.703\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.319 txt_loss: 0.384 img + txt loss 0.703\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.319 txt_loss: 0.383 img + txt loss 0.702\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.319 txt_loss: 0.383 img + txt loss 0.702\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.318 txt_loss: 0.383 img + txt loss 0.701\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.318 txt_loss: 0.383 img + txt loss 0.701\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.318 txt_loss: 0.383 img + txt loss 0.700\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.318 txt_loss: 0.383 img + txt loss 0.700\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.317 txt_loss: 0.383 img + txt loss 0.700\n",
      "val img loss: 0.081 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.317 txt_loss: 0.382 img + txt loss 0.700\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.178\n",
      "train img loss: 0.317 txt_loss: 0.382 img + txt loss 0.699\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.317 txt_loss: 0.382 img + txt loss 0.699\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.317 txt_loss: 0.382 img + txt loss 0.699\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.699\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.698\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.698\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.698\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.698\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.316 txt_loss: 0.382 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.382 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.382 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.697\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.315 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.696\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.177\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.695\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.313 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.314 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "train img loss: 0.313 txt_loss: 0.381 img + txt loss 0.694\n",
      "val img loss: 0.080 val txt_loss: 0.097 img + txt loss 0.176\n",
      "finished for 785.7661480903625 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  128\n",
      "train img loss: 0.692 txt_loss: 0.717 img + txt loss 1.409\n",
      "val img loss: 0.125 val txt_loss: 0.136 img + txt loss 0.261\n",
      "train img loss: 0.407 txt_loss: 0.462 img + txt loss 0.869\n",
      "val img loss: 0.086 val txt_loss: 0.103 img + txt loss 0.189\n",
      "train img loss: 0.302 txt_loss: 0.376 img + txt loss 0.678\n",
      "val img loss: 0.069 val txt_loss: 0.089 img + txt loss 0.158\n",
      "train img loss: 0.254 txt_loss: 0.338 img + txt loss 0.592\n",
      "val img loss: 0.061 val txt_loss: 0.083 img + txt loss 0.144\n",
      "train img loss: 0.230 txt_loss: 0.317 img + txt loss 0.546\n",
      "val img loss: 0.056 val txt_loss: 0.078 img + txt loss 0.135\n",
      "train img loss: 0.215 txt_loss: 0.302 img + txt loss 0.516\n",
      "val img loss: 0.053 val txt_loss: 0.075 img + txt loss 0.128\n",
      "train img loss: 0.204 txt_loss: 0.289 img + txt loss 0.493\n",
      "val img loss: 0.051 val txt_loss: 0.072 img + txt loss 0.123\n",
      "train img loss: 0.196 txt_loss: 0.278 img + txt loss 0.474\n",
      "val img loss: 0.049 val txt_loss: 0.069 img + txt loss 0.119\n",
      "train img loss: 0.190 txt_loss: 0.269 img + txt loss 0.459\n",
      "val img loss: 0.048 val txt_loss: 0.067 img + txt loss 0.115\n",
      "train img loss: 0.185 txt_loss: 0.260 img + txt loss 0.445\n",
      "val img loss: 0.047 val txt_loss: 0.065 img + txt loss 0.112\n",
      "train img loss: 0.181 txt_loss: 0.253 img + txt loss 0.435\n",
      "val img loss: 0.046 val txt_loss: 0.064 img + txt loss 0.109\n",
      "train img loss: 0.178 txt_loss: 0.248 img + txt loss 0.426\n",
      "val img loss: 0.045 val txt_loss: 0.062 img + txt loss 0.107\n",
      "train img loss: 0.176 txt_loss: 0.243 img + txt loss 0.419\n",
      "val img loss: 0.045 val txt_loss: 0.061 img + txt loss 0.106\n",
      "train img loss: 0.174 txt_loss: 0.239 img + txt loss 0.414\n",
      "val img loss: 0.044 val txt_loss: 0.061 img + txt loss 0.105\n",
      "train img loss: 0.173 txt_loss: 0.237 img + txt loss 0.409\n",
      "val img loss: 0.044 val txt_loss: 0.060 img + txt loss 0.104\n",
      "train img loss: 0.171 txt_loss: 0.235 img + txt loss 0.406\n",
      "val img loss: 0.043 val txt_loss: 0.060 img + txt loss 0.103\n",
      "train img loss: 0.170 txt_loss: 0.233 img + txt loss 0.404\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.169 txt_loss: 0.232 img + txt loss 0.401\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.400\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.398\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.042 val txt_loss: 0.059 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.396\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.043 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.098\n",
      "finished for 1305.821764945984 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  256\n",
      "train img loss: 0.563 txt_loss: 0.616 img + txt loss 1.180\n",
      "val img loss: 0.087 val txt_loss: 0.103 img + txt loss 0.190\n",
      "train img loss: 0.266 txt_loss: 0.324 img + txt loss 0.589\n",
      "val img loss: 0.054 val txt_loss: 0.067 img + txt loss 0.121\n",
      "train img loss: 0.187 txt_loss: 0.228 img + txt loss 0.415\n",
      "val img loss: 0.042 val txt_loss: 0.051 img + txt loss 0.093\n",
      "train img loss: 0.153 txt_loss: 0.180 img + txt loss 0.333\n",
      "val img loss: 0.036 val txt_loss: 0.042 img + txt loss 0.078\n",
      "train img loss: 0.134 txt_loss: 0.151 img + txt loss 0.284\n",
      "val img loss: 0.032 val txt_loss: 0.036 img + txt loss 0.068\n",
      "train img loss: 0.121 txt_loss: 0.131 img + txt loss 0.252\n",
      "val img loss: 0.030 val txt_loss: 0.031 img + txt loss 0.061\n",
      "train img loss: 0.111 txt_loss: 0.116 img + txt loss 0.228\n",
      "val img loss: 0.027 val txt_loss: 0.028 img + txt loss 0.056\n",
      "train img loss: 0.104 txt_loss: 0.105 img + txt loss 0.208\n",
      "val img loss: 0.026 val txt_loss: 0.025 img + txt loss 0.051\n",
      "train img loss: 0.098 txt_loss: 0.094 img + txt loss 0.192\n",
      "val img loss: 0.024 val txt_loss: 0.023 img + txt loss 0.047\n",
      "train img loss: 0.093 txt_loss: 0.085 img + txt loss 0.178\n",
      "val img loss: 0.023 val txt_loss: 0.021 img + txt loss 0.044\n",
      "train img loss: 0.089 txt_loss: 0.077 img + txt loss 0.167\n",
      "val img loss: 0.023 val txt_loss: 0.019 img + txt loss 0.042\n",
      "train img loss: 0.087 txt_loss: 0.071 img + txt loss 0.157\n",
      "val img loss: 0.022 val txt_loss: 0.017 img + txt loss 0.039\n",
      "train img loss: 0.084 txt_loss: 0.065 img + txt loss 0.149\n",
      "val img loss: 0.021 val txt_loss: 0.016 img + txt loss 0.037\n",
      "train img loss: 0.082 txt_loss: 0.060 img + txt loss 0.142\n",
      "val img loss: 0.021 val txt_loss: 0.015 img + txt loss 0.036\n",
      "train img loss: 0.081 txt_loss: 0.055 img + txt loss 0.135\n",
      "val img loss: 0.021 val txt_loss: 0.014 img + txt loss 0.034\n",
      "train img loss: 0.079 txt_loss: 0.052 img + txt loss 0.131\n",
      "val img loss: 0.020 val txt_loss: 0.013 img + txt loss 0.033\n",
      "train img loss: 0.078 txt_loss: 0.050 img + txt loss 0.128\n",
      "val img loss: 0.020 val txt_loss: 0.013 img + txt loss 0.033\n",
      "train img loss: 0.078 txt_loss: 0.048 img + txt loss 0.126\n",
      "val img loss: 0.020 val txt_loss: 0.012 img + txt loss 0.032\n",
      "train img loss: 0.077 txt_loss: 0.047 img + txt loss 0.124\n",
      "val img loss: 0.020 val txt_loss: 0.012 img + txt loss 0.032\n",
      "train img loss: 0.076 txt_loss: 0.046 img + txt loss 0.122\n",
      "val img loss: 0.020 val txt_loss: 0.012 img + txt loss 0.031\n",
      "train img loss: 0.076 txt_loss: 0.045 img + txt loss 0.121\n",
      "val img loss: 0.019 val txt_loss: 0.012 img + txt loss 0.031\n",
      "train img loss: 0.075 txt_loss: 0.044 img + txt loss 0.120\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.031\n",
      "train img loss: 0.075 txt_loss: 0.044 img + txt loss 0.119\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.031\n",
      "train img loss: 0.075 txt_loss: 0.044 img + txt loss 0.118\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.074 txt_loss: 0.043 img + txt loss 0.117\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.074 txt_loss: 0.043 img + txt loss 0.117\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.074 txt_loss: 0.043 img + txt loss 0.116\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.074 txt_loss: 0.042 img + txt loss 0.116\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.030\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.073 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.073 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.073 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.019 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.019 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.019 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.018 val txt_loss: 0.010 img + txt loss 0.029\n",
      "finished for 1805.2369930744171 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width of hidden layer = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH d =  512\n",
      "train img loss: 0.454 txt_loss: 0.508 img + txt loss 0.962\n",
      "val img loss: 0.059 val txt_loss: 0.069 img + txt loss 0.127\n",
      "train img loss: 0.180 txt_loss: 0.189 img + txt loss 0.369\n",
      "val img loss: 0.037 val txt_loss: 0.034 img + txt loss 0.072\n",
      "train img loss: 0.131 txt_loss: 0.107 img + txt loss 0.238\n",
      "val img loss: 0.030 val txt_loss: 0.023 img + txt loss 0.053\n",
      "train img loss: 0.108 txt_loss: 0.078 img + txt loss 0.186\n",
      "val img loss: 0.026 val txt_loss: 0.018 img + txt loss 0.044\n",
      "train img loss: 0.093 txt_loss: 0.064 img + txt loss 0.157\n",
      "val img loss: 0.022 val txt_loss: 0.015 img + txt loss 0.038\n",
      "train img loss: 0.082 txt_loss: 0.055 img + txt loss 0.136\n",
      "val img loss: 0.020 val txt_loss: 0.013 img + txt loss 0.033\n",
      "train img loss: 0.073 txt_loss: 0.046 img + txt loss 0.119\n",
      "val img loss: 0.018 val txt_loss: 0.011 img + txt loss 0.029\n",
      "train img loss: 0.065 txt_loss: 0.038 img + txt loss 0.104\n",
      "val img loss: 0.016 val txt_loss: 0.009 img + txt loss 0.025\n",
      "train img loss: 0.059 txt_loss: 0.032 img + txt loss 0.091\n",
      "val img loss: 0.015 val txt_loss: 0.008 img + txt loss 0.022\n",
      "train img loss: 0.054 txt_loss: 0.026 img + txt loss 0.080\n",
      "val img loss: 0.014 val txt_loss: 0.006 img + txt loss 0.020\n",
      "train img loss: 0.050 txt_loss: 0.021 img + txt loss 0.071\n",
      "val img loss: 0.013 val txt_loss: 0.005 img + txt loss 0.018\n",
      "train img loss: 0.047 txt_loss: 0.017 img + txt loss 0.064\n",
      "val img loss: 0.012 val txt_loss: 0.004 img + txt loss 0.016\n",
      "train img loss: 0.045 txt_loss: 0.014 img + txt loss 0.058\n",
      "val img loss: 0.011 val txt_loss: 0.003 img + txt loss 0.015\n",
      "train img loss: 0.043 txt_loss: 0.011 img + txt loss 0.054\n",
      "val img loss: 0.011 val txt_loss: 0.003 img + txt loss 0.014\n",
      "train img loss: 0.042 txt_loss: 0.009 img + txt loss 0.051\n",
      "val img loss: 0.011 val txt_loss: 0.002 img + txt loss 0.013\n",
      "train img loss: 0.040 txt_loss: 0.007 img + txt loss 0.047\n",
      "val img loss: 0.010 val txt_loss: 0.002 img + txt loss 0.012\n",
      "train img loss: 0.039 txt_loss: 0.006 img + txt loss 0.045\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.012\n",
      "train img loss: 0.039 txt_loss: 0.005 img + txt loss 0.044\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.012\n",
      "train img loss: 0.038 txt_loss: 0.004 img + txt loss 0.042\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.011\n",
      "train img loss: 0.037 txt_loss: 0.004 img + txt loss 0.041\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.011\n",
      "train img loss: 0.037 txt_loss: 0.004 img + txt loss 0.041\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.011\n",
      "train img loss: 0.036 txt_loss: 0.003 img + txt loss 0.039\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.036 txt_loss: 0.003 img + txt loss 0.039\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.036 txt_loss: 0.003 img + txt loss 0.039\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.011\n",
      "train img loss: 0.035 txt_loss: 0.003 img + txt loss 0.037\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.035 txt_loss: 0.003 img + txt loss 0.038\n",
      "val img loss: 0.010 val txt_loss: 0.001 img + txt loss 0.011\n",
      "train img loss: 0.034 txt_loss: 0.002 img + txt loss 0.037\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.034 txt_loss: 0.002 img + txt loss 0.037\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.034 txt_loss: 0.002 img + txt loss 0.036\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.034 txt_loss: 0.002 img + txt loss 0.036\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.035\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.034 txt_loss: 0.002 img + txt loss 0.036\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.010\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.035\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.034 txt_loss: 0.002 img + txt loss 0.036\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.010\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.035\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.035\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.035\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.001 img + txt loss 0.034\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.002 img + txt loss 0.035\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.033 txt_loss: 0.001 img + txt loss 0.034\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.009 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.034\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.002 img + txt loss 0.034\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.034\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.034\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.002 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.008\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.001 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.032 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.009 val txt_loss: 0.000 img + txt loss 0.010\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.033\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.008\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "train img loss: 0.031 txt_loss: 0.001 img + txt loss 0.032\n",
      "val img loss: 0.008 val txt_loss: 0.000 img + txt loss 0.009\n",
      "finished for 3063.241856098175 seconds\n"
     ]
    }
   ],
   "source": [
    "test_trivial_autoencoder(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train_e = torch.tensor(x_img_train[:2600]).float()\n",
    "x_txt_train_e = torch.tensor(x_txt_train[:2600]).float()\n",
    "\n",
    "out = encoder(x_img_train_e, x_txt_train_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using encoder outputs as model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_128 = Autoencoder(d=128)\n",
    "optimizer_128 = torch.optim.Adam(autoencoder_128.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_128, optimizer_128, 100, [x_img_train, x_txt_train], [x_img_val, x_txt_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AfterEncoderModel(nn.Module):\n",
    "    def __init__(self, encoder, d=128, drop=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "            \n",
    "        self.fc1 = nn.Linear(d * 2, d)\n",
    "        self.fc2 = nn.Linear(d, d)\n",
    "        self.out = nn.Linear(d, N_CLASSES)\n",
    "\n",
    "        self.dropout = nn.modules.Dropout(p=drop)\n",
    "\n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = F.relu(self.encoder(inp_img, inp_txt))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.out(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(2.2405, grad_fn=<NllLossBackward>) average train loss tensor(2.8921, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4850331125827815 val_avg_loss: tensor(1.9243)\n",
      "epoch: 1 train_loss: tensor(1.9405, grad_fn=<NllLossBackward>) average train loss tensor(2.0796, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5497277409860192 val_avg_loss: tensor(1.6806)\n",
      "epoch: 2 train_loss: tensor(1.8638, grad_fn=<NllLossBackward>) average train loss tensor(1.9260, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5720971302428256 val_avg_loss: tensor(1.5968)\n",
      "epoch: 3 train_loss: tensor(1.7742, grad_fn=<NllLossBackward>) average train loss tensor(1.8515, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.582075055187638 val_avg_loss: tensor(1.5543)\n",
      "epoch: 4 train_loss: tensor(1.7440, grad_fn=<NllLossBackward>) average train loss tensor(1.8061, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5884915378955115 val_avg_loss: tensor(1.5244)\n",
      "epoch: 5 train_loss: tensor(1.6865, grad_fn=<NllLossBackward>) average train loss tensor(1.7758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5948197203826343 val_avg_loss: tensor(1.5044)\n",
      "epoch: 6 train_loss: tensor(1.6817, grad_fn=<NllLossBackward>) average train loss tensor(1.7505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5960264900662252 val_avg_loss: tensor(1.4909)\n",
      "epoch: 7 train_loss: tensor(1.6772, grad_fn=<NllLossBackward>) average train loss tensor(1.7248, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6002354672553348 val_avg_loss: tensor(1.4765)\n",
      "epoch: 8 train_loss: tensor(1.6707, grad_fn=<NllLossBackward>) average train loss tensor(1.7093, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6032082413539367 val_avg_loss: tensor(1.4693)\n",
      "epoch: 9 train_loss: tensor(1.6616, grad_fn=<NllLossBackward>) average train loss tensor(1.6979, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6035320088300221 val_avg_loss: tensor(1.4604)\n",
      "epoch: 10 train_loss: tensor(1.6155, grad_fn=<NllLossBackward>) average train loss tensor(1.6821, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6081236203090508 val_avg_loss: tensor(1.4507)\n",
      "epoch: 11 train_loss: tensor(1.6493, grad_fn=<NllLossBackward>) average train loss tensor(1.6713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6071817512877116 val_avg_loss: tensor(1.4461)\n",
      "epoch: 12 train_loss: tensor(1.5954, grad_fn=<NllLossBackward>) average train loss tensor(1.6594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.609271523178808 val_avg_loss: tensor(1.4367)\n",
      "epoch: 13 train_loss: tensor(1.5778, grad_fn=<NllLossBackward>) average train loss tensor(1.6488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.611037527593819 val_avg_loss: tensor(1.4340)\n",
      "epoch: 14 train_loss: tensor(1.5209, grad_fn=<NllLossBackward>) average train loss tensor(1.6377, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6106548933038999 val_avg_loss: tensor(1.4282)\n",
      "epoch: 15 train_loss: tensor(1.5418, grad_fn=<NllLossBackward>) average train loss tensor(1.6328, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6125386313465784 val_avg_loss: tensor(1.4240)\n",
      "epoch: 16 train_loss: tensor(1.5622, grad_fn=<NllLossBackward>) average train loss tensor(1.6240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6125680647534952 val_avg_loss: tensor(1.4207)\n",
      "epoch: 17 train_loss: tensor(1.5233, grad_fn=<NllLossBackward>) average train loss tensor(1.6181, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6130684326710817 val_avg_loss: tensor(1.4172)\n",
      "epoch: 18 train_loss: tensor(1.4995, grad_fn=<NllLossBackward>) average train loss tensor(1.6107, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6152465047829286 val_avg_loss: tensor(1.4118)\n",
      "epoch: 19 train_loss: tensor(1.4611, grad_fn=<NllLossBackward>) average train loss tensor(1.6044, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6148344370860928 val_avg_loss: tensor(1.4108)\n",
      "epoch: 20 train_loss: tensor(1.5305, grad_fn=<NllLossBackward>) average train loss tensor(1.5973, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6157468727005151 val_avg_loss: tensor(1.4094)\n",
      "epoch: 21 train_loss: tensor(1.5055, grad_fn=<NllLossBackward>) average train loss tensor(1.5961, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6169242089771891 val_avg_loss: tensor(1.4062)\n",
      "epoch: 22 train_loss: tensor(1.4990, grad_fn=<NllLossBackward>) average train loss tensor(1.5877, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6163355408388521 val_avg_loss: tensor(1.4018)\n",
      "epoch: 23 train_loss: tensor(1.4778, grad_fn=<NllLossBackward>) average train loss tensor(1.5802, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6163355408388521 val_avg_loss: tensor(1.4015)\n",
      "epoch: 24 train_loss: tensor(1.4870, grad_fn=<NllLossBackward>) average train loss tensor(1.5782, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.61598233995585 val_avg_loss: tensor(1.3991)\n",
      "epoch: 25 train_loss: tensor(1.4603, grad_fn=<NllLossBackward>) average train loss tensor(1.5685, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6178072111846946 val_avg_loss: tensor(1.3959)\n",
      "epoch: 26 train_loss: tensor(1.4307, grad_fn=<NllLossBackward>) average train loss tensor(1.5647, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6183958793230316 val_avg_loss: tensor(1.3920)\n",
      "epoch: 27 train_loss: tensor(1.4163, grad_fn=<NllLossBackward>) average train loss tensor(1.5628, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6178955114054452 val_avg_loss: tensor(1.3923)\n",
      "epoch: 28 train_loss: tensor(1.4333, grad_fn=<NllLossBackward>) average train loss tensor(1.5566, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6190139808682855 val_avg_loss: tensor(1.3907)\n",
      "epoch: 29 train_loss: tensor(1.4111, grad_fn=<NllLossBackward>) average train loss tensor(1.5567, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6200735835172921 val_avg_loss: tensor(1.3861)\n",
      "epoch: 30 train_loss: tensor(1.4494, grad_fn=<NllLossBackward>) average train loss tensor(1.5500, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6211626195732156 val_avg_loss: tensor(1.3877)\n",
      "epoch: 31 train_loss: tensor(1.3776, grad_fn=<NllLossBackward>) average train loss tensor(1.5399, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6196909492273731 val_avg_loss: tensor(1.3866)\n",
      "epoch: 32 train_loss: tensor(1.3870, grad_fn=<NllLossBackward>) average train loss tensor(1.5433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6207505518763797 val_avg_loss: tensor(1.3857)\n",
      "epoch: 33 train_loss: tensor(1.4230, grad_fn=<NllLossBackward>) average train loss tensor(1.5383, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6211037527593819 val_avg_loss: tensor(1.3845)\n",
      "epoch: 34 train_loss: tensor(1.4034, grad_fn=<NllLossBackward>) average train loss tensor(1.5335, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6220161883738042 val_avg_loss: tensor(1.3818)\n",
      "epoch: 35 train_loss: tensor(1.3700, grad_fn=<NllLossBackward>) average train loss tensor(1.5303, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6227814569536424 val_avg_loss: tensor(1.3788)\n",
      "epoch: 36 train_loss: tensor(1.4197, grad_fn=<NllLossBackward>) average train loss tensor(1.5258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6215158204562178 val_avg_loss: tensor(1.3780)\n",
      "epoch: 37 train_loss: tensor(1.3748, grad_fn=<NllLossBackward>) average train loss tensor(1.5239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6238999264164827 val_avg_loss: tensor(1.3767)\n",
      "epoch: 38 train_loss: tensor(1.3274, grad_fn=<NllLossBackward>) average train loss tensor(1.5220, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6223105224429728 val_avg_loss: tensor(1.3775)\n",
      "epoch: 39 train_loss: tensor(1.3691, grad_fn=<NllLossBackward>) average train loss tensor(1.5168, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6231935246504783 val_avg_loss: tensor(1.3729)\n",
      "epoch: 40 train_loss: tensor(1.3758, grad_fn=<NllLossBackward>) average train loss tensor(1.5119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.623046357615894 val_avg_loss: tensor(1.3710)\n",
      "epoch: 41 train_loss: tensor(1.3426, grad_fn=<NllLossBackward>) average train loss tensor(1.5109, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6227814569536424 val_avg_loss: tensor(1.3715)\n",
      "epoch: 42 train_loss: tensor(1.3841, grad_fn=<NllLossBackward>) average train loss tensor(1.5076, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6224282560706402 val_avg_loss: tensor(1.3699)\n",
      "epoch: 43 train_loss: tensor(1.3698, grad_fn=<NllLossBackward>) average train loss tensor(1.5010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241648270787343 val_avg_loss: tensor(1.3676)\n",
      "epoch: 44 train_loss: tensor(1.3542, grad_fn=<NllLossBackward>) average train loss tensor(1.4990, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242825607064018 val_avg_loss: tensor(1.3680)\n",
      "epoch: 45 train_loss: tensor(1.3301, grad_fn=<NllLossBackward>) average train loss tensor(1.4991, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6249006622516556 val_avg_loss: tensor(1.3680)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(1.3365, grad_fn=<NllLossBackward>) average train loss tensor(1.4964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242531272994849 val_avg_loss: tensor(1.3678)\n",
      "epoch: 47 train_loss: tensor(1.3226, grad_fn=<NllLossBackward>) average train loss tensor(1.4934, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6233701250919794 val_avg_loss: tensor(1.3671)\n",
      "epoch: 48 train_loss: tensor(1.3359, grad_fn=<NllLossBackward>) average train loss tensor(1.4897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6250772626931568 val_avg_loss: tensor(1.3647)\n",
      "epoch: 49 train_loss: tensor(1.2944, grad_fn=<NllLossBackward>) average train loss tensor(1.4857, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6239882266372333 val_avg_loss: tensor(1.3655)\n",
      "epoch: 50 train_loss: tensor(1.2921, grad_fn=<NllLossBackward>) average train loss tensor(1.4831, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6243414275202355 val_avg_loss: tensor(1.3649)\n",
      "epoch: 51 train_loss: tensor(1.3153, grad_fn=<NllLossBackward>) average train loss tensor(1.4845, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6248417954378219 val_avg_loss: tensor(1.3647)\n",
      "epoch: 52 train_loss: tensor(1.3156, grad_fn=<NllLossBackward>) average train loss tensor(1.4775, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6251949963208241 val_avg_loss: tensor(1.3621)\n",
      "epoch: 53 train_loss: tensor(1.2853, grad_fn=<NllLossBackward>) average train loss tensor(1.4764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.625430463576159 val_avg_loss: tensor(1.3636)\n",
      "epoch: 54 train_loss: tensor(1.2619, grad_fn=<NllLossBackward>) average train loss tensor(1.4697, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6250772626931568 val_avg_loss: tensor(1.3644)\n",
      "epoch: 55 train_loss: tensor(1.3017, grad_fn=<NllLossBackward>) average train loss tensor(1.4696, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258719646799117 val_avg_loss: tensor(1.3635)\n",
      "epoch: 56 train_loss: tensor(1.2914, grad_fn=<NllLossBackward>) average train loss tensor(1.4718, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6246063281824871 val_avg_loss: tensor(1.3616)\n",
      "epoch: 57 train_loss: tensor(1.2633, grad_fn=<NllLossBackward>) average train loss tensor(1.4670, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6260485651214128 val_avg_loss: tensor(1.3604)\n",
      "epoch: 58 train_loss: tensor(1.2637, grad_fn=<NllLossBackward>) average train loss tensor(1.4643, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.625430463576159 val_avg_loss: tensor(1.3584)\n",
      "epoch: 59 train_loss: tensor(1.2885, grad_fn=<NllLossBackward>) average train loss tensor(1.4632, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.625430463576159 val_avg_loss: tensor(1.3575)\n",
      "epoch: 60 train_loss: tensor(1.3180, grad_fn=<NllLossBackward>) average train loss tensor(1.4609, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241942604856512 val_avg_loss: tensor(1.3598)\n",
      "epoch: 61 train_loss: tensor(1.2890, grad_fn=<NllLossBackward>) average train loss tensor(1.4591, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258719646799117 val_avg_loss: tensor(1.3588)\n",
      "epoch: 62 train_loss: tensor(1.2878, grad_fn=<NllLossBackward>) average train loss tensor(1.4590, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258425312729948 val_avg_loss: tensor(1.3573)\n",
      "epoch: 63 train_loss: tensor(1.2769, grad_fn=<NllLossBackward>) average train loss tensor(1.4499, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264311994113319 val_avg_loss: tensor(1.3550)\n",
      "epoch: 64 train_loss: tensor(1.2510, grad_fn=<NllLossBackward>) average train loss tensor(1.4524, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6271670345842532 val_avg_loss: tensor(1.3547)\n",
      "epoch: 65 train_loss: tensor(1.2490, grad_fn=<NllLossBackward>) average train loss tensor(1.4482, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269021339220014 val_avg_loss: tensor(1.3541)\n",
      "epoch: 66 train_loss: tensor(1.2561, grad_fn=<NllLossBackward>) average train loss tensor(1.4468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268432671081677 val_avg_loss: tensor(1.3535)\n",
      "epoch: 67 train_loss: tensor(1.2645, grad_fn=<NllLossBackward>) average train loss tensor(1.4450, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6271670345842532 val_avg_loss: tensor(1.3541)\n",
      "epoch: 68 train_loss: tensor(1.2313, grad_fn=<NllLossBackward>) average train loss tensor(1.4432, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269315673289183 val_avg_loss: tensor(1.3540)\n",
      "epoch: 69 train_loss: tensor(1.2451, grad_fn=<NllLossBackward>) average train loss tensor(1.4430, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.627579102281089 val_avg_loss: tensor(1.3545)\n",
      "epoch: 70 train_loss: tensor(1.2461, grad_fn=<NllLossBackward>) average train loss tensor(1.4397, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6273436350257542 val_avg_loss: tensor(1.3517)\n",
      "epoch: 71 train_loss: tensor(1.3003, grad_fn=<NllLossBackward>) average train loss tensor(1.4393, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265194996320824 val_avg_loss: tensor(1.3533)\n",
      "epoch: 72 train_loss: tensor(1.3125, grad_fn=<NllLossBackward>) average train loss tensor(1.4346, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268138337012509 val_avg_loss: tensor(1.3526)\n",
      "epoch: 73 train_loss: tensor(1.1957, grad_fn=<NllLossBackward>) average train loss tensor(1.4338, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265489330389993 val_avg_loss: tensor(1.3516)\n",
      "epoch: 74 train_loss: tensor(1.2141, grad_fn=<NllLossBackward>) average train loss tensor(1.4302, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269315673289183 val_avg_loss: tensor(1.3514)\n",
      "epoch: 75 train_loss: tensor(1.2225, grad_fn=<NllLossBackward>) average train loss tensor(1.4271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6274908020603385 val_avg_loss: tensor(1.3516)\n",
      "epoch: 76 train_loss: tensor(1.2189, grad_fn=<NllLossBackward>) average train loss tensor(1.4315, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626607799852833 val_avg_loss: tensor(1.3528)\n",
      "epoch: 77 train_loss: tensor(1.2600, grad_fn=<NllLossBackward>) average train loss tensor(1.4269, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280206033848418 val_avg_loss: tensor(1.3502)\n",
      "epoch: 78 train_loss: tensor(1.2203, grad_fn=<NllLossBackward>) average train loss tensor(1.4206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6277262693156733 val_avg_loss: tensor(1.3490)\n",
      "epoch: 79 train_loss: tensor(1.1929, grad_fn=<NllLossBackward>) average train loss tensor(1.4235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6273436350257542 val_avg_loss: tensor(1.3490)\n",
      "epoch: 80 train_loss: tensor(1.2255, grad_fn=<NllLossBackward>) average train loss tensor(1.4202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6267549668874172 val_avg_loss: tensor(1.3502)\n",
      "epoch: 81 train_loss: tensor(1.2462, grad_fn=<NllLossBackward>) average train loss tensor(1.4177, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258719646799117 val_avg_loss: tensor(1.3491)\n",
      "epoch: 82 train_loss: tensor(1.1751, grad_fn=<NllLossBackward>) average train loss tensor(1.4168, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6282855040470935 val_avg_loss: tensor(1.3480)\n",
      "epoch: 83 train_loss: tensor(1.1936, grad_fn=<NllLossBackward>) average train loss tensor(1.4179, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270493009565857 val_avg_loss: tensor(1.3487)\n",
      "epoch: 84 train_loss: tensor(1.2225, grad_fn=<NllLossBackward>) average train loss tensor(1.4161, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626019131714496 val_avg_loss: tensor(1.3487)\n",
      "epoch: 85 train_loss: tensor(1.1589, grad_fn=<NllLossBackward>) average train loss tensor(1.4088, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6262251655629139 val_avg_loss: tensor(1.3489)\n",
      "epoch: 86 train_loss: tensor(1.1908, grad_fn=<NllLossBackward>) average train loss tensor(1.4105, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265489330389993 val_avg_loss: tensor(1.3485)\n",
      "epoch: 87 train_loss: tensor(1.1544, grad_fn=<NllLossBackward>) average train loss tensor(1.4124, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264900662251656 val_avg_loss: tensor(1.3492)\n",
      "epoch: 88 train_loss: tensor(1.2317, grad_fn=<NllLossBackward>) average train loss tensor(1.4108, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280206033848418 val_avg_loss: tensor(1.3481)\n",
      "epoch: 89 train_loss: tensor(1.1766, grad_fn=<NllLossBackward>) average train loss tensor(1.4068, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626990434142752 val_avg_loss: tensor(1.3476)\n",
      "epoch: 90 train_loss: tensor(1.1874, grad_fn=<NllLossBackward>) average train loss tensor(1.4079, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261074319352465 val_avg_loss: tensor(1.3475)\n",
      "epoch: 91 train_loss: tensor(1.1519, grad_fn=<NllLossBackward>) average train loss tensor(1.4025, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270493009565857 val_avg_loss: tensor(1.3464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 train_loss: tensor(1.1780, grad_fn=<NllLossBackward>) average train loss tensor(1.4019, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269021339220014 val_avg_loss: tensor(1.3467)\n",
      "epoch: 93 train_loss: tensor(1.1671, grad_fn=<NllLossBackward>) average train loss tensor(1.4023, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268138337012509 val_avg_loss: tensor(1.3463)\n",
      "epoch: 94 train_loss: tensor(1.1405, grad_fn=<NllLossBackward>) average train loss tensor(1.4006, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257542310522443 val_avg_loss: tensor(1.3477)\n",
      "epoch: 95 train_loss: tensor(1.1792, grad_fn=<NllLossBackward>) average train loss tensor(1.4015, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6271081677704194 val_avg_loss: tensor(1.3458)\n",
      "epoch: 96 train_loss: tensor(1.1610, grad_fn=<NllLossBackward>) average train loss tensor(1.3963, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626990434142752 val_avg_loss: tensor(1.3465)\n",
      "epoch: 97 train_loss: tensor(1.1960, grad_fn=<NllLossBackward>) average train loss tensor(1.3997, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270493009565857 val_avg_loss: tensor(1.3477)\n",
      "epoch: 98 train_loss: tensor(1.1449, grad_fn=<NllLossBackward>) average train loss tensor(1.3985, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272847682119206 val_avg_loss: tensor(1.3479)\n",
      "epoch: 99 train_loss: tensor(1.1508, grad_fn=<NllLossBackward>) average train loss tensor(1.3938, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269610007358352 val_avg_loss: tensor(1.3464)\n"
     ]
    }
   ],
   "source": [
    "import pytorch.torch_models as torch_models\n",
    "\n",
    "encoder_128 = autoencoder_128.encoder\n",
    "after_encoder_model_128 = AfterEncoderModel(encoder_128, d=128, drop=0.5)\n",
    "optimizer_aem_128 = torch.optim.Adam(after_encoder_model_128.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_128_bs2048_rs42_d128_wd0005_drop05_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_128,\n",
    "    optimizer=optimizer_aem_128,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now train autoencoder on all train samples and model only on 2000 train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.693 txt_loss: 0.719 img + txt loss 1.412\n",
      "val img loss: 0.125 val txt_loss: 0.136 img + txt loss 0.261\n",
      "train img loss: 0.408 txt_loss: 0.463 img + txt loss 0.871\n",
      "val img loss: 0.086 val txt_loss: 0.103 img + txt loss 0.190\n",
      "train img loss: 0.303 txt_loss: 0.376 img + txt loss 0.679\n",
      "val img loss: 0.069 val txt_loss: 0.089 img + txt loss 0.159\n",
      "train img loss: 0.254 txt_loss: 0.338 img + txt loss 0.592\n",
      "val img loss: 0.061 val txt_loss: 0.083 img + txt loss 0.144\n",
      "train img loss: 0.229 txt_loss: 0.317 img + txt loss 0.546\n",
      "val img loss: 0.056 val txt_loss: 0.078 img + txt loss 0.134\n",
      "train img loss: 0.213 txt_loss: 0.302 img + txt loss 0.516\n",
      "val img loss: 0.053 val txt_loss: 0.075 img + txt loss 0.128\n",
      "train img loss: 0.203 txt_loss: 0.290 img + txt loss 0.493\n",
      "val img loss: 0.050 val txt_loss: 0.072 img + txt loss 0.123\n",
      "train img loss: 0.195 txt_loss: 0.280 img + txt loss 0.475\n",
      "val img loss: 0.049 val txt_loss: 0.070 img + txt loss 0.119\n",
      "train img loss: 0.189 txt_loss: 0.270 img + txt loss 0.459\n",
      "val img loss: 0.048 val txt_loss: 0.068 img + txt loss 0.115\n",
      "train img loss: 0.185 txt_loss: 0.261 img + txt loss 0.446\n",
      "val img loss: 0.047 val txt_loss: 0.065 img + txt loss 0.112\n",
      "train img loss: 0.181 txt_loss: 0.253 img + txt loss 0.434\n",
      "val img loss: 0.046 val txt_loss: 0.064 img + txt loss 0.109\n",
      "train img loss: 0.179 txt_loss: 0.247 img + txt loss 0.426\n",
      "val img loss: 0.045 val txt_loss: 0.062 img + txt loss 0.107\n",
      "train img loss: 0.176 txt_loss: 0.242 img + txt loss 0.419\n",
      "val img loss: 0.045 val txt_loss: 0.061 img + txt loss 0.106\n",
      "train img loss: 0.174 txt_loss: 0.239 img + txt loss 0.414\n",
      "val img loss: 0.044 val txt_loss: 0.061 img + txt loss 0.105\n",
      "train img loss: 0.173 txt_loss: 0.237 img + txt loss 0.410\n",
      "val img loss: 0.044 val txt_loss: 0.060 img + txt loss 0.104\n",
      "train img loss: 0.171 txt_loss: 0.235 img + txt loss 0.406\n",
      "val img loss: 0.043 val txt_loss: 0.060 img + txt loss 0.103\n",
      "train img loss: 0.170 txt_loss: 0.233 img + txt loss 0.404\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.169 txt_loss: 0.232 img + txt loss 0.402\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.169 txt_loss: 0.231 img + txt loss 0.400\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.399\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.398\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.396\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "finished for 899.9717547893524 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_128_2 = Autoencoder(d=128)\n",
    "optimizer_128_2 = torch.optim.Adam(autoencoder_128_2.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_128_2, optimizer_128_2, 100, [x_img_train, x_txt_train], [x_img_val, x_txt_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.608 txt_loss: 0.627 img + txt loss 1.236\n",
      "val img loss: 0.400 val txt_loss: 0.438 img + txt loss 0.839\n",
      "train img loss: 0.326 txt_loss: 0.366 img + txt loss 0.692\n",
      "val img loss: 0.271 val txt_loss: 0.312 img + txt loss 0.582\n",
      "train img loss: 0.242 txt_loss: 0.284 img + txt loss 0.526\n",
      "val img loss: 0.218 val txt_loss: 0.262 img + txt loss 0.481\n",
      "train img loss: 0.205 txt_loss: 0.251 img + txt loss 0.456\n",
      "val img loss: 0.193 val txt_loss: 0.243 img + txt loss 0.436\n",
      "train img loss: 0.186 txt_loss: 0.239 img + txt loss 0.424\n",
      "val img loss: 0.179 val txt_loss: 0.235 img + txt loss 0.414\n",
      "train img loss: 0.175 txt_loss: 0.233 img + txt loss 0.408\n",
      "val img loss: 0.172 val txt_loss: 0.231 img + txt loss 0.403\n",
      "train img loss: 0.169 txt_loss: 0.230 img + txt loss 0.399\n",
      "val img loss: 0.167 val txt_loss: 0.229 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.395\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.393\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.162 val txt_loss: 0.227 img + txt loss 0.389\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.162 val txt_loss: 0.226 img + txt loss 0.388\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.162 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.387\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "finished for 706.2204780578613 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_f_128 = AutoencoderFixed(d=128)\n",
    "optimizer_f_128 = torch.optim.Adam(autoencoder_f_128.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_f_128, optimizer_f_128, 50, [x_img_train, x_txt_train], [x_img_val, x_txt_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_indices = np.random.randint(low=0, high=x_img_train.shape[0], size=2000)\n",
    "\n",
    "x_img_train_2000 = x_img_train[training_indices]\n",
    "x_txt_train_2000 = x_txt_train[training_indices]\n",
    "y_train_2000 = y_train[training_indices]\n",
    "\n",
    "x_img_train_t_2000 = torch.tensor(x_img_train_2000).float()\n",
    "x_txt_train_t_2000 = torch.tensor(x_txt_train_2000).float()\n",
    "y_train_t_2000 = torch.tensor(y_train_2000).float()\n",
    "\n",
    "train_ds_2000 = TensorDataset(x_img_train_t_2000, x_txt_train_t_2000, y_train_t_2000)\n",
    "train_loader_2000 = DataLoader(train_ds_2000, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8379, grad_fn=<NllLossBackward>) average train loss tensor(3.9031, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.09271523178807947 val_avg_loss: tensor(3.8059)\n",
      "epoch: 1 train_loss: tensor(3.6929, grad_fn=<NllLossBackward>) average train loss tensor(3.7439, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.09398086828550405 val_avg_loss: tensor(3.6885)\n",
      "epoch: 2 train_loss: tensor(3.6383, grad_fn=<NllLossBackward>) average train loss tensor(3.6451, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.12038263428991906 val_avg_loss: tensor(3.5805)\n",
      "epoch: 3 train_loss: tensor(3.4799, grad_fn=<NllLossBackward>) average train loss tensor(3.5479, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.19031640912435616 val_avg_loss: tensor(3.4694)\n",
      "epoch: 4 train_loss: tensor(3.3557, grad_fn=<NllLossBackward>) average train loss tensor(3.4323, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.23370125091979396 val_avg_loss: tensor(3.3411)\n",
      "epoch: 5 train_loss: tensor(3.2332, grad_fn=<NllLossBackward>) average train loss tensor(3.3046, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.25810154525386314 val_avg_loss: tensor(3.1950)\n",
      "epoch: 6 train_loss: tensor(3.0841, grad_fn=<NllLossBackward>) average train loss tensor(3.1805, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.27172921265636496 val_avg_loss: tensor(3.0377)\n",
      "epoch: 7 train_loss: tensor(3.0232, grad_fn=<NllLossBackward>) average train loss tensor(3.0657, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3030757910228109 val_avg_loss: tensor(2.8923)\n",
      "epoch: 8 train_loss: tensor(2.8458, grad_fn=<NllLossBackward>) average train loss tensor(2.9265, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3350110375275938 val_avg_loss: tensor(2.7628)\n",
      "epoch: 9 train_loss: tensor(2.6888, grad_fn=<NllLossBackward>) average train loss tensor(2.7969, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.35323031640912433 val_avg_loss: tensor(2.6423)\n",
      "epoch: 10 train_loss: tensor(2.5823, grad_fn=<NllLossBackward>) average train loss tensor(2.6563, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3691832229580574 val_avg_loss: tensor(2.5349)\n",
      "epoch: 11 train_loss: tensor(2.4465, grad_fn=<NllLossBackward>) average train loss tensor(2.5568, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38651949963208243 val_avg_loss: tensor(2.4437)\n",
      "epoch: 12 train_loss: tensor(2.3158, grad_fn=<NllLossBackward>) average train loss tensor(2.4465, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4016482707873436 val_avg_loss: tensor(2.3564)\n",
      "epoch: 13 train_loss: tensor(2.3495, grad_fn=<NllLossBackward>) average train loss tensor(2.3345, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.41253863134657837 val_avg_loss: tensor(2.2865)\n",
      "epoch: 14 train_loss: tensor(2.2193, grad_fn=<NllLossBackward>) average train loss tensor(2.2621, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42119205298013246 val_avg_loss: tensor(2.2354)\n",
      "epoch: 15 train_loss: tensor(2.0936, grad_fn=<NllLossBackward>) average train loss tensor(2.2037, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4324944812362031 val_avg_loss: tensor(2.1890)\n",
      "epoch: 16 train_loss: tensor(2.1177, grad_fn=<NllLossBackward>) average train loss tensor(2.1306, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43752759381898454 val_avg_loss: tensor(2.1508)\n",
      "epoch: 17 train_loss: tensor(1.9833, grad_fn=<NllLossBackward>) average train loss tensor(2.0699, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4424429727740986 val_avg_loss: tensor(2.1188)\n",
      "epoch: 18 train_loss: tensor(1.9746, grad_fn=<NllLossBackward>) average train loss tensor(2.0269, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44974245768947757 val_avg_loss: tensor(2.0869)\n",
      "epoch: 19 train_loss: tensor(1.9464, grad_fn=<NllLossBackward>) average train loss tensor(1.9825, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45536423841059603 val_avg_loss: tensor(2.0602)\n",
      "epoch: 20 train_loss: tensor(1.7880, grad_fn=<NllLossBackward>) average train loss tensor(1.9118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4590139808682855 val_avg_loss: tensor(2.0372)\n",
      "epoch: 21 train_loss: tensor(1.8196, grad_fn=<NllLossBackward>) average train loss tensor(1.8677, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46375275938189847 val_avg_loss: tensor(2.0238)\n",
      "epoch: 22 train_loss: tensor(1.8240, grad_fn=<NllLossBackward>) average train loss tensor(1.8278, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46728476821192055 val_avg_loss: tensor(2.0134)\n",
      "epoch: 23 train_loss: tensor(1.8320, grad_fn=<NllLossBackward>) average train loss tensor(1.7966, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4721412803532009 val_avg_loss: tensor(1.9963)\n",
      "epoch: 24 train_loss: tensor(1.7207, grad_fn=<NllLossBackward>) average train loss tensor(1.7599, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4752906548933039 val_avg_loss: tensor(1.9815)\n",
      "epoch: 25 train_loss: tensor(1.6193, grad_fn=<NllLossBackward>) average train loss tensor(1.6770, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4750551876379691 val_avg_loss: tensor(1.9775)\n",
      "epoch: 26 train_loss: tensor(1.6035, grad_fn=<NllLossBackward>) average train loss tensor(1.6706, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4764385577630611 val_avg_loss: tensor(1.9770)\n",
      "epoch: 27 train_loss: tensor(1.6008, grad_fn=<NllLossBackward>) average train loss tensor(1.6683, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4792935982339956 val_avg_loss: tensor(1.9764)\n",
      "epoch: 28 train_loss: tensor(1.5678, grad_fn=<NllLossBackward>) average train loss tensor(1.6265, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4795879323031641 val_avg_loss: tensor(1.9730)\n",
      "epoch: 29 train_loss: tensor(1.5424, grad_fn=<NllLossBackward>) average train loss tensor(1.5633, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4827961736571008 val_avg_loss: tensor(1.9697)\n",
      "epoch: 30 train_loss: tensor(1.4806, grad_fn=<NllLossBackward>) average train loss tensor(1.5539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48462104488594554 val_avg_loss: tensor(1.9700)\n",
      "epoch: 31 train_loss: tensor(1.5343, grad_fn=<NllLossBackward>) average train loss tensor(1.5643, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48497424576894776 val_avg_loss: tensor(1.9671)\n",
      "epoch: 32 train_loss: tensor(1.4654, grad_fn=<NllLossBackward>) average train loss tensor(1.5217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4860338484179544 val_avg_loss: tensor(1.9641)\n",
      "epoch: 33 train_loss: tensor(1.3988, grad_fn=<NllLossBackward>) average train loss tensor(1.4931, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4869462840323768 val_avg_loss: tensor(1.9647)\n",
      "epoch: 34 train_loss: tensor(1.3800, grad_fn=<NllLossBackward>) average train loss tensor(1.4351, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4867402501839588 val_avg_loss: tensor(1.9695)\n",
      "epoch: 35 train_loss: tensor(1.3207, grad_fn=<NllLossBackward>) average train loss tensor(1.3925, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4877115526122149 val_avg_loss: tensor(1.9739)\n",
      "epoch: 36 train_loss: tensor(1.3534, grad_fn=<NllLossBackward>) average train loss tensor(1.3954, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49012509197939663 val_avg_loss: tensor(1.9751)\n",
      "epoch: 37 train_loss: tensor(1.3375, grad_fn=<NllLossBackward>) average train loss tensor(1.3889, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49286239882266375 val_avg_loss: tensor(1.9795)\n",
      "epoch: 38 train_loss: tensor(1.3317, grad_fn=<NllLossBackward>) average train loss tensor(1.3864, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4933038999264165 val_avg_loss: tensor(1.9779)\n",
      "epoch: 39 train_loss: tensor(1.2978, grad_fn=<NllLossBackward>) average train loss tensor(1.3159, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4926269315673289 val_avg_loss: tensor(1.9840)\n",
      "epoch: 40 train_loss: tensor(1.2757, grad_fn=<NllLossBackward>) average train loss tensor(1.3399, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49439293598233996 val_avg_loss: tensor(1.9965)\n",
      "epoch: 41 train_loss: tensor(1.2085, grad_fn=<NllLossBackward>) average train loss tensor(1.2637, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4948344370860927 val_avg_loss: tensor(1.9934)\n",
      "epoch: 42 train_loss: tensor(1.2351, grad_fn=<NllLossBackward>) average train loss tensor(1.2821, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4951582045621781 val_avg_loss: tensor(1.9974)\n",
      "epoch: 43 train_loss: tensor(1.1315, grad_fn=<NllLossBackward>) average train loss tensor(1.2280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4933038999264165 val_avg_loss: tensor(2.0113)\n",
      "epoch: 44 train_loss: tensor(1.1813, grad_fn=<NllLossBackward>) average train loss tensor(1.2497, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49577630610743195 val_avg_loss: tensor(2.0152)\n",
      "epoch: 45 train_loss: tensor(1.1071, grad_fn=<NllLossBackward>) average train loss tensor(1.2198, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49495217071376013 val_avg_loss: tensor(2.0201)\n",
      "epoch: 46 train_loss: tensor(1.0452, grad_fn=<NllLossBackward>) average train loss tensor(1.1767, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.49518763796909493 val_avg_loss: tensor(2.0173)\n",
      "epoch: 47 train_loss: tensor(1.1300, grad_fn=<NllLossBackward>) average train loss tensor(1.1636, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4969830757910228 val_avg_loss: tensor(2.0283)\n",
      "epoch: 48 train_loss: tensor(0.9853, grad_fn=<NllLossBackward>) average train loss tensor(1.1528, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.496747608535688 val_avg_loss: tensor(2.0398)\n",
      "epoch: 49 train_loss: tensor(1.0180, grad_fn=<NllLossBackward>) average train loss tensor(1.1201, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4926269315673289 val_avg_loss: tensor(2.0592)\n",
      "epoch: 50 train_loss: tensor(0.9955, grad_fn=<NllLossBackward>) average train loss tensor(1.0994, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49439293598233996 val_avg_loss: tensor(2.0670)\n",
      "epoch: 51 train_loss: tensor(1.0541, grad_fn=<NllLossBackward>) average train loss tensor(1.1100, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49303899926416483 val_avg_loss: tensor(2.0846)\n",
      "epoch: 52 train_loss: tensor(0.9991, grad_fn=<NllLossBackward>) average train loss tensor(1.1121, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49271523178807947 val_avg_loss: tensor(2.0907)\n",
      "epoch: 53 train_loss: tensor(0.9900, grad_fn=<NllLossBackward>) average train loss tensor(1.0574, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49642384105960263 val_avg_loss: tensor(2.0951)\n",
      "epoch: 54 train_loss: tensor(0.9881, grad_fn=<NllLossBackward>) average train loss tensor(1.0813, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4946872700515085 val_avg_loss: tensor(2.0994)\n",
      "epoch: 55 train_loss: tensor(0.9576, grad_fn=<NllLossBackward>) average train loss tensor(1.0669, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49339220014716706 val_avg_loss: tensor(2.1047)\n",
      "epoch: 56 train_loss: tensor(0.9951, grad_fn=<NllLossBackward>) average train loss tensor(1.0427, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4951582045621781 val_avg_loss: tensor(2.1149)\n",
      "epoch: 57 train_loss: tensor(0.9158, grad_fn=<NllLossBackward>) average train loss tensor(0.9988, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4956585724797645 val_avg_loss: tensor(2.1130)\n",
      "epoch: 58 train_loss: tensor(0.8468, grad_fn=<NllLossBackward>) average train loss tensor(0.9575, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49701250919793966 val_avg_loss: tensor(2.1301)\n",
      "epoch: 59 train_loss: tensor(0.9199, grad_fn=<NllLossBackward>) average train loss tensor(1.0006, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49554083885209715 val_avg_loss: tensor(2.1517)\n",
      "epoch: 60 train_loss: tensor(0.9081, grad_fn=<NllLossBackward>) average train loss tensor(0.9731, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49183222958057393 val_avg_loss: tensor(2.1652)\n",
      "epoch: 61 train_loss: tensor(0.9181, grad_fn=<NllLossBackward>) average train loss tensor(0.9766, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4966887417218543 val_avg_loss: tensor(2.1642)\n",
      "epoch: 62 train_loss: tensor(0.8812, grad_fn=<NllLossBackward>) average train loss tensor(0.9658, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4971008094186902 val_avg_loss: tensor(2.1530)\n",
      "epoch: 63 train_loss: tensor(0.9330, grad_fn=<NllLossBackward>) average train loss tensor(0.9390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4952759381898455 val_avg_loss: tensor(2.1471)\n",
      "epoch: 64 train_loss: tensor(0.8019, grad_fn=<NllLossBackward>) average train loss tensor(0.9073, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4945401030169242 val_avg_loss: tensor(2.1650)\n",
      "epoch: 65 train_loss: tensor(0.8920, grad_fn=<NllLossBackward>) average train loss tensor(0.9595, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49415746872700517 val_avg_loss: tensor(2.1849)\n",
      "epoch: 66 train_loss: tensor(0.7913, grad_fn=<NllLossBackward>) average train loss tensor(0.8916, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4933627667402502 val_avg_loss: tensor(2.2010)\n",
      "epoch: 67 train_loss: tensor(0.7846, grad_fn=<NllLossBackward>) average train loss tensor(0.9057, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49642384105960263 val_avg_loss: tensor(2.1979)\n",
      "epoch: 68 train_loss: tensor(0.8262, grad_fn=<NllLossBackward>) average train loss tensor(0.9143, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4942457689477557 val_avg_loss: tensor(2.2095)\n",
      "epoch: 69 train_loss: tensor(0.7808, grad_fn=<NllLossBackward>) average train loss tensor(0.8728, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4940691685062546 val_avg_loss: tensor(2.2325)\n",
      "epoch: 70 train_loss: tensor(0.7518, grad_fn=<NllLossBackward>) average train loss tensor(0.8664, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4920971302428256 val_avg_loss: tensor(2.2480)\n",
      "epoch: 71 train_loss: tensor(0.7963, grad_fn=<NllLossBackward>) average train loss tensor(0.8513, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4888300220750552 val_avg_loss: tensor(2.2602)\n",
      "epoch: 72 train_loss: tensor(0.8031, grad_fn=<NllLossBackward>) average train loss tensor(0.8639, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4904782928623988 val_avg_loss: tensor(2.2607)\n",
      "epoch: 73 train_loss: tensor(0.7446, grad_fn=<NllLossBackward>) average train loss tensor(0.8330, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4917733627667403 val_avg_loss: tensor(2.2608)\n",
      "epoch: 74 train_loss: tensor(0.7159, grad_fn=<NllLossBackward>) average train loss tensor(0.8224, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4918616629874908 val_avg_loss: tensor(2.2644)\n",
      "epoch: 75 train_loss: tensor(0.7219, grad_fn=<NllLossBackward>) average train loss tensor(0.8118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49271523178807947 val_avg_loss: tensor(2.2798)\n",
      "epoch: 76 train_loss: tensor(0.6891, grad_fn=<NllLossBackward>) average train loss tensor(0.7976, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49203826342899193 val_avg_loss: tensor(2.3084)\n",
      "epoch: 77 train_loss: tensor(0.7411, grad_fn=<NllLossBackward>) average train loss tensor(0.8085, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4909786607799853 val_avg_loss: tensor(2.3222)\n",
      "epoch: 78 train_loss: tensor(0.7133, grad_fn=<NllLossBackward>) average train loss tensor(0.7524, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4910963944076527 val_avg_loss: tensor(2.3313)\n",
      "epoch: 79 train_loss: tensor(0.7694, grad_fn=<NllLossBackward>) average train loss tensor(0.7925, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4889477557027226 val_avg_loss: tensor(2.3437)\n",
      "epoch: 80 train_loss: tensor(0.6698, grad_fn=<NllLossBackward>) average train loss tensor(0.7808, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4866225165562914 val_avg_loss: tensor(2.3605)\n",
      "epoch: 81 train_loss: tensor(0.6857, grad_fn=<NllLossBackward>) average train loss tensor(0.7579, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48859455481972036 val_avg_loss: tensor(2.3682)\n",
      "epoch: 82 train_loss: tensor(0.6490, grad_fn=<NllLossBackward>) average train loss tensor(0.7677, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4897130242825607 val_avg_loss: tensor(2.3522)\n",
      "epoch: 83 train_loss: tensor(0.6785, grad_fn=<NllLossBackward>) average train loss tensor(0.7638, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49439293598233996 val_avg_loss: tensor(2.3458)\n",
      "epoch: 84 train_loss: tensor(0.6673, grad_fn=<NllLossBackward>) average train loss tensor(0.7523, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4910080941869021 val_avg_loss: tensor(2.3487)\n",
      "epoch: 85 train_loss: tensor(0.6682, grad_fn=<NllLossBackward>) average train loss tensor(0.7258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48724061810154523 val_avg_loss: tensor(2.3706)\n",
      "epoch: 86 train_loss: tensor(0.6127, grad_fn=<NllLossBackward>) average train loss tensor(0.7227, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48827078734363505 val_avg_loss: tensor(2.3899)\n",
      "epoch: 87 train_loss: tensor(0.6245, grad_fn=<NllLossBackward>) average train loss tensor(0.7137, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4864164827078734 val_avg_loss: tensor(2.4038)\n",
      "epoch: 88 train_loss: tensor(0.5753, grad_fn=<NllLossBackward>) average train loss tensor(0.6773, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.486504782928624 val_avg_loss: tensor(2.4047)\n",
      "epoch: 89 train_loss: tensor(0.5596, grad_fn=<NllLossBackward>) average train loss tensor(0.7109, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4884179543782193 val_avg_loss: tensor(2.4078)\n",
      "epoch: 90 train_loss: tensor(0.6740, grad_fn=<NllLossBackward>) average train loss tensor(0.7265, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4923914643119941 val_avg_loss: tensor(2.4233)\n",
      "epoch: 91 train_loss: tensor(0.5909, grad_fn=<NllLossBackward>) average train loss tensor(0.7006, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4907726269315673 val_avg_loss: tensor(2.4405)\n",
      "epoch: 92 train_loss: tensor(0.6088, grad_fn=<NllLossBackward>) average train loss tensor(0.6794, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4850036791758646 val_avg_loss: tensor(2.4524)\n",
      "epoch: 93 train_loss: tensor(0.6659, grad_fn=<NllLossBackward>) average train loss tensor(0.6899, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48391464311994115 val_avg_loss: tensor(2.4765)\n",
      "epoch: 94 train_loss: tensor(0.5933, grad_fn=<NllLossBackward>) average train loss tensor(0.6655, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4886534216335541 val_avg_loss: tensor(2.4909)\n",
      "epoch: 95 train_loss: tensor(0.6520, grad_fn=<NllLossBackward>) average train loss tensor(0.6553, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48729948491537894 val_avg_loss: tensor(2.4961)\n",
      "epoch: 96 train_loss: tensor(0.5678, grad_fn=<NllLossBackward>) average train loss tensor(0.6475, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48659308314937455 val_avg_loss: tensor(2.5003)\n",
      "epoch: 97 train_loss: tensor(0.4935, grad_fn=<NllLossBackward>) average train loss tensor(0.6248, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48921265636497424 val_avg_loss: tensor(2.5251)\n",
      "epoch: 98 train_loss: tensor(0.5798, grad_fn=<NllLossBackward>) average train loss tensor(0.6702, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48777041942604854 val_avg_loss: tensor(2.5461)\n",
      "epoch: 99 train_loss: tensor(0.6038, grad_fn=<NllLossBackward>) average train loss tensor(0.6691, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4847682119205298 val_avg_loss: tensor(2.5416)\n"
     ]
    }
   ],
   "source": [
    "encoder_128_2 = autoencoder_128_2.encoder\n",
    "after_encoder_model_128_2 = AfterEncoderModel(encoder_128_2, d=128, drop=0.5)\n",
    "optimizer_aem_128_2 = torch.optim.Adam(after_encoder_model_128_2.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_128_2_bs2048_rs42_d128_wd0005_drop05_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_128_2,\n",
    "    optimizer=optimizer_aem_128_2,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8616, grad_fn=<NllLossBackward>) average train loss tensor(3.8841, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.09091979396615159 val_avg_loss: tensor(3.8390)\n",
      "epoch: 1 train_loss: tensor(3.7379, grad_fn=<NllLossBackward>) average train loss tensor(3.7809, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.11599705665930832 val_avg_loss: tensor(3.7186)\n",
      "epoch: 2 train_loss: tensor(3.5536, grad_fn=<NllLossBackward>) average train loss tensor(3.6227, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.11646799116997793 val_avg_loss: tensor(3.5462)\n",
      "epoch: 3 train_loss: tensor(3.3934, grad_fn=<NllLossBackward>) average train loss tensor(3.4654, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1914054451802796 val_avg_loss: tensor(3.3924)\n",
      "epoch: 4 train_loss: tensor(3.1693, grad_fn=<NllLossBackward>) average train loss tensor(3.2956, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2513907284768212 val_avg_loss: tensor(3.1974)\n",
      "epoch: 5 train_loss: tensor(2.9944, grad_fn=<NllLossBackward>) average train loss tensor(3.1018, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2907726269315673 val_avg_loss: tensor(2.9899)\n",
      "epoch: 6 train_loss: tensor(2.7665, grad_fn=<NllLossBackward>) average train loss tensor(2.8731, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3183811626195732 val_avg_loss: tensor(2.7974)\n",
      "epoch: 7 train_loss: tensor(2.6097, grad_fn=<NllLossBackward>) average train loss tensor(2.6932, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3579690949227373 val_avg_loss: tensor(2.6378)\n",
      "epoch: 8 train_loss: tensor(2.3710, grad_fn=<NllLossBackward>) average train loss tensor(2.5039, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38675496688741723 val_avg_loss: tensor(2.5149)\n",
      "epoch: 9 train_loss: tensor(2.2666, grad_fn=<NllLossBackward>) average train loss tensor(2.3583, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40467991169977924 val_avg_loss: tensor(2.4142)\n",
      "epoch: 10 train_loss: tensor(2.1462, grad_fn=<NllLossBackward>) average train loss tensor(2.2591, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.41754231052244295 val_avg_loss: tensor(2.3336)\n",
      "epoch: 11 train_loss: tensor(1.9814, grad_fn=<NllLossBackward>) average train loss tensor(2.0835, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4352612214863871 val_avg_loss: tensor(2.2533)\n",
      "epoch: 12 train_loss: tensor(1.8545, grad_fn=<NllLossBackward>) average train loss tensor(1.9868, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430905077262693 val_avg_loss: tensor(2.2004)\n",
      "epoch: 13 train_loss: tensor(1.7267, grad_fn=<NllLossBackward>) average train loss tensor(1.8654, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4491243561442237 val_avg_loss: tensor(2.1671)\n",
      "epoch: 14 train_loss: tensor(1.6321, grad_fn=<NllLossBackward>) average train loss tensor(1.7691, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46086828550404707 val_avg_loss: tensor(2.1338)\n",
      "epoch: 15 train_loss: tensor(1.6178, grad_fn=<NllLossBackward>) average train loss tensor(1.6758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4634289919058131 val_avg_loss: tensor(2.1235)\n",
      "epoch: 16 train_loss: tensor(1.4731, grad_fn=<NllLossBackward>) average train loss tensor(1.6088, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47025754231052247 val_avg_loss: tensor(2.1011)\n",
      "epoch: 17 train_loss: tensor(1.4027, grad_fn=<NllLossBackward>) average train loss tensor(1.5483, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47381898454746135 val_avg_loss: tensor(2.0895)\n",
      "epoch: 18 train_loss: tensor(1.3765, grad_fn=<NllLossBackward>) average train loss tensor(1.4597, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748197203826343 val_avg_loss: tensor(2.1049)\n",
      "epoch: 19 train_loss: tensor(1.3829, grad_fn=<NllLossBackward>) average train loss tensor(1.4054, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47846946284032377 val_avg_loss: tensor(2.1017)\n",
      "epoch: 20 train_loss: tensor(1.2419, grad_fn=<NllLossBackward>) average train loss tensor(1.3713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478822663723326 val_avg_loss: tensor(2.1113)\n",
      "epoch: 21 train_loss: tensor(1.1467, grad_fn=<NllLossBackward>) average train loss tensor(1.2796, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48008830022075055 val_avg_loss: tensor(2.1324)\n",
      "epoch: 22 train_loss: tensor(1.1570, grad_fn=<NllLossBackward>) average train loss tensor(1.2158, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48185430463576157 val_avg_loss: tensor(2.1539)\n",
      "epoch: 23 train_loss: tensor(1.0857, grad_fn=<NllLossBackward>) average train loss tensor(1.1450, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48217807211184693 val_avg_loss: tensor(2.1684)\n",
      "epoch: 24 train_loss: tensor(1.0746, grad_fn=<NllLossBackward>) average train loss tensor(1.1240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4832671081677704 val_avg_loss: tensor(2.1921)\n",
      "epoch: 25 train_loss: tensor(0.9243, grad_fn=<NllLossBackward>) average train loss tensor(1.0770, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48409124356144223 val_avg_loss: tensor(2.2177)\n",
      "epoch: 26 train_loss: tensor(0.9571, grad_fn=<NllLossBackward>) average train loss tensor(1.0268, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4819131714495953 val_avg_loss: tensor(2.2544)\n",
      "epoch: 27 train_loss: tensor(0.9385, grad_fn=<NllLossBackward>) average train loss tensor(1.0029, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47967623252391467 val_avg_loss: tensor(2.2852)\n",
      "epoch: 28 train_loss: tensor(0.8706, grad_fn=<NllLossBackward>) average train loss tensor(0.9746, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4800588668138337 val_avg_loss: tensor(2.3063)\n",
      "epoch: 29 train_loss: tensor(0.8279, grad_fn=<NllLossBackward>) average train loss tensor(0.9346, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4805298013245033 val_avg_loss: tensor(2.3237)\n",
      "epoch: 30 train_loss: tensor(0.8470, grad_fn=<NllLossBackward>) average train loss tensor(0.9119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4809713024282561 val_avg_loss: tensor(2.3574)\n",
      "epoch: 31 train_loss: tensor(0.8147, grad_fn=<NllLossBackward>) average train loss tensor(0.8724, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47723325974981606 val_avg_loss: tensor(2.4076)\n",
      "epoch: 32 train_loss: tensor(0.6806, grad_fn=<NllLossBackward>) average train loss tensor(0.8019, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.476850625459897 val_avg_loss: tensor(2.4276)\n",
      "epoch: 33 train_loss: tensor(0.7396, grad_fn=<NllLossBackward>) average train loss tensor(0.7844, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4782634289919058 val_avg_loss: tensor(2.4618)\n",
      "epoch: 34 train_loss: tensor(0.7040, grad_fn=<NllLossBackward>) average train loss tensor(0.7603, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4767623252391464 val_avg_loss: tensor(2.4987)\n",
      "epoch: 35 train_loss: tensor(0.6060, grad_fn=<NllLossBackward>) average train loss tensor(0.7283, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47573215599705665 val_avg_loss: tensor(2.5413)\n",
      "epoch: 36 train_loss: tensor(0.6829, grad_fn=<NllLossBackward>) average train loss tensor(0.6956, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47770419426048566 val_avg_loss: tensor(2.5893)\n",
      "epoch: 37 train_loss: tensor(0.6375, grad_fn=<NllLossBackward>) average train loss tensor(0.6818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4772921265636497 val_avg_loss: tensor(2.6308)\n",
      "epoch: 38 train_loss: tensor(0.5984, grad_fn=<NllLossBackward>) average train loss tensor(0.6539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4773804267844003 val_avg_loss: tensor(2.6845)\n",
      "epoch: 39 train_loss: tensor(0.6417, grad_fn=<NllLossBackward>) average train loss tensor(0.6582, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4766740250183959 val_avg_loss: tensor(2.7168)\n",
      "epoch: 40 train_loss: tensor(0.5394, grad_fn=<NllLossBackward>) average train loss tensor(0.6061, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47137601177336275 val_avg_loss: tensor(2.7607)\n",
      "epoch: 41 train_loss: tensor(0.5558, grad_fn=<NllLossBackward>) average train loss tensor(0.5913, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47049300956585727 val_avg_loss: tensor(2.8184)\n",
      "epoch: 42 train_loss: tensor(0.5492, grad_fn=<NllLossBackward>) average train loss tensor(0.5773, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47426048565121415 val_avg_loss: tensor(2.8288)\n",
      "epoch: 43 train_loss: tensor(0.4758, grad_fn=<NllLossBackward>) average train loss tensor(0.5493, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.469551140544518 val_avg_loss: tensor(2.8426)\n",
      "epoch: 44 train_loss: tensor(0.5349, grad_fn=<NllLossBackward>) average train loss tensor(0.5606, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47334805003679176 val_avg_loss: tensor(2.8632)\n",
      "epoch: 45 train_loss: tensor(0.4337, grad_fn=<NllLossBackward>) average train loss tensor(0.5402, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47167034584253126 val_avg_loss: tensor(2.9269)\n",
      "epoch: 46 train_loss: tensor(0.4488, grad_fn=<NllLossBackward>) average train loss tensor(0.5421, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.47172921265636497 val_avg_loss: tensor(2.9627)\n",
      "epoch: 47 train_loss: tensor(0.4260, grad_fn=<NllLossBackward>) average train loss tensor(0.4747, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4714054451802796 val_avg_loss: tensor(2.9927)\n",
      "epoch: 48 train_loss: tensor(0.4707, grad_fn=<NllLossBackward>) average train loss tensor(0.5097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4706401766004415 val_avg_loss: tensor(3.0378)\n",
      "epoch: 49 train_loss: tensor(0.3891, grad_fn=<NllLossBackward>) average train loss tensor(0.4383, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4695805739514349 val_avg_loss: tensor(3.0831)\n",
      "epoch: 50 train_loss: tensor(0.3751, grad_fn=<NllLossBackward>) average train loss tensor(0.4539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.469168506254599 val_avg_loss: tensor(3.1051)\n",
      "epoch: 51 train_loss: tensor(0.3832, grad_fn=<NllLossBackward>) average train loss tensor(0.4504, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4649889624724062 val_avg_loss: tensor(3.1555)\n",
      "epoch: 52 train_loss: tensor(0.3623, grad_fn=<NllLossBackward>) average train loss tensor(0.4000, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46654893303899925 val_avg_loss: tensor(3.2154)\n",
      "epoch: 53 train_loss: tensor(0.4383, grad_fn=<NllLossBackward>) average train loss tensor(0.4389, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47152317880794703 val_avg_loss: tensor(3.2221)\n",
      "epoch: 54 train_loss: tensor(0.3458, grad_fn=<NllLossBackward>) average train loss tensor(0.4223, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4708167770419426 val_avg_loss: tensor(3.2501)\n",
      "epoch: 55 train_loss: tensor(0.3011, grad_fn=<NllLossBackward>) average train loss tensor(0.3703, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46684326710816776 val_avg_loss: tensor(3.2895)\n",
      "epoch: 56 train_loss: tensor(0.3698, grad_fn=<NllLossBackward>) average train loss tensor(0.3785, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4686092715231788 val_avg_loss: tensor(3.3138)\n",
      "epoch: 57 train_loss: tensor(0.3032, grad_fn=<NllLossBackward>) average train loss tensor(0.3555, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4704047093451067 val_avg_loss: tensor(3.3592)\n",
      "epoch: 58 train_loss: tensor(0.3055, grad_fn=<NllLossBackward>) average train loss tensor(0.3601, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4670198675496689 val_avg_loss: tensor(3.4006)\n",
      "epoch: 59 train_loss: tensor(0.3418, grad_fn=<NllLossBackward>) average train loss tensor(0.3975, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46669610007358353 val_avg_loss: tensor(3.4416)\n",
      "epoch: 60 train_loss: tensor(0.3165, grad_fn=<NllLossBackward>) average train loss tensor(0.3501, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4691979396615158 val_avg_loss: tensor(3.4620)\n",
      "epoch: 61 train_loss: tensor(0.2754, grad_fn=<NllLossBackward>) average train loss tensor(0.3226, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4705224429727741 val_avg_loss: tensor(3.4709)\n",
      "epoch: 62 train_loss: tensor(0.3243, grad_fn=<NllLossBackward>) average train loss tensor(0.3518, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46660779985283296 val_avg_loss: tensor(3.5022)\n",
      "epoch: 63 train_loss: tensor(0.2579, grad_fn=<NllLossBackward>) average train loss tensor(0.3214, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4641942604856512 val_avg_loss: tensor(3.5418)\n",
      "epoch: 64 train_loss: tensor(0.2500, grad_fn=<NllLossBackward>) average train loss tensor(0.3042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45839587932303166 val_avg_loss: tensor(3.5625)\n",
      "epoch: 65 train_loss: tensor(0.2337, grad_fn=<NllLossBackward>) average train loss tensor(0.2846, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4599852832965416 val_avg_loss: tensor(3.6043)\n",
      "epoch: 66 train_loss: tensor(0.2208, grad_fn=<NllLossBackward>) average train loss tensor(0.2989, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4655776306107432 val_avg_loss: tensor(3.6354)\n",
      "epoch: 67 train_loss: tensor(0.2458, grad_fn=<NllLossBackward>) average train loss tensor(0.2927, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46445916114790287 val_avg_loss: tensor(3.6791)\n",
      "epoch: 68 train_loss: tensor(0.2208, grad_fn=<NllLossBackward>) average train loss tensor(0.2750, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46545989698307577 val_avg_loss: tensor(3.7035)\n",
      "epoch: 69 train_loss: tensor(0.2082, grad_fn=<NllLossBackward>) average train loss tensor(0.2502, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4627520235467255 val_avg_loss: tensor(3.7533)\n",
      "epoch: 70 train_loss: tensor(0.2265, grad_fn=<NllLossBackward>) average train loss tensor(0.2853, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46225165562913906 val_avg_loss: tensor(3.7707)\n",
      "epoch: 71 train_loss: tensor(0.2391, grad_fn=<NllLossBackward>) average train loss tensor(0.2750, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4597498160412068 val_avg_loss: tensor(3.7981)\n",
      "epoch: 72 train_loss: tensor(0.2743, grad_fn=<NllLossBackward>) average train loss tensor(0.2893, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4613392200147167 val_avg_loss: tensor(3.8432)\n",
      "epoch: 73 train_loss: tensor(0.2880, grad_fn=<NllLossBackward>) average train loss tensor(0.2962, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4603090507726269 val_avg_loss: tensor(3.8525)\n",
      "epoch: 74 train_loss: tensor(0.2387, grad_fn=<NllLossBackward>) average train loss tensor(0.2754, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4608094186902134 val_avg_loss: tensor(3.8497)\n",
      "epoch: 75 train_loss: tensor(0.2534, grad_fn=<NllLossBackward>) average train loss tensor(0.2660, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46375275938189847 val_avg_loss: tensor(3.8946)\n",
      "epoch: 76 train_loss: tensor(0.2326, grad_fn=<NllLossBackward>) average train loss tensor(0.2460, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4655776306107432 val_avg_loss: tensor(3.8967)\n",
      "epoch: 77 train_loss: tensor(0.2216, grad_fn=<NllLossBackward>) average train loss tensor(0.2467, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4618984547461369 val_avg_loss: tensor(3.8802)\n",
      "epoch: 78 train_loss: tensor(0.2704, grad_fn=<NllLossBackward>) average train loss tensor(0.2518, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45939661515820457 val_avg_loss: tensor(3.9094)\n",
      "epoch: 79 train_loss: tensor(0.1703, grad_fn=<NllLossBackward>) average train loss tensor(0.2304, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45957321559970565 val_avg_loss: tensor(3.9328)\n",
      "epoch: 80 train_loss: tensor(0.1755, grad_fn=<NllLossBackward>) average train loss tensor(0.2182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46033848417954376 val_avg_loss: tensor(3.9675)\n",
      "epoch: 81 train_loss: tensor(0.1730, grad_fn=<NllLossBackward>) average train loss tensor(0.2251, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.461280353200883 val_avg_loss: tensor(3.9912)\n",
      "epoch: 82 train_loss: tensor(0.2284, grad_fn=<NllLossBackward>) average train loss tensor(0.2373, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4593671817512877 val_avg_loss: tensor(4.0399)\n",
      "epoch: 83 train_loss: tensor(0.1812, grad_fn=<NllLossBackward>) average train loss tensor(0.2038, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45665930831493745 val_avg_loss: tensor(4.0802)\n",
      "epoch: 84 train_loss: tensor(0.1750, grad_fn=<NllLossBackward>) average train loss tensor(0.1960, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45689477557027225 val_avg_loss: tensor(4.1168)\n",
      "epoch: 85 train_loss: tensor(0.1871, grad_fn=<NllLossBackward>) average train loss tensor(0.2195, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4588962472406181 val_avg_loss: tensor(4.1383)\n",
      "epoch: 86 train_loss: tensor(0.1499, grad_fn=<NllLossBackward>) average train loss tensor(0.1982, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4594260485651214 val_avg_loss: tensor(4.1857)\n",
      "epoch: 87 train_loss: tensor(0.1534, grad_fn=<NllLossBackward>) average train loss tensor(0.1945, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45986754966887416 val_avg_loss: tensor(4.2113)\n",
      "epoch: 88 train_loss: tensor(0.1965, grad_fn=<NllLossBackward>) average train loss tensor(0.1871, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4573068432671082 val_avg_loss: tensor(4.2776)\n",
      "epoch: 89 train_loss: tensor(0.1945, grad_fn=<NllLossBackward>) average train loss tensor(0.2020, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45795437821927887 val_avg_loss: tensor(4.2957)\n",
      "epoch: 90 train_loss: tensor(0.1690, grad_fn=<NllLossBackward>) average train loss tensor(0.1822, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4594554819720383 val_avg_loss: tensor(4.2894)\n",
      "epoch: 91 train_loss: tensor(0.1838, grad_fn=<NllLossBackward>) average train loss tensor(0.1731, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46101545253863135 val_avg_loss: tensor(4.3202)\n",
      "epoch: 92 train_loss: tensor(0.1604, grad_fn=<NllLossBackward>) average train loss tensor(0.1759, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.45818984547461367 val_avg_loss: tensor(4.3374)\n",
      "epoch: 93 train_loss: tensor(0.1635, grad_fn=<NllLossBackward>) average train loss tensor(0.1892, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4563355408388521 val_avg_loss: tensor(4.3592)\n",
      "epoch: 94 train_loss: tensor(0.1512, grad_fn=<NllLossBackward>) average train loss tensor(0.1784, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4570125091979397 val_avg_loss: tensor(4.4123)\n",
      "epoch: 95 train_loss: tensor(0.1511, grad_fn=<NllLossBackward>) average train loss tensor(0.1689, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4582192788815305 val_avg_loss: tensor(4.4261)\n",
      "epoch: 96 train_loss: tensor(0.1735, grad_fn=<NllLossBackward>) average train loss tensor(0.1824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4594554819720383 val_avg_loss: tensor(4.4187)\n",
      "epoch: 97 train_loss: tensor(0.0954, grad_fn=<NllLossBackward>) average train loss tensor(0.1540, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45933774834437086 val_avg_loss: tensor(4.4270)\n",
      "epoch: 98 train_loss: tensor(0.1460, grad_fn=<NllLossBackward>) average train loss tensor(0.1669, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45851361295069903 val_avg_loss: tensor(4.4555)\n",
      "epoch: 99 train_loss: tensor(0.1541, grad_fn=<NllLossBackward>) average train loss tensor(0.1534, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4572185430463576 val_avg_loss: tensor(4.4727)\n"
     ]
    }
   ],
   "source": [
    "import pytorch.torch_models as torch_models\n",
    "\n",
    "encoder_f_128 = autoencoder_f_128.encoder\n",
    "after_encoder_model_f_128 = AfterEncoderModel(encoder_f_128, d=128, drop=0.5)\n",
    "optimizer_aem_f_128 = torch.optim.Adam(after_encoder_model_f_128.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_f_128_bs2048_rs42_d128_drop05_t2000_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_f_128,\n",
    "    optimizer=optimizer_aem_f_128,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.700 txt_loss: 0.731 img + txt loss 1.431\n",
      "val img loss: 0.519 val txt_loss: 0.567 img + txt loss 1.086\n",
      "train img loss: 0.458 txt_loss: 0.510 img + txt loss 0.968\n",
      "val img loss: 0.413 val txt_loss: 0.467 img + txt loss 0.880\n",
      "train img loss: 0.386 txt_loss: 0.441 img + txt loss 0.826\n",
      "val img loss: 0.363 val txt_loss: 0.419 img + txt loss 0.782\n",
      "train img loss: 0.347 txt_loss: 0.402 img + txt loss 0.749\n",
      "val img loss: 0.332 val txt_loss: 0.389 img + txt loss 0.721\n",
      "train img loss: 0.321 txt_loss: 0.376 img + txt loss 0.697\n",
      "val img loss: 0.311 val txt_loss: 0.367 img + txt loss 0.678\n",
      "train img loss: 0.301 txt_loss: 0.356 img + txt loss 0.656\n",
      "val img loss: 0.294 val txt_loss: 0.348 img + txt loss 0.642\n",
      "train img loss: 0.286 txt_loss: 0.339 img + txt loss 0.625\n",
      "val img loss: 0.280 val txt_loss: 0.332 img + txt loss 0.612\n",
      "train img loss: 0.273 txt_loss: 0.324 img + txt loss 0.597\n",
      "val img loss: 0.268 val txt_loss: 0.318 img + txt loss 0.585\n",
      "train img loss: 0.262 txt_loss: 0.311 img + txt loss 0.573\n",
      "val img loss: 0.259 val txt_loss: 0.305 img + txt loss 0.564\n",
      "train img loss: 0.253 txt_loss: 0.299 img + txt loss 0.551\n",
      "val img loss: 0.249 val txt_loss: 0.294 img + txt loss 0.543\n",
      "train img loss: 0.245 txt_loss: 0.288 img + txt loss 0.533\n",
      "val img loss: 0.242 val txt_loss: 0.284 img + txt loss 0.526\n",
      "train img loss: 0.238 txt_loss: 0.278 img + txt loss 0.516\n",
      "val img loss: 0.235 val txt_loss: 0.274 img + txt loss 0.510\n",
      "train img loss: 0.232 txt_loss: 0.270 img + txt loss 0.502\n",
      "val img loss: 0.236 val txt_loss: 0.268 img + txt loss 0.503\n",
      "train img loss: 0.227 txt_loss: 0.263 img + txt loss 0.490\n",
      "val img loss: 0.224 val txt_loss: 0.261 img + txt loss 0.485\n",
      "train img loss: 0.221 txt_loss: 0.258 img + txt loss 0.479\n",
      "val img loss: 0.220 val txt_loss: 0.257 img + txt loss 0.477\n",
      "train img loss: 0.218 txt_loss: 0.253 img + txt loss 0.471\n",
      "val img loss: 0.216 val txt_loss: 0.252 img + txt loss 0.468\n",
      "train img loss: 0.213 txt_loss: 0.250 img + txt loss 0.463\n",
      "val img loss: 0.212 val txt_loss: 0.249 img + txt loss 0.460\n",
      "train img loss: 0.210 txt_loss: 0.247 img + txt loss 0.456\n",
      "val img loss: 0.211 val txt_loss: 0.246 img + txt loss 0.457\n",
      "train img loss: 0.206 txt_loss: 0.245 img + txt loss 0.451\n",
      "val img loss: 0.205 val txt_loss: 0.245 img + txt loss 0.450\n",
      "train img loss: 0.204 txt_loss: 0.242 img + txt loss 0.446\n",
      "val img loss: 0.203 val txt_loss: 0.242 img + txt loss 0.446\n",
      "train img loss: 0.202 txt_loss: 0.241 img + txt loss 0.443\n",
      "val img loss: 0.202 val txt_loss: 0.241 img + txt loss 0.443\n",
      "train img loss: 0.199 txt_loss: 0.239 img + txt loss 0.438\n",
      "val img loss: 0.201 val txt_loss: 0.241 img + txt loss 0.442\n",
      "train img loss: 0.197 txt_loss: 0.239 img + txt loss 0.436\n",
      "val img loss: 0.196 val txt_loss: 0.238 img + txt loss 0.434\n",
      "train img loss: 0.195 txt_loss: 0.237 img + txt loss 0.432\n",
      "val img loss: 0.194 val txt_loss: 0.238 img + txt loss 0.432\n",
      "train img loss: 0.194 txt_loss: 0.237 img + txt loss 0.430\n",
      "val img loss: 0.193 val txt_loss: 0.237 img + txt loss 0.430\n",
      "train img loss: 0.192 txt_loss: 0.236 img + txt loss 0.428\n",
      "val img loss: 0.192 val txt_loss: 0.236 img + txt loss 0.428\n",
      "train img loss: 0.190 txt_loss: 0.235 img + txt loss 0.425\n",
      "val img loss: 0.189 val txt_loss: 0.236 img + txt loss 0.426\n",
      "train img loss: 0.189 txt_loss: 0.235 img + txt loss 0.424\n",
      "val img loss: 0.190 val txt_loss: 0.235 img + txt loss 0.425\n",
      "train img loss: 0.187 txt_loss: 0.234 img + txt loss 0.421\n",
      "val img loss: 0.192 val txt_loss: 0.236 img + txt loss 0.428\n",
      "train img loss: 0.186 txt_loss: 0.233 img + txt loss 0.419\n",
      "val img loss: 0.185 val txt_loss: 0.234 img + txt loss 0.420\n",
      "train img loss: 0.184 txt_loss: 0.233 img + txt loss 0.418\n",
      "val img loss: 0.184 val txt_loss: 0.233 img + txt loss 0.418\n",
      "train img loss: 0.184 txt_loss: 0.232 img + txt loss 0.416\n",
      "val img loss: 0.185 val txt_loss: 0.233 img + txt loss 0.418\n",
      "train img loss: 0.183 txt_loss: 0.233 img + txt loss 0.416\n",
      "val img loss: 0.183 val txt_loss: 0.233 img + txt loss 0.416\n",
      "train img loss: 0.183 txt_loss: 0.232 img + txt loss 0.415\n",
      "val img loss: 0.185 val txt_loss: 0.232 img + txt loss 0.417\n",
      "train img loss: 0.181 txt_loss: 0.232 img + txt loss 0.413\n",
      "val img loss: 0.182 val txt_loss: 0.234 img + txt loss 0.416\n",
      "train img loss: 0.180 txt_loss: 0.231 img + txt loss 0.412\n",
      "val img loss: 0.182 val txt_loss: 0.232 img + txt loss 0.414\n",
      "train img loss: 0.180 txt_loss: 0.231 img + txt loss 0.411\n",
      "val img loss: 0.180 val txt_loss: 0.232 img + txt loss 0.412\n",
      "train img loss: 0.179 txt_loss: 0.231 img + txt loss 0.411\n",
      "val img loss: 0.180 val txt_loss: 0.231 img + txt loss 0.411\n",
      "train img loss: 0.179 txt_loss: 0.231 img + txt loss 0.410\n",
      "val img loss: 0.179 val txt_loss: 0.231 img + txt loss 0.410\n",
      "train img loss: 0.179 txt_loss: 0.230 img + txt loss 0.409\n",
      "val img loss: 0.179 val txt_loss: 0.231 img + txt loss 0.411\n",
      "train img loss: 0.178 txt_loss: 0.230 img + txt loss 0.408\n",
      "val img loss: 0.180 val txt_loss: 0.231 img + txt loss 0.411\n",
      "train img loss: 0.178 txt_loss: 0.230 img + txt loss 0.408\n",
      "val img loss: 0.178 val txt_loss: 0.231 img + txt loss 0.408\n",
      "train img loss: 0.177 txt_loss: 0.230 img + txt loss 0.407\n",
      "val img loss: 0.178 val txt_loss: 0.232 img + txt loss 0.410\n",
      "train img loss: 0.177 txt_loss: 0.230 img + txt loss 0.407\n",
      "val img loss: 0.178 val txt_loss: 0.231 img + txt loss 0.409\n",
      "train img loss: 0.177 txt_loss: 0.229 img + txt loss 0.406\n",
      "val img loss: 0.176 val txt_loss: 0.230 img + txt loss 0.407\n",
      "train img loss: 0.176 txt_loss: 0.230 img + txt loss 0.406\n",
      "val img loss: 0.179 val txt_loss: 0.231 img + txt loss 0.409\n",
      "train img loss: 0.176 txt_loss: 0.229 img + txt loss 0.405\n",
      "val img loss: 0.177 val txt_loss: 0.231 img + txt loss 0.408\n",
      "train img loss: 0.176 txt_loss: 0.229 img + txt loss 0.406\n",
      "val img loss: 0.177 val txt_loss: 0.230 img + txt loss 0.407\n",
      "train img loss: 0.175 txt_loss: 0.229 img + txt loss 0.404\n",
      "val img loss: 0.175 val txt_loss: 0.230 img + txt loss 0.406\n",
      "train img loss: 0.175 txt_loss: 0.229 img + txt loss 0.404\n",
      "val img loss: 0.175 val txt_loss: 0.231 img + txt loss 0.406\n",
      "finished for 655.0612728595734 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_relu_128 = AutoencoderRelu(d=128)\n",
    "optimizer_relu_128 = torch.optim.Adam(autoencoder_relu_128.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_relu_128, optimizer_relu_128, 50, [x_img_train, x_txt_train], [x_img_val, x_txt_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8111, grad_fn=<NllLossBackward>) average train loss tensor(3.8890, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.051979396615158206 val_avg_loss: tensor(3.7849)\n",
      "epoch: 1 train_loss: tensor(3.6866, grad_fn=<NllLossBackward>) average train loss tensor(3.7291, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.08264900662251656 val_avg_loss: tensor(3.6674)\n",
      "epoch: 2 train_loss: tensor(3.5885, grad_fn=<NllLossBackward>) average train loss tensor(3.6417, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.12868285504047094 val_avg_loss: tensor(3.5684)\n",
      "epoch: 3 train_loss: tensor(3.4793, grad_fn=<NllLossBackward>) average train loss tensor(3.5419, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.18908020603384842 val_avg_loss: tensor(3.4693)\n",
      "epoch: 4 train_loss: tensor(3.3642, grad_fn=<NllLossBackward>) average train loss tensor(3.4289, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20753495217071377 val_avg_loss: tensor(3.3417)\n",
      "epoch: 5 train_loss: tensor(3.2833, grad_fn=<NllLossBackward>) average train loss tensor(3.3199, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.24317880794701988 val_avg_loss: tensor(3.1988)\n",
      "epoch: 6 train_loss: tensor(3.1732, grad_fn=<NllLossBackward>) average train loss tensor(3.2011, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2621927888153054 val_avg_loss: tensor(3.0671)\n",
      "epoch: 7 train_loss: tensor(2.9876, grad_fn=<NllLossBackward>) average train loss tensor(3.0488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2808830022075055 val_avg_loss: tensor(2.9330)\n",
      "epoch: 8 train_loss: tensor(2.8365, grad_fn=<NllLossBackward>) average train loss tensor(2.8971, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3110522442972774 val_avg_loss: tensor(2.7941)\n",
      "epoch: 9 train_loss: tensor(2.6376, grad_fn=<NllLossBackward>) average train loss tensor(2.7763, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3351582045621781 val_avg_loss: tensor(2.6692)\n",
      "epoch: 10 train_loss: tensor(2.5526, grad_fn=<NllLossBackward>) average train loss tensor(2.6472, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3551140544518028 val_avg_loss: tensor(2.5619)\n",
      "epoch: 11 train_loss: tensor(2.3659, grad_fn=<NllLossBackward>) average train loss tensor(2.4897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.37065489330389995 val_avg_loss: tensor(2.4706)\n",
      "epoch: 12 train_loss: tensor(2.2937, grad_fn=<NllLossBackward>) average train loss tensor(2.3911, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38743193524650477 val_avg_loss: tensor(2.3811)\n",
      "epoch: 13 train_loss: tensor(2.2501, grad_fn=<NllLossBackward>) average train loss tensor(2.3359, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4001177336276674 val_avg_loss: tensor(2.3234)\n",
      "epoch: 14 train_loss: tensor(2.1260, grad_fn=<NllLossBackward>) average train loss tensor(2.1924, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4095364238410596 val_avg_loss: tensor(2.2659)\n",
      "epoch: 15 train_loss: tensor(2.0751, grad_fn=<NllLossBackward>) average train loss tensor(2.1204, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4186313465783664 val_avg_loss: tensor(2.2240)\n",
      "epoch: 16 train_loss: tensor(1.9217, grad_fn=<NllLossBackward>) average train loss tensor(2.0242, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4295217071376012 val_avg_loss: tensor(2.1919)\n",
      "epoch: 17 train_loss: tensor(1.8303, grad_fn=<NllLossBackward>) average train loss tensor(1.9238, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4396173657100809 val_avg_loss: tensor(2.1541)\n",
      "epoch: 18 train_loss: tensor(1.7565, grad_fn=<NllLossBackward>) average train loss tensor(1.8452, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430610743193525 val_avg_loss: tensor(2.1395)\n",
      "epoch: 19 train_loss: tensor(1.6856, grad_fn=<NllLossBackward>) average train loss tensor(1.7947, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4482119205298013 val_avg_loss: tensor(2.1280)\n",
      "epoch: 20 train_loss: tensor(1.5277, grad_fn=<NllLossBackward>) average train loss tensor(1.7075, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4517144959529065 val_avg_loss: tensor(2.1079)\n",
      "epoch: 21 train_loss: tensor(1.5764, grad_fn=<NllLossBackward>) average train loss tensor(1.6339, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45695364238410596 val_avg_loss: tensor(2.1090)\n",
      "epoch: 22 train_loss: tensor(1.4255, grad_fn=<NllLossBackward>) average train loss tensor(1.5608, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4596909492273731 val_avg_loss: tensor(2.1095)\n",
      "epoch: 23 train_loss: tensor(1.3697, grad_fn=<NllLossBackward>) average train loss tensor(1.4768, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4667255334805004 val_avg_loss: tensor(2.1085)\n",
      "epoch: 24 train_loss: tensor(1.2586, grad_fn=<NllLossBackward>) average train loss tensor(1.4354, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46984547461368653 val_avg_loss: tensor(2.1088)\n",
      "epoch: 25 train_loss: tensor(1.3155, grad_fn=<NllLossBackward>) average train loss tensor(1.3670, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4667255334805004 val_avg_loss: tensor(2.1389)\n",
      "epoch: 26 train_loss: tensor(1.1944, grad_fn=<NllLossBackward>) average train loss tensor(1.3235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4683443708609272 val_avg_loss: tensor(2.1561)\n",
      "epoch: 27 train_loss: tensor(1.1914, grad_fn=<NllLossBackward>) average train loss tensor(1.2722, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46719646799117 val_avg_loss: tensor(2.1605)\n",
      "epoch: 28 train_loss: tensor(1.1198, grad_fn=<NllLossBackward>) average train loss tensor(1.2142, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4674319352465048 val_avg_loss: tensor(2.1784)\n",
      "epoch: 29 train_loss: tensor(1.0575, grad_fn=<NllLossBackward>) average train loss tensor(1.1901, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46637233259749816 val_avg_loss: tensor(2.2099)\n",
      "epoch: 30 train_loss: tensor(1.0313, grad_fn=<NllLossBackward>) average train loss tensor(1.1235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4690802060338484 val_avg_loss: tensor(2.2278)\n",
      "epoch: 31 train_loss: tensor(0.9156, grad_fn=<NllLossBackward>) average train loss tensor(1.0370, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46646063281824873 val_avg_loss: tensor(2.2731)\n",
      "epoch: 32 train_loss: tensor(0.9478, grad_fn=<NllLossBackward>) average train loss tensor(1.0456, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46760853568800587 val_avg_loss: tensor(2.2973)\n",
      "epoch: 33 train_loss: tensor(0.8718, grad_fn=<NllLossBackward>) average train loss tensor(1.0053, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46881530537159677 val_avg_loss: tensor(2.3322)\n",
      "epoch: 34 train_loss: tensor(0.8818, grad_fn=<NllLossBackward>) average train loss tensor(0.9709, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4666666666666667 val_avg_loss: tensor(2.3747)\n",
      "epoch: 35 train_loss: tensor(0.7915, grad_fn=<NllLossBackward>) average train loss tensor(0.9064, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46269315673289185 val_avg_loss: tensor(2.3977)\n",
      "epoch: 36 train_loss: tensor(0.7645, grad_fn=<NllLossBackward>) average train loss tensor(0.8673, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46675496688741724 val_avg_loss: tensor(2.4316)\n",
      "epoch: 37 train_loss: tensor(0.8333, grad_fn=<NllLossBackward>) average train loss tensor(0.8532, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46537159676232526 val_avg_loss: tensor(2.4969)\n",
      "epoch: 38 train_loss: tensor(0.7162, grad_fn=<NllLossBackward>) average train loss tensor(0.8147, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46398822663723327 val_avg_loss: tensor(2.5187)\n",
      "epoch: 39 train_loss: tensor(0.6954, grad_fn=<NllLossBackward>) average train loss tensor(0.7906, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4661074319352465 val_avg_loss: tensor(2.5177)\n",
      "epoch: 40 train_loss: tensor(0.6297, grad_fn=<NllLossBackward>) average train loss tensor(0.7262, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4607505518763797 val_avg_loss: tensor(2.5973)\n",
      "epoch: 41 train_loss: tensor(0.6541, grad_fn=<NllLossBackward>) average train loss tensor(0.7308, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4614569536423841 val_avg_loss: tensor(2.6237)\n",
      "epoch: 42 train_loss: tensor(0.5904, grad_fn=<NllLossBackward>) average train loss tensor(0.6738, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4592200147167035 val_avg_loss: tensor(2.6821)\n",
      "epoch: 43 train_loss: tensor(0.5507, grad_fn=<NllLossBackward>) average train loss tensor(0.6657, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46042678440029433 val_avg_loss: tensor(2.7133)\n",
      "epoch: 44 train_loss: tensor(0.6033, grad_fn=<NllLossBackward>) average train loss tensor(0.6488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45986754966887416 val_avg_loss: tensor(2.7425)\n",
      "epoch: 45 train_loss: tensor(0.4832, grad_fn=<NllLossBackward>) average train loss tensor(0.5873, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4594260485651214 val_avg_loss: tensor(2.8031)\n",
      "epoch: 46 train_loss: tensor(0.5645, grad_fn=<NllLossBackward>) average train loss tensor(0.5865, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4580132450331126 val_avg_loss: tensor(2.8287)\n",
      "epoch: 47 train_loss: tensor(0.5273, grad_fn=<NllLossBackward>) average train loss tensor(0.5625, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4603090507726269 val_avg_loss: tensor(2.8947)\n",
      "epoch: 48 train_loss: tensor(0.4474, grad_fn=<NllLossBackward>) average train loss tensor(0.5210, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45863134657836646 val_avg_loss: tensor(2.9432)\n",
      "epoch: 49 train_loss: tensor(0.4732, grad_fn=<NllLossBackward>) average train loss tensor(0.5406, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45810154525386315 val_avg_loss: tensor(2.9674)\n",
      "epoch: 50 train_loss: tensor(0.4247, grad_fn=<NllLossBackward>) average train loss tensor(0.4920, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4596615158204562 val_avg_loss: tensor(2.9767)\n",
      "epoch: 51 train_loss: tensor(0.4152, grad_fn=<NllLossBackward>) average train loss tensor(0.5003, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4588373804267844 val_avg_loss: tensor(2.9907)\n",
      "epoch: 52 train_loss: tensor(0.4292, grad_fn=<NllLossBackward>) average train loss tensor(0.4488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45336276674025017 val_avg_loss: tensor(3.0593)\n",
      "epoch: 53 train_loss: tensor(0.3811, grad_fn=<NllLossBackward>) average train loss tensor(0.4200, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45565857247976455 val_avg_loss: tensor(3.1194)\n",
      "epoch: 54 train_loss: tensor(0.3553, grad_fn=<NllLossBackward>) average train loss tensor(0.4249, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4529506990434143 val_avg_loss: tensor(3.1845)\n",
      "epoch: 55 train_loss: tensor(0.3376, grad_fn=<NllLossBackward>) average train loss tensor(0.4261, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45392200147167033 val_avg_loss: tensor(3.2269)\n",
      "epoch: 56 train_loss: tensor(0.3434, grad_fn=<NllLossBackward>) average train loss tensor(0.4001, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4519499632082414 val_avg_loss: tensor(3.2923)\n",
      "epoch: 57 train_loss: tensor(0.3263, grad_fn=<NllLossBackward>) average train loss tensor(0.3655, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4501250919793966 val_avg_loss: tensor(3.3157)\n",
      "epoch: 58 train_loss: tensor(0.3584, grad_fn=<NllLossBackward>) average train loss tensor(0.3943, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45236203090507726 val_avg_loss: tensor(3.2995)\n",
      "epoch: 59 train_loss: tensor(0.3085, grad_fn=<NllLossBackward>) average train loss tensor(0.3453, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45236203090507726 val_avg_loss: tensor(3.3451)\n",
      "epoch: 60 train_loss: tensor(0.3511, grad_fn=<NllLossBackward>) average train loss tensor(0.3408, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4519205298013245 val_avg_loss: tensor(3.3817)\n",
      "epoch: 61 train_loss: tensor(0.2597, grad_fn=<NllLossBackward>) average train loss tensor(0.3292, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503605592347314 val_avg_loss: tensor(3.4794)\n",
      "epoch: 62 train_loss: tensor(0.2924, grad_fn=<NllLossBackward>) average train loss tensor(0.3484, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45021339220014717 val_avg_loss: tensor(3.5653)\n",
      "epoch: 63 train_loss: tensor(0.2784, grad_fn=<NllLossBackward>) average train loss tensor(0.3077, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45221486387049303 val_avg_loss: tensor(3.5454)\n",
      "epoch: 64 train_loss: tensor(0.2305, grad_fn=<NllLossBackward>) average train loss tensor(0.3204, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45345106696100074 val_avg_loss: tensor(3.5313)\n",
      "epoch: 65 train_loss: tensor(0.2587, grad_fn=<NllLossBackward>) average train loss tensor(0.3023, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45100809418690213 val_avg_loss: tensor(3.6129)\n",
      "epoch: 66 train_loss: tensor(0.2457, grad_fn=<NllLossBackward>) average train loss tensor(0.3016, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4508609271523179 val_avg_loss: tensor(3.6254)\n",
      "epoch: 67 train_loss: tensor(0.2681, grad_fn=<NllLossBackward>) average train loss tensor(0.2858, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4495952906548933 val_avg_loss: tensor(3.6766)\n",
      "epoch: 68 train_loss: tensor(0.2714, grad_fn=<NllLossBackward>) average train loss tensor(0.2962, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44830022075055187 val_avg_loss: tensor(3.7620)\n",
      "epoch: 69 train_loss: tensor(0.2210, grad_fn=<NllLossBackward>) average train loss tensor(0.2367, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44938925680647535 val_avg_loss: tensor(3.7696)\n",
      "epoch: 70 train_loss: tensor(0.2398, grad_fn=<NllLossBackward>) average train loss tensor(0.2492, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4509492273730684 val_avg_loss: tensor(3.7943)\n",
      "epoch: 71 train_loss: tensor(0.2390, grad_fn=<NllLossBackward>) average train loss tensor(0.2609, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44986019131714494 val_avg_loss: tensor(3.8383)\n",
      "epoch: 72 train_loss: tensor(0.2309, grad_fn=<NllLossBackward>) average train loss tensor(0.2301, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44538631346578367 val_avg_loss: tensor(3.9050)\n",
      "epoch: 73 train_loss: tensor(0.2366, grad_fn=<NllLossBackward>) average train loss tensor(0.2484, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4485945548197204 val_avg_loss: tensor(3.8934)\n",
      "epoch: 74 train_loss: tensor(0.2097, grad_fn=<NllLossBackward>) average train loss tensor(0.2148, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4495952906548933 val_avg_loss: tensor(3.9502)\n",
      "epoch: 75 train_loss: tensor(0.1862, grad_fn=<NllLossBackward>) average train loss tensor(0.2241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4494186902133922 val_avg_loss: tensor(4.0042)\n",
      "epoch: 76 train_loss: tensor(0.1606, grad_fn=<NllLossBackward>) average train loss tensor(0.1991, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45059602649006625 val_avg_loss: tensor(4.0302)\n",
      "epoch: 77 train_loss: tensor(0.1988, grad_fn=<NllLossBackward>) average train loss tensor(0.2034, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4509492273730684 val_avg_loss: tensor(4.0176)\n",
      "epoch: 78 train_loss: tensor(0.1926, grad_fn=<NllLossBackward>) average train loss tensor(0.2077, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4493009565857248 val_avg_loss: tensor(4.0151)\n",
      "epoch: 79 train_loss: tensor(0.1967, grad_fn=<NllLossBackward>) average train loss tensor(0.2052, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44641648270787343 val_avg_loss: tensor(3.9969)\n",
      "epoch: 80 train_loss: tensor(0.1589, grad_fn=<NllLossBackward>) average train loss tensor(0.2046, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4448859455481972 val_avg_loss: tensor(3.9864)\n",
      "epoch: 81 train_loss: tensor(0.1731, grad_fn=<NllLossBackward>) average train loss tensor(0.1833, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.441383370125092 val_avg_loss: tensor(4.0562)\n",
      "epoch: 82 train_loss: tensor(0.1743, grad_fn=<NllLossBackward>) average train loss tensor(0.1824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44632818248712286 val_avg_loss: tensor(4.0629)\n",
      "epoch: 83 train_loss: tensor(0.1487, grad_fn=<NllLossBackward>) average train loss tensor(0.1751, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4461515820456218 val_avg_loss: tensor(4.1787)\n",
      "epoch: 84 train_loss: tensor(0.1650, grad_fn=<NllLossBackward>) average train loss tensor(0.1673, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4467402501839588 val_avg_loss: tensor(4.2875)\n",
      "epoch: 85 train_loss: tensor(0.1598, grad_fn=<NllLossBackward>) average train loss tensor(0.1670, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4452391464311994 val_avg_loss: tensor(4.3387)\n",
      "epoch: 86 train_loss: tensor(0.1709, grad_fn=<NllLossBackward>) average train loss tensor(0.1671, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4436791758646063 val_avg_loss: tensor(4.3617)\n",
      "epoch: 87 train_loss: tensor(0.1353, grad_fn=<NllLossBackward>) average train loss tensor(0.1718, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44347314201618837 val_avg_loss: tensor(4.3683)\n",
      "epoch: 88 train_loss: tensor(0.1518, grad_fn=<NllLossBackward>) average train loss tensor(0.1760, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4483590875643856 val_avg_loss: tensor(4.3793)\n",
      "epoch: 89 train_loss: tensor(0.1394, grad_fn=<NllLossBackward>) average train loss tensor(0.1602, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44497424576894773 val_avg_loss: tensor(4.3565)\n",
      "epoch: 90 train_loss: tensor(0.1348, grad_fn=<NllLossBackward>) average train loss tensor(0.1612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44362030905077265 val_avg_loss: tensor(4.3307)\n",
      "epoch: 91 train_loss: tensor(0.1024, grad_fn=<NllLossBackward>) average train loss tensor(0.1319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44594554819720383 val_avg_loss: tensor(4.3440)\n",
      "epoch: 92 train_loss: tensor(0.1741, grad_fn=<NllLossBackward>) average train loss tensor(0.1579, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.44618101545253863 val_avg_loss: tensor(4.4217)\n",
      "epoch: 93 train_loss: tensor(0.1161, grad_fn=<NllLossBackward>) average train loss tensor(0.1410, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4437674760853569 val_avg_loss: tensor(4.4616)\n",
      "epoch: 94 train_loss: tensor(0.1345, grad_fn=<NllLossBackward>) average train loss tensor(0.1331, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44311994113318615 val_avg_loss: tensor(4.4856)\n",
      "epoch: 95 train_loss: tensor(0.0832, grad_fn=<NllLossBackward>) average train loss tensor(0.1215, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4447682119205298 val_avg_loss: tensor(4.5071)\n",
      "epoch: 96 train_loss: tensor(0.1180, grad_fn=<NllLossBackward>) average train loss tensor(0.1329, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.447093451066961 val_avg_loss: tensor(4.5562)\n",
      "epoch: 97 train_loss: tensor(0.1356, grad_fn=<NllLossBackward>) average train loss tensor(0.1412, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4472111846946284 val_avg_loss: tensor(4.6275)\n",
      "epoch: 98 train_loss: tensor(0.1209, grad_fn=<NllLossBackward>) average train loss tensor(0.1369, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44497424576894773 val_avg_loss: tensor(4.6660)\n",
      "epoch: 99 train_loss: tensor(0.1098, grad_fn=<NllLossBackward>) average train loss tensor(0.1194, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4445916114790287 val_avg_loss: tensor(4.7172)\n"
     ]
    }
   ],
   "source": [
    "import pytorch.torch_models as torch_models\n",
    "\n",
    "encoder_relu_128 = autoencoder_relu_128.encoder\n",
    "after_encoder_model_relu_128 = AfterEncoderModel(encoder_relu_128, d=128, drop=0.5)\n",
    "optimizer_aem_relu_128 = torch.optim.Adam(after_encoder_model_relu_128.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_relu_128_bs2048_rs42_d128_drop05_t2000_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_relu_128,\n",
    "    optimizer=optimizer_aem_relu_128,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.624 txt_loss: 0.637 img + txt loss 1.261\n",
      "val img loss: 0.393 val txt_loss: 0.417 img + txt loss 0.810\n",
      "train img loss: 0.308 txt_loss: 0.339 img + txt loss 0.648\n",
      "val img loss: 0.246 val txt_loss: 0.286 img + txt loss 0.532\n",
      "train img loss: 0.215 txt_loss: 0.266 img + txt loss 0.481\n",
      "val img loss: 0.192 val txt_loss: 0.252 img + txt loss 0.444\n",
      "train img loss: 0.181 txt_loss: 0.246 img + txt loss 0.427\n",
      "val img loss: 0.172 val txt_loss: 0.240 img + txt loss 0.412\n",
      "train img loss: 0.168 txt_loss: 0.237 img + txt loss 0.406\n",
      "val img loss: 0.165 val txt_loss: 0.234 img + txt loss 0.400\n",
      "train img loss: 0.164 txt_loss: 0.233 img + txt loss 0.397\n",
      "val img loss: 0.163 val txt_loss: 0.231 img + txt loss 0.394\n",
      "train img loss: 0.163 txt_loss: 0.230 img + txt loss 0.393\n",
      "val img loss: 0.162 val txt_loss: 0.229 img + txt loss 0.391\n",
      "train img loss: 0.162 txt_loss: 0.229 img + txt loss 0.391\n",
      "val img loss: 0.162 val txt_loss: 0.228 img + txt loss 0.390\n",
      "train img loss: 0.162 txt_loss: 0.228 img + txt loss 0.390\n",
      "val img loss: 0.161 val txt_loss: 0.227 img + txt loss 0.389\n",
      "train img loss: 0.162 txt_loss: 0.227 img + txt loss 0.389\n",
      "val img loss: 0.162 val txt_loss: 0.227 img + txt loss 0.388\n",
      "train img loss: 0.162 txt_loss: 0.227 img + txt loss 0.388\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.161 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.162 val txt_loss: 0.225 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.162 val txt_loss: 0.225 img + txt loss 0.387\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.162 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "finished for 650.9201951026917 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_concat_128 = AutoencoderConcat(d=128)\n",
    "optimizer_concat_128 = torch.optim.Adam(autoencoder_concat_128.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_concat_128, optimizer_concat_128, 50, [x_img_train, x_txt_train], [x_img_val, x_txt_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(0.1310, grad_fn=<NllLossBackward>) average train loss tensor(0.1469, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4429139072847682 val_avg_loss: tensor(4.6798)\n",
      "epoch: 1 train_loss: tensor(0.0908, grad_fn=<NllLossBackward>) average train loss tensor(0.1235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4416188373804268 val_avg_loss: tensor(4.6694)\n",
      "epoch: 2 train_loss: tensor(0.1022, grad_fn=<NllLossBackward>) average train loss tensor(0.1271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44235467255334804 val_avg_loss: tensor(4.6251)\n",
      "epoch: 3 train_loss: tensor(0.1136, grad_fn=<NllLossBackward>) average train loss tensor(0.1184, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4440029433406917 val_avg_loss: tensor(4.5841)\n",
      "epoch: 4 train_loss: tensor(0.0880, grad_fn=<NllLossBackward>) average train loss tensor(0.1080, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44332597498160414 val_avg_loss: tensor(4.6219)\n",
      "epoch: 5 train_loss: tensor(0.0769, grad_fn=<NllLossBackward>) average train loss tensor(0.1151, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44326710816777043 val_avg_loss: tensor(4.6832)\n",
      "epoch: 6 train_loss: tensor(0.1375, grad_fn=<NllLossBackward>) average train loss tensor(0.1286, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4403826342899191 val_avg_loss: tensor(4.7348)\n",
      "epoch: 7 train_loss: tensor(0.0994, grad_fn=<NllLossBackward>) average train loss tensor(0.1080, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4426195732155997 val_avg_loss: tensor(4.7999)\n",
      "epoch: 8 train_loss: tensor(0.1219, grad_fn=<NllLossBackward>) average train loss tensor(0.1189, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44335540838852094 val_avg_loss: tensor(4.8545)\n",
      "epoch: 9 train_loss: tensor(0.0856, grad_fn=<NllLossBackward>) average train loss tensor(0.1080, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4391464311994113 val_avg_loss: tensor(4.8236)\n",
      "epoch: 10 train_loss: tensor(0.0602, grad_fn=<NllLossBackward>) average train loss tensor(0.1096, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4398822663723326 val_avg_loss: tensor(4.8055)\n",
      "epoch: 11 train_loss: tensor(0.0716, grad_fn=<NllLossBackward>) average train loss tensor(0.0967, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4428550404709345 val_avg_loss: tensor(4.8791)\n",
      "epoch: 12 train_loss: tensor(0.0773, grad_fn=<NllLossBackward>) average train loss tensor(0.1063, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4432376747608536 val_avg_loss: tensor(4.9152)\n",
      "epoch: 13 train_loss: tensor(0.0871, grad_fn=<NllLossBackward>) average train loss tensor(0.0879, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44182487122884473 val_avg_loss: tensor(4.9905)\n",
      "epoch: 14 train_loss: tensor(0.0689, grad_fn=<NllLossBackward>) average train loss tensor(0.0882, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44150110375275936 val_avg_loss: tensor(5.0541)\n",
      "epoch: 15 train_loss: tensor(0.0982, grad_fn=<NllLossBackward>) average train loss tensor(0.1112, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44438557763061076 val_avg_loss: tensor(5.0815)\n",
      "epoch: 16 train_loss: tensor(0.1007, grad_fn=<NllLossBackward>) average train loss tensor(0.0919, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44897718910963946 val_avg_loss: tensor(5.1002)\n",
      "epoch: 17 train_loss: tensor(0.0745, grad_fn=<NllLossBackward>) average train loss tensor(0.0941, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4471228844738778 val_avg_loss: tensor(5.0772)\n",
      "epoch: 18 train_loss: tensor(0.0918, grad_fn=<NllLossBackward>) average train loss tensor(0.0987, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4462104488594555 val_avg_loss: tensor(5.0600)\n",
      "epoch: 19 train_loss: tensor(0.0710, grad_fn=<NllLossBackward>) average train loss tensor(0.0815, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44641648270787343 val_avg_loss: tensor(5.0425)\n",
      "epoch: 20 train_loss: tensor(0.0874, grad_fn=<NllLossBackward>) average train loss tensor(0.1002, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44491537895511407 val_avg_loss: tensor(5.0861)\n",
      "epoch: 21 train_loss: tensor(0.0747, grad_fn=<NllLossBackward>) average train loss tensor(0.0941, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44456217807211185 val_avg_loss: tensor(5.1255)\n",
      "epoch: 22 train_loss: tensor(0.0747, grad_fn=<NllLossBackward>) average train loss tensor(0.0876, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44432671081677705 val_avg_loss: tensor(5.1360)\n",
      "epoch: 23 train_loss: tensor(0.0586, grad_fn=<NllLossBackward>) average train loss tensor(0.0891, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4435025754231052 val_avg_loss: tensor(5.1484)\n",
      "epoch: 24 train_loss: tensor(0.0876, grad_fn=<NllLossBackward>) average train loss tensor(0.0932, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4442089771891096 val_avg_loss: tensor(5.2111)\n",
      "epoch: 25 train_loss: tensor(0.0798, grad_fn=<NllLossBackward>) average train loss tensor(0.0858, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44415011037527596 val_avg_loss: tensor(5.2460)\n",
      "epoch: 26 train_loss: tensor(0.0695, grad_fn=<NllLossBackward>) average train loss tensor(0.0836, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430610743193525 val_avg_loss: tensor(5.2489)\n",
      "epoch: 27 train_loss: tensor(0.1031, grad_fn=<NllLossBackward>) average train loss tensor(0.0855, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4415305371596762 val_avg_loss: tensor(5.2083)\n",
      "epoch: 28 train_loss: tensor(0.0545, grad_fn=<NllLossBackward>) average train loss tensor(0.0776, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4405298013245033 val_avg_loss: tensor(5.1962)\n",
      "epoch: 29 train_loss: tensor(0.0899, grad_fn=<NllLossBackward>) average train loss tensor(0.0896, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44317880794701986 val_avg_loss: tensor(5.2353)\n",
      "epoch: 30 train_loss: tensor(0.0695, grad_fn=<NllLossBackward>) average train loss tensor(0.0699, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4438852097130243 val_avg_loss: tensor(5.2466)\n",
      "epoch: 31 train_loss: tensor(0.0793, grad_fn=<NllLossBackward>) average train loss tensor(0.0884, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44532744665194995 val_avg_loss: tensor(5.2458)\n",
      "epoch: 32 train_loss: tensor(0.0526, grad_fn=<NllLossBackward>) average train loss tensor(0.0769, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4461515820456218 val_avg_loss: tensor(5.2483)\n",
      "epoch: 33 train_loss: tensor(0.0776, grad_fn=<NllLossBackward>) average train loss tensor(0.0764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4495069904341428 val_avg_loss: tensor(5.3179)\n",
      "epoch: 34 train_loss: tensor(0.0433, grad_fn=<NllLossBackward>) average train loss tensor(0.0679, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.449271523178808 val_avg_loss: tensor(5.3462)\n",
      "epoch: 35 train_loss: tensor(0.0572, grad_fn=<NllLossBackward>) average train loss tensor(0.0705, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4477998528329654 val_avg_loss: tensor(5.3885)\n",
      "epoch: 36 train_loss: tensor(0.0585, grad_fn=<NllLossBackward>) average train loss tensor(0.0717, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44485651214128036 val_avg_loss: tensor(5.4501)\n",
      "epoch: 37 train_loss: tensor(0.0883, grad_fn=<NllLossBackward>) average train loss tensor(0.0773, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4476526857983812 val_avg_loss: tensor(5.3489)\n",
      "epoch: 38 train_loss: tensor(0.0702, grad_fn=<NllLossBackward>) average train loss tensor(0.0816, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4493009565857248 val_avg_loss: tensor(5.3059)\n",
      "epoch: 39 train_loss: tensor(0.0654, grad_fn=<NllLossBackward>) average train loss tensor(0.0792, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4476526857983812 val_avg_loss: tensor(5.3474)\n",
      "epoch: 40 train_loss: tensor(0.0708, grad_fn=<NllLossBackward>) average train loss tensor(0.0742, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4478292862398823 val_avg_loss: tensor(5.3577)\n",
      "epoch: 41 train_loss: tensor(0.0678, grad_fn=<NllLossBackward>) average train loss tensor(0.0678, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4443561442236939 val_avg_loss: tensor(5.3967)\n",
      "epoch: 42 train_loss: tensor(0.0401, grad_fn=<NllLossBackward>) average train loss tensor(0.0737, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4422958057395143 val_avg_loss: tensor(5.4300)\n",
      "epoch: 43 train_loss: tensor(0.0560, grad_fn=<NllLossBackward>) average train loss tensor(0.0763, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4407064017660044 val_avg_loss: tensor(5.4690)\n",
      "epoch: 44 train_loss: tensor(0.0781, grad_fn=<NllLossBackward>) average train loss tensor(0.0713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4365562913907285 val_avg_loss: tensor(5.5264)\n",
      "epoch: 45 train_loss: tensor(0.0713, grad_fn=<NllLossBackward>) average train loss tensor(0.0807, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43991169977924943 val_avg_loss: tensor(5.5510)\n",
      "epoch: 46 train_loss: tensor(0.0511, grad_fn=<NllLossBackward>) average train loss tensor(0.0656, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.44409124356144225 val_avg_loss: tensor(5.5885)\n",
      "epoch: 47 train_loss: tensor(0.0721, grad_fn=<NllLossBackward>) average train loss tensor(0.0643, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44479764532744664 val_avg_loss: tensor(5.6368)\n",
      "epoch: 48 train_loss: tensor(0.0868, grad_fn=<NllLossBackward>) average train loss tensor(0.0774, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4455923473142016 val_avg_loss: tensor(5.6604)\n",
      "epoch: 49 train_loss: tensor(0.0491, grad_fn=<NllLossBackward>) average train loss tensor(0.0578, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4434437086092715 val_avg_loss: tensor(5.6674)\n",
      "epoch: 50 train_loss: tensor(0.0675, grad_fn=<NllLossBackward>) average train loss tensor(0.0749, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4411479028697572 val_avg_loss: tensor(5.6427)\n",
      "epoch: 51 train_loss: tensor(0.0581, grad_fn=<NllLossBackward>) average train loss tensor(0.0733, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44379690949227374 val_avg_loss: tensor(5.5728)\n",
      "epoch: 52 train_loss: tensor(0.0459, grad_fn=<NllLossBackward>) average train loss tensor(0.0562, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4433848417954378 val_avg_loss: tensor(5.6006)\n",
      "epoch: 53 train_loss: tensor(0.0638, grad_fn=<NllLossBackward>) average train loss tensor(0.0649, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4409124356144224 val_avg_loss: tensor(5.6741)\n",
      "epoch: 54 train_loss: tensor(0.0609, grad_fn=<NllLossBackward>) average train loss tensor(0.0717, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44135393671817513 val_avg_loss: tensor(5.7179)\n",
      "epoch: 55 train_loss: tensor(0.0514, grad_fn=<NllLossBackward>) average train loss tensor(0.0598, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4450625459896983 val_avg_loss: tensor(5.7148)\n",
      "epoch: 56 train_loss: tensor(0.0592, grad_fn=<NllLossBackward>) average train loss tensor(0.0687, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4442384105960265 val_avg_loss: tensor(5.6873)\n",
      "epoch: 57 train_loss: tensor(0.0545, grad_fn=<NllLossBackward>) average train loss tensor(0.0701, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4438263428991906 val_avg_loss: tensor(5.6554)\n",
      "epoch: 58 train_loss: tensor(0.0603, grad_fn=<NllLossBackward>) average train loss tensor(0.0642, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4444444444444444 val_avg_loss: tensor(5.6611)\n",
      "epoch: 59 train_loss: tensor(0.0447, grad_fn=<NllLossBackward>) average train loss tensor(0.0529, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44509197939661516 val_avg_loss: tensor(5.6800)\n",
      "epoch: 60 train_loss: tensor(0.0633, grad_fn=<NllLossBackward>) average train loss tensor(0.0586, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44503311258278144 val_avg_loss: tensor(5.6958)\n",
      "epoch: 61 train_loss: tensor(0.0363, grad_fn=<NllLossBackward>) average train loss tensor(0.0506, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4425312729948492 val_avg_loss: tensor(5.7297)\n",
      "epoch: 62 train_loss: tensor(0.0391, grad_fn=<NllLossBackward>) average train loss tensor(0.0614, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4418543046357616 val_avg_loss: tensor(5.7045)\n",
      "epoch: 63 train_loss: tensor(0.0519, grad_fn=<NllLossBackward>) average train loss tensor(0.0527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.440588668138337 val_avg_loss: tensor(5.7309)\n",
      "epoch: 64 train_loss: tensor(0.0542, grad_fn=<NllLossBackward>) average train loss tensor(0.0626, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4424429727740986 val_avg_loss: tensor(5.7310)\n",
      "epoch: 65 train_loss: tensor(0.0480, grad_fn=<NllLossBackward>) average train loss tensor(0.0542, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4457395143487859 val_avg_loss: tensor(5.7581)\n",
      "epoch: 66 train_loss: tensor(0.0408, grad_fn=<NllLossBackward>) average train loss tensor(0.0468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44473877851361293 val_avg_loss: tensor(5.7962)\n",
      "epoch: 67 train_loss: tensor(0.0322, grad_fn=<NllLossBackward>) average train loss tensor(0.0467, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4416777041942605 val_avg_loss: tensor(5.8428)\n",
      "epoch: 68 train_loss: tensor(0.0380, grad_fn=<NllLossBackward>) average train loss tensor(0.0409, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44055923473142017 val_avg_loss: tensor(5.9250)\n",
      "epoch: 69 train_loss: tensor(0.0632, grad_fn=<NllLossBackward>) average train loss tensor(0.0458, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4393230316409124 val_avg_loss: tensor(6.0322)\n",
      "epoch: 70 train_loss: tensor(0.0353, grad_fn=<NllLossBackward>) average train loss tensor(0.0482, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43902869757174395 val_avg_loss: tensor(6.0229)\n",
      "epoch: 71 train_loss: tensor(0.0432, grad_fn=<NllLossBackward>) average train loss tensor(0.0492, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43740986019131717 val_avg_loss: tensor(6.0210)\n",
      "epoch: 72 train_loss: tensor(0.0454, grad_fn=<NllLossBackward>) average train loss tensor(0.0600, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43805739514348785 val_avg_loss: tensor(6.0103)\n",
      "epoch: 73 train_loss: tensor(0.0410, grad_fn=<NllLossBackward>) average train loss tensor(0.0477, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43973509933774835 val_avg_loss: tensor(6.0288)\n",
      "epoch: 74 train_loss: tensor(0.0420, grad_fn=<NllLossBackward>) average train loss tensor(0.0522, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4438852097130243 val_avg_loss: tensor(5.9740)\n",
      "epoch: 75 train_loss: tensor(0.0561, grad_fn=<NllLossBackward>) average train loss tensor(0.0468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44341427520235466 val_avg_loss: tensor(5.9565)\n",
      "epoch: 76 train_loss: tensor(0.0311, grad_fn=<NllLossBackward>) average train loss tensor(0.0607, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430905077262693 val_avg_loss: tensor(5.9778)\n",
      "epoch: 77 train_loss: tensor(0.0455, grad_fn=<NllLossBackward>) average train loss tensor(0.0489, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4415305371596762 val_avg_loss: tensor(5.9814)\n",
      "epoch: 78 train_loss: tensor(0.0436, grad_fn=<NllLossBackward>) average train loss tensor(0.0592, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44117733627667405 val_avg_loss: tensor(5.9810)\n",
      "epoch: 79 train_loss: tensor(0.0775, grad_fn=<NllLossBackward>) average train loss tensor(0.0605, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4381456953642384 val_avg_loss: tensor(5.9866)\n",
      "epoch: 80 train_loss: tensor(0.0565, grad_fn=<NllLossBackward>) average train loss tensor(0.0563, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43584988962472404 val_avg_loss: tensor(6.0637)\n",
      "epoch: 81 train_loss: tensor(0.0546, grad_fn=<NllLossBackward>) average train loss tensor(0.0462, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4371449595290655 val_avg_loss: tensor(6.1483)\n",
      "epoch: 82 train_loss: tensor(0.0472, grad_fn=<NllLossBackward>) average train loss tensor(0.0551, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4421486387049301 val_avg_loss: tensor(6.1378)\n",
      "epoch: 83 train_loss: tensor(0.0526, grad_fn=<NllLossBackward>) average train loss tensor(0.0557, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44217807211184695 val_avg_loss: tensor(6.1883)\n",
      "epoch: 84 train_loss: tensor(0.0926, grad_fn=<NllLossBackward>) average train loss tensor(0.0639, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43864606328182487 val_avg_loss: tensor(6.2525)\n",
      "epoch: 85 train_loss: tensor(0.0586, grad_fn=<NllLossBackward>) average train loss tensor(0.0549, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43567328918322296 val_avg_loss: tensor(6.1988)\n",
      "epoch: 86 train_loss: tensor(0.0672, grad_fn=<NllLossBackward>) average train loss tensor(0.0619, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4369683590875644 val_avg_loss: tensor(6.1077)\n",
      "epoch: 87 train_loss: tensor(0.0403, grad_fn=<NllLossBackward>) average train loss tensor(0.0499, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4384694628403238 val_avg_loss: tensor(6.0650)\n",
      "epoch: 88 train_loss: tensor(0.0590, grad_fn=<NllLossBackward>) average train loss tensor(0.0532, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4415305371596762 val_avg_loss: tensor(6.0636)\n",
      "epoch: 89 train_loss: tensor(0.0307, grad_fn=<NllLossBackward>) average train loss tensor(0.0434, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44150110375275936 val_avg_loss: tensor(6.0658)\n",
      "epoch: 90 train_loss: tensor(0.0397, grad_fn=<NllLossBackward>) average train loss tensor(0.0452, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43926416482707875 val_avg_loss: tensor(5.9890)\n",
      "epoch: 91 train_loss: tensor(0.0384, grad_fn=<NllLossBackward>) average train loss tensor(0.0466, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43911699779249447 val_avg_loss: tensor(5.9298)\n",
      "epoch: 92 train_loss: tensor(0.0417, grad_fn=<NllLossBackward>) average train loss tensor(0.0456, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4392935982339956 val_avg_loss: tensor(5.9056)\n",
      "epoch: 93 train_loss: tensor(0.0328, grad_fn=<NllLossBackward>) average train loss tensor(0.0426, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43858719646799116 val_avg_loss: tensor(5.9308)\n",
      "epoch: 94 train_loss: tensor(0.0430, grad_fn=<NllLossBackward>) average train loss tensor(0.0465, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4422663723325975 val_avg_loss: tensor(5.9655)\n",
      "epoch: 95 train_loss: tensor(0.0209, grad_fn=<NllLossBackward>) average train loss tensor(0.0458, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44432671081677705 val_avg_loss: tensor(6.0432)\n",
      "epoch: 96 train_loss: tensor(0.0513, grad_fn=<NllLossBackward>) average train loss tensor(0.0435, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44282560706401763 val_avg_loss: tensor(6.1172)\n",
      "epoch: 97 train_loss: tensor(0.0308, grad_fn=<NllLossBackward>) average train loss tensor(0.0465, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4394701986754967 val_avg_loss: tensor(6.1783)\n",
      "epoch: 98 train_loss: tensor(0.0230, grad_fn=<NllLossBackward>) average train loss tensor(0.0423, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43958793230316406 val_avg_loss: tensor(6.2550)\n",
      "epoch: 99 train_loss: tensor(0.0390, grad_fn=<NllLossBackward>) average train loss tensor(0.0488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4396467991169978 val_avg_loss: tensor(6.3498)\n"
     ]
    }
   ],
   "source": [
    "encoder_concat_128 = autoencoder_concat_128.encoder\n",
    "after_encoder_model_concat_128 = AfterEncoderModel(encoder_concat_128, d=128, drop=0.5)\n",
    "optimizer_aem_concat_128 = torch.optim.Adam(after_encoder_model_concat_128.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_concat_128_bs2048_rs42_d128_drop05_t2000_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_relu_128,\n",
    "    optimizer=optimizer_aem_relu_128,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.691 txt_loss: 0.718 img + txt loss 1.408\n",
      "val img loss: 0.491 val txt_loss: 0.536 img + txt loss 1.027\n",
      "train img loss: 0.405 txt_loss: 0.463 img + txt loss 0.868\n",
      "val img loss: 0.338 val txt_loss: 0.407 img + txt loss 0.745\n",
      "train img loss: 0.300 txt_loss: 0.377 img + txt loss 0.677\n",
      "val img loss: 0.271 val txt_loss: 0.353 img + txt loss 0.624\n",
      "train img loss: 0.253 txt_loss: 0.338 img + txt loss 0.591\n",
      "val img loss: 0.239 val txt_loss: 0.326 img + txt loss 0.565\n",
      "train img loss: 0.228 txt_loss: 0.317 img + txt loss 0.545\n",
      "val img loss: 0.220 val txt_loss: 0.309 img + txt loss 0.530\n",
      "train img loss: 0.214 txt_loss: 0.302 img + txt loss 0.516\n",
      "val img loss: 0.208 val txt_loss: 0.296 img + txt loss 0.504\n",
      "train img loss: 0.203 txt_loss: 0.290 img + txt loss 0.493\n",
      "val img loss: 0.199 val txt_loss: 0.285 img + txt loss 0.484\n",
      "train img loss: 0.195 txt_loss: 0.279 img + txt loss 0.474\n",
      "val img loss: 0.192 val txt_loss: 0.275 img + txt loss 0.467\n",
      "train img loss: 0.189 txt_loss: 0.270 img + txt loss 0.458\n",
      "val img loss: 0.187 val txt_loss: 0.266 img + txt loss 0.453\n",
      "train img loss: 0.184 txt_loss: 0.261 img + txt loss 0.445\n",
      "val img loss: 0.183 val txt_loss: 0.257 img + txt loss 0.440\n",
      "train img loss: 0.180 txt_loss: 0.252 img + txt loss 0.433\n",
      "val img loss: 0.180 val txt_loss: 0.250 img + txt loss 0.429\n",
      "train img loss: 0.178 txt_loss: 0.246 img + txt loss 0.424\n",
      "val img loss: 0.177 val txt_loss: 0.245 img + txt loss 0.422\n",
      "train img loss: 0.176 txt_loss: 0.242 img + txt loss 0.417\n",
      "val img loss: 0.175 val txt_loss: 0.241 img + txt loss 0.416\n",
      "train img loss: 0.174 txt_loss: 0.239 img + txt loss 0.412\n",
      "val img loss: 0.174 val txt_loss: 0.238 img + txt loss 0.412\n",
      "train img loss: 0.172 txt_loss: 0.236 img + txt loss 0.409\n",
      "val img loss: 0.172 val txt_loss: 0.236 img + txt loss 0.408\n",
      "train img loss: 0.171 txt_loss: 0.235 img + txt loss 0.406\n",
      "val img loss: 0.171 val txt_loss: 0.235 img + txt loss 0.406\n",
      "train img loss: 0.170 txt_loss: 0.233 img + txt loss 0.403\n",
      "val img loss: 0.170 val txt_loss: 0.233 img + txt loss 0.404\n",
      "train img loss: 0.169 txt_loss: 0.232 img + txt loss 0.401\n",
      "val img loss: 0.169 val txt_loss: 0.232 img + txt loss 0.402\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.400\n",
      "val img loss: 0.169 val txt_loss: 0.232 img + txt loss 0.400\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.398\n",
      "val img loss: 0.168 val txt_loss: 0.231 img + txt loss 0.399\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.167 val txt_loss: 0.231 img + txt loss 0.398\n",
      "train img loss: 0.167 txt_loss: 0.229 img + txt loss 0.396\n",
      "val img loss: 0.168 val txt_loss: 0.230 img + txt loss 0.398\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.396\n",
      "val img loss: 0.167 val txt_loss: 0.230 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.166 val txt_loss: 0.228 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.166 val txt_loss: 0.228 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "finished for 399.69438314437866 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_128_3 = Autoencoder(d=128)\n",
    "optimizer_128_3 = torch.optim.Adam(autoencoder_128_3.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_128_3, optimizer_128_3, 30, [x_img_train, x_txt_train], [x_img_val, x_txt_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.9509, grad_fn=<NllLossBackward>) average train loss tensor(3.9509, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.036467991169977926 val_avg_loss: tensor(3.8701)\n",
      "epoch: 1 train_loss: tensor(3.8789, grad_fn=<NllLossBackward>) average train loss tensor(3.8789, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.05598233995584989 val_avg_loss: tensor(3.8264)\n",
      "epoch: 2 train_loss: tensor(3.8290, grad_fn=<NllLossBackward>) average train loss tensor(3.8290, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.05757174392935983 val_avg_loss: tensor(3.7869)\n",
      "epoch: 3 train_loss: tensor(3.7779, grad_fn=<NllLossBackward>) average train loss tensor(3.7779, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.06322295805739514 val_avg_loss: tensor(3.7439)\n",
      "epoch: 4 train_loss: tensor(3.7325, grad_fn=<NllLossBackward>) average train loss tensor(3.7325, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07620309050772626 val_avg_loss: tensor(3.6986)\n",
      "epoch: 5 train_loss: tensor(3.6882, grad_fn=<NllLossBackward>) average train loss tensor(3.6882, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.09365710080941869 val_avg_loss: tensor(3.6532)\n",
      "epoch: 6 train_loss: tensor(3.6441, grad_fn=<NllLossBackward>) average train loss tensor(3.6441, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.10699043414275203 val_avg_loss: tensor(3.6088)\n",
      "epoch: 7 train_loss: tensor(3.5998, grad_fn=<NllLossBackward>) average train loss tensor(3.5998, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.12373804267844003 val_avg_loss: tensor(3.5654)\n",
      "epoch: 8 train_loss: tensor(3.5736, grad_fn=<NllLossBackward>) average train loss tensor(3.5736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1406328182487123 val_avg_loss: tensor(3.5227)\n",
      "epoch: 9 train_loss: tensor(3.5360, grad_fn=<NllLossBackward>) average train loss tensor(3.5360, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.15917586460632818 val_avg_loss: tensor(3.4803)\n",
      "epoch: 10 train_loss: tensor(3.4995, grad_fn=<NllLossBackward>) average train loss tensor(3.4995, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1798381162619573 val_avg_loss: tensor(3.4374)\n",
      "epoch: 11 train_loss: tensor(3.4800, grad_fn=<NllLossBackward>) average train loss tensor(3.4800, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2020309050772627 val_avg_loss: tensor(3.3941)\n",
      "epoch: 12 train_loss: tensor(3.3988, grad_fn=<NllLossBackward>) average train loss tensor(3.3988, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22183958793230316 val_avg_loss: tensor(3.3493)\n",
      "epoch: 13 train_loss: tensor(3.3769, grad_fn=<NllLossBackward>) average train loss tensor(3.3769, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.23855776306107432 val_avg_loss: tensor(3.3017)\n",
      "epoch: 14 train_loss: tensor(3.3268, grad_fn=<NllLossBackward>) average train loss tensor(3.3268, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2489477557027226 val_avg_loss: tensor(3.2512)\n",
      "epoch: 15 train_loss: tensor(3.2676, grad_fn=<NllLossBackward>) average train loss tensor(3.2676, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.26095658572479763 val_avg_loss: tensor(3.1973)\n",
      "epoch: 16 train_loss: tensor(3.2298, grad_fn=<NllLossBackward>) average train loss tensor(3.2298, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2721412803532009 val_avg_loss: tensor(3.1405)\n",
      "epoch: 17 train_loss: tensor(3.1818, grad_fn=<NllLossBackward>) average train loss tensor(3.1818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2826490066225166 val_avg_loss: tensor(3.0823)\n",
      "epoch: 18 train_loss: tensor(3.1078, grad_fn=<NllLossBackward>) average train loss tensor(3.1078, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.29233259749816043 val_avg_loss: tensor(3.0228)\n",
      "epoch: 19 train_loss: tensor(3.0863, grad_fn=<NllLossBackward>) average train loss tensor(3.0863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3007799852832965 val_avg_loss: tensor(2.9632)\n",
      "epoch: 20 train_loss: tensor(3.0441, grad_fn=<NllLossBackward>) average train loss tensor(3.0441, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.30846210448859457 val_avg_loss: tensor(2.9045)\n",
      "epoch: 21 train_loss: tensor(2.9593, grad_fn=<NllLossBackward>) average train loss tensor(2.9593, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3156438557763061 val_avg_loss: tensor(2.8468)\n",
      "epoch: 22 train_loss: tensor(2.8924, grad_fn=<NllLossBackward>) average train loss tensor(2.8924, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3225312729948491 val_avg_loss: tensor(2.7906)\n",
      "epoch: 23 train_loss: tensor(2.8544, grad_fn=<NllLossBackward>) average train loss tensor(2.8544, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3307431935246505 val_avg_loss: tensor(2.7355)\n",
      "epoch: 24 train_loss: tensor(2.8089, grad_fn=<NllLossBackward>) average train loss tensor(2.8089, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.34166298749080204 val_avg_loss: tensor(2.6830)\n",
      "epoch: 25 train_loss: tensor(2.7905, grad_fn=<NllLossBackward>) average train loss tensor(2.7905, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3510228108903606 val_avg_loss: tensor(2.6334)\n",
      "epoch: 26 train_loss: tensor(2.6978, grad_fn=<NllLossBackward>) average train loss tensor(2.6978, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.35991169977924947 val_avg_loss: tensor(2.5860)\n",
      "epoch: 27 train_loss: tensor(2.6708, grad_fn=<NllLossBackward>) average train loss tensor(2.6708, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3673877851361295 val_avg_loss: tensor(2.5406)\n",
      "epoch: 28 train_loss: tensor(2.6011, grad_fn=<NllLossBackward>) average train loss tensor(2.6011, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.37495217071376014 val_avg_loss: tensor(2.4980)\n",
      "epoch: 29 train_loss: tensor(2.5686, grad_fn=<NllLossBackward>) average train loss tensor(2.5686, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3823988226637233 val_avg_loss: tensor(2.4582)\n",
      "epoch: 30 train_loss: tensor(2.5381, grad_fn=<NllLossBackward>) average train loss tensor(2.5381, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3878440029433407 val_avg_loss: tensor(2.4225)\n",
      "epoch: 31 train_loss: tensor(2.4704, grad_fn=<NllLossBackward>) average train loss tensor(2.4704, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.39240618101545255 val_avg_loss: tensor(2.3894)\n",
      "epoch: 32 train_loss: tensor(2.4371, grad_fn=<NllLossBackward>) average train loss tensor(2.4371, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3964974245768948 val_avg_loss: tensor(2.3581)\n",
      "epoch: 33 train_loss: tensor(2.3919, grad_fn=<NllLossBackward>) average train loss tensor(2.3919, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40344370860927153 val_avg_loss: tensor(2.3288)\n",
      "epoch: 34 train_loss: tensor(2.3794, grad_fn=<NllLossBackward>) average train loss tensor(2.3794, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40950699043414274 val_avg_loss: tensor(2.3012)\n",
      "epoch: 35 train_loss: tensor(2.3395, grad_fn=<NllLossBackward>) average train loss tensor(2.3395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4154819720382634 val_avg_loss: tensor(2.2760)\n",
      "epoch: 36 train_loss: tensor(2.2701, grad_fn=<NllLossBackward>) average train loss tensor(2.2701, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.41945548197203825 val_avg_loss: tensor(2.2527)\n",
      "epoch: 37 train_loss: tensor(2.2770, grad_fn=<NllLossBackward>) average train loss tensor(2.2770, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42319352465047827 val_avg_loss: tensor(2.2307)\n",
      "epoch: 38 train_loss: tensor(2.1958, grad_fn=<NllLossBackward>) average train loss tensor(2.1958, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4263723325974982 val_avg_loss: tensor(2.2090)\n",
      "epoch: 39 train_loss: tensor(2.1459, grad_fn=<NllLossBackward>) average train loss tensor(2.1459, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43066961000735837 val_avg_loss: tensor(2.1893)\n",
      "epoch: 40 train_loss: tensor(2.2077, grad_fn=<NllLossBackward>) average train loss tensor(2.2077, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4324944812362031 val_avg_loss: tensor(2.1711)\n",
      "epoch: 41 train_loss: tensor(2.0942, grad_fn=<NllLossBackward>) average train loss tensor(2.0942, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43420161883738045 val_avg_loss: tensor(2.1548)\n",
      "epoch: 42 train_loss: tensor(2.1016, grad_fn=<NllLossBackward>) average train loss tensor(2.1016, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43723325974981603 val_avg_loss: tensor(2.1393)\n",
      "epoch: 43 train_loss: tensor(2.0791, grad_fn=<NllLossBackward>) average train loss tensor(2.0791, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4402943340691685 val_avg_loss: tensor(2.1234)\n",
      "epoch: 44 train_loss: tensor(2.0200, grad_fn=<NllLossBackward>) average train loss tensor(2.0200, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44462104488594556 val_avg_loss: tensor(2.1086)\n",
      "epoch: 45 train_loss: tensor(2.0052, grad_fn=<NllLossBackward>) average train loss tensor(2.0052, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.44762325239146433 val_avg_loss: tensor(2.0949)\n",
      "epoch: 46 train_loss: tensor(1.9664, grad_fn=<NllLossBackward>) average train loss tensor(1.9664, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4511846946284032 val_avg_loss: tensor(2.0829)\n",
      "epoch: 47 train_loss: tensor(1.9610, grad_fn=<NllLossBackward>) average train loss tensor(1.9610, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.453392200147167 val_avg_loss: tensor(2.0732)\n",
      "epoch: 48 train_loss: tensor(1.9180, grad_fn=<NllLossBackward>) average train loss tensor(1.9180, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4553936718175129 val_avg_loss: tensor(2.0637)\n",
      "epoch: 49 train_loss: tensor(1.9221, grad_fn=<NllLossBackward>) average train loss tensor(1.9221, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4576894775570272 val_avg_loss: tensor(2.0547)\n",
      "epoch: 50 train_loss: tensor(1.8832, grad_fn=<NllLossBackward>) average train loss tensor(1.8832, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45927888153053714 val_avg_loss: tensor(2.0467)\n",
      "epoch: 51 train_loss: tensor(1.8521, grad_fn=<NllLossBackward>) average train loss tensor(1.8521, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46048565121412804 val_avg_loss: tensor(2.0391)\n",
      "epoch: 52 train_loss: tensor(1.8424, grad_fn=<NllLossBackward>) average train loss tensor(1.8424, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46298749080206036 val_avg_loss: tensor(2.0315)\n",
      "epoch: 53 train_loss: tensor(1.8290, grad_fn=<NllLossBackward>) average train loss tensor(1.8290, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46469462840323766 val_avg_loss: tensor(2.0251)\n",
      "epoch: 54 train_loss: tensor(1.7926, grad_fn=<NllLossBackward>) average train loss tensor(1.7926, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4671081677704194 val_avg_loss: tensor(2.0193)\n",
      "epoch: 55 train_loss: tensor(1.7570, grad_fn=<NllLossBackward>) average train loss tensor(1.7570, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4683149374540103 val_avg_loss: tensor(2.0153)\n",
      "epoch: 56 train_loss: tensor(1.7656, grad_fn=<NllLossBackward>) average train loss tensor(1.7656, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46952170713760116 val_avg_loss: tensor(2.0121)\n",
      "epoch: 57 train_loss: tensor(1.7249, grad_fn=<NllLossBackward>) average train loss tensor(1.7249, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46922737306843265 val_avg_loss: tensor(2.0085)\n",
      "epoch: 58 train_loss: tensor(1.7189, grad_fn=<NllLossBackward>) average train loss tensor(1.7189, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47084621044885944 val_avg_loss: tensor(2.0034)\n",
      "epoch: 59 train_loss: tensor(1.7217, grad_fn=<NllLossBackward>) average train loss tensor(1.7217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4722590139808683 val_avg_loss: tensor(1.9989)\n",
      "epoch: 60 train_loss: tensor(1.6677, grad_fn=<NllLossBackward>) average train loss tensor(1.6677, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47211184694628405 val_avg_loss: tensor(1.9950)\n",
      "epoch: 61 train_loss: tensor(1.6655, grad_fn=<NllLossBackward>) average train loss tensor(1.6655, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47305371596762325 val_avg_loss: tensor(1.9915)\n",
      "epoch: 62 train_loss: tensor(1.6217, grad_fn=<NllLossBackward>) average train loss tensor(1.6217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47381898454746135 val_avg_loss: tensor(1.9889)\n",
      "epoch: 63 train_loss: tensor(1.6085, grad_fn=<NllLossBackward>) average train loss tensor(1.6085, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47602649006622516 val_avg_loss: tensor(1.9864)\n",
      "epoch: 64 train_loss: tensor(1.6090, grad_fn=<NllLossBackward>) average train loss tensor(1.6090, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47640912435614424 val_avg_loss: tensor(1.9841)\n",
      "epoch: 65 train_loss: tensor(1.6079, grad_fn=<NllLossBackward>) average train loss tensor(1.6079, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4789992641648271 val_avg_loss: tensor(1.9807)\n",
      "epoch: 66 train_loss: tensor(1.5814, grad_fn=<NllLossBackward>) average train loss tensor(1.5814, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801177336276674 val_avg_loss: tensor(1.9785)\n",
      "epoch: 67 train_loss: tensor(1.5756, grad_fn=<NllLossBackward>) average train loss tensor(1.5756, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48153053715967625 val_avg_loss: tensor(1.9770)\n",
      "epoch: 68 train_loss: tensor(1.5293, grad_fn=<NllLossBackward>) average train loss tensor(1.5293, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48161883738042677 val_avg_loss: tensor(1.9745)\n",
      "epoch: 69 train_loss: tensor(1.5559, grad_fn=<NllLossBackward>) average train loss tensor(1.5559, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4821192052980132 val_avg_loss: tensor(1.9732)\n",
      "epoch: 70 train_loss: tensor(1.5316, grad_fn=<NllLossBackward>) average train loss tensor(1.5316, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4827961736571008 val_avg_loss: tensor(1.9739)\n",
      "epoch: 71 train_loss: tensor(1.5086, grad_fn=<NllLossBackward>) average train loss tensor(1.5086, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4830316409124356 val_avg_loss: tensor(1.9753)\n",
      "epoch: 72 train_loss: tensor(1.4526, grad_fn=<NllLossBackward>) average train loss tensor(1.4526, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4831199411331862 val_avg_loss: tensor(1.9759)\n",
      "epoch: 73 train_loss: tensor(1.4731, grad_fn=<NllLossBackward>) average train loss tensor(1.4731, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4833259749816041 val_avg_loss: tensor(1.9742)\n",
      "epoch: 74 train_loss: tensor(1.4604, grad_fn=<NllLossBackward>) average train loss tensor(1.4604, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4835614422369389 val_avg_loss: tensor(1.9715)\n",
      "epoch: 75 train_loss: tensor(1.4583, grad_fn=<NllLossBackward>) average train loss tensor(1.4583, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4847093451066961 val_avg_loss: tensor(1.9694)\n",
      "epoch: 76 train_loss: tensor(1.3883, grad_fn=<NllLossBackward>) average train loss tensor(1.3883, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.486504782928624 val_avg_loss: tensor(1.9682)\n",
      "epoch: 77 train_loss: tensor(1.4097, grad_fn=<NllLossBackward>) average train loss tensor(1.4097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48735835172921266 val_avg_loss: tensor(1.9683)\n",
      "epoch: 78 train_loss: tensor(1.4169, grad_fn=<NllLossBackward>) average train loss tensor(1.4169, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48806475349521705 val_avg_loss: tensor(1.9694)\n",
      "epoch: 79 train_loss: tensor(1.3803, grad_fn=<NllLossBackward>) average train loss tensor(1.3803, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48788815305371597 val_avg_loss: tensor(1.9720)\n",
      "epoch: 80 train_loss: tensor(1.3680, grad_fn=<NllLossBackward>) average train loss tensor(1.3680, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4878587196467991 val_avg_loss: tensor(1.9748)\n",
      "epoch: 81 train_loss: tensor(1.3415, grad_fn=<NllLossBackward>) average train loss tensor(1.3415, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4890066225165563 val_avg_loss: tensor(1.9767)\n",
      "epoch: 82 train_loss: tensor(1.3483, grad_fn=<NllLossBackward>) average train loss tensor(1.3483, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49027225901398086 val_avg_loss: tensor(1.9782)\n",
      "epoch: 83 train_loss: tensor(1.3182, grad_fn=<NllLossBackward>) average train loss tensor(1.3182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4904782928623988 val_avg_loss: tensor(1.9804)\n",
      "epoch: 84 train_loss: tensor(1.3367, grad_fn=<NllLossBackward>) average train loss tensor(1.3367, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48974245768947755 val_avg_loss: tensor(1.9835)\n",
      "epoch: 85 train_loss: tensor(1.3100, grad_fn=<NllLossBackward>) average train loss tensor(1.3100, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49159676232523913 val_avg_loss: tensor(1.9868)\n",
      "epoch: 86 train_loss: tensor(1.2863, grad_fn=<NllLossBackward>) average train loss tensor(1.2863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4920971302428256 val_avg_loss: tensor(1.9889)\n",
      "epoch: 87 train_loss: tensor(1.2697, grad_fn=<NllLossBackward>) average train loss tensor(1.2697, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49236203090507724 val_avg_loss: tensor(1.9897)\n",
      "epoch: 88 train_loss: tensor(1.3144, grad_fn=<NllLossBackward>) average train loss tensor(1.3144, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4920971302428256 val_avg_loss: tensor(1.9903)\n",
      "epoch: 89 train_loss: tensor(1.2780, grad_fn=<NllLossBackward>) average train loss tensor(1.2780, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49242089771891095 val_avg_loss: tensor(1.9925)\n",
      "epoch: 90 train_loss: tensor(1.2359, grad_fn=<NllLossBackward>) average train loss tensor(1.2359, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4922737306843267 val_avg_loss: tensor(1.9945)\n",
      "epoch: 91 train_loss: tensor(1.2763, grad_fn=<NllLossBackward>) average train loss tensor(1.2763, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.49200883002207507 val_avg_loss: tensor(1.9955)\n",
      "epoch: 92 train_loss: tensor(1.2338, grad_fn=<NllLossBackward>) average train loss tensor(1.2338, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4925386313465784 val_avg_loss: tensor(2.0019)\n",
      "epoch: 93 train_loss: tensor(1.2201, grad_fn=<NllLossBackward>) average train loss tensor(1.2201, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4923031640912436 val_avg_loss: tensor(2.0076)\n",
      "epoch: 94 train_loss: tensor(1.2002, grad_fn=<NllLossBackward>) average train loss tensor(1.2002, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4933627667402502 val_avg_loss: tensor(2.0133)\n",
      "epoch: 95 train_loss: tensor(1.1906, grad_fn=<NllLossBackward>) average train loss tensor(1.1906, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4919205298013245 val_avg_loss: tensor(2.0189)\n",
      "epoch: 96 train_loss: tensor(1.1929, grad_fn=<NllLossBackward>) average train loss tensor(1.1929, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49212656364974244 val_avg_loss: tensor(2.0243)\n",
      "epoch: 97 train_loss: tensor(1.1816, grad_fn=<NllLossBackward>) average train loss tensor(1.1816, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4921559970566593 val_avg_loss: tensor(2.0276)\n",
      "epoch: 98 train_loss: tensor(1.1764, grad_fn=<NllLossBackward>) average train loss tensor(1.1764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49342163355408386 val_avg_loss: tensor(2.0297)\n",
      "epoch: 99 train_loss: tensor(1.1398, grad_fn=<NllLossBackward>) average train loss tensor(1.1398, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49409860191317145 val_avg_loss: tensor(2.0318)\n"
     ]
    }
   ],
   "source": [
    "cur_train_loader = DataLoader(train_ds_2000, batch_size=2048)\n",
    "\n",
    "encoder_128_3 = autoencoder_128_3.encoder\n",
    "after_encoder_model_128_3 = AfterEncoderModel(encoder_128_3, d=128, drop=0.5)\n",
    "optimizer_aem_128_3 = torch.optim.Adam(after_encoder_model_128_3.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_128_3_bs2048_rs42_d128_wd0005_drop05_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_128_3,\n",
    "    optimizer=optimizer_aem_128_3,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=cur_train_loader,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(1.1750, grad_fn=<NllLossBackward>) average train loss tensor(1.1750, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49642384105960263 val_avg_loss: tensor(2.0321)\n",
      "epoch: 1 train_loss: tensor(1.1366, grad_fn=<NllLossBackward>) average train loss tensor(1.1366, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4963944076526858 val_avg_loss: tensor(2.0331)\n",
      "epoch: 2 train_loss: tensor(1.1363, grad_fn=<NllLossBackward>) average train loss tensor(1.1363, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49630610743193526 val_avg_loss: tensor(2.0373)\n",
      "epoch: 3 train_loss: tensor(1.1504, grad_fn=<NllLossBackward>) average train loss tensor(1.1504, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4955114054451803 val_avg_loss: tensor(2.0423)\n",
      "epoch: 4 train_loss: tensor(1.0970, grad_fn=<NllLossBackward>) average train loss tensor(1.0970, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49562913907284767 val_avg_loss: tensor(2.0463)\n",
      "epoch: 5 train_loss: tensor(1.1007, grad_fn=<NllLossBackward>) average train loss tensor(1.1007, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4960412067696836 val_avg_loss: tensor(2.0512)\n",
      "epoch: 6 train_loss: tensor(1.0898, grad_fn=<NllLossBackward>) average train loss tensor(1.0898, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4950699043414275 val_avg_loss: tensor(2.0575)\n",
      "epoch: 7 train_loss: tensor(1.0970, grad_fn=<NllLossBackward>) average train loss tensor(1.0970, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49571743929359824 val_avg_loss: tensor(2.0631)\n",
      "epoch: 8 train_loss: tensor(1.0778, grad_fn=<NllLossBackward>) average train loss tensor(1.0778, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4949227373068433 val_avg_loss: tensor(2.0693)\n",
      "epoch: 9 train_loss: tensor(1.0608, grad_fn=<NllLossBackward>) average train loss tensor(1.0608, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4956880058866814 val_avg_loss: tensor(2.0741)\n",
      "epoch: 10 train_loss: tensor(1.0395, grad_fn=<NllLossBackward>) average train loss tensor(1.0395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.496364974245769 val_avg_loss: tensor(2.0766)\n",
      "epoch: 11 train_loss: tensor(1.0558, grad_fn=<NllLossBackward>) average train loss tensor(1.0558, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49618837380426783 val_avg_loss: tensor(2.0805)\n",
      "epoch: 12 train_loss: tensor(1.0499, grad_fn=<NllLossBackward>) average train loss tensor(1.0499, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4969830757910228 val_avg_loss: tensor(2.0836)\n",
      "epoch: 13 train_loss: tensor(1.0286, grad_fn=<NllLossBackward>) average train loss tensor(1.0286, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4975128771155261 val_avg_loss: tensor(2.0860)\n",
      "epoch: 14 train_loss: tensor(1.0182, grad_fn=<NllLossBackward>) average train loss tensor(1.0182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49724797645327445 val_avg_loss: tensor(2.0890)\n",
      "epoch: 15 train_loss: tensor(1.0124, grad_fn=<NllLossBackward>) average train loss tensor(1.0124, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4965121412803532 val_avg_loss: tensor(2.0927)\n",
      "epoch: 16 train_loss: tensor(0.9860, grad_fn=<NllLossBackward>) average train loss tensor(0.9860, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49554083885209715 val_avg_loss: tensor(2.0983)\n",
      "epoch: 17 train_loss: tensor(1.0206, grad_fn=<NllLossBackward>) average train loss tensor(1.0206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4952759381898455 val_avg_loss: tensor(2.1041)\n",
      "epoch: 18 train_loss: tensor(0.9766, grad_fn=<NllLossBackward>) average train loss tensor(0.9766, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4962178072111847 val_avg_loss: tensor(2.1093)\n",
      "epoch: 19 train_loss: tensor(0.9803, grad_fn=<NllLossBackward>) average train loss tensor(0.9803, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49610007358351726 val_avg_loss: tensor(2.1139)\n",
      "epoch: 20 train_loss: tensor(0.9893, grad_fn=<NllLossBackward>) average train loss tensor(0.9893, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4966004415011038 val_avg_loss: tensor(2.1185)\n",
      "epoch: 21 train_loss: tensor(0.9850, grad_fn=<NllLossBackward>) average train loss tensor(0.9850, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4962766740250184 val_avg_loss: tensor(2.1224)\n",
      "epoch: 22 train_loss: tensor(0.9813, grad_fn=<NllLossBackward>) average train loss tensor(0.9813, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49595290654893304 val_avg_loss: tensor(2.1274)\n",
      "epoch: 23 train_loss: tensor(0.9528, grad_fn=<NllLossBackward>) average train loss tensor(0.9528, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49557027225901396 val_avg_loss: tensor(2.1335)\n",
      "epoch: 24 train_loss: tensor(0.9908, grad_fn=<NllLossBackward>) average train loss tensor(0.9908, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.496158940397351 val_avg_loss: tensor(2.1391)\n",
      "epoch: 25 train_loss: tensor(0.9641, grad_fn=<NllLossBackward>) average train loss tensor(0.9641, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4971008094186902 val_avg_loss: tensor(2.1430)\n",
      "epoch: 26 train_loss: tensor(0.9648, grad_fn=<NllLossBackward>) average train loss tensor(0.9648, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4979543782192789 val_avg_loss: tensor(2.1460)\n",
      "epoch: 27 train_loss: tensor(0.9556, grad_fn=<NllLossBackward>) average train loss tensor(0.9556, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4980721118469463 val_avg_loss: tensor(2.1502)\n",
      "epoch: 28 train_loss: tensor(0.9065, grad_fn=<NllLossBackward>) average train loss tensor(0.9065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4969830757910228 val_avg_loss: tensor(2.1544)\n",
      "epoch: 29 train_loss: tensor(0.9234, grad_fn=<NllLossBackward>) average train loss tensor(0.9234, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49730684326710817 val_avg_loss: tensor(2.1587)\n",
      "epoch: 30 train_loss: tensor(0.8990, grad_fn=<NllLossBackward>) average train loss tensor(0.8990, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49730684326710817 val_avg_loss: tensor(2.1639)\n",
      "epoch: 31 train_loss: tensor(0.9043, grad_fn=<NllLossBackward>) average train loss tensor(0.9043, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4969242089771891 val_avg_loss: tensor(2.1676)\n",
      "epoch: 32 train_loss: tensor(0.9097, grad_fn=<NllLossBackward>) average train loss tensor(0.9097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49683590875643857 val_avg_loss: tensor(2.1721)\n",
      "epoch: 33 train_loss: tensor(0.8989, grad_fn=<NllLossBackward>) average train loss tensor(0.8989, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49718910963944074 val_avg_loss: tensor(2.1787)\n",
      "epoch: 34 train_loss: tensor(0.8711, grad_fn=<NllLossBackward>) average train loss tensor(0.8711, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49665930831493743 val_avg_loss: tensor(2.1880)\n",
      "epoch: 35 train_loss: tensor(0.8720, grad_fn=<NllLossBackward>) average train loss tensor(0.8720, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49642384105960263 val_avg_loss: tensor(2.1987)\n",
      "epoch: 36 train_loss: tensor(0.8544, grad_fn=<NllLossBackward>) average train loss tensor(0.8544, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4951582045621781 val_avg_loss: tensor(2.2103)\n",
      "epoch: 37 train_loss: tensor(0.8654, grad_fn=<NllLossBackward>) average train loss tensor(0.8654, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49462840323767476 val_avg_loss: tensor(2.2180)\n",
      "epoch: 38 train_loss: tensor(0.8258, grad_fn=<NllLossBackward>) average train loss tensor(0.8258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49456953642384105 val_avg_loss: tensor(2.2244)\n",
      "epoch: 39 train_loss: tensor(0.8543, grad_fn=<NllLossBackward>) average train loss tensor(0.8543, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4946578366445916 val_avg_loss: tensor(2.2273)\n",
      "epoch: 40 train_loss: tensor(0.8158, grad_fn=<NllLossBackward>) average train loss tensor(0.8158, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49501103752759384 val_avg_loss: tensor(2.2284)\n",
      "epoch: 41 train_loss: tensor(0.8263, grad_fn=<NllLossBackward>) average train loss tensor(0.8263, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49471670345842533 val_avg_loss: tensor(2.2295)\n",
      "epoch: 42 train_loss: tensor(0.8835, grad_fn=<NllLossBackward>) average train loss tensor(0.8835, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-c5d092152e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_train_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/Thesis/topics_ds/pytorch/torch_models.py\u001b[0m in \u001b[0;36mfit_topics_model\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, writer, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mloss_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_128_3,\n",
    "    optimizer=optimizer_aem_128_3,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=cur_train_loader,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_dict = {\n",
    "    'trivial': Autoencoder,\n",
    "    'inter_fc': AutoencoderFixed,\n",
    "    'relu': AutoencoderRelu,\n",
    "    'complex': AutoencoderComplex\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.691 txt_loss: 0.715 img + txt loss 1.406\n",
      "val img loss: 0.489 val txt_loss: 0.532 img + txt loss 1.021\n",
      "train img loss: 0.404 txt_loss: 0.460 img + txt loss 0.864\n",
      "val img loss: 0.338 val txt_loss: 0.405 img + txt loss 0.743\n",
      "train img loss: 0.301 txt_loss: 0.376 img + txt loss 0.677\n",
      "val img loss: 0.271 val txt_loss: 0.353 img + txt loss 0.624\n",
      "train img loss: 0.253 txt_loss: 0.338 img + txt loss 0.591\n",
      "val img loss: 0.239 val txt_loss: 0.326 img + txt loss 0.565\n",
      "train img loss: 0.229 txt_loss: 0.317 img + txt loss 0.546\n",
      "val img loss: 0.221 val txt_loss: 0.310 img + txt loss 0.531\n",
      "train img loss: 0.214 txt_loss: 0.303 img + txt loss 0.517\n",
      "val img loss: 0.209 val txt_loss: 0.297 img + txt loss 0.506\n",
      "train img loss: 0.204 txt_loss: 0.291 img + txt loss 0.495\n",
      "val img loss: 0.200 val txt_loss: 0.286 img + txt loss 0.486\n",
      "train img loss: 0.196 txt_loss: 0.280 img + txt loss 0.476\n",
      "val img loss: 0.193 val txt_loss: 0.275 img + txt loss 0.469\n",
      "train img loss: 0.190 txt_loss: 0.270 img + txt loss 0.460\n",
      "val img loss: 0.188 val txt_loss: 0.266 img + txt loss 0.454\n",
      "train img loss: 0.185 txt_loss: 0.260 img + txt loss 0.446\n",
      "val img loss: 0.183 val txt_loss: 0.256 img + txt loss 0.440\n",
      "train img loss: 0.181 txt_loss: 0.252 img + txt loss 0.433\n",
      "val img loss: 0.180 val txt_loss: 0.249 img + txt loss 0.429\n",
      "train img loss: 0.178 txt_loss: 0.246 img + txt loss 0.424\n",
      "val img loss: 0.177 val txt_loss: 0.244 img + txt loss 0.422\n",
      "train img loss: 0.176 txt_loss: 0.242 img + txt loss 0.417\n",
      "val img loss: 0.175 val txt_loss: 0.241 img + txt loss 0.416\n",
      "train img loss: 0.174 txt_loss: 0.239 img + txt loss 0.412\n",
      "val img loss: 0.174 val txt_loss: 0.238 img + txt loss 0.412\n",
      "train img loss: 0.172 txt_loss: 0.236 img + txt loss 0.409\n",
      "val img loss: 0.172 val txt_loss: 0.236 img + txt loss 0.408\n",
      "train img loss: 0.171 txt_loss: 0.234 img + txt loss 0.405\n",
      "val img loss: 0.171 val txt_loss: 0.234 img + txt loss 0.405\n",
      "train img loss: 0.170 txt_loss: 0.233 img + txt loss 0.403\n",
      "val img loss: 0.170 val txt_loss: 0.233 img + txt loss 0.403\n",
      "train img loss: 0.169 txt_loss: 0.232 img + txt loss 0.401\n",
      "val img loss: 0.169 val txt_loss: 0.232 img + txt loss 0.401\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.399\n",
      "val img loss: 0.168 val txt_loss: 0.232 img + txt loss 0.400\n",
      "train img loss: 0.168 txt_loss: 0.230 img + txt loss 0.398\n",
      "val img loss: 0.168 val txt_loss: 0.231 img + txt loss 0.399\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.167 val txt_loss: 0.231 img + txt loss 0.398\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.396\n",
      "val img loss: 0.167 val txt_loss: 0.230 img + txt loss 0.397\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.167 val txt_loss: 0.230 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.165 val txt_loss: 0.229 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.392\n",
      "val img loss: 0.166 val txt_loss: 0.228 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.164 val txt_loss: 0.228 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.164 val txt_loss: 0.228 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.390\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.165 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.163 val txt_loss: 0.227 img + txt loss 0.390\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.163 val txt_loss: 0.227 img + txt loss 0.390\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.163 val txt_loss: 0.227 img + txt loss 0.390\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.163 val txt_loss: 0.227 img + txt loss 0.390\n",
      "autoencoder fitting finished for 510.9655659198761 seconds\n",
      "train img loss: 0.605 txt_loss: 0.628 img + txt loss 1.232\n",
      "val img loss: 0.398 val txt_loss: 0.439 img + txt loss 0.836\n",
      "train img loss: 0.324 txt_loss: 0.366 img + txt loss 0.690\n",
      "val img loss: 0.269 val txt_loss: 0.311 img + txt loss 0.579\n",
      "train img loss: 0.240 txt_loss: 0.283 img + txt loss 0.523\n",
      "val img loss: 0.217 val txt_loss: 0.261 img + txt loss 0.478\n",
      "train img loss: 0.204 txt_loss: 0.251 img + txt loss 0.454\n",
      "val img loss: 0.192 val txt_loss: 0.243 img + txt loss 0.435\n",
      "train img loss: 0.185 txt_loss: 0.238 img + txt loss 0.424\n",
      "val img loss: 0.178 val txt_loss: 0.235 img + txt loss 0.413\n",
      "train img loss: 0.175 txt_loss: 0.233 img + txt loss 0.408\n",
      "val img loss: 0.171 val txt_loss: 0.231 img + txt loss 0.402\n",
      "train img loss: 0.169 txt_loss: 0.230 img + txt loss 0.399\n",
      "val img loss: 0.167 val txt_loss: 0.229 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.164 txt_loss: 0.228 img + txt loss 0.392\n",
      "val img loss: 0.163 val txt_loss: 0.227 img + txt loss 0.390\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.390\n",
      "val img loss: 0.163 val txt_loss: 0.227 img + txt loss 0.390\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.162 val txt_loss: 0.226 img + txt loss 0.388\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.388\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.226 img + txt loss 0.387\n",
      "train img loss: 0.162 txt_loss: 0.226 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.387\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.387\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.386\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "train img loss: 0.161 txt_loss: 0.225 img + txt loss 0.386\n",
      "val img loss: 0.161 val txt_loss: 0.225 img + txt loss 0.385\n",
      "autoencoder fitting finished for 534.1691861152649 seconds\n",
      "train img loss: 0.697 txt_loss: 0.734 img + txt loss 1.431\n",
      "val img loss: 0.517 val txt_loss: 0.568 img + txt loss 1.086\n",
      "train img loss: 0.458 txt_loss: 0.511 img + txt loss 0.969\n",
      "val img loss: 0.414 val txt_loss: 0.469 img + txt loss 0.883\n",
      "train img loss: 0.386 txt_loss: 0.443 img + txt loss 0.829\n",
      "val img loss: 0.362 val txt_loss: 0.422 img + txt loss 0.785\n",
      "train img loss: 0.345 txt_loss: 0.406 img + txt loss 0.751\n",
      "val img loss: 0.331 val txt_loss: 0.392 img + txt loss 0.723\n",
      "train img loss: 0.318 txt_loss: 0.379 img + txt loss 0.698\n",
      "val img loss: 0.308 val txt_loss: 0.369 img + txt loss 0.677\n",
      "train img loss: 0.299 txt_loss: 0.359 img + txt loss 0.657\n",
      "val img loss: 0.291 val txt_loss: 0.350 img + txt loss 0.641\n",
      "train img loss: 0.283 txt_loss: 0.342 img + txt loss 0.625\n",
      "val img loss: 0.279 val txt_loss: 0.335 img + txt loss 0.614\n",
      "train img loss: 0.270 txt_loss: 0.327 img + txt loss 0.597\n",
      "val img loss: 0.265 val txt_loss: 0.321 img + txt loss 0.587\n",
      "train img loss: 0.260 txt_loss: 0.314 img + txt loss 0.574\n",
      "val img loss: 0.256 val txt_loss: 0.309 img + txt loss 0.565\n",
      "train img loss: 0.251 txt_loss: 0.302 img + txt loss 0.553\n",
      "val img loss: 0.247 val txt_loss: 0.298 img + txt loss 0.545\n",
      "train img loss: 0.243 txt_loss: 0.292 img + txt loss 0.535\n",
      "val img loss: 0.241 val txt_loss: 0.288 img + txt loss 0.529\n",
      "train img loss: 0.236 txt_loss: 0.282 img + txt loss 0.518\n",
      "val img loss: 0.234 val txt_loss: 0.279 img + txt loss 0.513\n",
      "train img loss: 0.229 txt_loss: 0.274 img + txt loss 0.504\n",
      "val img loss: 0.228 val txt_loss: 0.271 img + txt loss 0.499\n",
      "train img loss: 0.224 txt_loss: 0.267 img + txt loss 0.490\n",
      "val img loss: 0.221 val txt_loss: 0.264 img + txt loss 0.485\n",
      "train img loss: 0.218 txt_loss: 0.260 img + txt loss 0.479\n",
      "val img loss: 0.216 val txt_loss: 0.259 img + txt loss 0.475\n",
      "train img loss: 0.214 txt_loss: 0.256 img + txt loss 0.470\n",
      "val img loss: 0.213 val txt_loss: 0.254 img + txt loss 0.467\n",
      "train img loss: 0.210 txt_loss: 0.252 img + txt loss 0.462\n",
      "val img loss: 0.209 val txt_loss: 0.251 img + txt loss 0.460\n",
      "train img loss: 0.206 txt_loss: 0.248 img + txt loss 0.454\n",
      "val img loss: 0.206 val txt_loss: 0.248 img + txt loss 0.454\n",
      "train img loss: 0.203 txt_loss: 0.246 img + txt loss 0.449\n",
      "val img loss: 0.202 val txt_loss: 0.245 img + txt loss 0.448\n",
      "train img loss: 0.199 txt_loss: 0.244 img + txt loss 0.444\n",
      "val img loss: 0.199 val txt_loss: 0.244 img + txt loss 0.444\n",
      "train img loss: 0.197 txt_loss: 0.242 img + txt loss 0.438\n",
      "val img loss: 0.202 val txt_loss: 0.243 img + txt loss 0.445\n",
      "train img loss: 0.194 txt_loss: 0.240 img + txt loss 0.435\n",
      "val img loss: 0.194 val txt_loss: 0.243 img + txt loss 0.437\n",
      "train img loss: 0.192 txt_loss: 0.239 img + txt loss 0.431\n",
      "val img loss: 0.193 val txt_loss: 0.239 img + txt loss 0.432\n",
      "train img loss: 0.190 txt_loss: 0.238 img + txt loss 0.428\n",
      "val img loss: 0.191 val txt_loss: 0.239 img + txt loss 0.430\n",
      "train img loss: 0.188 txt_loss: 0.237 img + txt loss 0.425\n",
      "val img loss: 0.188 val txt_loss: 0.237 img + txt loss 0.425\n",
      "train img loss: 0.187 txt_loss: 0.236 img + txt loss 0.423\n",
      "val img loss: 0.187 val txt_loss: 0.237 img + txt loss 0.424\n",
      "train img loss: 0.186 txt_loss: 0.235 img + txt loss 0.421\n",
      "val img loss: 0.185 val txt_loss: 0.236 img + txt loss 0.421\n",
      "train img loss: 0.184 txt_loss: 0.235 img + txt loss 0.419\n",
      "val img loss: 0.184 val txt_loss: 0.235 img + txt loss 0.419\n",
      "train img loss: 0.183 txt_loss: 0.234 img + txt loss 0.417\n",
      "val img loss: 0.183 val txt_loss: 0.235 img + txt loss 0.418\n",
      "train img loss: 0.183 txt_loss: 0.234 img + txt loss 0.416\n",
      "val img loss: 0.183 val txt_loss: 0.234 img + txt loss 0.417\n",
      "train img loss: 0.181 txt_loss: 0.233 img + txt loss 0.414\n",
      "val img loss: 0.182 val txt_loss: 0.235 img + txt loss 0.417\n",
      "train img loss: 0.181 txt_loss: 0.233 img + txt loss 0.414\n",
      "val img loss: 0.181 val txt_loss: 0.234 img + txt loss 0.415\n",
      "train img loss: 0.180 txt_loss: 0.233 img + txt loss 0.413\n",
      "val img loss: 0.181 val txt_loss: 0.234 img + txt loss 0.415\n",
      "train img loss: 0.179 txt_loss: 0.232 img + txt loss 0.412\n",
      "val img loss: 0.180 val txt_loss: 0.234 img + txt loss 0.414\n",
      "train img loss: 0.179 txt_loss: 0.232 img + txt loss 0.410\n",
      "val img loss: 0.182 val txt_loss: 0.234 img + txt loss 0.416\n",
      "train img loss: 0.178 txt_loss: 0.231 img + txt loss 0.410\n",
      "val img loss: 0.179 val txt_loss: 0.233 img + txt loss 0.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.178 txt_loss: 0.231 img + txt loss 0.409\n",
      "val img loss: 0.178 val txt_loss: 0.232 img + txt loss 0.410\n",
      "train img loss: 0.178 txt_loss: 0.231 img + txt loss 0.409\n",
      "val img loss: 0.178 val txt_loss: 0.232 img + txt loss 0.410\n",
      "train img loss: 0.178 txt_loss: 0.231 img + txt loss 0.408\n",
      "val img loss: 0.178 val txt_loss: 0.231 img + txt loss 0.410\n",
      "train img loss: 0.178 txt_loss: 0.231 img + txt loss 0.408\n",
      "val img loss: 0.178 val txt_loss: 0.232 img + txt loss 0.409\n",
      "train img loss: 0.177 txt_loss: 0.230 img + txt loss 0.407\n",
      "val img loss: 0.177 val txt_loss: 0.231 img + txt loss 0.408\n",
      "train img loss: 0.177 txt_loss: 0.230 img + txt loss 0.407\n",
      "val img loss: 0.177 val txt_loss: 0.233 img + txt loss 0.410\n",
      "train img loss: 0.176 txt_loss: 0.230 img + txt loss 0.407\n",
      "val img loss: 0.177 val txt_loss: 0.231 img + txt loss 0.408\n",
      "train img loss: 0.177 txt_loss: 0.230 img + txt loss 0.407\n",
      "val img loss: 0.176 val txt_loss: 0.230 img + txt loss 0.407\n",
      "train img loss: 0.176 txt_loss: 0.230 img + txt loss 0.406\n",
      "val img loss: 0.176 val txt_loss: 0.230 img + txt loss 0.406\n",
      "train img loss: 0.176 txt_loss: 0.229 img + txt loss 0.405\n",
      "val img loss: 0.176 val txt_loss: 0.230 img + txt loss 0.406\n",
      "train img loss: 0.176 txt_loss: 0.230 img + txt loss 0.405\n",
      "val img loss: 0.176 val txt_loss: 0.230 img + txt loss 0.406\n",
      "train img loss: 0.176 txt_loss: 0.229 img + txt loss 0.405\n",
      "val img loss: 0.175 val txt_loss: 0.230 img + txt loss 0.405\n",
      "train img loss: 0.176 txt_loss: 0.229 img + txt loss 0.405\n",
      "val img loss: 0.175 val txt_loss: 0.230 img + txt loss 0.405\n",
      "train img loss: 0.175 txt_loss: 0.229 img + txt loss 0.404\n",
      "val img loss: 0.175 val txt_loss: 0.230 img + txt loss 0.405\n",
      "autoencoder fitting finished for 526.7265768051147 seconds\n",
      "train img loss: 0.688 txt_loss: 0.718 img + txt loss 1.406\n",
      "val img loss: 0.489 val txt_loss: 0.536 img + txt loss 1.025\n",
      "train img loss: 0.405 txt_loss: 0.462 img + txt loss 0.867\n",
      "val img loss: 0.339 val txt_loss: 0.406 img + txt loss 0.746\n",
      "train img loss: 0.301 txt_loss: 0.376 img + txt loss 0.678\n",
      "val img loss: 0.272 val txt_loss: 0.352 img + txt loss 0.624\n",
      "train img loss: 0.253 txt_loss: 0.338 img + txt loss 0.591\n",
      "val img loss: 0.239 val txt_loss: 0.326 img + txt loss 0.565\n",
      "train img loss: 0.228 txt_loss: 0.318 img + txt loss 0.546\n",
      "val img loss: 0.220 val txt_loss: 0.310 img + txt loss 0.530\n",
      "train img loss: 0.214 txt_loss: 0.303 img + txt loss 0.517\n",
      "val img loss: 0.209 val txt_loss: 0.297 img + txt loss 0.506\n",
      "train img loss: 0.203 txt_loss: 0.291 img + txt loss 0.494\n",
      "val img loss: 0.200 val txt_loss: 0.285 img + txt loss 0.485\n",
      "train img loss: 0.195 txt_loss: 0.279 img + txt loss 0.475\n",
      "val img loss: 0.193 val txt_loss: 0.275 img + txt loss 0.467\n",
      "train img loss: 0.189 txt_loss: 0.269 img + txt loss 0.458\n",
      "val img loss: 0.187 val txt_loss: 0.264 img + txt loss 0.451\n",
      "train img loss: 0.184 txt_loss: 0.259 img + txt loss 0.444\n",
      "val img loss: 0.183 val txt_loss: 0.256 img + txt loss 0.439\n",
      "train img loss: 0.181 txt_loss: 0.252 img + txt loss 0.432\n",
      "val img loss: 0.180 val txt_loss: 0.249 img + txt loss 0.429\n",
      "train img loss: 0.178 txt_loss: 0.246 img + txt loss 0.424\n",
      "val img loss: 0.177 val txt_loss: 0.244 img + txt loss 0.421\n",
      "train img loss: 0.176 txt_loss: 0.241 img + txt loss 0.417\n",
      "val img loss: 0.175 val txt_loss: 0.240 img + txt loss 0.416\n",
      "train img loss: 0.174 txt_loss: 0.238 img + txt loss 0.412\n",
      "val img loss: 0.174 val txt_loss: 0.238 img + txt loss 0.412\n",
      "train img loss: 0.173 txt_loss: 0.236 img + txt loss 0.409\n",
      "val img loss: 0.172 val txt_loss: 0.236 img + txt loss 0.408\n",
      "train img loss: 0.171 txt_loss: 0.234 img + txt loss 0.405\n",
      "val img loss: 0.171 val txt_loss: 0.234 img + txt loss 0.405\n",
      "train img loss: 0.170 txt_loss: 0.233 img + txt loss 0.403\n",
      "val img loss: 0.170 val txt_loss: 0.233 img + txt loss 0.403\n",
      "train img loss: 0.169 txt_loss: 0.232 img + txt loss 0.401\n",
      "val img loss: 0.169 val txt_loss: 0.232 img + txt loss 0.402\n",
      "train img loss: 0.169 txt_loss: 0.231 img + txt loss 0.400\n",
      "val img loss: 0.169 val txt_loss: 0.231 img + txt loss 0.400\n",
      "train img loss: 0.168 txt_loss: 0.230 img + txt loss 0.398\n",
      "val img loss: 0.168 val txt_loss: 0.231 img + txt loss 0.399\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.168 val txt_loss: 0.230 img + txt loss 0.398\n",
      "train img loss: 0.167 txt_loss: 0.229 img + txt loss 0.396\n",
      "val img loss: 0.167 val txt_loss: 0.230 img + txt loss 0.397\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.167 val txt_loss: 0.230 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.167 val txt_loss: 0.229 img + txt loss 0.396\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.166 val txt_loss: 0.229 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.166 val txt_loss: 0.228 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.393\n",
      "val img loss: 0.166 val txt_loss: 0.228 img + txt loss 0.394\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.167 val txt_loss: 0.228 img + txt loss 0.395\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.165 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.166 val txt_loss: 0.228 img + txt loss 0.393\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.165 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.165 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.391\n",
      "val img loss: 0.165 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.165 val txt_loss: 0.227 img + txt loss 0.392\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.391\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.164 val txt_loss: 0.227 img + txt loss 0.390\n",
      "autoencoder fitting finished for 478.174702167511 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_dict = {}\n",
    "\n",
    "for k in constructor_dict:\n",
    "    cur_autoencoder = constructor_dict[k](d=128)\n",
    "    cur_optimizer = torch.optim.Adam(cur_autoencoder.parameters(), lr=1e-3)\n",
    "    fit_autoencoder(\n",
    "        cur_autoencoder, \n",
    "        cur_optimizer, \n",
    "        epochs=50, \n",
    "        X_train=[x_img_train, x_txt_train], \n",
    "        X_val=[x_img_val, x_txt_val]\n",
    "    ) \n",
    "    autoencoder_dict[k] = cur_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8147, grad_fn=<NllLossBackward>) average train loss tensor(3.8888, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.0848270787343635 val_avg_loss: tensor(3.7951)\n",
      "epoch: 1 train_loss: tensor(3.6779, grad_fn=<NllLossBackward>) average train loss tensor(3.7258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.08906548933038999 val_avg_loss: tensor(3.6651)\n",
      "epoch: 2 train_loss: tensor(3.5690, grad_fn=<NllLossBackward>) average train loss tensor(3.6159, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1552317880794702 val_avg_loss: tensor(3.5585)\n",
      "epoch: 3 train_loss: tensor(3.4350, grad_fn=<NllLossBackward>) average train loss tensor(3.5147, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2025018395879323 val_avg_loss: tensor(3.4498)\n",
      "epoch: 4 train_loss: tensor(3.3540, grad_fn=<NllLossBackward>) average train loss tensor(3.4012, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2183664459161148 val_avg_loss: tensor(3.3228)\n",
      "epoch: 5 train_loss: tensor(3.1595, grad_fn=<NllLossBackward>) average train loss tensor(3.2730, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22966887417218543 val_avg_loss: tensor(3.1809)\n",
      "epoch: 6 train_loss: tensor(3.0582, grad_fn=<NllLossBackward>) average train loss tensor(3.1665, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.26054451802796175 val_avg_loss: tensor(3.0340)\n",
      "epoch: 7 train_loss: tensor(2.9269, grad_fn=<NllLossBackward>) average train loss tensor(3.0319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2866225165562914 val_avg_loss: tensor(2.8951)\n",
      "epoch: 8 train_loss: tensor(2.8329, grad_fn=<NllLossBackward>) average train loss tensor(2.8889, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3144076526857984 val_avg_loss: tensor(2.7625)\n",
      "epoch: 9 train_loss: tensor(2.7122, grad_fn=<NllLossBackward>) average train loss tensor(2.7666, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3294775570272259 val_avg_loss: tensor(2.6351)\n",
      "epoch: 10 train_loss: tensor(2.6357, grad_fn=<NllLossBackward>) average train loss tensor(2.6427, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3439587932303164 val_avg_loss: tensor(2.5257)\n",
      "epoch: 11 train_loss: tensor(2.4668, grad_fn=<NllLossBackward>) average train loss tensor(2.5288, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.36264900662251653 val_avg_loss: tensor(2.4378)\n",
      "epoch: 12 train_loss: tensor(2.3748, grad_fn=<NllLossBackward>) average train loss tensor(2.4408, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3792788815305372 val_avg_loss: tensor(2.3602)\n",
      "epoch: 13 train_loss: tensor(2.3129, grad_fn=<NllLossBackward>) average train loss tensor(2.3508, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.391523178807947 val_avg_loss: tensor(2.2972)\n",
      "epoch: 14 train_loss: tensor(2.1920, grad_fn=<NllLossBackward>) average train loss tensor(2.2772, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3985871964679912 val_avg_loss: tensor(2.2559)\n",
      "epoch: 15 train_loss: tensor(2.0795, grad_fn=<NllLossBackward>) average train loss tensor(2.1772, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4065636497424577 val_avg_loss: tensor(2.2126)\n",
      "epoch: 16 train_loss: tensor(2.0671, grad_fn=<NllLossBackward>) average train loss tensor(2.1014, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42060338484179544 val_avg_loss: tensor(2.1607)\n",
      "epoch: 17 train_loss: tensor(1.9160, grad_fn=<NllLossBackward>) average train loss tensor(2.0203, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4294922737306843 val_avg_loss: tensor(2.1343)\n",
      "epoch: 18 train_loss: tensor(1.8530, grad_fn=<NllLossBackward>) average train loss tensor(1.9935, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4327299484915379 val_avg_loss: tensor(2.1266)\n",
      "epoch: 19 train_loss: tensor(1.9340, grad_fn=<NllLossBackward>) average train loss tensor(1.9594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43820456217807213 val_avg_loss: tensor(2.1081)\n",
      "epoch: 20 train_loss: tensor(1.8170, grad_fn=<NllLossBackward>) average train loss tensor(1.8921, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4456806475349522 val_avg_loss: tensor(2.0839)\n",
      "epoch: 21 train_loss: tensor(1.7910, grad_fn=<NllLossBackward>) average train loss tensor(1.8217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45153789551140544 val_avg_loss: tensor(2.0586)\n",
      "epoch: 22 train_loss: tensor(1.7698, grad_fn=<NllLossBackward>) average train loss tensor(1.7879, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45245033112582783 val_avg_loss: tensor(2.0522)\n",
      "epoch: 23 train_loss: tensor(1.7432, grad_fn=<NllLossBackward>) average train loss tensor(1.7775, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45742457689477556 val_avg_loss: tensor(2.0409)\n",
      "epoch: 24 train_loss: tensor(1.6606, grad_fn=<NllLossBackward>) average train loss tensor(1.7353, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46072111846946284 val_avg_loss: tensor(2.0383)\n",
      "epoch: 25 train_loss: tensor(1.5609, grad_fn=<NllLossBackward>) average train loss tensor(1.6969, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46334069168506253 val_avg_loss: tensor(2.0244)\n",
      "epoch: 26 train_loss: tensor(1.6045, grad_fn=<NllLossBackward>) average train loss tensor(1.6385, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4651949963208241 val_avg_loss: tensor(2.0161)\n",
      "epoch: 27 train_loss: tensor(1.5387, grad_fn=<NllLossBackward>) average train loss tensor(1.6389, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46675496688741724 val_avg_loss: tensor(2.0114)\n",
      "epoch: 28 train_loss: tensor(1.5098, grad_fn=<NllLossBackward>) average train loss tensor(1.5910, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4715526122148639 val_avg_loss: tensor(2.0064)\n",
      "epoch: 29 train_loss: tensor(1.4405, grad_fn=<NllLossBackward>) average train loss tensor(1.5183, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47579102281089036 val_avg_loss: tensor(1.9996)\n",
      "epoch: 30 train_loss: tensor(1.2993, grad_fn=<NllLossBackward>) average train loss tensor(1.4928, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765857247976453 val_avg_loss: tensor(2.0023)\n",
      "epoch: 31 train_loss: tensor(1.3849, grad_fn=<NllLossBackward>) average train loss tensor(1.4649, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47726269315673286 val_avg_loss: tensor(2.0151)\n",
      "epoch: 32 train_loss: tensor(1.3376, grad_fn=<NllLossBackward>) average train loss tensor(1.4670, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47364238410596027 val_avg_loss: tensor(2.0285)\n",
      "epoch: 33 train_loss: tensor(1.3049, grad_fn=<NllLossBackward>) average train loss tensor(1.3877, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47841059602649005 val_avg_loss: tensor(2.0206)\n",
      "epoch: 34 train_loss: tensor(1.3466, grad_fn=<NllLossBackward>) average train loss tensor(1.4329, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4811184694628403 val_avg_loss: tensor(2.0197)\n",
      "epoch: 35 train_loss: tensor(1.2781, grad_fn=<NllLossBackward>) average train loss tensor(1.3576, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47985283296541575 val_avg_loss: tensor(2.0360)\n",
      "epoch: 36 train_loss: tensor(1.3056, grad_fn=<NllLossBackward>) average train loss tensor(1.3788, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47991169977924947 val_avg_loss: tensor(2.0296)\n",
      "epoch: 37 train_loss: tensor(1.2427, grad_fn=<NllLossBackward>) average train loss tensor(1.3311, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48329654157468727 val_avg_loss: tensor(2.0292)\n",
      "epoch: 38 train_loss: tensor(1.1421, grad_fn=<NllLossBackward>) average train loss tensor(1.3019, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4824429727740986 val_avg_loss: tensor(2.0443)\n",
      "epoch: 39 train_loss: tensor(1.2467, grad_fn=<NllLossBackward>) average train loss tensor(1.3303, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48100073583517294 val_avg_loss: tensor(2.0466)\n",
      "epoch: 40 train_loss: tensor(1.2254, grad_fn=<NllLossBackward>) average train loss tensor(1.2762, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4842678440029433 val_avg_loss: tensor(2.0417)\n",
      "epoch: 41 train_loss: tensor(1.1720, grad_fn=<NllLossBackward>) average train loss tensor(1.2706, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4845621780721118 val_avg_loss: tensor(2.0343)\n",
      "epoch: 42 train_loss: tensor(1.2232, grad_fn=<NllLossBackward>) average train loss tensor(1.2480, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4845916114790287 val_avg_loss: tensor(2.0514)\n",
      "epoch: 43 train_loss: tensor(1.2040, grad_fn=<NllLossBackward>) average train loss tensor(1.2207, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4868579838116262 val_avg_loss: tensor(2.0637)\n",
      "epoch: 44 train_loss: tensor(1.0834, grad_fn=<NllLossBackward>) average train loss tensor(1.2061, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48806475349521705 val_avg_loss: tensor(2.0552)\n",
      "epoch: 45 train_loss: tensor(1.1152, grad_fn=<NllLossBackward>) average train loss tensor(1.1605, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48765268579838117 val_avg_loss: tensor(2.0672)\n",
      "epoch: 46 train_loss: tensor(1.1239, grad_fn=<NllLossBackward>) average train loss tensor(1.1479, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.48844738778513613 val_avg_loss: tensor(2.0780)\n",
      "epoch: 47 train_loss: tensor(1.1378, grad_fn=<NllLossBackward>) average train loss tensor(1.1343, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4880353200883002 val_avg_loss: tensor(2.0854)\n",
      "epoch: 48 train_loss: tensor(1.0077, grad_fn=<NllLossBackward>) average train loss tensor(1.1149, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4844150110375276 val_avg_loss: tensor(2.1032)\n",
      "epoch: 49 train_loss: tensor(0.9911, grad_fn=<NllLossBackward>) average train loss tensor(1.1127, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48485651214128034 val_avg_loss: tensor(2.1015)\n",
      "epoch: 50 train_loss: tensor(1.0222, grad_fn=<NllLossBackward>) average train loss tensor(1.1015, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48850625459896985 val_avg_loss: tensor(2.0991)\n",
      "epoch: 51 train_loss: tensor(1.0195, grad_fn=<NllLossBackward>) average train loss tensor(1.0674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48944812362030904 val_avg_loss: tensor(2.1156)\n",
      "epoch: 52 train_loss: tensor(0.9973, grad_fn=<NllLossBackward>) average train loss tensor(1.0529, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4895364238410596 val_avg_loss: tensor(2.1242)\n",
      "epoch: 53 train_loss: tensor(0.9470, grad_fn=<NllLossBackward>) average train loss tensor(1.0639, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48897718910963944 val_avg_loss: tensor(2.1323)\n",
      "epoch: 54 train_loss: tensor(0.8887, grad_fn=<NllLossBackward>) average train loss tensor(1.0225, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4903016924208977 val_avg_loss: tensor(2.1388)\n",
      "epoch: 55 train_loss: tensor(0.9303, grad_fn=<NllLossBackward>) average train loss tensor(1.0092, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4892420897718911 val_avg_loss: tensor(2.1543)\n",
      "epoch: 56 train_loss: tensor(0.8920, grad_fn=<NllLossBackward>) average train loss tensor(0.9824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4900073583517292 val_avg_loss: tensor(2.1581)\n",
      "epoch: 57 train_loss: tensor(0.8861, grad_fn=<NllLossBackward>) average train loss tensor(1.0065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4894775570272259 val_avg_loss: tensor(2.1600)\n",
      "epoch: 58 train_loss: tensor(0.8479, grad_fn=<NllLossBackward>) average train loss tensor(0.9728, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4897718910963944 val_avg_loss: tensor(2.1794)\n",
      "epoch: 59 train_loss: tensor(0.8734, grad_fn=<NllLossBackward>) average train loss tensor(0.9723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48997792494481235 val_avg_loss: tensor(2.1940)\n",
      "epoch: 60 train_loss: tensor(0.9222, grad_fn=<NllLossBackward>) average train loss tensor(0.9648, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4881530537159676 val_avg_loss: tensor(2.1963)\n",
      "epoch: 61 train_loss: tensor(0.8726, grad_fn=<NllLossBackward>) average train loss tensor(0.9079, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4885356880058867 val_avg_loss: tensor(2.2088)\n",
      "epoch: 62 train_loss: tensor(0.8883, grad_fn=<NllLossBackward>) average train loss tensor(0.9486, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48974245768947755 val_avg_loss: tensor(2.2224)\n",
      "epoch: 63 train_loss: tensor(0.8170, grad_fn=<NllLossBackward>) average train loss tensor(0.8925, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48806475349521705 val_avg_loss: tensor(2.2346)\n",
      "epoch: 64 train_loss: tensor(0.7580, grad_fn=<NllLossBackward>) average train loss tensor(0.9007, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.488476821192053 val_avg_loss: tensor(2.2345)\n",
      "epoch: 65 train_loss: tensor(0.8969, grad_fn=<NllLossBackward>) average train loss tensor(0.9022, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49159676232523913 val_avg_loss: tensor(2.2354)\n",
      "epoch: 66 train_loss: tensor(0.8405, grad_fn=<NllLossBackward>) average train loss tensor(0.8796, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49206769683590873 val_avg_loss: tensor(2.2447)\n",
      "epoch: 67 train_loss: tensor(0.7932, grad_fn=<NllLossBackward>) average train loss tensor(0.8420, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4877115526122149 val_avg_loss: tensor(2.2876)\n",
      "epoch: 68 train_loss: tensor(0.7885, grad_fn=<NllLossBackward>) average train loss tensor(0.8791, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.485710080941869 val_avg_loss: tensor(2.2922)\n",
      "epoch: 69 train_loss: tensor(0.7885, grad_fn=<NllLossBackward>) average train loss tensor(0.8542, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4880941869021339 val_avg_loss: tensor(2.2816)\n",
      "epoch: 70 train_loss: tensor(0.7518, grad_fn=<NllLossBackward>) average train loss tensor(0.8471, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4910080941869021 val_avg_loss: tensor(2.2877)\n",
      "epoch: 71 train_loss: tensor(0.7792, grad_fn=<NllLossBackward>) average train loss tensor(0.8497, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4894775570272259 val_avg_loss: tensor(2.3052)\n",
      "epoch: 72 train_loss: tensor(0.7172, grad_fn=<NllLossBackward>) average train loss tensor(0.8114, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48903605592347316 val_avg_loss: tensor(2.3049)\n",
      "epoch: 73 train_loss: tensor(0.7780, grad_fn=<NllLossBackward>) average train loss tensor(0.7859, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4864164827078734 val_avg_loss: tensor(2.3283)\n",
      "epoch: 74 train_loss: tensor(0.7373, grad_fn=<NllLossBackward>) average train loss tensor(0.7900, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48529801324503313 val_avg_loss: tensor(2.3479)\n",
      "epoch: 75 train_loss: tensor(0.7211, grad_fn=<NllLossBackward>) average train loss tensor(0.8078, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49041942604856514 val_avg_loss: tensor(2.3433)\n",
      "epoch: 76 train_loss: tensor(0.6819, grad_fn=<NllLossBackward>) average train loss tensor(0.7730, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4871523178807947 val_avg_loss: tensor(2.3600)\n",
      "epoch: 77 train_loss: tensor(0.6646, grad_fn=<NllLossBackward>) average train loss tensor(0.7653, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48462104488594554 val_avg_loss: tensor(2.3768)\n",
      "epoch: 78 train_loss: tensor(0.7150, grad_fn=<NllLossBackward>) average train loss tensor(0.7840, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4860338484179544 val_avg_loss: tensor(2.3902)\n",
      "epoch: 79 train_loss: tensor(0.6738, grad_fn=<NllLossBackward>) average train loss tensor(0.7392, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4869757174392936 val_avg_loss: tensor(2.3934)\n",
      "epoch: 80 train_loss: tensor(0.6834, grad_fn=<NllLossBackward>) average train loss tensor(0.7574, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4877115526122149 val_avg_loss: tensor(2.4049)\n",
      "epoch: 81 train_loss: tensor(0.7087, grad_fn=<NllLossBackward>) average train loss tensor(0.7385, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4887711552612215 val_avg_loss: tensor(2.4156)\n",
      "epoch: 82 train_loss: tensor(0.6373, grad_fn=<NllLossBackward>) average train loss tensor(0.7133, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4877998528329654 val_avg_loss: tensor(2.4067)\n",
      "epoch: 83 train_loss: tensor(0.5734, grad_fn=<NllLossBackward>) average train loss tensor(0.6917, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4840323767476085 val_avg_loss: tensor(2.4356)\n",
      "epoch: 84 train_loss: tensor(0.6133, grad_fn=<NllLossBackward>) average train loss tensor(0.7041, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4847093451066961 val_avg_loss: tensor(2.4612)\n",
      "epoch: 85 train_loss: tensor(0.6493, grad_fn=<NllLossBackward>) average train loss tensor(0.6773, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4847682119205298 val_avg_loss: tensor(2.4636)\n",
      "epoch: 86 train_loss: tensor(0.6459, grad_fn=<NllLossBackward>) average train loss tensor(0.7130, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48532744665195 val_avg_loss: tensor(2.4606)\n",
      "epoch: 87 train_loss: tensor(0.5960, grad_fn=<NllLossBackward>) average train loss tensor(0.6897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4855040470934511 val_avg_loss: tensor(2.4626)\n",
      "epoch: 88 train_loss: tensor(0.5582, grad_fn=<NllLossBackward>) average train loss tensor(0.6855, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48397350993377486 val_avg_loss: tensor(2.4867)\n",
      "epoch: 89 train_loss: tensor(0.6010, grad_fn=<NllLossBackward>) average train loss tensor(0.6544, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48329654157468727 val_avg_loss: tensor(2.4913)\n",
      "epoch: 90 train_loss: tensor(0.5413, grad_fn=<NllLossBackward>) average train loss tensor(0.6296, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48462104488594554 val_avg_loss: tensor(2.4844)\n",
      "epoch: 91 train_loss: tensor(0.6120, grad_fn=<NllLossBackward>) average train loss tensor(0.6711, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4873289183222958 val_avg_loss: tensor(2.5039)\n",
      "epoch: 92 train_loss: tensor(0.5090, grad_fn=<NllLossBackward>) average train loss tensor(0.6083, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4850331125827815 val_avg_loss: tensor(2.5302)\n",
      "epoch: 93 train_loss: tensor(0.5719, grad_fn=<NllLossBackward>) average train loss tensor(0.6456, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48353200883002206 val_avg_loss: tensor(2.5595)\n",
      "epoch: 94 train_loss: tensor(0.6515, grad_fn=<NllLossBackward>) average train loss tensor(0.6449, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4835614422369389 val_avg_loss: tensor(2.5710)\n",
      "epoch: 95 train_loss: tensor(0.5394, grad_fn=<NllLossBackward>) average train loss tensor(0.6228, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48606328182487124 val_avg_loss: tensor(2.5694)\n",
      "epoch: 96 train_loss: tensor(0.5521, grad_fn=<NllLossBackward>) average train loss tensor(0.6499, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48264900662251653 val_avg_loss: tensor(2.5730)\n",
      "epoch: 97 train_loss: tensor(0.5014, grad_fn=<NllLossBackward>) average train loss tensor(0.6081, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48129506990434145 val_avg_loss: tensor(2.5706)\n",
      "epoch: 98 train_loss: tensor(0.5678, grad_fn=<NllLossBackward>) average train loss tensor(0.6366, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48294334069168504 val_avg_loss: tensor(2.5698)\n",
      "epoch: 99 train_loss: tensor(0.5286, grad_fn=<NllLossBackward>) average train loss tensor(0.5856, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4859455481972038 val_avg_loss: tensor(2.5658)\n",
      "epoch: 100 train_loss: tensor(0.5337, grad_fn=<NllLossBackward>) average train loss tensor(0.5919, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48515084621044885 val_avg_loss: tensor(2.5679)\n",
      "epoch: 101 train_loss: tensor(0.5359, grad_fn=<NllLossBackward>) average train loss tensor(0.5686, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4830905077262693 val_avg_loss: tensor(2.5891)\n",
      "epoch: 102 train_loss: tensor(0.5066, grad_fn=<NllLossBackward>) average train loss tensor(0.6259, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4858866813833701 val_avg_loss: tensor(2.6122)\n",
      "epoch: 103 train_loss: tensor(0.5587, grad_fn=<NllLossBackward>) average train loss tensor(0.5800, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4861810154525386 val_avg_loss: tensor(2.6276)\n",
      "epoch: 104 train_loss: tensor(0.5680, grad_fn=<NllLossBackward>) average train loss tensor(0.6169, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48668138337012506 val_avg_loss: tensor(2.6260)\n",
      "epoch: 105 train_loss: tensor(0.6187, grad_fn=<NllLossBackward>) average train loss tensor(0.5936, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48314937454010304 val_avg_loss: tensor(2.6252)\n",
      "epoch: 106 train_loss: tensor(0.5455, grad_fn=<NllLossBackward>) average train loss tensor(0.5667, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4833259749816041 val_avg_loss: tensor(2.6448)\n",
      "epoch: 107 train_loss: tensor(0.5688, grad_fn=<NllLossBackward>) average train loss tensor(0.5785, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48282560706401767 val_avg_loss: tensor(2.6546)\n",
      "epoch: 108 train_loss: tensor(0.5412, grad_fn=<NllLossBackward>) average train loss tensor(0.5696, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4817365710080942 val_avg_loss: tensor(2.6857)\n",
      "epoch: 109 train_loss: tensor(0.4721, grad_fn=<NllLossBackward>) average train loss tensor(0.5210, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4810596026490066 val_avg_loss: tensor(2.7200)\n",
      "epoch: 110 train_loss: tensor(0.4152, grad_fn=<NllLossBackward>) average train loss tensor(0.5149, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48444444444444446 val_avg_loss: tensor(2.7068)\n",
      "epoch: 111 train_loss: tensor(0.4872, grad_fn=<NllLossBackward>) average train loss tensor(0.5415, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48621044885945547 val_avg_loss: tensor(2.7196)\n",
      "epoch: 112 train_loss: tensor(0.4436, grad_fn=<NllLossBackward>) average train loss tensor(0.5190, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48491537895511405 val_avg_loss: tensor(2.7274)\n",
      "epoch: 113 train_loss: tensor(0.4695, grad_fn=<NllLossBackward>) average train loss tensor(0.5075, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4845621780721118 val_avg_loss: tensor(2.7337)\n",
      "epoch: 114 train_loss: tensor(0.5011, grad_fn=<NllLossBackward>) average train loss tensor(0.5354, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48338484179543784 val_avg_loss: tensor(2.7665)\n",
      "epoch: 115 train_loss: tensor(0.4475, grad_fn=<NllLossBackward>) average train loss tensor(0.5184, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48376747608535686 val_avg_loss: tensor(2.7933)\n",
      "epoch: 116 train_loss: tensor(0.4168, grad_fn=<NllLossBackward>) average train loss tensor(0.5112, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48462104488594554 val_avg_loss: tensor(2.7871)\n",
      "epoch: 117 train_loss: tensor(0.4558, grad_fn=<NllLossBackward>) average train loss tensor(0.5143, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4824429727740986 val_avg_loss: tensor(2.7785)\n",
      "epoch: 118 train_loss: tensor(0.4340, grad_fn=<NllLossBackward>) average train loss tensor(0.5045, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801766004415011 val_avg_loss: tensor(2.7898)\n",
      "epoch: 119 train_loss: tensor(0.4264, grad_fn=<NllLossBackward>) average train loss tensor(0.4952, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801766004415011 val_avg_loss: tensor(2.8177)\n",
      "epoch: 120 train_loss: tensor(0.4574, grad_fn=<NllLossBackward>) average train loss tensor(0.5098, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48132450331125826 val_avg_loss: tensor(2.8103)\n",
      "epoch: 121 train_loss: tensor(0.4782, grad_fn=<NllLossBackward>) average train loss tensor(0.5359, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4845916114790287 val_avg_loss: tensor(2.7625)\n",
      "epoch: 122 train_loss: tensor(0.4407, grad_fn=<NllLossBackward>) average train loss tensor(0.4792, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4823546725533481 val_avg_loss: tensor(2.7746)\n",
      "epoch: 123 train_loss: tensor(0.4044, grad_fn=<NllLossBackward>) average train loss tensor(0.4733, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4785871964679912 val_avg_loss: tensor(2.8131)\n",
      "epoch: 124 train_loss: tensor(0.4615, grad_fn=<NllLossBackward>) average train loss tensor(0.4730, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759087564385578 val_avg_loss: tensor(2.8623)\n",
      "epoch: 125 train_loss: tensor(0.3767, grad_fn=<NllLossBackward>) average train loss tensor(0.4720, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47970566593083147 val_avg_loss: tensor(2.8906)\n",
      "epoch: 126 train_loss: tensor(0.4176, grad_fn=<NllLossBackward>) average train loss tensor(0.4746, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48200147167034585 val_avg_loss: tensor(2.9071)\n",
      "epoch: 127 train_loss: tensor(0.4788, grad_fn=<NllLossBackward>) average train loss tensor(0.5142, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.479205298013245 val_avg_loss: tensor(2.9192)\n",
      "epoch: 128 train_loss: tensor(0.4176, grad_fn=<NllLossBackward>) average train loss tensor(0.4675, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47793966151582046 val_avg_loss: tensor(2.9295)\n",
      "epoch: 129 train_loss: tensor(0.4989, grad_fn=<NllLossBackward>) average train loss tensor(0.4642, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47626195732155996 val_avg_loss: tensor(2.9497)\n",
      "epoch: 130 train_loss: tensor(0.4614, grad_fn=<NllLossBackward>) average train loss tensor(0.4768, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47902869757174393 val_avg_loss: tensor(2.9283)\n",
      "epoch: 131 train_loss: tensor(0.4244, grad_fn=<NllLossBackward>) average train loss tensor(0.4738, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.480588668138337 val_avg_loss: tensor(2.8901)\n",
      "epoch: 132 train_loss: tensor(0.3655, grad_fn=<NllLossBackward>) average train loss tensor(0.4406, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47864606328182485 val_avg_loss: tensor(2.8971)\n",
      "epoch: 133 train_loss: tensor(0.3913, grad_fn=<NllLossBackward>) average train loss tensor(0.4672, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47688005886681384 val_avg_loss: tensor(2.9126)\n",
      "epoch: 134 train_loss: tensor(0.4022, grad_fn=<NllLossBackward>) average train loss tensor(0.4606, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47938189845474616 val_avg_loss: tensor(2.9044)\n",
      "epoch: 135 train_loss: tensor(0.4551, grad_fn=<NllLossBackward>) average train loss tensor(0.4454, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4806769683590876 val_avg_loss: tensor(2.9203)\n",
      "epoch: 136 train_loss: tensor(0.3916, grad_fn=<NllLossBackward>) average train loss tensor(0.4235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48008830022075055 val_avg_loss: tensor(2.9410)\n",
      "epoch: 137 train_loss: tensor(0.3445, grad_fn=<NllLossBackward>) average train loss tensor(0.4065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47817512877115526 val_avg_loss: tensor(2.9806)\n",
      "epoch: 138 train_loss: tensor(0.3918, grad_fn=<NllLossBackward>) average train loss tensor(0.4217, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4797350993377483 val_avg_loss: tensor(3.0016)\n",
      "epoch: 139 train_loss: tensor(0.4137, grad_fn=<NllLossBackward>) average train loss tensor(0.4401, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48108903605592346 val_avg_loss: tensor(2.9988)\n",
      "epoch: 0 train_loss: tensor(3.8626, grad_fn=<NllLossBackward>) average train loss tensor(3.8913, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1012214863870493 val_avg_loss: tensor(3.8480)\n",
      "epoch: 1 train_loss: tensor(3.7496, grad_fn=<NllLossBackward>) average train loss tensor(3.7900, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.13495217071376012 val_avg_loss: tensor(3.7369)\n",
      "epoch: 2 train_loss: tensor(3.5519, grad_fn=<NllLossBackward>) average train loss tensor(3.6285, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1316850625459897 val_avg_loss: tensor(3.5469)\n",
      "epoch: 3 train_loss: tensor(3.3690, grad_fn=<NllLossBackward>) average train loss tensor(3.4599, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.15793966151582045 val_avg_loss: tensor(3.3940)\n",
      "epoch: 4 train_loss: tensor(3.1988, grad_fn=<NllLossBackward>) average train loss tensor(3.3060, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22033848417954377 val_avg_loss: tensor(3.2148)\n",
      "epoch: 5 train_loss: tensor(3.0543, grad_fn=<NllLossBackward>) average train loss tensor(3.1291, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.25824871228844737 val_avg_loss: tensor(3.0384)\n",
      "epoch: 6 train_loss: tensor(2.7955, grad_fn=<NllLossBackward>) average train loss tensor(2.9246, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3030757910228109 val_avg_loss: tensor(2.8518)\n",
      "epoch: 7 train_loss: tensor(2.6113, grad_fn=<NllLossBackward>) average train loss tensor(2.7142, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.33974981604120674 val_avg_loss: tensor(2.6799)\n",
      "epoch: 8 train_loss: tensor(2.4367, grad_fn=<NllLossBackward>) average train loss tensor(2.5338, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3663281824871229 val_avg_loss: tensor(2.5430)\n",
      "epoch: 9 train_loss: tensor(2.2700, grad_fn=<NllLossBackward>) average train loss tensor(2.3942, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3887270051508462 val_avg_loss: tensor(2.4369)\n",
      "epoch: 10 train_loss: tensor(2.1908, grad_fn=<NllLossBackward>) average train loss tensor(2.2483, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40008830022075054 val_avg_loss: tensor(2.3507)\n",
      "epoch: 11 train_loss: tensor(2.0444, grad_fn=<NllLossBackward>) average train loss tensor(2.1004, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4140397350993377 val_avg_loss: tensor(2.2768)\n",
      "epoch: 12 train_loss: tensor(1.8689, grad_fn=<NllLossBackward>) average train loss tensor(1.9572, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42534216335540836 val_avg_loss: tensor(2.2284)\n",
      "epoch: 13 train_loss: tensor(1.8234, grad_fn=<NllLossBackward>) average train loss tensor(1.8732, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4356438557763061 val_avg_loss: tensor(2.1831)\n",
      "epoch: 14 train_loss: tensor(1.6834, grad_fn=<NllLossBackward>) average train loss tensor(1.7685, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4453568800588668 val_avg_loss: tensor(2.1521)\n",
      "epoch: 15 train_loss: tensor(1.6605, grad_fn=<NllLossBackward>) average train loss tensor(1.6902, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45618837380426785 val_avg_loss: tensor(2.1253)\n",
      "epoch: 16 train_loss: tensor(1.5289, grad_fn=<NllLossBackward>) average train loss tensor(1.5990, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4601618837380427 val_avg_loss: tensor(2.1066)\n",
      "epoch: 17 train_loss: tensor(1.4087, grad_fn=<NllLossBackward>) average train loss tensor(1.5192, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46669610007358353 val_avg_loss: tensor(2.1005)\n",
      "epoch: 18 train_loss: tensor(1.4153, grad_fn=<NllLossBackward>) average train loss tensor(1.4853, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4701692420897719 val_avg_loss: tensor(2.1041)\n",
      "epoch: 19 train_loss: tensor(1.3121, grad_fn=<NllLossBackward>) average train loss tensor(1.3973, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47084621044885944 val_avg_loss: tensor(2.1219)\n",
      "epoch: 20 train_loss: tensor(1.2653, grad_fn=<NllLossBackward>) average train loss tensor(1.3460, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47458425312729946 val_avg_loss: tensor(2.1278)\n",
      "epoch: 21 train_loss: tensor(1.1867, grad_fn=<NllLossBackward>) average train loss tensor(1.2996, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47543782192788814 val_avg_loss: tensor(2.1314)\n",
      "epoch: 22 train_loss: tensor(1.1612, grad_fn=<NllLossBackward>) average train loss tensor(1.2344, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765268579838116 val_avg_loss: tensor(2.1457)\n",
      "epoch: 23 train_loss: tensor(1.0644, grad_fn=<NllLossBackward>) average train loss tensor(1.1911, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48008830022075055 val_avg_loss: tensor(2.1682)\n",
      "epoch: 24 train_loss: tensor(1.0731, grad_fn=<NllLossBackward>) average train loss tensor(1.1497, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.480588668138337 val_avg_loss: tensor(2.1881)\n",
      "epoch: 25 train_loss: tensor(1.0558, grad_fn=<NllLossBackward>) average train loss tensor(1.1156, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47779249448123623 val_avg_loss: tensor(2.2156)\n",
      "epoch: 26 train_loss: tensor(0.9715, grad_fn=<NllLossBackward>) average train loss tensor(1.0532, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48085356880058866 val_avg_loss: tensor(2.2352)\n",
      "epoch: 27 train_loss: tensor(0.9515, grad_fn=<NllLossBackward>) average train loss tensor(1.0060, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4789109639440765 val_avg_loss: tensor(2.2702)\n",
      "epoch: 28 train_loss: tensor(0.8387, grad_fn=<NllLossBackward>) average train loss tensor(0.9707, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47817512877115526 val_avg_loss: tensor(2.3167)\n",
      "epoch: 29 train_loss: tensor(0.8682, grad_fn=<NllLossBackward>) average train loss tensor(0.9392, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48055923473142015 val_avg_loss: tensor(2.3568)\n",
      "epoch: 30 train_loss: tensor(0.8691, grad_fn=<NllLossBackward>) average train loss tensor(0.8987, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4805298013245033 val_avg_loss: tensor(2.3659)\n",
      "epoch: 31 train_loss: tensor(0.7494, grad_fn=<NllLossBackward>) average train loss tensor(0.8566, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4798233995584989 val_avg_loss: tensor(2.3927)\n",
      "epoch: 32 train_loss: tensor(0.7997, grad_fn=<NllLossBackward>) average train loss tensor(0.8600, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4761442236938926 val_avg_loss: tensor(2.4434)\n",
      "epoch: 33 train_loss: tensor(0.6836, grad_fn=<NllLossBackward>) average train loss tensor(0.7990, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47832229580573954 val_avg_loss: tensor(2.4954)\n",
      "epoch: 34 train_loss: tensor(0.6984, grad_fn=<NllLossBackward>) average train loss tensor(0.7801, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47711552612214864 val_avg_loss: tensor(2.5051)\n",
      "epoch: 35 train_loss: tensor(0.6476, grad_fn=<NllLossBackward>) average train loss tensor(0.7300, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47405445180279615 val_avg_loss: tensor(2.5458)\n",
      "epoch: 36 train_loss: tensor(0.6506, grad_fn=<NllLossBackward>) average train loss tensor(0.7357, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748491537895511 val_avg_loss: tensor(2.5915)\n",
      "epoch: 37 train_loss: tensor(0.5874, grad_fn=<NllLossBackward>) average train loss tensor(0.6663, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.474083885209713 val_avg_loss: tensor(2.6427)\n",
      "epoch: 38 train_loss: tensor(0.6205, grad_fn=<NllLossBackward>) average train loss tensor(0.6740, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47093451066961 val_avg_loss: tensor(2.6998)\n",
      "epoch: 39 train_loss: tensor(0.5781, grad_fn=<NllLossBackward>) average train loss tensor(0.6415, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4746431199411332 val_avg_loss: tensor(2.7235)\n",
      "epoch: 40 train_loss: tensor(0.5794, grad_fn=<NllLossBackward>) average train loss tensor(0.6001, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4743782192788815 val_avg_loss: tensor(2.7729)\n",
      "epoch: 41 train_loss: tensor(0.5218, grad_fn=<NllLossBackward>) average train loss tensor(0.5998, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47305371596762325 val_avg_loss: tensor(2.8141)\n",
      "epoch: 42 train_loss: tensor(0.5220, grad_fn=<NllLossBackward>) average train loss tensor(0.5824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4681972038263429 val_avg_loss: tensor(2.8163)\n",
      "epoch: 43 train_loss: tensor(0.4527, grad_fn=<NllLossBackward>) average train loss tensor(0.5528, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4696983075791023 val_avg_loss: tensor(2.8487)\n",
      "epoch: 44 train_loss: tensor(0.5054, grad_fn=<NllLossBackward>) average train loss tensor(0.5427, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4696983075791023 val_avg_loss: tensor(2.9370)\n",
      "epoch: 45 train_loss: tensor(0.4744, grad_fn=<NllLossBackward>) average train loss tensor(0.5237, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46545989698307577 val_avg_loss: tensor(2.9811)\n",
      "epoch: 46 train_loss: tensor(0.4756, grad_fn=<NllLossBackward>) average train loss tensor(0.5118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4643708609271523 val_avg_loss: tensor(2.9735)\n",
      "epoch: 47 train_loss: tensor(0.4558, grad_fn=<NllLossBackward>) average train loss tensor(0.4831, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46707873436350256 val_avg_loss: tensor(3.0255)\n",
      "epoch: 48 train_loss: tensor(0.4473, grad_fn=<NllLossBackward>) average train loss tensor(0.4714, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4694922737306843 val_avg_loss: tensor(3.0477)\n",
      "epoch: 49 train_loss: tensor(0.4601, grad_fn=<NllLossBackward>) average train loss tensor(0.4692, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4649595290654893 val_avg_loss: tensor(3.1071)\n",
      "epoch: 50 train_loss: tensor(0.3913, grad_fn=<NllLossBackward>) average train loss tensor(0.4478, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4653421633554084 val_avg_loss: tensor(3.1821)\n",
      "epoch: 51 train_loss: tensor(0.4169, grad_fn=<NllLossBackward>) average train loss tensor(0.4365, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46722590139808684 val_avg_loss: tensor(3.2153)\n",
      "epoch: 52 train_loss: tensor(0.4088, grad_fn=<NllLossBackward>) average train loss tensor(0.4296, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4652832965415747 val_avg_loss: tensor(3.2087)\n",
      "epoch: 53 train_loss: tensor(0.3567, grad_fn=<NllLossBackward>) average train loss tensor(0.4137, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4634289919058131 val_avg_loss: tensor(3.2243)\n",
      "epoch: 54 train_loss: tensor(0.3601, grad_fn=<NllLossBackward>) average train loss tensor(0.4003, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4626048565121413 val_avg_loss: tensor(3.2874)\n",
      "epoch: 55 train_loss: tensor(0.3237, grad_fn=<NllLossBackward>) average train loss tensor(0.3642, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4602796173657101 val_avg_loss: tensor(3.3694)\n",
      "epoch: 56 train_loss: tensor(0.3172, grad_fn=<NllLossBackward>) average train loss tensor(0.3663, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46010301692420896 val_avg_loss: tensor(3.3960)\n",
      "epoch: 57 train_loss: tensor(0.3004, grad_fn=<NllLossBackward>) average train loss tensor(0.3414, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46054451802796176 val_avg_loss: tensor(3.4362)\n",
      "epoch: 58 train_loss: tensor(0.3520, grad_fn=<NllLossBackward>) average train loss tensor(0.3515, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4628403237674761 val_avg_loss: tensor(3.4940)\n",
      "epoch: 59 train_loss: tensor(0.3130, grad_fn=<NllLossBackward>) average train loss tensor(0.3463, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4605739514348786 val_avg_loss: tensor(3.5165)\n",
      "epoch: 60 train_loss: tensor(0.3308, grad_fn=<NllLossBackward>) average train loss tensor(0.3296, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4596615158204562 val_avg_loss: tensor(3.5309)\n",
      "epoch: 61 train_loss: tensor(0.2862, grad_fn=<NllLossBackward>) average train loss tensor(0.3096, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4588962472406181 val_avg_loss: tensor(3.5894)\n",
      "epoch: 62 train_loss: tensor(0.3400, grad_fn=<NllLossBackward>) average train loss tensor(0.3560, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46219278881530534 val_avg_loss: tensor(3.6093)\n",
      "epoch: 63 train_loss: tensor(0.2589, grad_fn=<NllLossBackward>) average train loss tensor(0.2933, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.460691685062546 val_avg_loss: tensor(3.6463)\n",
      "epoch: 64 train_loss: tensor(0.2585, grad_fn=<NllLossBackward>) average train loss tensor(0.2986, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45880794701986755 val_avg_loss: tensor(3.6667)\n",
      "epoch: 65 train_loss: tensor(0.2595, grad_fn=<NllLossBackward>) average train loss tensor(0.2995, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45439293598233993 val_avg_loss: tensor(3.7179)\n",
      "epoch: 66 train_loss: tensor(0.2649, grad_fn=<NllLossBackward>) average train loss tensor(0.2814, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4572479764532745 val_avg_loss: tensor(3.7679)\n",
      "epoch: 67 train_loss: tensor(0.2263, grad_fn=<NllLossBackward>) average train loss tensor(0.2659, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45933774834437086 val_avg_loss: tensor(3.8123)\n",
      "epoch: 68 train_loss: tensor(0.2363, grad_fn=<NllLossBackward>) average train loss tensor(0.2771, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45886681383370126 val_avg_loss: tensor(3.8130)\n",
      "epoch: 69 train_loss: tensor(0.2468, grad_fn=<NllLossBackward>) average train loss tensor(0.2770, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4550110375275938 val_avg_loss: tensor(3.8283)\n",
      "epoch: 70 train_loss: tensor(0.2188, grad_fn=<NllLossBackward>) average train loss tensor(0.2505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45607064017660043 val_avg_loss: tensor(3.8599)\n",
      "epoch: 71 train_loss: tensor(0.2540, grad_fn=<NllLossBackward>) average train loss tensor(0.2562, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45604120676968357 val_avg_loss: tensor(3.8914)\n",
      "epoch: 72 train_loss: tensor(0.2322, grad_fn=<NllLossBackward>) average train loss tensor(0.2505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45813097866078 val_avg_loss: tensor(3.9021)\n",
      "epoch: 73 train_loss: tensor(0.2134, grad_fn=<NllLossBackward>) average train loss tensor(0.2171, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4586019131714496 val_avg_loss: tensor(3.9361)\n",
      "epoch: 74 train_loss: tensor(0.2238, grad_fn=<NllLossBackward>) average train loss tensor(0.2239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4563061074319352 val_avg_loss: tensor(3.9914)\n",
      "epoch: 75 train_loss: tensor(0.2250, grad_fn=<NllLossBackward>) average train loss tensor(0.2469, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4520382634289919 val_avg_loss: tensor(4.0211)\n",
      "epoch: 76 train_loss: tensor(0.2887, grad_fn=<NllLossBackward>) average train loss tensor(0.2521, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45153789551140544 val_avg_loss: tensor(4.0650)\n",
      "epoch: 77 train_loss: tensor(0.1641, grad_fn=<NllLossBackward>) average train loss tensor(0.2211, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4544223693892568 val_avg_loss: tensor(4.1009)\n",
      "epoch: 78 train_loss: tensor(0.1993, grad_fn=<NllLossBackward>) average train loss tensor(0.2297, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45612950699043414 val_avg_loss: tensor(4.1234)\n",
      "epoch: 79 train_loss: tensor(0.2278, grad_fn=<NllLossBackward>) average train loss tensor(0.2371, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4537159676232524 val_avg_loss: tensor(4.1489)\n",
      "epoch: 80 train_loss: tensor(0.1937, grad_fn=<NllLossBackward>) average train loss tensor(0.2363, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503605592347314 val_avg_loss: tensor(4.1384)\n",
      "epoch: 81 train_loss: tensor(0.2455, grad_fn=<NllLossBackward>) average train loss tensor(0.2304, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4507137601177336 val_avg_loss: tensor(4.1520)\n",
      "epoch: 82 train_loss: tensor(0.2135, grad_fn=<NllLossBackward>) average train loss tensor(0.2236, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45345106696100074 val_avg_loss: tensor(4.1831)\n",
      "epoch: 83 train_loss: tensor(0.2376, grad_fn=<NllLossBackward>) average train loss tensor(0.2078, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4542457689477557 val_avg_loss: tensor(4.2314)\n",
      "epoch: 84 train_loss: tensor(0.1705, grad_fn=<NllLossBackward>) average train loss tensor(0.2356, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45415746872700513 val_avg_loss: tensor(4.2444)\n",
      "epoch: 85 train_loss: tensor(0.1927, grad_fn=<NllLossBackward>) average train loss tensor(0.2131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4526269315673289 val_avg_loss: tensor(4.2647)\n",
      "epoch: 86 train_loss: tensor(0.2419, grad_fn=<NllLossBackward>) average train loss tensor(0.2060, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4536571008094187 val_avg_loss: tensor(4.2614)\n",
      "epoch: 87 train_loss: tensor(0.1560, grad_fn=<NllLossBackward>) average train loss tensor(0.1966, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45153789551140544 val_avg_loss: tensor(4.2967)\n",
      "epoch: 88 train_loss: tensor(0.1603, grad_fn=<NllLossBackward>) average train loss tensor(0.1828, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45312729948491537 val_avg_loss: tensor(4.3572)\n",
      "epoch: 89 train_loss: tensor(0.1908, grad_fn=<NllLossBackward>) average train loss tensor(0.2056, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45445180279617364 val_avg_loss: tensor(4.3787)\n",
      "epoch: 90 train_loss: tensor(0.1849, grad_fn=<NllLossBackward>) average train loss tensor(0.1771, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.45398086828550405 val_avg_loss: tensor(4.3483)\n",
      "epoch: 91 train_loss: tensor(0.1832, grad_fn=<NllLossBackward>) average train loss tensor(0.1885, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4559823399558499 val_avg_loss: tensor(4.3706)\n",
      "epoch: 92 train_loss: tensor(0.1928, grad_fn=<NllLossBackward>) average train loss tensor(0.1960, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4544812362030905 val_avg_loss: tensor(4.4083)\n",
      "epoch: 93 train_loss: tensor(0.1831, grad_fn=<NllLossBackward>) average train loss tensor(0.1925, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4533038999264165 val_avg_loss: tensor(4.4273)\n",
      "epoch: 94 train_loss: tensor(0.1378, grad_fn=<NllLossBackward>) average train loss tensor(0.1867, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4529212656364974 val_avg_loss: tensor(4.4712)\n",
      "epoch: 95 train_loss: tensor(0.1954, grad_fn=<NllLossBackward>) average train loss tensor(0.1746, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45038999264164825 val_avg_loss: tensor(4.4507)\n",
      "epoch: 96 train_loss: tensor(0.1448, grad_fn=<NllLossBackward>) average train loss tensor(0.1758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4497130242825607 val_avg_loss: tensor(4.4917)\n",
      "epoch: 97 train_loss: tensor(0.1205, grad_fn=<NllLossBackward>) average train loss tensor(0.1659, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45268579838116263 val_avg_loss: tensor(4.5470)\n",
      "epoch: 98 train_loss: tensor(0.1151, grad_fn=<NllLossBackward>) average train loss tensor(0.1643, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.450242825607064 val_avg_loss: tensor(4.5640)\n",
      "epoch: 99 train_loss: tensor(0.1085, grad_fn=<NllLossBackward>) average train loss tensor(0.1544, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4513907284768212 val_avg_loss: tensor(4.5765)\n",
      "epoch: 100 train_loss: tensor(0.1155, grad_fn=<NllLossBackward>) average train loss tensor(0.1495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45124356144223693 val_avg_loss: tensor(4.6220)\n",
      "epoch: 101 train_loss: tensor(0.1718, grad_fn=<NllLossBackward>) average train loss tensor(0.1567, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45374540103016925 val_avg_loss: tensor(4.6588)\n",
      "epoch: 102 train_loss: tensor(0.1583, grad_fn=<NllLossBackward>) average train loss tensor(0.1486, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45571743929359826 val_avg_loss: tensor(4.6995)\n",
      "epoch: 103 train_loss: tensor(0.1346, grad_fn=<NllLossBackward>) average train loss tensor(0.1539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4548638704930096 val_avg_loss: tensor(4.7116)\n",
      "epoch: 104 train_loss: tensor(0.1399, grad_fn=<NllLossBackward>) average train loss tensor(0.1520, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45559970566593083 val_avg_loss: tensor(4.7319)\n",
      "epoch: 105 train_loss: tensor(0.1619, grad_fn=<NllLossBackward>) average train loss tensor(0.1422, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4518027961736571 val_avg_loss: tensor(4.7692)\n",
      "epoch: 106 train_loss: tensor(0.1505, grad_fn=<NllLossBackward>) average train loss tensor(0.1379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4506548933038999 val_avg_loss: tensor(4.7984)\n",
      "epoch: 107 train_loss: tensor(0.1326, grad_fn=<NllLossBackward>) average train loss tensor(0.1358, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45283296541574686 val_avg_loss: tensor(4.8451)\n",
      "epoch: 108 train_loss: tensor(0.1201, grad_fn=<NllLossBackward>) average train loss tensor(0.1540, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45200883002207504 val_avg_loss: tensor(4.8316)\n",
      "epoch: 109 train_loss: tensor(0.1391, grad_fn=<NllLossBackward>) average train loss tensor(0.1399, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4512141280353201 val_avg_loss: tensor(4.8784)\n",
      "epoch: 110 train_loss: tensor(0.1366, grad_fn=<NllLossBackward>) average train loss tensor(0.1473, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45159676232523915 val_avg_loss: tensor(4.9124)\n",
      "epoch: 111 train_loss: tensor(0.1280, grad_fn=<NllLossBackward>) average train loss tensor(0.1354, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4533038999264165 val_avg_loss: tensor(4.9638)\n",
      "epoch: 112 train_loss: tensor(0.1433, grad_fn=<NllLossBackward>) average train loss tensor(0.1460, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45298013245033114 val_avg_loss: tensor(4.9737)\n",
      "epoch: 113 train_loss: tensor(0.1339, grad_fn=<NllLossBackward>) average train loss tensor(0.1475, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503311258278146 val_avg_loss: tensor(4.9515)\n",
      "epoch: 114 train_loss: tensor(0.1683, grad_fn=<NllLossBackward>) average train loss tensor(0.1508, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.450242825607064 val_avg_loss: tensor(4.9345)\n",
      "epoch: 115 train_loss: tensor(0.1022, grad_fn=<NllLossBackward>) average train loss tensor(0.1271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4505077262693157 val_avg_loss: tensor(4.9658)\n",
      "epoch: 116 train_loss: tensor(0.1461, grad_fn=<NllLossBackward>) average train loss tensor(0.1362, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44906548933039 val_avg_loss: tensor(4.9894)\n",
      "epoch: 117 train_loss: tensor(0.1360, grad_fn=<NllLossBackward>) average train loss tensor(0.1222, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44718175128771154 val_avg_loss: tensor(4.9533)\n",
      "epoch: 118 train_loss: tensor(0.1708, grad_fn=<NllLossBackward>) average train loss tensor(0.1432, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44933038999264163 val_avg_loss: tensor(4.9748)\n",
      "epoch: 119 train_loss: tensor(0.1012, grad_fn=<NllLossBackward>) average train loss tensor(0.1140, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4513318616629875 val_avg_loss: tensor(5.0618)\n",
      "epoch: 120 train_loss: tensor(0.1126, grad_fn=<NllLossBackward>) average train loss tensor(0.1265, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44944812362030906 val_avg_loss: tensor(5.0704)\n",
      "epoch: 121 train_loss: tensor(0.0882, grad_fn=<NllLossBackward>) average train loss tensor(0.1120, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4460338484179544 val_avg_loss: tensor(5.0660)\n",
      "epoch: 122 train_loss: tensor(0.1194, grad_fn=<NllLossBackward>) average train loss tensor(0.1102, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44729948491537896 val_avg_loss: tensor(5.0872)\n",
      "epoch: 123 train_loss: tensor(0.1246, grad_fn=<NllLossBackward>) average train loss tensor(0.1168, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4485651214128035 val_avg_loss: tensor(5.1158)\n",
      "epoch: 124 train_loss: tensor(0.1086, grad_fn=<NllLossBackward>) average train loss tensor(0.1197, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.447682119205298 val_avg_loss: tensor(5.1498)\n",
      "epoch: 125 train_loss: tensor(0.1241, grad_fn=<NllLossBackward>) average train loss tensor(0.1316, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4484179543782193 val_avg_loss: tensor(5.1862)\n",
      "epoch: 126 train_loss: tensor(0.1158, grad_fn=<NllLossBackward>) average train loss tensor(0.1301, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44671081677704194 val_avg_loss: tensor(5.2130)\n",
      "epoch: 127 train_loss: tensor(0.1283, grad_fn=<NllLossBackward>) average train loss tensor(0.1231, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4469168506254599 val_avg_loss: tensor(5.1945)\n",
      "epoch: 128 train_loss: tensor(0.0618, grad_fn=<NllLossBackward>) average train loss tensor(0.1030, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44609271523178806 val_avg_loss: tensor(5.1851)\n",
      "epoch: 129 train_loss: tensor(0.1280, grad_fn=<NllLossBackward>) average train loss tensor(0.1265, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44497424576894773 val_avg_loss: tensor(5.1784)\n",
      "epoch: 130 train_loss: tensor(0.1251, grad_fn=<NllLossBackward>) average train loss tensor(0.1116, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44556291390728475 val_avg_loss: tensor(5.2194)\n",
      "epoch: 131 train_loss: tensor(0.1070, grad_fn=<NllLossBackward>) average train loss tensor(0.1028, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.447682119205298 val_avg_loss: tensor(5.2501)\n",
      "epoch: 132 train_loss: tensor(0.0851, grad_fn=<NllLossBackward>) average train loss tensor(0.0973, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4513318616629875 val_avg_loss: tensor(5.2743)\n",
      "epoch: 133 train_loss: tensor(0.0809, grad_fn=<NllLossBackward>) average train loss tensor(0.1010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45221486387049303 val_avg_loss: tensor(5.2793)\n",
      "epoch: 134 train_loss: tensor(0.1273, grad_fn=<NllLossBackward>) average train loss tensor(0.0986, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45021339220014717 val_avg_loss: tensor(5.2864)\n",
      "epoch: 135 train_loss: tensor(0.0741, grad_fn=<NllLossBackward>) average train loss tensor(0.0918, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44997792494481237 val_avg_loss: tensor(5.3089)\n",
      "epoch: 136 train_loss: tensor(0.1017, grad_fn=<NllLossBackward>) average train loss tensor(0.0996, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.45159676232523915 val_avg_loss: tensor(5.3114)\n",
      "epoch: 137 train_loss: tensor(0.0750, grad_fn=<NllLossBackward>) average train loss tensor(0.1037, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45153789551140544 val_avg_loss: tensor(5.3295)\n",
      "epoch: 138 train_loss: tensor(0.1094, grad_fn=<NllLossBackward>) average train loss tensor(0.1047, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44986019131714494 val_avg_loss: tensor(5.3397)\n",
      "epoch: 139 train_loss: tensor(0.0952, grad_fn=<NllLossBackward>) average train loss tensor(0.1027, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.449271523178808 val_avg_loss: tensor(5.3887)\n",
      "epoch: 0 train_loss: tensor(3.7994, grad_fn=<NllLossBackward>) average train loss tensor(3.8983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.08803532008830021 val_avg_loss: tensor(3.7558)\n",
      "epoch: 1 train_loss: tensor(3.6780, grad_fn=<NllLossBackward>) average train loss tensor(3.7378, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07579102281089035 val_avg_loss: tensor(3.6553)\n",
      "epoch: 2 train_loss: tensor(3.6011, grad_fn=<NllLossBackward>) average train loss tensor(3.6354, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.11958793230316409 val_avg_loss: tensor(3.5784)\n",
      "epoch: 3 train_loss: tensor(3.4809, grad_fn=<NllLossBackward>) average train loss tensor(3.5390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.16712288447387785 val_avg_loss: tensor(3.4848)\n",
      "epoch: 4 train_loss: tensor(3.3812, grad_fn=<NllLossBackward>) average train loss tensor(3.4380, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20459161147902868 val_avg_loss: tensor(3.3716)\n",
      "epoch: 5 train_loss: tensor(3.2703, grad_fn=<NllLossBackward>) average train loss tensor(3.3417, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22622516556291392 val_avg_loss: tensor(3.2516)\n",
      "epoch: 6 train_loss: tensor(3.1229, grad_fn=<NllLossBackward>) average train loss tensor(3.2000, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2519793966151582 val_avg_loss: tensor(3.1173)\n",
      "epoch: 7 train_loss: tensor(3.0100, grad_fn=<NllLossBackward>) average train loss tensor(3.0682, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2810301692420898 val_avg_loss: tensor(2.9697)\n",
      "epoch: 8 train_loss: tensor(2.9034, grad_fn=<NllLossBackward>) average train loss tensor(2.9434, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3043708609271523 val_avg_loss: tensor(2.8313)\n",
      "epoch: 9 train_loss: tensor(2.7538, grad_fn=<NllLossBackward>) average train loss tensor(2.8099, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3318027961736571 val_avg_loss: tensor(2.7098)\n",
      "epoch: 10 train_loss: tensor(2.6046, grad_fn=<NllLossBackward>) average train loss tensor(2.6872, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3450478292862399 val_avg_loss: tensor(2.6183)\n",
      "epoch: 11 train_loss: tensor(2.4627, grad_fn=<NllLossBackward>) average train loss tensor(2.5387, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3557615894039735 val_avg_loss: tensor(2.5203)\n",
      "epoch: 12 train_loss: tensor(2.4010, grad_fn=<NllLossBackward>) average train loss tensor(2.4644, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3705665930831494 val_avg_loss: tensor(2.4446)\n",
      "epoch: 13 train_loss: tensor(2.2181, grad_fn=<NllLossBackward>) average train loss tensor(2.3275, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3797203826342899 val_avg_loss: tensor(2.3815)\n",
      "epoch: 14 train_loss: tensor(2.1544, grad_fn=<NllLossBackward>) average train loss tensor(2.2123, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3906401766004415 val_avg_loss: tensor(2.3212)\n",
      "epoch: 15 train_loss: tensor(2.0624, grad_fn=<NllLossBackward>) average train loss tensor(2.1162, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3981162619573216 val_avg_loss: tensor(2.2787)\n",
      "epoch: 16 train_loss: tensor(1.9377, grad_fn=<NllLossBackward>) average train loss tensor(2.0337, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.408476821192053 val_avg_loss: tensor(2.2404)\n",
      "epoch: 17 train_loss: tensor(1.7857, grad_fn=<NllLossBackward>) average train loss tensor(1.9308, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4230169242089772 val_avg_loss: tensor(2.2131)\n",
      "epoch: 18 train_loss: tensor(1.7880, grad_fn=<NllLossBackward>) average train loss tensor(1.8891, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4277262693156733 val_avg_loss: tensor(2.1856)\n",
      "epoch: 19 train_loss: tensor(1.7026, grad_fn=<NllLossBackward>) average train loss tensor(1.7692, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4359381898454746 val_avg_loss: tensor(2.1592)\n",
      "epoch: 20 train_loss: tensor(1.6269, grad_fn=<NllLossBackward>) average train loss tensor(1.7342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43905813097866075 val_avg_loss: tensor(2.1526)\n",
      "epoch: 21 train_loss: tensor(1.6459, grad_fn=<NllLossBackward>) average train loss tensor(1.6839, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4485945548197204 val_avg_loss: tensor(2.1329)\n",
      "epoch: 22 train_loss: tensor(1.5956, grad_fn=<NllLossBackward>) average train loss tensor(1.6352, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4531567328918322 val_avg_loss: tensor(2.1359)\n",
      "epoch: 23 train_loss: tensor(1.4864, grad_fn=<NllLossBackward>) average train loss tensor(1.5581, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45415746872700513 val_avg_loss: tensor(2.1437)\n",
      "epoch: 24 train_loss: tensor(1.4686, grad_fn=<NllLossBackward>) average train loss tensor(1.4983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45727740986019133 val_avg_loss: tensor(2.1424)\n",
      "epoch: 25 train_loss: tensor(1.3713, grad_fn=<NllLossBackward>) average train loss tensor(1.4328, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4572479764532745 val_avg_loss: tensor(2.1631)\n",
      "epoch: 26 train_loss: tensor(1.3191, grad_fn=<NllLossBackward>) average train loss tensor(1.3993, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4611331861662987 val_avg_loss: tensor(2.1639)\n",
      "epoch: 27 train_loss: tensor(1.3030, grad_fn=<NllLossBackward>) average train loss tensor(1.3357, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4669610007358352 val_avg_loss: tensor(2.1631)\n",
      "epoch: 28 train_loss: tensor(1.2103, grad_fn=<NllLossBackward>) average train loss tensor(1.3031, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4611626195732156 val_avg_loss: tensor(2.1999)\n",
      "epoch: 29 train_loss: tensor(1.1858, grad_fn=<NllLossBackward>) average train loss tensor(1.2723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4621339220014717 val_avg_loss: tensor(2.2129)\n",
      "epoch: 30 train_loss: tensor(1.0872, grad_fn=<NllLossBackward>) average train loss tensor(1.1948, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4628403237674761 val_avg_loss: tensor(2.2149)\n",
      "epoch: 31 train_loss: tensor(1.0834, grad_fn=<NllLossBackward>) average train loss tensor(1.1519, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46875643855776306 val_avg_loss: tensor(2.2406)\n",
      "epoch: 32 train_loss: tensor(1.0980, grad_fn=<NllLossBackward>) average train loss tensor(1.1206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46928623988226636 val_avg_loss: tensor(2.2707)\n",
      "epoch: 33 train_loss: tensor(1.0001, grad_fn=<NllLossBackward>) average train loss tensor(1.0408, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4681383370125092 val_avg_loss: tensor(2.3010)\n",
      "epoch: 34 train_loss: tensor(0.9356, grad_fn=<NllLossBackward>) average train loss tensor(1.0113, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46828550404709346 val_avg_loss: tensor(2.3308)\n",
      "epoch: 35 train_loss: tensor(0.9868, grad_fn=<NllLossBackward>) average train loss tensor(1.0132, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4686092715231788 val_avg_loss: tensor(2.3539)\n",
      "epoch: 36 train_loss: tensor(0.7873, grad_fn=<NllLossBackward>) average train loss tensor(0.9399, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4652832965415747 val_avg_loss: tensor(2.3825)\n",
      "epoch: 37 train_loss: tensor(0.8419, grad_fn=<NllLossBackward>) average train loss tensor(0.9188, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4645180279617366 val_avg_loss: tensor(2.4449)\n",
      "epoch: 38 train_loss: tensor(0.7636, grad_fn=<NllLossBackward>) average train loss tensor(0.8686, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46334069168506253 val_avg_loss: tensor(2.5140)\n",
      "epoch: 39 train_loss: tensor(0.7979, grad_fn=<NllLossBackward>) average train loss tensor(0.8280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4621339220014717 val_avg_loss: tensor(2.5448)\n",
      "epoch: 40 train_loss: tensor(0.6976, grad_fn=<NllLossBackward>) average train loss tensor(0.8097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4654304635761589 val_avg_loss: tensor(2.5496)\n",
      "epoch: 41 train_loss: tensor(0.6914, grad_fn=<NllLossBackward>) average train loss tensor(0.7598, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46548933038999263 val_avg_loss: tensor(2.5854)\n",
      "epoch: 42 train_loss: tensor(0.7037, grad_fn=<NllLossBackward>) average train loss tensor(0.7472, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4657542310522443 val_avg_loss: tensor(2.6130)\n",
      "epoch: 43 train_loss: tensor(0.6575, grad_fn=<NllLossBackward>) average train loss tensor(0.7042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4603679175864606 val_avg_loss: tensor(2.6708)\n",
      "epoch: 44 train_loss: tensor(0.6693, grad_fn=<NllLossBackward>) average train loss tensor(0.6891, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46278145695364237 val_avg_loss: tensor(2.7573)\n",
      "epoch: 45 train_loss: tensor(0.6130, grad_fn=<NllLossBackward>) average train loss tensor(0.6710, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4624282560706402 val_avg_loss: tensor(2.7753)\n",
      "epoch: 46 train_loss: tensor(0.5786, grad_fn=<NllLossBackward>) average train loss tensor(0.6311, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45789551140544515 val_avg_loss: tensor(2.7998)\n",
      "epoch: 47 train_loss: tensor(0.5894, grad_fn=<NllLossBackward>) average train loss tensor(0.6384, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46125091979396615 val_avg_loss: tensor(2.8218)\n",
      "epoch: 48 train_loss: tensor(0.4750, grad_fn=<NllLossBackward>) average train loss tensor(0.5851, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45818984547461367 val_avg_loss: tensor(2.9195)\n",
      "epoch: 49 train_loss: tensor(0.4896, grad_fn=<NllLossBackward>) average train loss tensor(0.5342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4580721118469463 val_avg_loss: tensor(2.9293)\n",
      "epoch: 50 train_loss: tensor(0.5020, grad_fn=<NllLossBackward>) average train loss tensor(0.5431, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45939661515820457 val_avg_loss: tensor(2.9883)\n",
      "epoch: 51 train_loss: tensor(0.4356, grad_fn=<NllLossBackward>) average train loss tensor(0.5251, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45665930831493745 val_avg_loss: tensor(3.0342)\n",
      "epoch: 52 train_loss: tensor(0.4037, grad_fn=<NllLossBackward>) average train loss tensor(0.4830, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45289183222958057 val_avg_loss: tensor(3.0853)\n",
      "epoch: 53 train_loss: tensor(0.4529, grad_fn=<NllLossBackward>) average train loss tensor(0.4673, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.453009565857248 val_avg_loss: tensor(3.1665)\n",
      "epoch: 54 train_loss: tensor(0.4067, grad_fn=<NllLossBackward>) average train loss tensor(0.4532, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4549227373068433 val_avg_loss: tensor(3.1918)\n",
      "epoch: 55 train_loss: tensor(0.3771, grad_fn=<NllLossBackward>) average train loss tensor(0.4523, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4550110375275938 val_avg_loss: tensor(3.1900)\n",
      "epoch: 56 train_loss: tensor(0.3839, grad_fn=<NllLossBackward>) average train loss tensor(0.4291, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45536423841059603 val_avg_loss: tensor(3.2271)\n",
      "epoch: 57 train_loss: tensor(0.3225, grad_fn=<NllLossBackward>) average train loss tensor(0.4108, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4538337012509198 val_avg_loss: tensor(3.2734)\n",
      "epoch: 58 train_loss: tensor(0.3597, grad_fn=<NllLossBackward>) average train loss tensor(0.4171, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4541280353200883 val_avg_loss: tensor(3.3229)\n",
      "epoch: 59 train_loss: tensor(0.3329, grad_fn=<NllLossBackward>) average train loss tensor(0.3845, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4511552612214864 val_avg_loss: tensor(3.3816)\n",
      "epoch: 60 train_loss: tensor(0.3377, grad_fn=<NllLossBackward>) average train loss tensor(0.3682, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45153789551140544 val_avg_loss: tensor(3.4009)\n",
      "epoch: 61 train_loss: tensor(0.3657, grad_fn=<NllLossBackward>) average train loss tensor(0.3778, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4498307579102281 val_avg_loss: tensor(3.4532)\n",
      "epoch: 62 train_loss: tensor(0.3173, grad_fn=<NllLossBackward>) average train loss tensor(0.3447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4507431935246505 val_avg_loss: tensor(3.4845)\n",
      "epoch: 63 train_loss: tensor(0.3198, grad_fn=<NllLossBackward>) average train loss tensor(0.3367, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44862398822663724 val_avg_loss: tensor(3.5356)\n",
      "epoch: 64 train_loss: tensor(0.2921, grad_fn=<NllLossBackward>) average train loss tensor(0.3212, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4497130242825607 val_avg_loss: tensor(3.5415)\n",
      "epoch: 65 train_loss: tensor(0.3292, grad_fn=<NllLossBackward>) average train loss tensor(0.3304, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4498896247240618 val_avg_loss: tensor(3.5309)\n",
      "epoch: 66 train_loss: tensor(0.2510, grad_fn=<NllLossBackward>) average train loss tensor(0.3093, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44771155261221485 val_avg_loss: tensor(3.5626)\n",
      "epoch: 67 train_loss: tensor(0.2637, grad_fn=<NllLossBackward>) average train loss tensor(0.2999, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44747608535688005 val_avg_loss: tensor(3.6574)\n",
      "epoch: 68 train_loss: tensor(0.2527, grad_fn=<NllLossBackward>) average train loss tensor(0.3004, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44609271523178806 val_avg_loss: tensor(3.7275)\n",
      "epoch: 69 train_loss: tensor(0.2508, grad_fn=<NllLossBackward>) average train loss tensor(0.3018, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4442384105960265 val_avg_loss: tensor(3.7829)\n",
      "epoch: 70 train_loss: tensor(0.2314, grad_fn=<NllLossBackward>) average train loss tensor(0.2765, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4469757174392936 val_avg_loss: tensor(3.8215)\n",
      "epoch: 71 train_loss: tensor(0.2377, grad_fn=<NllLossBackward>) average train loss tensor(0.2665, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503605592347314 val_avg_loss: tensor(3.8390)\n",
      "epoch: 72 train_loss: tensor(0.2563, grad_fn=<NllLossBackward>) average train loss tensor(0.2584, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44885945548197204 val_avg_loss: tensor(3.8999)\n",
      "epoch: 73 train_loss: tensor(0.2016, grad_fn=<NllLossBackward>) average train loss tensor(0.2401, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44332597498160414 val_avg_loss: tensor(3.9319)\n",
      "epoch: 74 train_loss: tensor(0.2245, grad_fn=<NllLossBackward>) average train loss tensor(0.2594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44279617365710083 val_avg_loss: tensor(3.9970)\n",
      "epoch: 75 train_loss: tensor(0.2059, grad_fn=<NllLossBackward>) average train loss tensor(0.2423, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430610743193525 val_avg_loss: tensor(3.9781)\n",
      "epoch: 76 train_loss: tensor(0.1792, grad_fn=<NllLossBackward>) average train loss tensor(0.2315, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44303164091243563 val_avg_loss: tensor(3.9993)\n",
      "epoch: 77 train_loss: tensor(0.1984, grad_fn=<NllLossBackward>) average train loss tensor(0.2284, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4439735099337748 val_avg_loss: tensor(3.9872)\n",
      "epoch: 78 train_loss: tensor(0.2378, grad_fn=<NllLossBackward>) average train loss tensor(0.2463, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44341427520235466 val_avg_loss: tensor(4.0199)\n",
      "epoch: 79 train_loss: tensor(0.2378, grad_fn=<NllLossBackward>) average train loss tensor(0.2388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44385577630610745 val_avg_loss: tensor(4.1189)\n",
      "epoch: 80 train_loss: tensor(0.2292, grad_fn=<NllLossBackward>) average train loss tensor(0.2133, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44259013980868284 val_avg_loss: tensor(4.1758)\n",
      "epoch: 81 train_loss: tensor(0.1963, grad_fn=<NllLossBackward>) average train loss tensor(0.2255, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44235467255334804 val_avg_loss: tensor(4.2343)\n",
      "epoch: 82 train_loss: tensor(0.2269, grad_fn=<NllLossBackward>) average train loss tensor(0.2193, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44335540838852094 val_avg_loss: tensor(4.2727)\n",
      "epoch: 83 train_loss: tensor(0.1740, grad_fn=<NllLossBackward>) average train loss tensor(0.1989, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44394407652685797 val_avg_loss: tensor(4.2770)\n",
      "epoch: 84 train_loss: tensor(0.1577, grad_fn=<NllLossBackward>) average train loss tensor(0.2071, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44373804267844 val_avg_loss: tensor(4.2888)\n",
      "epoch: 85 train_loss: tensor(0.1453, grad_fn=<NllLossBackward>) average train loss tensor(0.1830, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44409124356144225 val_avg_loss: tensor(4.3048)\n",
      "epoch: 86 train_loss: tensor(0.1562, grad_fn=<NllLossBackward>) average train loss tensor(0.1804, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4477998528329654 val_avg_loss: tensor(4.2801)\n",
      "epoch: 87 train_loss: tensor(0.1497, grad_fn=<NllLossBackward>) average train loss tensor(0.1783, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4442384105960265 val_avg_loss: tensor(4.3167)\n",
      "epoch: 88 train_loss: tensor(0.1721, grad_fn=<NllLossBackward>) average train loss tensor(0.2016, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.44282560706401763 val_avg_loss: tensor(4.3616)\n",
      "epoch: 89 train_loss: tensor(0.1525, grad_fn=<NllLossBackward>) average train loss tensor(0.1697, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44182487122884473 val_avg_loss: tensor(4.4300)\n",
      "epoch: 90 train_loss: tensor(0.1881, grad_fn=<NllLossBackward>) average train loss tensor(0.1753, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4438852097130243 val_avg_loss: tensor(4.4808)\n",
      "epoch: 91 train_loss: tensor(0.1771, grad_fn=<NllLossBackward>) average train loss tensor(0.1586, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.444532744665195 val_avg_loss: tensor(4.5680)\n",
      "epoch: 92 train_loss: tensor(0.1600, grad_fn=<NllLossBackward>) average train loss tensor(0.1650, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4464459161147903 val_avg_loss: tensor(4.6406)\n",
      "epoch: 93 train_loss: tensor(0.1390, grad_fn=<NllLossBackward>) average train loss tensor(0.1600, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.445121412803532 val_avg_loss: tensor(4.6056)\n",
      "epoch: 94 train_loss: tensor(0.1395, grad_fn=<NllLossBackward>) average train loss tensor(0.1515, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4435320088300221 val_avg_loss: tensor(4.5466)\n",
      "epoch: 95 train_loss: tensor(0.1204, grad_fn=<NllLossBackward>) average train loss tensor(0.1528, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44462104488594556 val_avg_loss: tensor(4.5236)\n",
      "epoch: 96 train_loss: tensor(0.1252, grad_fn=<NllLossBackward>) average train loss tensor(0.1577, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4453568800588668 val_avg_loss: tensor(4.5226)\n",
      "epoch: 97 train_loss: tensor(0.1036, grad_fn=<NllLossBackward>) average train loss tensor(0.1387, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44815305371596764 val_avg_loss: tensor(4.6033)\n",
      "epoch: 98 train_loss: tensor(0.1292, grad_fn=<NllLossBackward>) average train loss tensor(0.1479, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44862398822663724 val_avg_loss: tensor(4.6515)\n",
      "epoch: 99 train_loss: tensor(0.1433, grad_fn=<NllLossBackward>) average train loss tensor(0.1425, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44594554819720383 val_avg_loss: tensor(4.7251)\n",
      "epoch: 100 train_loss: tensor(0.1172, grad_fn=<NllLossBackward>) average train loss tensor(0.1302, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44347314201618837 val_avg_loss: tensor(4.7681)\n",
      "epoch: 101 train_loss: tensor(0.1266, grad_fn=<NllLossBackward>) average train loss tensor(0.1352, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4448270787343635 val_avg_loss: tensor(4.7521)\n",
      "epoch: 102 train_loss: tensor(0.0832, grad_fn=<NllLossBackward>) average train loss tensor(0.1277, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4456512141280353 val_avg_loss: tensor(4.7842)\n",
      "epoch: 103 train_loss: tensor(0.1139, grad_fn=<NllLossBackward>) average train loss tensor(0.1391, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44585724797645326 val_avg_loss: tensor(4.8234)\n",
      "epoch: 104 train_loss: tensor(0.1078, grad_fn=<NllLossBackward>) average train loss tensor(0.1297, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4455334805003679 val_avg_loss: tensor(4.8477)\n",
      "epoch: 105 train_loss: tensor(0.1082, grad_fn=<NllLossBackward>) average train loss tensor(0.1352, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4447682119205298 val_avg_loss: tensor(4.8125)\n",
      "epoch: 106 train_loss: tensor(0.1084, grad_fn=<NllLossBackward>) average train loss tensor(0.1167, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4459749816041207 val_avg_loss: tensor(4.7811)\n",
      "epoch: 107 train_loss: tensor(0.1247, grad_fn=<NllLossBackward>) average train loss tensor(0.1059, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44700515084621045 val_avg_loss: tensor(4.8447)\n",
      "epoch: 108 train_loss: tensor(0.0988, grad_fn=<NllLossBackward>) average train loss tensor(0.1233, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44706401766004417 val_avg_loss: tensor(4.9024)\n",
      "epoch: 109 train_loss: tensor(0.1015, grad_fn=<NllLossBackward>) average train loss tensor(0.1144, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4448859455481972 val_avg_loss: tensor(4.9489)\n",
      "epoch: 110 train_loss: tensor(0.1196, grad_fn=<NllLossBackward>) average train loss tensor(0.1251, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4426195732155997 val_avg_loss: tensor(4.9017)\n",
      "epoch: 111 train_loss: tensor(0.0834, grad_fn=<NllLossBackward>) average train loss tensor(0.1246, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4423252391464312 val_avg_loss: tensor(4.8925)\n",
      "epoch: 112 train_loss: tensor(0.1068, grad_fn=<NllLossBackward>) average train loss tensor(0.1151, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44532744665194995 val_avg_loss: tensor(4.9258)\n",
      "epoch: 113 train_loss: tensor(0.0888, grad_fn=<NllLossBackward>) average train loss tensor(0.0939, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44600441501103755 val_avg_loss: tensor(4.9969)\n",
      "epoch: 114 train_loss: tensor(0.0811, grad_fn=<NllLossBackward>) average train loss tensor(0.0964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44576894775570275 val_avg_loss: tensor(5.0910)\n",
      "epoch: 115 train_loss: tensor(0.1133, grad_fn=<NllLossBackward>) average train loss tensor(0.1086, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4440029433406917 val_avg_loss: tensor(5.1249)\n",
      "epoch: 116 train_loss: tensor(0.0766, grad_fn=<NllLossBackward>) average train loss tensor(0.0963, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43944076526857984 val_avg_loss: tensor(5.1187)\n",
      "epoch: 117 train_loss: tensor(0.1144, grad_fn=<NllLossBackward>) average train loss tensor(0.1174, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44170713760117736 val_avg_loss: tensor(5.1060)\n",
      "epoch: 118 train_loss: tensor(0.0654, grad_fn=<NllLossBackward>) average train loss tensor(0.0866, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44571008094186904 val_avg_loss: tensor(5.0658)\n",
      "epoch: 119 train_loss: tensor(0.0832, grad_fn=<NllLossBackward>) average train loss tensor(0.1010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.445916114790287 val_avg_loss: tensor(5.0346)\n",
      "epoch: 120 train_loss: tensor(0.0893, grad_fn=<NllLossBackward>) average train loss tensor(0.0862, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44370860927152317 val_avg_loss: tensor(5.0331)\n",
      "epoch: 121 train_loss: tensor(0.0971, grad_fn=<NllLossBackward>) average train loss tensor(0.0946, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4440029433406917 val_avg_loss: tensor(5.1071)\n",
      "epoch: 122 train_loss: tensor(0.0727, grad_fn=<NllLossBackward>) average train loss tensor(0.0885, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44279617365710083 val_avg_loss: tensor(5.1668)\n",
      "epoch: 123 train_loss: tensor(0.1010, grad_fn=<NllLossBackward>) average train loss tensor(0.0957, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4432965415746873 val_avg_loss: tensor(5.2604)\n",
      "epoch: 124 train_loss: tensor(0.1071, grad_fn=<NllLossBackward>) average train loss tensor(0.0991, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44417954378219277 val_avg_loss: tensor(5.3167)\n",
      "epoch: 125 train_loss: tensor(0.0697, grad_fn=<NllLossBackward>) average train loss tensor(0.0975, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44629874908020606 val_avg_loss: tensor(5.2351)\n",
      "epoch: 126 train_loss: tensor(0.1227, grad_fn=<NllLossBackward>) average train loss tensor(0.0967, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44247240618101547 val_avg_loss: tensor(5.2282)\n",
      "epoch: 127 train_loss: tensor(0.0692, grad_fn=<NllLossBackward>) average train loss tensor(0.0863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44120676968359085 val_avg_loss: tensor(5.1943)\n",
      "epoch: 128 train_loss: tensor(0.1007, grad_fn=<NllLossBackward>) average train loss tensor(0.0992, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44164827078734364 val_avg_loss: tensor(5.2165)\n",
      "epoch: 129 train_loss: tensor(0.1016, grad_fn=<NllLossBackward>) average train loss tensor(0.0884, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4418543046357616 val_avg_loss: tensor(5.2695)\n",
      "epoch: 130 train_loss: tensor(0.0963, grad_fn=<NllLossBackward>) average train loss tensor(0.1066, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44417954378219277 val_avg_loss: tensor(5.2633)\n",
      "epoch: 131 train_loss: tensor(0.0551, grad_fn=<NllLossBackward>) average train loss tensor(0.0835, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.441383370125092 val_avg_loss: tensor(5.2586)\n",
      "epoch: 132 train_loss: tensor(0.0983, grad_fn=<NllLossBackward>) average train loss tensor(0.0791, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4413245033112583 val_avg_loss: tensor(5.3132)\n",
      "epoch: 133 train_loss: tensor(0.0876, grad_fn=<NllLossBackward>) average train loss tensor(0.1058, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44311994113318615 val_avg_loss: tensor(5.3290)\n",
      "epoch: 134 train_loss: tensor(0.0708, grad_fn=<NllLossBackward>) average train loss tensor(0.0858, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.445121412803532 val_avg_loss: tensor(5.3603)\n",
      "epoch: 135 train_loss: tensor(0.0859, grad_fn=<NllLossBackward>) average train loss tensor(0.0812, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4440029433406917 val_avg_loss: tensor(5.4543)\n",
      "epoch: 136 train_loss: tensor(0.0791, grad_fn=<NllLossBackward>) average train loss tensor(0.0911, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4442384105960265 val_avg_loss: tensor(5.4508)\n",
      "epoch: 137 train_loss: tensor(0.0634, grad_fn=<NllLossBackward>) average train loss tensor(0.0697, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44179543782192787 val_avg_loss: tensor(5.4740)\n",
      "epoch: 138 train_loss: tensor(0.1358, grad_fn=<NllLossBackward>) average train loss tensor(0.0892, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4398822663723326 val_avg_loss: tensor(5.5204)\n",
      "epoch: 139 train_loss: tensor(0.0699, grad_fn=<NllLossBackward>) average train loss tensor(0.0827, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4429727740986019 val_avg_loss: tensor(5.4941)\n",
      "epoch: 0 train_loss: tensor(3.8323, grad_fn=<NllLossBackward>) average train loss tensor(3.9011, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07729212656364974 val_avg_loss: tensor(3.8103)\n",
      "epoch: 1 train_loss: tensor(3.7079, grad_fn=<NllLossBackward>) average train loss tensor(3.7527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.09760117733627667 val_avg_loss: tensor(3.6963)\n",
      "epoch: 2 train_loss: tensor(3.6263, grad_fn=<NllLossBackward>) average train loss tensor(3.6521, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1484326710816777 val_avg_loss: tensor(3.6024)\n",
      "epoch: 3 train_loss: tensor(3.4796, grad_fn=<NllLossBackward>) average train loss tensor(3.5583, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.13972038263428993 val_avg_loss: tensor(3.5032)\n",
      "epoch: 4 train_loss: tensor(3.4097, grad_fn=<NllLossBackward>) average train loss tensor(3.4539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20044150110375275 val_avg_loss: tensor(3.3848)\n",
      "epoch: 5 train_loss: tensor(3.3150, grad_fn=<NllLossBackward>) average train loss tensor(3.3523, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.23502575423105224 val_avg_loss: tensor(3.2475)\n",
      "epoch: 6 train_loss: tensor(3.1221, grad_fn=<NllLossBackward>) average train loss tensor(3.2161, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.24856512141280354 val_avg_loss: tensor(3.0946)\n",
      "epoch: 7 train_loss: tensor(3.0120, grad_fn=<NllLossBackward>) average train loss tensor(3.0866, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2640176600441501 val_avg_loss: tensor(2.9464)\n",
      "epoch: 8 train_loss: tensor(2.8582, grad_fn=<NllLossBackward>) average train loss tensor(2.9410, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.29969094922737305 val_avg_loss: tensor(2.8123)\n",
      "epoch: 9 train_loss: tensor(2.7467, grad_fn=<NllLossBackward>) average train loss tensor(2.8186, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.33383370125091977 val_avg_loss: tensor(2.6831)\n",
      "epoch: 10 train_loss: tensor(2.6348, grad_fn=<NllLossBackward>) average train loss tensor(2.7222, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.346401766004415 val_avg_loss: tensor(2.5747)\n",
      "epoch: 11 train_loss: tensor(2.4974, grad_fn=<NllLossBackward>) average train loss tensor(2.5668, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.36079470198675495 val_avg_loss: tensor(2.4855)\n",
      "epoch: 12 train_loss: tensor(2.3842, grad_fn=<NllLossBackward>) average train loss tensor(2.4659, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3703899926416483 val_avg_loss: tensor(2.4109)\n",
      "epoch: 13 train_loss: tensor(2.3265, grad_fn=<NllLossBackward>) average train loss tensor(2.3772, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3827814569536424 val_avg_loss: tensor(2.3434)\n",
      "epoch: 14 train_loss: tensor(2.2347, grad_fn=<NllLossBackward>) average train loss tensor(2.2954, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.39467255334805 val_avg_loss: tensor(2.2901)\n",
      "epoch: 15 train_loss: tensor(2.1281, grad_fn=<NllLossBackward>) average train loss tensor(2.2197, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40335540838852096 val_avg_loss: tensor(2.2479)\n",
      "epoch: 16 train_loss: tensor(2.0606, grad_fn=<NllLossBackward>) average train loss tensor(2.1469, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.41018395879323033 val_avg_loss: tensor(2.2135)\n",
      "epoch: 17 train_loss: tensor(1.9529, grad_fn=<NllLossBackward>) average train loss tensor(2.0833, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4174245768947756 val_avg_loss: tensor(2.1783)\n",
      "epoch: 18 train_loss: tensor(1.9187, grad_fn=<NllLossBackward>) average train loss tensor(2.0433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42643119941133184 val_avg_loss: tensor(2.1533)\n",
      "epoch: 19 train_loss: tensor(1.9619, grad_fn=<NllLossBackward>) average train loss tensor(2.0037, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4373804267844003 val_avg_loss: tensor(2.1149)\n",
      "epoch: 20 train_loss: tensor(1.8966, grad_fn=<NllLossBackward>) average train loss tensor(1.9283, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44462104488594556 val_avg_loss: tensor(2.0842)\n",
      "epoch: 21 train_loss: tensor(1.8320, grad_fn=<NllLossBackward>) average train loss tensor(1.8904, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4452097130242826 val_avg_loss: tensor(2.0778)\n",
      "epoch: 22 train_loss: tensor(1.8063, grad_fn=<NllLossBackward>) average train loss tensor(1.8593, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44974245768947757 val_avg_loss: tensor(2.0639)\n",
      "epoch: 23 train_loss: tensor(1.6864, grad_fn=<NllLossBackward>) average train loss tensor(1.7615, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45827814569536424 val_avg_loss: tensor(2.0367)\n",
      "epoch: 24 train_loss: tensor(1.6577, grad_fn=<NllLossBackward>) average train loss tensor(1.7345, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4659308314937454 val_avg_loss: tensor(2.0149)\n",
      "epoch: 25 train_loss: tensor(1.6830, grad_fn=<NllLossBackward>) average train loss tensor(1.7124, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4659602649006622 val_avg_loss: tensor(2.0213)\n",
      "epoch: 26 train_loss: tensor(1.6152, grad_fn=<NllLossBackward>) average train loss tensor(1.7010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46837380426784403 val_avg_loss: tensor(2.0122)\n",
      "epoch: 27 train_loss: tensor(1.5638, grad_fn=<NllLossBackward>) average train loss tensor(1.6588, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47323031640912433 val_avg_loss: tensor(1.9974)\n",
      "epoch: 28 train_loss: tensor(1.4601, grad_fn=<NllLossBackward>) average train loss tensor(1.5950, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4705224429727741 val_avg_loss: tensor(2.0008)\n",
      "epoch: 29 train_loss: tensor(1.4749, grad_fn=<NllLossBackward>) average train loss tensor(1.5451, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748197203826343 val_avg_loss: tensor(2.0109)\n",
      "epoch: 30 train_loss: tensor(1.4489, grad_fn=<NllLossBackward>) average train loss tensor(1.5651, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4774981604120677 val_avg_loss: tensor(2.0042)\n",
      "epoch: 31 train_loss: tensor(1.4915, grad_fn=<NllLossBackward>) average train loss tensor(1.5757, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47811626195732154 val_avg_loss: tensor(1.9841)\n",
      "epoch: 32 train_loss: tensor(1.3903, grad_fn=<NllLossBackward>) average train loss tensor(1.5072, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48132450331125826 val_avg_loss: tensor(1.9790)\n",
      "epoch: 33 train_loss: tensor(1.3743, grad_fn=<NllLossBackward>) average train loss tensor(1.4726, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.482560706401766 val_avg_loss: tensor(1.9845)\n",
      "epoch: 34 train_loss: tensor(1.3420, grad_fn=<NllLossBackward>) average train loss tensor(1.4482, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48253127299484916 val_avg_loss: tensor(1.9852)\n",
      "epoch: 35 train_loss: tensor(1.2979, grad_fn=<NllLossBackward>) average train loss tensor(1.3984, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4829139072847682 val_avg_loss: tensor(1.9913)\n",
      "epoch: 36 train_loss: tensor(1.3478, grad_fn=<NllLossBackward>) average train loss tensor(1.3961, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4850331125827815 val_avg_loss: tensor(1.9934)\n",
      "epoch: 37 train_loss: tensor(1.2965, grad_fn=<NllLossBackward>) average train loss tensor(1.3953, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48729948491537894 val_avg_loss: tensor(1.9953)\n",
      "epoch: 38 train_loss: tensor(1.2591, grad_fn=<NllLossBackward>) average train loss tensor(1.3627, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48409124356144223 val_avg_loss: tensor(1.9995)\n",
      "epoch: 39 train_loss: tensor(1.2486, grad_fn=<NllLossBackward>) average train loss tensor(1.3378, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4857983811626196 val_avg_loss: tensor(2.0024)\n",
      "epoch: 40 train_loss: tensor(1.2261, grad_fn=<NllLossBackward>) average train loss tensor(1.2929, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4886534216335541 val_avg_loss: tensor(2.0096)\n",
      "epoch: 41 train_loss: tensor(1.2651, grad_fn=<NllLossBackward>) average train loss tensor(1.2989, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48933038999264167 val_avg_loss: tensor(2.0112)\n",
      "epoch: 42 train_loss: tensor(1.1944, grad_fn=<NllLossBackward>) average train loss tensor(1.2660, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49059602649006623 val_avg_loss: tensor(2.0150)\n",
      "epoch: 43 train_loss: tensor(1.2160, grad_fn=<NllLossBackward>) average train loss tensor(1.2241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48944812362030904 val_avg_loss: tensor(2.0351)\n",
      "epoch: 44 train_loss: tensor(1.1471, grad_fn=<NllLossBackward>) average train loss tensor(1.1922, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4906254598969831 val_avg_loss: tensor(2.0422)\n",
      "epoch: 45 train_loss: tensor(1.1645, grad_fn=<NllLossBackward>) average train loss tensor(1.1704, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4920971302428256 val_avg_loss: tensor(2.0463)\n",
      "epoch: 46 train_loss: tensor(1.0362, grad_fn=<NllLossBackward>) average train loss tensor(1.1974, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49056659308314937 val_avg_loss: tensor(2.0480)\n",
      "epoch: 47 train_loss: tensor(1.0963, grad_fn=<NllLossBackward>) average train loss tensor(1.1508, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4900956585724798 val_avg_loss: tensor(2.0567)\n",
      "epoch: 48 train_loss: tensor(1.1585, grad_fn=<NllLossBackward>) average train loss tensor(1.1655, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49165562913907285 val_avg_loss: tensor(2.0654)\n",
      "epoch: 49 train_loss: tensor(1.0588, grad_fn=<NllLossBackward>) average train loss tensor(1.0781, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4894186902133922 val_avg_loss: tensor(2.0815)\n",
      "epoch: 50 train_loss: tensor(0.9895, grad_fn=<NllLossBackward>) average train loss tensor(1.0977, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4852391464311994 val_avg_loss: tensor(2.0961)\n",
      "epoch: 51 train_loss: tensor(1.0605, grad_fn=<NllLossBackward>) average train loss tensor(1.1290, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4909786607799853 val_avg_loss: tensor(2.0954)\n",
      "epoch: 52 train_loss: tensor(0.9901, grad_fn=<NllLossBackward>) average train loss tensor(1.0964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.489654157468727 val_avg_loss: tensor(2.0945)\n",
      "epoch: 53 train_loss: tensor(0.9716, grad_fn=<NllLossBackward>) average train loss tensor(1.0571, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48968359087564384 val_avg_loss: tensor(2.0926)\n",
      "epoch: 54 train_loss: tensor(0.9561, grad_fn=<NllLossBackward>) average train loss tensor(1.0342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49080206033848417 val_avg_loss: tensor(2.0935)\n",
      "epoch: 55 train_loss: tensor(0.9599, grad_fn=<NllLossBackward>) average train loss tensor(1.0478, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49159676232523913 val_avg_loss: tensor(2.1082)\n",
      "epoch: 56 train_loss: tensor(0.9719, grad_fn=<NllLossBackward>) average train loss tensor(1.0075, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49271523178807947 val_avg_loss: tensor(2.1181)\n",
      "epoch: 57 train_loss: tensor(1.0142, grad_fn=<NllLossBackward>) average train loss tensor(1.0254, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49242089771891095 val_avg_loss: tensor(2.1299)\n",
      "epoch: 58 train_loss: tensor(0.8914, grad_fn=<NllLossBackward>) average train loss tensor(1.0329, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4942457689477557 val_avg_loss: tensor(2.1276)\n",
      "epoch: 59 train_loss: tensor(0.8686, grad_fn=<NllLossBackward>) average train loss tensor(1.0152, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4913907284768212 val_avg_loss: tensor(2.1450)\n",
      "epoch: 60 train_loss: tensor(0.9548, grad_fn=<NllLossBackward>) average train loss tensor(0.9792, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49027225901398086 val_avg_loss: tensor(2.1572)\n",
      "epoch: 61 train_loss: tensor(0.9199, grad_fn=<NllLossBackward>) average train loss tensor(0.9883, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48903605592347316 val_avg_loss: tensor(2.1642)\n",
      "epoch: 62 train_loss: tensor(0.8351, grad_fn=<NllLossBackward>) average train loss tensor(0.9356, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49289183222958055 val_avg_loss: tensor(2.1608)\n",
      "epoch: 63 train_loss: tensor(0.8581, grad_fn=<NllLossBackward>) average train loss tensor(0.9217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49212656364974244 val_avg_loss: tensor(2.1669)\n",
      "epoch: 64 train_loss: tensor(0.8958, grad_fn=<NllLossBackward>) average train loss tensor(0.9470, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49392200147167037 val_avg_loss: tensor(2.1824)\n",
      "epoch: 65 train_loss: tensor(0.8562, grad_fn=<NllLossBackward>) average train loss tensor(0.9428, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.494186902133922 val_avg_loss: tensor(2.1926)\n",
      "epoch: 66 train_loss: tensor(0.7432, grad_fn=<NllLossBackward>) average train loss tensor(0.8854, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4909197939661516 val_avg_loss: tensor(2.2010)\n",
      "epoch: 67 train_loss: tensor(0.7579, grad_fn=<NllLossBackward>) average train loss tensor(0.8570, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.489654157468727 val_avg_loss: tensor(2.2237)\n",
      "epoch: 68 train_loss: tensor(0.7806, grad_fn=<NllLossBackward>) average train loss tensor(0.8413, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49212656364974244 val_avg_loss: tensor(2.2453)\n",
      "epoch: 69 train_loss: tensor(0.8171, grad_fn=<NllLossBackward>) average train loss tensor(0.8993, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49056659308314937 val_avg_loss: tensor(2.2660)\n",
      "epoch: 70 train_loss: tensor(0.8573, grad_fn=<NllLossBackward>) average train loss tensor(0.8851, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4900662251655629 val_avg_loss: tensor(2.2659)\n",
      "epoch: 71 train_loss: tensor(0.8485, grad_fn=<NllLossBackward>) average train loss tensor(0.8915, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49124356144223696 val_avg_loss: tensor(2.2669)\n",
      "epoch: 72 train_loss: tensor(0.8552, grad_fn=<NllLossBackward>) average train loss tensor(0.8567, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48980132450331126 val_avg_loss: tensor(2.2622)\n",
      "epoch: 73 train_loss: tensor(0.7342, grad_fn=<NllLossBackward>) average train loss tensor(0.8064, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4871817512877116 val_avg_loss: tensor(2.2602)\n",
      "epoch: 74 train_loss: tensor(0.7102, grad_fn=<NllLossBackward>) average train loss tensor(0.8118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49159676232523913 val_avg_loss: tensor(2.2635)\n",
      "epoch: 75 train_loss: tensor(0.7416, grad_fn=<NllLossBackward>) average train loss tensor(0.7854, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4909197939661516 val_avg_loss: tensor(2.2868)\n",
      "epoch: 76 train_loss: tensor(0.8480, grad_fn=<NllLossBackward>) average train loss tensor(0.8169, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48912435614422367 val_avg_loss: tensor(2.3050)\n",
      "epoch: 77 train_loss: tensor(0.7235, grad_fn=<NllLossBackward>) average train loss tensor(0.7994, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4903311258278146 val_avg_loss: tensor(2.3259)\n",
      "epoch: 78 train_loss: tensor(0.7261, grad_fn=<NllLossBackward>) average train loss tensor(0.7871, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4892420897718911 val_avg_loss: tensor(2.3560)\n",
      "epoch: 79 train_loss: tensor(0.6551, grad_fn=<NllLossBackward>) average train loss tensor(0.7736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49206769683590873 val_avg_loss: tensor(2.3408)\n",
      "epoch: 80 train_loss: tensor(0.7290, grad_fn=<NllLossBackward>) average train loss tensor(0.7637, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4895364238410596 val_avg_loss: tensor(2.3433)\n",
      "epoch: 81 train_loss: tensor(0.7172, grad_fn=<NllLossBackward>) average train loss tensor(0.7693, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4886534216335541 val_avg_loss: tensor(2.3554)\n",
      "epoch: 82 train_loss: tensor(0.7240, grad_fn=<NllLossBackward>) average train loss tensor(0.7176, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4894186902133922 val_avg_loss: tensor(2.3894)\n",
      "epoch: 83 train_loss: tensor(0.6005, grad_fn=<NllLossBackward>) average train loss tensor(0.7107, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49012509197939663 val_avg_loss: tensor(2.3936)\n",
      "epoch: 84 train_loss: tensor(0.6726, grad_fn=<NllLossBackward>) average train loss tensor(0.7243, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48753495217071374 val_avg_loss: tensor(2.3988)\n",
      "epoch: 85 train_loss: tensor(0.6756, grad_fn=<NllLossBackward>) average train loss tensor(0.7089, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4897718910963944 val_avg_loss: tensor(2.4177)\n",
      "epoch: 86 train_loss: tensor(0.6252, grad_fn=<NllLossBackward>) average train loss tensor(0.6849, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.48950699043414275 val_avg_loss: tensor(2.4444)\n",
      "epoch: 87 train_loss: tensor(0.6564, grad_fn=<NllLossBackward>) average train loss tensor(0.7119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4860044150110375 val_avg_loss: tensor(2.4446)\n",
      "epoch: 88 train_loss: tensor(0.6234, grad_fn=<NllLossBackward>) average train loss tensor(0.6913, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4846504782928624 val_avg_loss: tensor(2.4466)\n",
      "epoch: 89 train_loss: tensor(0.5705, grad_fn=<NllLossBackward>) average train loss tensor(0.6530, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4906843267108168 val_avg_loss: tensor(2.4560)\n",
      "epoch: 90 train_loss: tensor(0.6421, grad_fn=<NllLossBackward>) average train loss tensor(0.6803, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48821192052980134 val_avg_loss: tensor(2.4823)\n",
      "epoch: 91 train_loss: tensor(0.6347, grad_fn=<NllLossBackward>) average train loss tensor(0.6623, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48706401766004415 val_avg_loss: tensor(2.4795)\n",
      "epoch: 92 train_loss: tensor(0.5389, grad_fn=<NllLossBackward>) average train loss tensor(0.6247, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4861810154525386 val_avg_loss: tensor(2.4771)\n",
      "epoch: 93 train_loss: tensor(0.6650, grad_fn=<NllLossBackward>) average train loss tensor(0.7157, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4877998528329654 val_avg_loss: tensor(2.4865)\n",
      "epoch: 94 train_loss: tensor(0.5531, grad_fn=<NllLossBackward>) average train loss tensor(0.6633, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4894186902133922 val_avg_loss: tensor(2.4994)\n",
      "epoch: 95 train_loss: tensor(0.5828, grad_fn=<NllLossBackward>) average train loss tensor(0.6430, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48859455481972036 val_avg_loss: tensor(2.5074)\n",
      "epoch: 96 train_loss: tensor(0.6418, grad_fn=<NllLossBackward>) average train loss tensor(0.6472, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48921265636497424 val_avg_loss: tensor(2.5142)\n",
      "epoch: 97 train_loss: tensor(0.5946, grad_fn=<NllLossBackward>) average train loss tensor(0.6440, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4903899926416483 val_avg_loss: tensor(2.5049)\n",
      "epoch: 98 train_loss: tensor(0.5680, grad_fn=<NllLossBackward>) average train loss tensor(0.6230, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4858866813833701 val_avg_loss: tensor(2.5211)\n",
      "epoch: 99 train_loss: tensor(0.5815, grad_fn=<NllLossBackward>) average train loss tensor(0.6095, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48615158204562176 val_avg_loss: tensor(2.5324)\n",
      "epoch: 100 train_loss: tensor(0.6052, grad_fn=<NllLossBackward>) average train loss tensor(0.6470, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48897718910963944 val_avg_loss: tensor(2.5406)\n",
      "epoch: 101 train_loss: tensor(0.5146, grad_fn=<NllLossBackward>) average train loss tensor(0.5850, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48891832229580573 val_avg_loss: tensor(2.5467)\n",
      "epoch: 102 train_loss: tensor(0.5022, grad_fn=<NllLossBackward>) average train loss tensor(0.5831, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4869462840323768 val_avg_loss: tensor(2.5702)\n",
      "epoch: 103 train_loss: tensor(0.5294, grad_fn=<NllLossBackward>) average train loss tensor(0.5887, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4860044150110375 val_avg_loss: tensor(2.5937)\n",
      "epoch: 104 train_loss: tensor(0.4847, grad_fn=<NllLossBackward>) average train loss tensor(0.5815, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48859455481972036 val_avg_loss: tensor(2.5846)\n",
      "epoch: 105 train_loss: tensor(0.5821, grad_fn=<NllLossBackward>) average train loss tensor(0.6025, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48859455481972036 val_avg_loss: tensor(2.5715)\n",
      "epoch: 106 train_loss: tensor(0.5075, grad_fn=<NllLossBackward>) average train loss tensor(0.5522, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4871523178807947 val_avg_loss: tensor(2.5803)\n",
      "epoch: 107 train_loss: tensor(0.5797, grad_fn=<NllLossBackward>) average train loss tensor(0.5757, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48906548933039 val_avg_loss: tensor(2.5994)\n",
      "epoch: 108 train_loss: tensor(0.5391, grad_fn=<NllLossBackward>) average train loss tensor(0.5517, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4880058866813834 val_avg_loss: tensor(2.6272)\n",
      "epoch: 109 train_loss: tensor(0.5021, grad_fn=<NllLossBackward>) average train loss tensor(0.5589, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48347314201618835 val_avg_loss: tensor(2.6699)\n",
      "epoch: 110 train_loss: tensor(0.5349, grad_fn=<NllLossBackward>) average train loss tensor(0.5390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48635761589403975 val_avg_loss: tensor(2.6627)\n",
      "epoch: 111 train_loss: tensor(0.5139, grad_fn=<NllLossBackward>) average train loss tensor(0.5790, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4867402501839588 val_avg_loss: tensor(2.6618)\n",
      "epoch: 112 train_loss: tensor(0.5355, grad_fn=<NllLossBackward>) average train loss tensor(0.5630, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48591611479028696 val_avg_loss: tensor(2.6619)\n",
      "epoch: 113 train_loss: tensor(0.4745, grad_fn=<NllLossBackward>) average train loss tensor(0.5095, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4838852097130243 val_avg_loss: tensor(2.6761)\n",
      "epoch: 114 train_loss: tensor(0.5380, grad_fn=<NllLossBackward>) average train loss tensor(0.5499, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4843561442236939 val_avg_loss: tensor(2.7039)\n",
      "epoch: 115 train_loss: tensor(0.5097, grad_fn=<NllLossBackward>) average train loss tensor(0.5433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48562178072111845 val_avg_loss: tensor(2.7018)\n",
      "epoch: 116 train_loss: tensor(0.5118, grad_fn=<NllLossBackward>) average train loss tensor(0.5168, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48653421633554084 val_avg_loss: tensor(2.6846)\n",
      "epoch: 117 train_loss: tensor(0.4873, grad_fn=<NllLossBackward>) average train loss tensor(0.5422, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4859455481972038 val_avg_loss: tensor(2.6836)\n",
      "epoch: 118 train_loss: tensor(0.5047, grad_fn=<NllLossBackward>) average train loss tensor(0.5321, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48635761589403975 val_avg_loss: tensor(2.6915)\n",
      "epoch: 119 train_loss: tensor(0.4850, grad_fn=<NllLossBackward>) average train loss tensor(0.5186, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4837969094922737 val_avg_loss: tensor(2.7148)\n",
      "epoch: 120 train_loss: tensor(0.5207, grad_fn=<NllLossBackward>) average train loss tensor(0.5047, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4844150110375276 val_avg_loss: tensor(2.7305)\n",
      "epoch: 121 train_loss: tensor(0.4379, grad_fn=<NllLossBackward>) average train loss tensor(0.5299, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48782928623988225 val_avg_loss: tensor(2.7253)\n",
      "epoch: 122 train_loss: tensor(0.4576, grad_fn=<NllLossBackward>) average train loss tensor(0.5270, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4872700515084621 val_avg_loss: tensor(2.7122)\n",
      "epoch: 123 train_loss: tensor(0.4428, grad_fn=<NllLossBackward>) average train loss tensor(0.4944, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48432671081677703 val_avg_loss: tensor(2.7289)\n",
      "epoch: 124 train_loss: tensor(0.4796, grad_fn=<NllLossBackward>) average train loss tensor(0.5152, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4827961736571008 val_avg_loss: tensor(2.7335)\n",
      "epoch: 125 train_loss: tensor(0.4574, grad_fn=<NllLossBackward>) average train loss tensor(0.4722, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.481972038263429 val_avg_loss: tensor(2.7546)\n",
      "epoch: 126 train_loss: tensor(0.4621, grad_fn=<NllLossBackward>) average train loss tensor(0.4999, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4867991169977925 val_avg_loss: tensor(2.7737)\n",
      "epoch: 127 train_loss: tensor(0.4161, grad_fn=<NllLossBackward>) average train loss tensor(0.4717, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4857395143487859 val_avg_loss: tensor(2.7977)\n",
      "epoch: 128 train_loss: tensor(0.4756, grad_fn=<NllLossBackward>) average train loss tensor(0.5090, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48347314201618835 val_avg_loss: tensor(2.8031)\n",
      "epoch: 129 train_loss: tensor(0.4354, grad_fn=<NllLossBackward>) average train loss tensor(0.4818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4843561442236939 val_avg_loss: tensor(2.8033)\n",
      "epoch: 130 train_loss: tensor(0.4318, grad_fn=<NllLossBackward>) average train loss tensor(0.4508, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4862693156732892 val_avg_loss: tensor(2.8197)\n",
      "epoch: 131 train_loss: tensor(0.3644, grad_fn=<NllLossBackward>) average train loss tensor(0.4598, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4826784400294334 val_avg_loss: tensor(2.8379)\n",
      "epoch: 132 train_loss: tensor(0.4366, grad_fn=<NllLossBackward>) average train loss tensor(0.4852, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4837969094922737 val_avg_loss: tensor(2.8293)\n",
      "epoch: 133 train_loss: tensor(0.3930, grad_fn=<NllLossBackward>) average train loss tensor(0.4342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4870345842531273 val_avg_loss: tensor(2.8229)\n",
      "epoch: 134 train_loss: tensor(0.4037, grad_fn=<NllLossBackward>) average train loss tensor(0.4462, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.488476821192053 val_avg_loss: tensor(2.8247)\n",
      "epoch: 135 train_loss: tensor(0.4586, grad_fn=<NllLossBackward>) average train loss tensor(0.4325, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4855629139072848 val_avg_loss: tensor(2.8603)\n",
      "epoch: 136 train_loss: tensor(0.4148, grad_fn=<NllLossBackward>) average train loss tensor(0.4332, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4830316409124356 val_avg_loss: tensor(2.8973)\n",
      "epoch: 137 train_loss: tensor(0.4104, grad_fn=<NllLossBackward>) average train loss tensor(0.4360, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4827373068432671 val_avg_loss: tensor(2.9231)\n",
      "epoch: 138 train_loss: tensor(0.4465, grad_fn=<NllLossBackward>) average train loss tensor(0.4807, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4828550404709345 val_avg_loss: tensor(2.9281)\n",
      "epoch: 139 train_loss: tensor(0.4005, grad_fn=<NllLossBackward>) average train loss tensor(0.4053, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48038263428991906 val_avg_loss: tensor(2.9130)\n",
      "epoch: 0 train_loss: tensor(3.8479, grad_fn=<NllLossBackward>) average train loss tensor(3.9110, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.043649742457689475 val_avg_loss: tensor(3.8166)\n",
      "epoch: 1 train_loss: tensor(3.7237, grad_fn=<NllLossBackward>) average train loss tensor(3.7595, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.060132450331125825 val_avg_loss: tensor(3.6899)\n",
      "epoch: 2 train_loss: tensor(3.6488, grad_fn=<NllLossBackward>) average train loss tensor(3.6517, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.14434142752023546 val_avg_loss: tensor(3.5764)\n",
      "epoch: 3 train_loss: tensor(3.5071, grad_fn=<NllLossBackward>) average train loss tensor(3.5550, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1738337012509198 val_avg_loss: tensor(3.4794)\n",
      "epoch: 4 train_loss: tensor(3.4456, grad_fn=<NllLossBackward>) average train loss tensor(3.4666, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.19072847682119207 val_avg_loss: tensor(3.3741)\n",
      "epoch: 5 train_loss: tensor(3.3365, grad_fn=<NllLossBackward>) average train loss tensor(3.3426, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2335540838852097 val_avg_loss: tensor(3.2389)\n",
      "epoch: 6 train_loss: tensor(3.1893, grad_fn=<NllLossBackward>) average train loss tensor(3.2249, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2819426048565121 val_avg_loss: tensor(3.0807)\n",
      "epoch: 7 train_loss: tensor(3.0756, grad_fn=<NllLossBackward>) average train loss tensor(3.0924, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.30322295805739513 val_avg_loss: tensor(2.9317)\n",
      "epoch: 8 train_loss: tensor(2.8876, grad_fn=<NllLossBackward>) average train loss tensor(2.9486, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.32809418690213393 val_avg_loss: tensor(2.8008)\n",
      "epoch: 9 train_loss: tensor(2.7137, grad_fn=<NllLossBackward>) average train loss tensor(2.8201, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.35449595290654895 val_avg_loss: tensor(2.6788)\n",
      "epoch: 10 train_loss: tensor(2.6064, grad_fn=<NllLossBackward>) average train loss tensor(2.6829, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.36835908756438557 val_avg_loss: tensor(2.5663)\n",
      "epoch: 11 train_loss: tensor(2.5165, grad_fn=<NllLossBackward>) average train loss tensor(2.5874, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.37718910963944074 val_avg_loss: tensor(2.4735)\n",
      "epoch: 12 train_loss: tensor(2.4132, grad_fn=<NllLossBackward>) average train loss tensor(2.4771, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3848123620309051 val_avg_loss: tensor(2.4003)\n",
      "epoch: 13 train_loss: tensor(2.3715, grad_fn=<NllLossBackward>) average train loss tensor(2.4118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.395673289183223 val_avg_loss: tensor(2.3464)\n",
      "epoch: 14 train_loss: tensor(2.2519, grad_fn=<NllLossBackward>) average train loss tensor(2.3161, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.404532744665195 val_avg_loss: tensor(2.2894)\n",
      "epoch: 15 train_loss: tensor(2.1464, grad_fn=<NllLossBackward>) average train loss tensor(2.2542, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4099190581309787 val_avg_loss: tensor(2.2417)\n",
      "epoch: 16 train_loss: tensor(2.0769, grad_fn=<NllLossBackward>) average train loss tensor(2.1693, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.420485651214128 val_avg_loss: tensor(2.2051)\n",
      "epoch: 17 train_loss: tensor(1.9961, grad_fn=<NllLossBackward>) average train loss tensor(2.1170, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.425224429727741 val_avg_loss: tensor(2.1775)\n",
      "epoch: 18 train_loss: tensor(1.9430, grad_fn=<NllLossBackward>) average train loss tensor(2.0385, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43193524650478293 val_avg_loss: tensor(2.1406)\n",
      "epoch: 19 train_loss: tensor(1.9218, grad_fn=<NllLossBackward>) average train loss tensor(2.0054, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43688005886681386 val_avg_loss: tensor(2.1200)\n",
      "epoch: 20 train_loss: tensor(1.9027, grad_fn=<NllLossBackward>) average train loss tensor(1.9612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4435908756438558 val_avg_loss: tensor(2.1009)\n",
      "epoch: 21 train_loss: tensor(1.7369, grad_fn=<NllLossBackward>) average train loss tensor(1.8965, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44777041942604856 val_avg_loss: tensor(2.0817)\n",
      "epoch: 22 train_loss: tensor(1.7300, grad_fn=<NllLossBackward>) average train loss tensor(1.8605, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4493598233995585 val_avg_loss: tensor(2.0724)\n",
      "epoch: 23 train_loss: tensor(1.6832, grad_fn=<NllLossBackward>) average train loss tensor(1.8231, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45439293598233993 val_avg_loss: tensor(2.0534)\n",
      "epoch: 24 train_loss: tensor(1.6143, grad_fn=<NllLossBackward>) average train loss tensor(1.7494, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45795437821927887 val_avg_loss: tensor(2.0442)\n",
      "epoch: 25 train_loss: tensor(1.5810, grad_fn=<NllLossBackward>) average train loss tensor(1.6992, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45972038263428994 val_avg_loss: tensor(2.0402)\n",
      "epoch: 26 train_loss: tensor(1.5261, grad_fn=<NllLossBackward>) average train loss tensor(1.6721, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46548933038999263 val_avg_loss: tensor(2.0275)\n",
      "epoch: 27 train_loss: tensor(1.5035, grad_fn=<NllLossBackward>) average train loss tensor(1.6297, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4685504047093451 val_avg_loss: tensor(2.0231)\n",
      "epoch: 28 train_loss: tensor(1.4562, grad_fn=<NllLossBackward>) average train loss tensor(1.6205, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4675496688741722 val_avg_loss: tensor(2.0228)\n",
      "epoch: 29 train_loss: tensor(1.5211, grad_fn=<NllLossBackward>) average train loss tensor(1.5736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46966887417218545 val_avg_loss: tensor(2.0256)\n",
      "epoch: 30 train_loss: tensor(1.3936, grad_fn=<NllLossBackward>) average train loss tensor(1.5576, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4726122148638705 val_avg_loss: tensor(2.0168)\n",
      "epoch: 31 train_loss: tensor(1.4192, grad_fn=<NllLossBackward>) average train loss tensor(1.5046, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47611479028697573 val_avg_loss: tensor(2.0202)\n",
      "epoch: 32 train_loss: tensor(1.3688, grad_fn=<NllLossBackward>) average train loss tensor(1.5042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765268579838116 val_avg_loss: tensor(2.0292)\n",
      "epoch: 33 train_loss: tensor(1.4020, grad_fn=<NllLossBackward>) average train loss tensor(1.5081, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4744665194996321 val_avg_loss: tensor(2.0317)\n",
      "epoch: 34 train_loss: tensor(1.3714, grad_fn=<NllLossBackward>) average train loss tensor(1.4980, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47670345842531275 val_avg_loss: tensor(2.0186)\n",
      "epoch: 35 train_loss: tensor(1.3619, grad_fn=<NllLossBackward>) average train loss tensor(1.4256, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47949963208241353 val_avg_loss: tensor(2.0211)\n",
      "epoch: 36 train_loss: tensor(1.2894, grad_fn=<NllLossBackward>) average train loss tensor(1.4097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4782928623988227 val_avg_loss: tensor(2.0275)\n",
      "epoch: 37 train_loss: tensor(1.2310, grad_fn=<NllLossBackward>) average train loss tensor(1.3417, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47782192788815303 val_avg_loss: tensor(2.0389)\n",
      "epoch: 38 train_loss: tensor(1.2387, grad_fn=<NllLossBackward>) average train loss tensor(1.3706, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4795879323031641 val_avg_loss: tensor(2.0439)\n",
      "epoch: 39 train_loss: tensor(1.2524, grad_fn=<NllLossBackward>) average train loss tensor(1.3256, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48100073583517294 val_avg_loss: tensor(2.0420)\n",
      "epoch: 40 train_loss: tensor(1.1821, grad_fn=<NllLossBackward>) average train loss tensor(1.3137, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48264900662251653 val_avg_loss: tensor(2.0544)\n",
      "epoch: 41 train_loss: tensor(1.1609, grad_fn=<NllLossBackward>) average train loss tensor(1.3110, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48132450331125826 val_avg_loss: tensor(2.0645)\n",
      "epoch: 42 train_loss: tensor(1.1748, grad_fn=<NllLossBackward>) average train loss tensor(1.2772, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48 val_avg_loss: tensor(2.0719)\n",
      "epoch: 43 train_loss: tensor(1.1432, grad_fn=<NllLossBackward>) average train loss tensor(1.2380, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4819131714495953 val_avg_loss: tensor(2.0742)\n",
      "epoch: 44 train_loss: tensor(1.1282, grad_fn=<NllLossBackward>) average train loss tensor(1.2106, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48462104488594554 val_avg_loss: tensor(2.0709)\n",
      "epoch: 45 train_loss: tensor(1.1149, grad_fn=<NllLossBackward>) average train loss tensor(1.2097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4840323767476085 val_avg_loss: tensor(2.0795)\n",
      "epoch: 46 train_loss: tensor(1.1086, grad_fn=<NllLossBackward>) average train loss tensor(1.2070, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4836497424576895 val_avg_loss: tensor(2.1006)\n",
      "epoch: 47 train_loss: tensor(1.0923, grad_fn=<NllLossBackward>) average train loss tensor(1.1843, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48506254598969833 val_avg_loss: tensor(2.1037)\n",
      "epoch: 48 train_loss: tensor(1.0400, grad_fn=<NllLossBackward>) average train loss tensor(1.1909, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48300220750551875 val_avg_loss: tensor(2.1074)\n",
      "epoch: 49 train_loss: tensor(1.0652, grad_fn=<NllLossBackward>) average train loss tensor(1.1215, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4841206769683591 val_avg_loss: tensor(2.1152)\n",
      "epoch: 50 train_loss: tensor(1.0206, grad_fn=<NllLossBackward>) average train loss tensor(1.1355, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4830316409124356 val_avg_loss: tensor(2.1214)\n",
      "epoch: 51 train_loss: tensor(1.0154, grad_fn=<NllLossBackward>) average train loss tensor(1.1012, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4829139072847682 val_avg_loss: tensor(2.1460)\n",
      "epoch: 52 train_loss: tensor(1.0051, grad_fn=<NllLossBackward>) average train loss tensor(1.1193, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4855040470934511 val_avg_loss: tensor(2.1527)\n",
      "epoch: 53 train_loss: tensor(0.9976, grad_fn=<NllLossBackward>) average train loss tensor(1.0879, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4833259749816041 val_avg_loss: tensor(2.1675)\n",
      "epoch: 54 train_loss: tensor(1.0187, grad_fn=<NllLossBackward>) average train loss tensor(1.0964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48397350993377486 val_avg_loss: tensor(2.1624)\n",
      "epoch: 55 train_loss: tensor(0.9355, grad_fn=<NllLossBackward>) average train loss tensor(1.0236, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4847976453274466 val_avg_loss: tensor(2.1713)\n",
      "epoch: 56 train_loss: tensor(0.9035, grad_fn=<NllLossBackward>) average train loss tensor(1.0111, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4854746136865342 val_avg_loss: tensor(2.1814)\n",
      "epoch: 57 train_loss: tensor(0.9747, grad_fn=<NllLossBackward>) average train loss tensor(1.0163, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4831788079470199 val_avg_loss: tensor(2.1849)\n",
      "epoch: 58 train_loss: tensor(0.9196, grad_fn=<NllLossBackward>) average train loss tensor(1.0110, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.483944076526858 val_avg_loss: tensor(2.1987)\n",
      "epoch: 59 train_loss: tensor(0.8885, grad_fn=<NllLossBackward>) average train loss tensor(0.9723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48344370860927155 val_avg_loss: tensor(2.2210)\n",
      "epoch: 60 train_loss: tensor(0.9110, grad_fn=<NllLossBackward>) average train loss tensor(0.9959, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4840323767476085 val_avg_loss: tensor(2.2258)\n",
      "epoch: 61 train_loss: tensor(0.8604, grad_fn=<NllLossBackward>) average train loss tensor(0.9661, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4835025754231052 val_avg_loss: tensor(2.2308)\n",
      "epoch: 62 train_loss: tensor(0.9219, grad_fn=<NllLossBackward>) average train loss tensor(0.9731, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812656364974246 val_avg_loss: tensor(2.2441)\n",
      "epoch: 63 train_loss: tensor(0.8334, grad_fn=<NllLossBackward>) average train loss tensor(0.9192, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4825018395879323 val_avg_loss: tensor(2.2569)\n",
      "epoch: 64 train_loss: tensor(0.8323, grad_fn=<NllLossBackward>) average train loss tensor(0.9355, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4855629139072848 val_avg_loss: tensor(2.2566)\n",
      "epoch: 65 train_loss: tensor(0.8852, grad_fn=<NllLossBackward>) average train loss tensor(0.9210, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48347314201618835 val_avg_loss: tensor(2.2713)\n",
      "epoch: 66 train_loss: tensor(0.7113, grad_fn=<NllLossBackward>) average train loss tensor(0.8756, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48117733627667403 val_avg_loss: tensor(2.2829)\n",
      "epoch: 67 train_loss: tensor(0.7777, grad_fn=<NllLossBackward>) average train loss tensor(0.9191, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4834142752023547 val_avg_loss: tensor(2.2892)\n",
      "epoch: 68 train_loss: tensor(0.7795, grad_fn=<NllLossBackward>) average train loss tensor(0.8734, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4826784400294334 val_avg_loss: tensor(2.3014)\n",
      "epoch: 69 train_loss: tensor(0.7985, grad_fn=<NllLossBackward>) average train loss tensor(0.8722, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48123620309050774 val_avg_loss: tensor(2.3152)\n",
      "epoch: 70 train_loss: tensor(0.8258, grad_fn=<NllLossBackward>) average train loss tensor(0.8853, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48032376747608535 val_avg_loss: tensor(2.3357)\n",
      "epoch: 71 train_loss: tensor(0.7536, grad_fn=<NllLossBackward>) average train loss tensor(0.8280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478616629874908 val_avg_loss: tensor(2.3545)\n",
      "epoch: 72 train_loss: tensor(0.7531, grad_fn=<NllLossBackward>) average train loss tensor(0.8194, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48047093451066963 val_avg_loss: tensor(2.3675)\n",
      "epoch: 73 train_loss: tensor(0.7068, grad_fn=<NllLossBackward>) average train loss tensor(0.8087, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48276674025018396 val_avg_loss: tensor(2.3643)\n",
      "epoch: 74 train_loss: tensor(0.6735, grad_fn=<NllLossBackward>) average train loss tensor(0.8214, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812656364974246 val_avg_loss: tensor(2.3721)\n",
      "epoch: 75 train_loss: tensor(0.7263, grad_fn=<NllLossBackward>) average train loss tensor(0.7950, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47985283296541575 val_avg_loss: tensor(2.3833)\n",
      "epoch: 76 train_loss: tensor(0.7148, grad_fn=<NllLossBackward>) average train loss tensor(0.7795, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812067696835909 val_avg_loss: tensor(2.3914)\n",
      "epoch: 77 train_loss: tensor(0.7358, grad_fn=<NllLossBackward>) average train loss tensor(0.7767, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4828844738778514 val_avg_loss: tensor(2.4170)\n",
      "epoch: 78 train_loss: tensor(0.7026, grad_fn=<NllLossBackward>) average train loss tensor(0.7715, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4821486387049301 val_avg_loss: tensor(2.4274)\n",
      "epoch: 79 train_loss: tensor(0.6449, grad_fn=<NllLossBackward>) average train loss tensor(0.7303, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4821192052980132 val_avg_loss: tensor(2.4386)\n",
      "epoch: 80 train_loss: tensor(0.7172, grad_fn=<NllLossBackward>) average train loss tensor(0.7629, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47902869757174393 val_avg_loss: tensor(2.4687)\n",
      "epoch: 81 train_loss: tensor(0.6919, grad_fn=<NllLossBackward>) average train loss tensor(0.7067, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4797350993377483 val_avg_loss: tensor(2.5002)\n",
      "epoch: 82 train_loss: tensor(0.7352, grad_fn=<NllLossBackward>) average train loss tensor(0.7707, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4806769683590876 val_avg_loss: tensor(2.4905)\n",
      "epoch: 83 train_loss: tensor(0.6570, grad_fn=<NllLossBackward>) average train loss tensor(0.7271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47888153053715965 val_avg_loss: tensor(2.4815)\n",
      "epoch: 84 train_loss: tensor(0.6446, grad_fn=<NllLossBackward>) average train loss tensor(0.7176, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.47979396615158204 val_avg_loss: tensor(2.4878)\n",
      "epoch: 85 train_loss: tensor(0.6517, grad_fn=<NllLossBackward>) average train loss tensor(0.7097, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4810596026490066 val_avg_loss: tensor(2.4990)\n",
      "epoch: 86 train_loss: tensor(0.6316, grad_fn=<NllLossBackward>) average train loss tensor(0.6929, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4823841059602649 val_avg_loss: tensor(2.4862)\n",
      "epoch: 87 train_loss: tensor(0.5983, grad_fn=<NllLossBackward>) average train loss tensor(0.6860, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4798822663723326 val_avg_loss: tensor(2.4987)\n",
      "epoch: 88 train_loss: tensor(0.5855, grad_fn=<NllLossBackward>) average train loss tensor(0.6727, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47902869757174393 val_avg_loss: tensor(2.5231)\n",
      "epoch: 89 train_loss: tensor(0.6207, grad_fn=<NllLossBackward>) average train loss tensor(0.6781, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.482560706401766 val_avg_loss: tensor(2.5279)\n",
      "epoch: 90 train_loss: tensor(0.6737, grad_fn=<NllLossBackward>) average train loss tensor(0.6968, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48420897718910966 val_avg_loss: tensor(2.5357)\n",
      "epoch: 91 train_loss: tensor(0.5557, grad_fn=<NllLossBackward>) average train loss tensor(0.6444, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4804120676968359 val_avg_loss: tensor(2.5600)\n",
      "epoch: 92 train_loss: tensor(0.5664, grad_fn=<NllLossBackward>) average train loss tensor(0.6379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47902869757174393 val_avg_loss: tensor(2.5726)\n",
      "epoch: 93 train_loss: tensor(0.5580, grad_fn=<NllLossBackward>) average train loss tensor(0.6527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4806769683590876 val_avg_loss: tensor(2.5716)\n",
      "epoch: 94 train_loss: tensor(0.5983, grad_fn=<NllLossBackward>) average train loss tensor(0.6616, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4814422369389257 val_avg_loss: tensor(2.5712)\n",
      "epoch: 95 train_loss: tensor(0.5557, grad_fn=<NllLossBackward>) average train loss tensor(0.6116, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.479205298013245 val_avg_loss: tensor(2.5838)\n",
      "epoch: 96 train_loss: tensor(0.5743, grad_fn=<NllLossBackward>) average train loss tensor(0.6237, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47717439293598235 val_avg_loss: tensor(2.6068)\n",
      "epoch: 97 train_loss: tensor(0.5580, grad_fn=<NllLossBackward>) average train loss tensor(0.6393, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4783811626195732 val_avg_loss: tensor(2.6157)\n",
      "epoch: 98 train_loss: tensor(0.5761, grad_fn=<NllLossBackward>) average train loss tensor(0.6395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47693892568064755 val_avg_loss: tensor(2.6247)\n",
      "epoch: 99 train_loss: tensor(0.5772, grad_fn=<NllLossBackward>) average train loss tensor(0.6320, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47864606328182485 val_avg_loss: tensor(2.6412)\n",
      "epoch: 100 train_loss: tensor(0.5044, grad_fn=<NllLossBackward>) average train loss tensor(0.5929, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478027961736571 val_avg_loss: tensor(2.6387)\n",
      "epoch: 101 train_loss: tensor(0.5045, grad_fn=<NllLossBackward>) average train loss tensor(0.5925, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4790581309786608 val_avg_loss: tensor(2.6379)\n",
      "epoch: 102 train_loss: tensor(0.6028, grad_fn=<NllLossBackward>) average train loss tensor(0.6071, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47740986019131715 val_avg_loss: tensor(2.6609)\n",
      "epoch: 103 train_loss: tensor(0.5735, grad_fn=<NllLossBackward>) average train loss tensor(0.6456, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47564385577630613 val_avg_loss: tensor(2.6627)\n",
      "epoch: 104 train_loss: tensor(0.4753, grad_fn=<NllLossBackward>) average train loss tensor(0.5653, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4734657836644592 val_avg_loss: tensor(2.6808)\n",
      "epoch: 105 train_loss: tensor(0.5131, grad_fn=<NllLossBackward>) average train loss tensor(0.5744, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765857247976453 val_avg_loss: tensor(2.6939)\n",
      "epoch: 106 train_loss: tensor(0.5722, grad_fn=<NllLossBackward>) average train loss tensor(0.6040, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4768211920529801 val_avg_loss: tensor(2.7006)\n",
      "epoch: 107 train_loss: tensor(0.5106, grad_fn=<NllLossBackward>) average train loss tensor(0.5836, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47234731420161885 val_avg_loss: tensor(2.7285)\n",
      "epoch: 108 train_loss: tensor(0.5132, grad_fn=<NllLossBackward>) average train loss tensor(0.5708, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4762913907284768 val_avg_loss: tensor(2.7168)\n",
      "epoch: 109 train_loss: tensor(0.4958, grad_fn=<NllLossBackward>) average train loss tensor(0.5615, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4787637969094923 val_avg_loss: tensor(2.7165)\n",
      "epoch: 110 train_loss: tensor(0.4765, grad_fn=<NllLossBackward>) average train loss tensor(0.5650, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4781456953642384 val_avg_loss: tensor(2.7179)\n",
      "epoch: 111 train_loss: tensor(0.5187, grad_fn=<NllLossBackward>) average train loss tensor(0.5741, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47620309050772625 val_avg_loss: tensor(2.7199)\n",
      "epoch: 112 train_loss: tensor(0.4868, grad_fn=<NllLossBackward>) average train loss tensor(0.5300, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.474289919058131 val_avg_loss: tensor(2.7355)\n",
      "epoch: 113 train_loss: tensor(0.5330, grad_fn=<NllLossBackward>) average train loss tensor(0.5406, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759381898454746 val_avg_loss: tensor(2.7621)\n",
      "epoch: 114 train_loss: tensor(0.4179, grad_fn=<NllLossBackward>) average train loss tensor(0.5188, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.476850625459897 val_avg_loss: tensor(2.7721)\n",
      "epoch: 115 train_loss: tensor(0.4815, grad_fn=<NllLossBackward>) average train loss tensor(0.5055, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47508462104488597 val_avg_loss: tensor(2.7815)\n",
      "epoch: 116 train_loss: tensor(0.4796, grad_fn=<NllLossBackward>) average train loss tensor(0.4897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4762913907284768 val_avg_loss: tensor(2.8001)\n",
      "epoch: 117 train_loss: tensor(0.5428, grad_fn=<NllLossBackward>) average train loss tensor(0.5334, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47735099337748343 val_avg_loss: tensor(2.8306)\n",
      "epoch: 118 train_loss: tensor(0.4269, grad_fn=<NllLossBackward>) average train loss tensor(0.5454, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478027961736571 val_avg_loss: tensor(2.8424)\n",
      "epoch: 119 train_loss: tensor(0.4780, grad_fn=<NllLossBackward>) average train loss tensor(0.4962, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4741721854304636 val_avg_loss: tensor(2.8448)\n",
      "epoch: 120 train_loss: tensor(0.4536, grad_fn=<NllLossBackward>) average train loss tensor(0.5084, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4774981604120677 val_avg_loss: tensor(2.8289)\n",
      "epoch: 121 train_loss: tensor(0.4344, grad_fn=<NllLossBackward>) average train loss tensor(0.4954, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47758646063281823 val_avg_loss: tensor(2.8266)\n",
      "epoch: 122 train_loss: tensor(0.3664, grad_fn=<NllLossBackward>) average train loss tensor(0.4419, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4763208241353937 val_avg_loss: tensor(2.8496)\n",
      "epoch: 123 train_loss: tensor(0.3593, grad_fn=<NllLossBackward>) average train loss tensor(0.4800, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47555555555555556 val_avg_loss: tensor(2.8814)\n",
      "epoch: 124 train_loss: tensor(0.4469, grad_fn=<NllLossBackward>) average train loss tensor(0.4649, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4776158940397351 val_avg_loss: tensor(2.8839)\n",
      "epoch: 125 train_loss: tensor(0.3964, grad_fn=<NllLossBackward>) average train loss tensor(0.4714, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47573215599705665 val_avg_loss: tensor(2.8989)\n",
      "epoch: 126 train_loss: tensor(0.4340, grad_fn=<NllLossBackward>) average train loss tensor(0.4787, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4735540838852097 val_avg_loss: tensor(2.9124)\n",
      "epoch: 127 train_loss: tensor(0.4449, grad_fn=<NllLossBackward>) average train loss tensor(0.4860, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4730242825607064 val_avg_loss: tensor(2.9286)\n",
      "epoch: 128 train_loss: tensor(0.3223, grad_fn=<NllLossBackward>) average train loss tensor(0.4567, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47455481972038266 val_avg_loss: tensor(2.9318)\n",
      "epoch: 129 train_loss: tensor(0.3536, grad_fn=<NllLossBackward>) average train loss tensor(0.4322, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47119941133186166 val_avg_loss: tensor(2.9337)\n",
      "epoch: 130 train_loss: tensor(0.4036, grad_fn=<NllLossBackward>) average train loss tensor(0.4495, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.46961000735835173 val_avg_loss: tensor(2.9527)\n",
      "epoch: 131 train_loss: tensor(0.4592, grad_fn=<NllLossBackward>) average train loss tensor(0.4495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47167034584253126 val_avg_loss: tensor(2.9659)\n",
      "epoch: 132 train_loss: tensor(0.4046, grad_fn=<NllLossBackward>) average train loss tensor(0.4709, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47508462104488597 val_avg_loss: tensor(2.9537)\n",
      "epoch: 133 train_loss: tensor(0.4145, grad_fn=<NllLossBackward>) average train loss tensor(0.4357, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47152317880794703 val_avg_loss: tensor(2.9444)\n",
      "epoch: 134 train_loss: tensor(0.3938, grad_fn=<NllLossBackward>) average train loss tensor(0.4402, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.473701250919794 val_avg_loss: tensor(2.9433)\n",
      "epoch: 135 train_loss: tensor(0.3996, grad_fn=<NllLossBackward>) average train loss tensor(0.4440, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765268579838116 val_avg_loss: tensor(2.9601)\n",
      "epoch: 136 train_loss: tensor(0.3866, grad_fn=<NllLossBackward>) average train loss tensor(0.4526, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4769977924944812 val_avg_loss: tensor(2.9743)\n",
      "epoch: 137 train_loss: tensor(0.4163, grad_fn=<NllLossBackward>) average train loss tensor(0.4448, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.472906548933039 val_avg_loss: tensor(2.9910)\n",
      "epoch: 138 train_loss: tensor(0.4760, grad_fn=<NllLossBackward>) average train loss tensor(0.4266, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47234731420161885 val_avg_loss: tensor(3.0115)\n",
      "epoch: 139 train_loss: tensor(0.4100, grad_fn=<NllLossBackward>) average train loss tensor(0.4347, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47387785136129507 val_avg_loss: tensor(3.0308)\n",
      "epoch: 0 train_loss: tensor(3.8526, grad_fn=<NllLossBackward>) average train loss tensor(3.8874, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.08971302428256071 val_avg_loss: tensor(3.8445)\n",
      "epoch: 1 train_loss: tensor(3.7281, grad_fn=<NllLossBackward>) average train loss tensor(3.7790, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1393671817512877 val_avg_loss: tensor(3.7216)\n",
      "epoch: 2 train_loss: tensor(3.5718, grad_fn=<NllLossBackward>) average train loss tensor(3.6281, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.12388520971302429 val_avg_loss: tensor(3.5534)\n",
      "epoch: 3 train_loss: tensor(3.4292, grad_fn=<NllLossBackward>) average train loss tensor(3.4765, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20041206769683592 val_avg_loss: tensor(3.4105)\n",
      "epoch: 4 train_loss: tensor(3.2354, grad_fn=<NllLossBackward>) average train loss tensor(3.3148, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2648123620309051 val_avg_loss: tensor(3.2151)\n",
      "epoch: 5 train_loss: tensor(3.0345, grad_fn=<NllLossBackward>) average train loss tensor(3.1010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.30007358351729213 val_avg_loss: tensor(3.0193)\n",
      "epoch: 6 train_loss: tensor(2.8011, grad_fn=<NllLossBackward>) average train loss tensor(2.9063, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.33030169242089774 val_avg_loss: tensor(2.8299)\n",
      "epoch: 7 train_loss: tensor(2.5744, grad_fn=<NllLossBackward>) average train loss tensor(2.7089, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3634142752023547 val_avg_loss: tensor(2.6753)\n",
      "epoch: 8 train_loss: tensor(2.4375, grad_fn=<NllLossBackward>) average train loss tensor(2.5359, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.39699779249448125 val_avg_loss: tensor(2.5375)\n",
      "epoch: 9 train_loss: tensor(2.2465, grad_fn=<NllLossBackward>) average train loss tensor(2.3720, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4112141280353201 val_avg_loss: tensor(2.4330)\n",
      "epoch: 10 train_loss: tensor(2.1064, grad_fn=<NllLossBackward>) average train loss tensor(2.2340, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4184841795437822 val_avg_loss: tensor(2.3592)\n",
      "epoch: 11 train_loss: tensor(2.0220, grad_fn=<NllLossBackward>) average train loss tensor(2.1223, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4247534952170714 val_avg_loss: tensor(2.3020)\n",
      "epoch: 12 train_loss: tensor(1.8989, grad_fn=<NllLossBackward>) average train loss tensor(1.9983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43414275202354674 val_avg_loss: tensor(2.2498)\n",
      "epoch: 13 train_loss: tensor(1.7861, grad_fn=<NllLossBackward>) average train loss tensor(1.8630, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4393818984547461 val_avg_loss: tensor(2.2233)\n",
      "epoch: 14 train_loss: tensor(1.6851, grad_fn=<NllLossBackward>) average train loss tensor(1.7891, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4467402501839588 val_avg_loss: tensor(2.2025)\n",
      "epoch: 15 train_loss: tensor(1.5418, grad_fn=<NllLossBackward>) average train loss tensor(1.7108, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4531861662987491 val_avg_loss: tensor(2.1889)\n",
      "epoch: 16 train_loss: tensor(1.5178, grad_fn=<NllLossBackward>) average train loss tensor(1.6342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45680647534952173 val_avg_loss: tensor(2.1846)\n",
      "epoch: 17 train_loss: tensor(1.4106, grad_fn=<NllLossBackward>) average train loss tensor(1.5221, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4608094186902134 val_avg_loss: tensor(2.1781)\n",
      "epoch: 18 train_loss: tensor(1.3373, grad_fn=<NllLossBackward>) average train loss tensor(1.4835, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46781456953642386 val_avg_loss: tensor(2.1812)\n",
      "epoch: 19 train_loss: tensor(1.3207, grad_fn=<NllLossBackward>) average train loss tensor(1.4472, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4700220750551876 val_avg_loss: tensor(2.1845)\n",
      "epoch: 20 train_loss: tensor(1.2449, grad_fn=<NllLossBackward>) average train loss tensor(1.3543, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.468962472406181 val_avg_loss: tensor(2.2001)\n",
      "epoch: 21 train_loss: tensor(1.1838, grad_fn=<NllLossBackward>) average train loss tensor(1.2980, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4724650478292862 val_avg_loss: tensor(2.2216)\n",
      "epoch: 22 train_loss: tensor(1.1500, grad_fn=<NllLossBackward>) average train loss tensor(1.2396, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47096394407652686 val_avg_loss: tensor(2.2326)\n",
      "epoch: 23 train_loss: tensor(1.0322, grad_fn=<NllLossBackward>) average train loss tensor(1.1793, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4735540838852097 val_avg_loss: tensor(2.2593)\n",
      "epoch: 24 train_loss: tensor(1.0005, grad_fn=<NllLossBackward>) average train loss tensor(1.1172, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765857247976453 val_avg_loss: tensor(2.2964)\n",
      "epoch: 25 train_loss: tensor(1.0041, grad_fn=<NllLossBackward>) average train loss tensor(1.0996, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4728476821192053 val_avg_loss: tensor(2.3300)\n",
      "epoch: 26 train_loss: tensor(0.9241, grad_fn=<NllLossBackward>) average train loss tensor(1.0349, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4749963208241354 val_avg_loss: tensor(2.3608)\n",
      "epoch: 27 train_loss: tensor(0.9393, grad_fn=<NllLossBackward>) average train loss tensor(1.0049, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4744076526857984 val_avg_loss: tensor(2.3947)\n",
      "epoch: 28 train_loss: tensor(0.8781, grad_fn=<NllLossBackward>) average train loss tensor(0.9581, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4734657836644592 val_avg_loss: tensor(2.4157)\n",
      "epoch: 29 train_loss: tensor(0.7951, grad_fn=<NllLossBackward>) average train loss tensor(0.9344, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47061074319352464 val_avg_loss: tensor(2.4611)\n",
      "epoch: 30 train_loss: tensor(0.8231, grad_fn=<NllLossBackward>) average train loss tensor(0.9160, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4722590139808683 val_avg_loss: tensor(2.4960)\n",
      "epoch: 31 train_loss: tensor(0.8096, grad_fn=<NllLossBackward>) average train loss tensor(0.8386, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47061074319352464 val_avg_loss: tensor(2.5237)\n",
      "epoch: 32 train_loss: tensor(0.7270, grad_fn=<NllLossBackward>) average train loss tensor(0.8147, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4693156732891832 val_avg_loss: tensor(2.5635)\n",
      "epoch: 33 train_loss: tensor(0.6389, grad_fn=<NllLossBackward>) average train loss tensor(0.7664, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4702281089036056 val_avg_loss: tensor(2.5803)\n",
      "epoch: 34 train_loss: tensor(0.6566, grad_fn=<NllLossBackward>) average train loss tensor(0.7374, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47175864606328183 val_avg_loss: tensor(2.6290)\n",
      "epoch: 35 train_loss: tensor(0.6232, grad_fn=<NllLossBackward>) average train loss tensor(0.7041, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4682560706401766 val_avg_loss: tensor(2.6967)\n",
      "epoch: 36 train_loss: tensor(0.6031, grad_fn=<NllLossBackward>) average train loss tensor(0.7274, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.46722590139808684 val_avg_loss: tensor(2.7182)\n",
      "epoch: 37 train_loss: tensor(0.6171, grad_fn=<NllLossBackward>) average train loss tensor(0.6831, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4661074319352465 val_avg_loss: tensor(2.7670)\n",
      "epoch: 38 train_loss: tensor(0.5602, grad_fn=<NllLossBackward>) average train loss tensor(0.6169, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4639587932303164 val_avg_loss: tensor(2.8160)\n",
      "epoch: 39 train_loss: tensor(0.5850, grad_fn=<NllLossBackward>) average train loss tensor(0.6284, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46507726269315675 val_avg_loss: tensor(2.8525)\n",
      "epoch: 40 train_loss: tensor(0.5292, grad_fn=<NllLossBackward>) average train loss tensor(0.6053, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4679028697571744 val_avg_loss: tensor(2.8764)\n",
      "epoch: 41 train_loss: tensor(0.4963, grad_fn=<NllLossBackward>) average train loss tensor(0.5789, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4687270051508462 val_avg_loss: tensor(2.9231)\n",
      "epoch: 42 train_loss: tensor(0.5017, grad_fn=<NllLossBackward>) average train loss tensor(0.5770, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46560706401766006 val_avg_loss: tensor(2.9576)\n",
      "epoch: 43 train_loss: tensor(0.4976, grad_fn=<NllLossBackward>) average train loss tensor(0.5682, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4638999264164827 val_avg_loss: tensor(2.9948)\n",
      "epoch: 44 train_loss: tensor(0.4027, grad_fn=<NllLossBackward>) average train loss tensor(0.5115, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4703164091243561 val_avg_loss: tensor(3.0053)\n",
      "epoch: 45 train_loss: tensor(0.4079, grad_fn=<NllLossBackward>) average train loss tensor(0.4851, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47181751287711554 val_avg_loss: tensor(3.0334)\n",
      "epoch: 46 train_loss: tensor(0.4408, grad_fn=<NllLossBackward>) average train loss tensor(0.4849, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4653421633554084 val_avg_loss: tensor(3.0898)\n",
      "epoch: 47 train_loss: tensor(0.3935, grad_fn=<NllLossBackward>) average train loss tensor(0.4972, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46607799852832965 val_avg_loss: tensor(3.1560)\n",
      "epoch: 48 train_loss: tensor(0.3850, grad_fn=<NllLossBackward>) average train loss tensor(0.4438, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4648712288447388 val_avg_loss: tensor(3.2221)\n",
      "epoch: 49 train_loss: tensor(0.4131, grad_fn=<NllLossBackward>) average train loss tensor(0.4550, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4600735835172921 val_avg_loss: tensor(3.2443)\n",
      "epoch: 50 train_loss: tensor(0.4012, grad_fn=<NllLossBackward>) average train loss tensor(0.4520, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4603090507726269 val_avg_loss: tensor(3.2786)\n",
      "epoch: 51 train_loss: tensor(0.3524, grad_fn=<NllLossBackward>) average train loss tensor(0.4131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4577777777777778 val_avg_loss: tensor(3.3328)\n",
      "epoch: 52 train_loss: tensor(0.3530, grad_fn=<NllLossBackward>) average train loss tensor(0.4066, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45480500367917587 val_avg_loss: tensor(3.3821)\n",
      "epoch: 53 train_loss: tensor(0.3215, grad_fn=<NllLossBackward>) average train loss tensor(0.3909, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46186902133922003 val_avg_loss: tensor(3.3947)\n",
      "epoch: 54 train_loss: tensor(0.3362, grad_fn=<NllLossBackward>) average train loss tensor(0.3995, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46233995584988963 val_avg_loss: tensor(3.4079)\n",
      "epoch: 55 train_loss: tensor(0.2980, grad_fn=<NllLossBackward>) average train loss tensor(0.3942, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45933774834437086 val_avg_loss: tensor(3.4213)\n",
      "epoch: 56 train_loss: tensor(0.3402, grad_fn=<NllLossBackward>) average train loss tensor(0.3862, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4562178072111847 val_avg_loss: tensor(3.5101)\n",
      "epoch: 57 train_loss: tensor(0.3030, grad_fn=<NllLossBackward>) average train loss tensor(0.3594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45542310522442975 val_avg_loss: tensor(3.5765)\n",
      "epoch: 58 train_loss: tensor(0.3225, grad_fn=<NllLossBackward>) average train loss tensor(0.3694, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45910228108903606 val_avg_loss: tensor(3.5941)\n",
      "epoch: 59 train_loss: tensor(0.2853, grad_fn=<NllLossBackward>) average train loss tensor(0.3385, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45986754966887416 val_avg_loss: tensor(3.5952)\n",
      "epoch: 60 train_loss: tensor(0.2744, grad_fn=<NllLossBackward>) average train loss tensor(0.3031, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4576011773362767 val_avg_loss: tensor(3.6191)\n",
      "epoch: 61 train_loss: tensor(0.3597, grad_fn=<NllLossBackward>) average train loss tensor(0.3572, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45648270787343637 val_avg_loss: tensor(3.6682)\n",
      "epoch: 62 train_loss: tensor(0.2593, grad_fn=<NllLossBackward>) average train loss tensor(0.3140, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4569242089771891 val_avg_loss: tensor(3.7249)\n",
      "epoch: 63 train_loss: tensor(0.2615, grad_fn=<NllLossBackward>) average train loss tensor(0.3027, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45986754966887416 val_avg_loss: tensor(3.7525)\n",
      "epoch: 64 train_loss: tensor(0.2620, grad_fn=<NllLossBackward>) average train loss tensor(0.3232, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45551140544518026 val_avg_loss: tensor(3.7436)\n",
      "epoch: 65 train_loss: tensor(0.2606, grad_fn=<NllLossBackward>) average train loss tensor(0.2961, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4538925680647535 val_avg_loss: tensor(3.7785)\n",
      "epoch: 66 train_loss: tensor(0.2339, grad_fn=<NllLossBackward>) average train loss tensor(0.2979, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503311258278146 val_avg_loss: tensor(3.8526)\n",
      "epoch: 67 train_loss: tensor(0.2104, grad_fn=<NllLossBackward>) average train loss tensor(0.2758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45356880058866816 val_avg_loss: tensor(3.8769)\n",
      "epoch: 68 train_loss: tensor(0.2496, grad_fn=<NllLossBackward>) average train loss tensor(0.2981, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4548344370860927 val_avg_loss: tensor(3.8646)\n",
      "epoch: 69 train_loss: tensor(0.2609, grad_fn=<NllLossBackward>) average train loss tensor(0.2808, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4543046357615894 val_avg_loss: tensor(3.8841)\n",
      "epoch: 70 train_loss: tensor(0.2389, grad_fn=<NllLossBackward>) average train loss tensor(0.2526, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4576011773362767 val_avg_loss: tensor(3.8972)\n",
      "epoch: 71 train_loss: tensor(0.2673, grad_fn=<NllLossBackward>) average train loss tensor(0.2567, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45571743929359826 val_avg_loss: tensor(3.9371)\n",
      "epoch: 72 train_loss: tensor(0.2377, grad_fn=<NllLossBackward>) average train loss tensor(0.2657, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45642384105960265 val_avg_loss: tensor(3.9928)\n",
      "epoch: 73 train_loss: tensor(0.2003, grad_fn=<NllLossBackward>) average train loss tensor(0.2468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45439293598233993 val_avg_loss: tensor(4.0647)\n",
      "epoch: 74 train_loss: tensor(0.2527, grad_fn=<NllLossBackward>) average train loss tensor(0.2612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4556291390728477 val_avg_loss: tensor(4.0745)\n",
      "epoch: 75 train_loss: tensor(0.2156, grad_fn=<NllLossBackward>) average train loss tensor(0.2388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4517439293598234 val_avg_loss: tensor(4.1195)\n",
      "epoch: 76 train_loss: tensor(0.2135, grad_fn=<NllLossBackward>) average train loss tensor(0.2344, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45336276674025017 val_avg_loss: tensor(4.1642)\n",
      "epoch: 77 train_loss: tensor(0.1986, grad_fn=<NllLossBackward>) average train loss tensor(0.2339, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45636497424576894 val_avg_loss: tensor(4.1789)\n",
      "epoch: 78 train_loss: tensor(0.2046, grad_fn=<NllLossBackward>) average train loss tensor(0.2354, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4553053715967623 val_avg_loss: tensor(4.1693)\n",
      "epoch: 79 train_loss: tensor(0.2248, grad_fn=<NllLossBackward>) average train loss tensor(0.2451, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45374540103016925 val_avg_loss: tensor(4.1950)\n",
      "epoch: 80 train_loss: tensor(0.1967, grad_fn=<NllLossBackward>) average train loss tensor(0.2254, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4528623988226637 val_avg_loss: tensor(4.2090)\n",
      "epoch: 81 train_loss: tensor(0.1733, grad_fn=<NllLossBackward>) average train loss tensor(0.1974, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4515673289183223 val_avg_loss: tensor(4.2530)\n",
      "epoch: 82 train_loss: tensor(0.2089, grad_fn=<NllLossBackward>) average train loss tensor(0.2169, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4534805003679176 val_avg_loss: tensor(4.2753)\n",
      "epoch: 83 train_loss: tensor(0.1778, grad_fn=<NllLossBackward>) average train loss tensor(0.2124, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45321559970566594 val_avg_loss: tensor(4.2991)\n",
      "epoch: 84 train_loss: tensor(0.1536, grad_fn=<NllLossBackward>) average train loss tensor(0.2098, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45574687270051506 val_avg_loss: tensor(4.2819)\n",
      "epoch: 85 train_loss: tensor(0.1893, grad_fn=<NllLossBackward>) average train loss tensor(0.2032, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4537748344370861 val_avg_loss: tensor(4.3075)\n",
      "epoch: 86 train_loss: tensor(0.1778, grad_fn=<NllLossBackward>) average train loss tensor(0.2056, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4519499632082414 val_avg_loss: tensor(4.3716)\n",
      "epoch: 87 train_loss: tensor(0.2154, grad_fn=<NllLossBackward>) average train loss tensor(0.2284, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4475938189845475 val_avg_loss: tensor(4.3869)\n",
      "epoch: 88 train_loss: tensor(0.2005, grad_fn=<NllLossBackward>) average train loss tensor(0.2054, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45112582781456956 val_avg_loss: tensor(4.3722)\n",
      "epoch: 89 train_loss: tensor(0.1602, grad_fn=<NllLossBackward>) average train loss tensor(0.1987, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4540986019131715 val_avg_loss: tensor(4.3587)\n",
      "epoch: 90 train_loss: tensor(0.1823, grad_fn=<NllLossBackward>) average train loss tensor(0.1971, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45200883002207504 val_avg_loss: tensor(4.3710)\n",
      "epoch: 91 train_loss: tensor(0.1694, grad_fn=<NllLossBackward>) average train loss tensor(0.2023, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45230316409124355 val_avg_loss: tensor(4.4121)\n",
      "epoch: 92 train_loss: tensor(0.1437, grad_fn=<NllLossBackward>) average train loss tensor(0.1734, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4471523178807947 val_avg_loss: tensor(4.4366)\n",
      "epoch: 93 train_loss: tensor(0.1692, grad_fn=<NllLossBackward>) average train loss tensor(0.1678, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503311258278146 val_avg_loss: tensor(4.4529)\n",
      "epoch: 94 train_loss: tensor(0.1814, grad_fn=<NllLossBackward>) average train loss tensor(0.1983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4538925680647535 val_avg_loss: tensor(4.4676)\n",
      "epoch: 95 train_loss: tensor(0.1848, grad_fn=<NllLossBackward>) average train loss tensor(0.1704, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4551582045621781 val_avg_loss: tensor(4.5040)\n",
      "epoch: 96 train_loss: tensor(0.1458, grad_fn=<NllLossBackward>) average train loss tensor(0.1739, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4518027961736571 val_avg_loss: tensor(4.5202)\n",
      "epoch: 97 train_loss: tensor(0.1421, grad_fn=<NllLossBackward>) average train loss tensor(0.1474, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503605592347314 val_avg_loss: tensor(4.5807)\n",
      "epoch: 98 train_loss: tensor(0.1544, grad_fn=<NllLossBackward>) average train loss tensor(0.1673, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4501839587932303 val_avg_loss: tensor(4.6282)\n",
      "epoch: 99 train_loss: tensor(0.1133, grad_fn=<NllLossBackward>) average train loss tensor(0.1424, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4521559970566593 val_avg_loss: tensor(4.6687)\n",
      "epoch: 100 train_loss: tensor(0.1487, grad_fn=<NllLossBackward>) average train loss tensor(0.1544, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45030169242089774 val_avg_loss: tensor(4.7001)\n",
      "epoch: 101 train_loss: tensor(0.1177, grad_fn=<NllLossBackward>) average train loss tensor(0.1586, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44741721854304634 val_avg_loss: tensor(4.7306)\n",
      "epoch: 102 train_loss: tensor(0.1263, grad_fn=<NllLossBackward>) average train loss tensor(0.1536, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44771155261221485 val_avg_loss: tensor(4.7423)\n",
      "epoch: 103 train_loss: tensor(0.1133, grad_fn=<NllLossBackward>) average train loss tensor(0.1350, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44877115526122147 val_avg_loss: tensor(4.7592)\n",
      "epoch: 104 train_loss: tensor(0.1216, grad_fn=<NllLossBackward>) average train loss tensor(0.1503, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45165562913907287 val_avg_loss: tensor(4.7957)\n",
      "epoch: 105 train_loss: tensor(0.1069, grad_fn=<NllLossBackward>) average train loss tensor(0.1377, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4536571008094187 val_avg_loss: tensor(4.7848)\n",
      "epoch: 106 train_loss: tensor(0.0959, grad_fn=<NllLossBackward>) average train loss tensor(0.1472, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45177336276674024 val_avg_loss: tensor(4.8265)\n",
      "epoch: 107 train_loss: tensor(0.1387, grad_fn=<NllLossBackward>) average train loss tensor(0.1491, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4498013245033113 val_avg_loss: tensor(4.8728)\n",
      "epoch: 108 train_loss: tensor(0.0928, grad_fn=<NllLossBackward>) average train loss tensor(0.1308, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45077262693156733 val_avg_loss: tensor(4.8791)\n",
      "epoch: 109 train_loss: tensor(0.1314, grad_fn=<NllLossBackward>) average train loss tensor(0.1401, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44824135393671816 val_avg_loss: tensor(4.9087)\n",
      "epoch: 110 train_loss: tensor(0.0821, grad_fn=<NllLossBackward>) average train loss tensor(0.1312, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4473583517292127 val_avg_loss: tensor(4.9384)\n",
      "epoch: 111 train_loss: tensor(0.1170, grad_fn=<NllLossBackward>) average train loss tensor(0.1427, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4469757174392936 val_avg_loss: tensor(4.9466)\n",
      "epoch: 112 train_loss: tensor(0.0995, grad_fn=<NllLossBackward>) average train loss tensor(0.1252, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4481236203090508 val_avg_loss: tensor(4.9960)\n",
      "epoch: 113 train_loss: tensor(0.0856, grad_fn=<NllLossBackward>) average train loss tensor(0.1230, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44800588668138336 val_avg_loss: tensor(5.0389)\n",
      "epoch: 114 train_loss: tensor(0.1188, grad_fn=<NllLossBackward>) average train loss tensor(0.1287, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44900662251655626 val_avg_loss: tensor(5.0261)\n",
      "epoch: 115 train_loss: tensor(0.1082, grad_fn=<NllLossBackward>) average train loss tensor(0.1342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.450242825607064 val_avg_loss: tensor(4.9964)\n",
      "epoch: 116 train_loss: tensor(0.1139, grad_fn=<NllLossBackward>) average train loss tensor(0.1276, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44806475349521707 val_avg_loss: tensor(5.0538)\n",
      "epoch: 117 train_loss: tensor(0.1114, grad_fn=<NllLossBackward>) average train loss tensor(0.1106, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430610743193525 val_avg_loss: tensor(5.1154)\n",
      "epoch: 118 train_loss: tensor(0.0992, grad_fn=<NllLossBackward>) average train loss tensor(0.1319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44491537895511407 val_avg_loss: tensor(5.1235)\n",
      "epoch: 119 train_loss: tensor(0.0724, grad_fn=<NllLossBackward>) average train loss tensor(0.1194, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4458866813833701 val_avg_loss: tensor(5.1410)\n",
      "epoch: 120 train_loss: tensor(0.1065, grad_fn=<NllLossBackward>) average train loss tensor(0.1395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44777041942604856 val_avg_loss: tensor(5.1612)\n",
      "epoch: 121 train_loss: tensor(0.1312, grad_fn=<NllLossBackward>) average train loss tensor(0.1346, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4501250919793966 val_avg_loss: tensor(5.1725)\n",
      "epoch: 122 train_loss: tensor(0.1266, grad_fn=<NllLossBackward>) average train loss tensor(0.1190, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4487122884473878 val_avg_loss: tensor(5.2032)\n",
      "epoch: 123 train_loss: tensor(0.1028, grad_fn=<NllLossBackward>) average train loss tensor(0.1126, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4470345842531273 val_avg_loss: tensor(5.1729)\n",
      "epoch: 124 train_loss: tensor(0.0914, grad_fn=<NllLossBackward>) average train loss tensor(0.1100, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44556291390728475 val_avg_loss: tensor(5.1804)\n",
      "epoch: 125 train_loss: tensor(0.1201, grad_fn=<NllLossBackward>) average train loss tensor(0.1068, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4475643855776306 val_avg_loss: tensor(5.1999)\n",
      "epoch: 126 train_loss: tensor(0.1161, grad_fn=<NllLossBackward>) average train loss tensor(0.1055, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4520382634289919 val_avg_loss: tensor(5.2416)\n",
      "epoch: 127 train_loss: tensor(0.1040, grad_fn=<NllLossBackward>) average train loss tensor(0.1343, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.452420897718911 val_avg_loss: tensor(5.2506)\n",
      "epoch: 128 train_loss: tensor(0.0777, grad_fn=<NllLossBackward>) average train loss tensor(0.1194, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.450242825607064 val_avg_loss: tensor(5.2613)\n",
      "epoch: 129 train_loss: tensor(0.1150, grad_fn=<NllLossBackward>) average train loss tensor(0.1235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4458278145695364 val_avg_loss: tensor(5.2755)\n",
      "epoch: 130 train_loss: tensor(0.0665, grad_fn=<NllLossBackward>) average train loss tensor(0.0964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44432671081677705 val_avg_loss: tensor(5.3421)\n",
      "epoch: 131 train_loss: tensor(0.1049, grad_fn=<NllLossBackward>) average train loss tensor(0.1163, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44456217807211185 val_avg_loss: tensor(5.3718)\n",
      "epoch: 132 train_loss: tensor(0.0968, grad_fn=<NllLossBackward>) average train loss tensor(0.0974, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44653421633554086 val_avg_loss: tensor(5.3769)\n",
      "epoch: 133 train_loss: tensor(0.0856, grad_fn=<NllLossBackward>) average train loss tensor(0.1069, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4469168506254599 val_avg_loss: tensor(5.3753)\n",
      "epoch: 134 train_loss: tensor(0.1247, grad_fn=<NllLossBackward>) average train loss tensor(0.1033, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44600441501103755 val_avg_loss: tensor(5.3827)\n",
      "epoch: 135 train_loss: tensor(0.1071, grad_fn=<NllLossBackward>) average train loss tensor(0.1182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4430022075055188 val_avg_loss: tensor(5.4118)\n",
      "epoch: 136 train_loss: tensor(0.0956, grad_fn=<NllLossBackward>) average train loss tensor(0.1245, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44403237674760854 val_avg_loss: tensor(5.3709)\n",
      "epoch: 137 train_loss: tensor(0.0933, grad_fn=<NllLossBackward>) average train loss tensor(0.1161, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44809418690213393 val_avg_loss: tensor(5.3744)\n",
      "epoch: 138 train_loss: tensor(0.0712, grad_fn=<NllLossBackward>) average train loss tensor(0.0961, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4477409860191317 val_avg_loss: tensor(5.4013)\n",
      "epoch: 139 train_loss: tensor(0.0746, grad_fn=<NllLossBackward>) average train loss tensor(0.1020, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44844738778513615 val_avg_loss: tensor(5.3890)\n",
      "epoch: 0 train_loss: tensor(3.8283, grad_fn=<NllLossBackward>) average train loss tensor(3.9259, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.04621044885945548 val_avg_loss: tensor(3.7868)\n",
      "epoch: 1 train_loss: tensor(3.7142, grad_fn=<NllLossBackward>) average train loss tensor(3.7752, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07652685798381163 val_avg_loss: tensor(3.6956)\n",
      "epoch: 2 train_loss: tensor(3.6556, grad_fn=<NllLossBackward>) average train loss tensor(3.6897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.09247976453274466 val_avg_loss: tensor(3.6116)\n",
      "epoch: 3 train_loss: tensor(3.5649, grad_fn=<NllLossBackward>) average train loss tensor(3.5957, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.14136865342163354 val_avg_loss: tensor(3.5198)\n",
      "epoch: 4 train_loss: tensor(3.4520, grad_fn=<NllLossBackward>) average train loss tensor(3.5037, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.17365710080941868 val_avg_loss: tensor(3.4149)\n",
      "epoch: 5 train_loss: tensor(3.3739, grad_fn=<NllLossBackward>) average train loss tensor(3.3886, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.21197939661515822 val_avg_loss: tensor(3.2790)\n",
      "epoch: 6 train_loss: tensor(3.2030, grad_fn=<NllLossBackward>) average train loss tensor(3.2675, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2512729948491538 val_avg_loss: tensor(3.1311)\n",
      "epoch: 7 train_loss: tensor(3.0709, grad_fn=<NllLossBackward>) average train loss tensor(3.1235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.29286239882266374 val_avg_loss: tensor(2.9809)\n",
      "epoch: 8 train_loss: tensor(2.9088, grad_fn=<NllLossBackward>) average train loss tensor(2.9642, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.32509197939661516 val_avg_loss: tensor(2.8222)\n",
      "epoch: 9 train_loss: tensor(2.7577, grad_fn=<NllLossBackward>) average train loss tensor(2.8484, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3485504047093451 val_avg_loss: tensor(2.6834)\n",
      "epoch: 10 train_loss: tensor(2.6417, grad_fn=<NllLossBackward>) average train loss tensor(2.6902, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3622663723325975 val_avg_loss: tensor(2.5696)\n",
      "epoch: 11 train_loss: tensor(2.4834, grad_fn=<NllLossBackward>) average train loss tensor(2.5857, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38251655629139075 val_avg_loss: tensor(2.4733)\n",
      "epoch: 12 train_loss: tensor(2.3632, grad_fn=<NllLossBackward>) average train loss tensor(2.4492, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.39358351729212654 val_avg_loss: tensor(2.3884)\n",
      "epoch: 13 train_loss: tensor(2.2353, grad_fn=<NllLossBackward>) average train loss tensor(2.3394, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3959087564385578 val_avg_loss: tensor(2.3239)\n",
      "epoch: 14 train_loss: tensor(2.1254, grad_fn=<NllLossBackward>) average train loss tensor(2.2033, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40794701986754967 val_avg_loss: tensor(2.2701)\n",
      "epoch: 15 train_loss: tensor(2.0134, grad_fn=<NllLossBackward>) average train loss tensor(2.1150, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4136571008094187 val_avg_loss: tensor(2.2203)\n",
      "epoch: 16 train_loss: tensor(1.8650, grad_fn=<NllLossBackward>) average train loss tensor(2.0222, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42251655629139073 val_avg_loss: tensor(2.1914)\n",
      "epoch: 17 train_loss: tensor(1.8048, grad_fn=<NllLossBackward>) average train loss tensor(1.9449, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4258719646799117 val_avg_loss: tensor(2.1593)\n",
      "epoch: 18 train_loss: tensor(1.7806, grad_fn=<NllLossBackward>) average train loss tensor(1.8785, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43376011773362766 val_avg_loss: tensor(2.1442)\n",
      "epoch: 19 train_loss: tensor(1.6136, grad_fn=<NllLossBackward>) average train loss tensor(1.7792, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44270787343635026 val_avg_loss: tensor(2.1311)\n",
      "epoch: 20 train_loss: tensor(1.6245, grad_fn=<NllLossBackward>) average train loss tensor(1.7260, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4421486387049301 val_avg_loss: tensor(2.1318)\n",
      "epoch: 21 train_loss: tensor(1.5862, grad_fn=<NllLossBackward>) average train loss tensor(1.6584, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44809418690213393 val_avg_loss: tensor(2.1344)\n",
      "epoch: 22 train_loss: tensor(1.5091, grad_fn=<NllLossBackward>) average train loss tensor(1.5958, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4498307579102281 val_avg_loss: tensor(2.1306)\n",
      "epoch: 23 train_loss: tensor(1.4317, grad_fn=<NllLossBackward>) average train loss tensor(1.5341, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.453392200147167 val_avg_loss: tensor(2.1343)\n",
      "epoch: 24 train_loss: tensor(1.3568, grad_fn=<NllLossBackward>) average train loss tensor(1.4688, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46231052244297277 val_avg_loss: tensor(2.1449)\n",
      "epoch: 25 train_loss: tensor(1.2808, grad_fn=<NllLossBackward>) average train loss tensor(1.4068, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45951434878587194 val_avg_loss: tensor(2.1518)\n",
      "epoch: 26 train_loss: tensor(1.2664, grad_fn=<NllLossBackward>) average train loss tensor(1.3885, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.458719646799117 val_avg_loss: tensor(2.1722)\n",
      "epoch: 27 train_loss: tensor(1.2017, grad_fn=<NllLossBackward>) average train loss tensor(1.3063, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4603973509933775 val_avg_loss: tensor(2.1794)\n",
      "epoch: 28 train_loss: tensor(1.1502, grad_fn=<NllLossBackward>) average train loss tensor(1.2481, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4607505518763797 val_avg_loss: tensor(2.2103)\n",
      "epoch: 29 train_loss: tensor(1.1136, grad_fn=<NllLossBackward>) average train loss tensor(1.2068, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46545989698307577 val_avg_loss: tensor(2.2569)\n",
      "epoch: 30 train_loss: tensor(1.0514, grad_fn=<NllLossBackward>) average train loss tensor(1.1495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4643708609271523 val_avg_loss: tensor(2.2560)\n",
      "epoch: 31 train_loss: tensor(1.0124, grad_fn=<NllLossBackward>) average train loss tensor(1.1284, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4658719646799117 val_avg_loss: tensor(2.2749)\n",
      "epoch: 32 train_loss: tensor(0.9615, grad_fn=<NllLossBackward>) average train loss tensor(1.0793, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4611626195732156 val_avg_loss: tensor(2.3123)\n",
      "epoch: 33 train_loss: tensor(0.9173, grad_fn=<NllLossBackward>) average train loss tensor(1.0240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4610448859455482 val_avg_loss: tensor(2.3554)\n",
      "epoch: 34 train_loss: tensor(0.9471, grad_fn=<NllLossBackward>) average train loss tensor(0.9915, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4625754231052244 val_avg_loss: tensor(2.3751)\n",
      "epoch: 35 train_loss: tensor(0.8486, grad_fn=<NllLossBackward>) average train loss tensor(0.9529, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4635172921265637 val_avg_loss: tensor(2.4049)\n",
      "epoch: 36 train_loss: tensor(0.8491, grad_fn=<NllLossBackward>) average train loss tensor(0.9033, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4609271523178808 val_avg_loss: tensor(2.4526)\n",
      "epoch: 37 train_loss: tensor(0.8279, grad_fn=<NllLossBackward>) average train loss tensor(0.8717, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45880794701986755 val_avg_loss: tensor(2.5134)\n",
      "epoch: 38 train_loss: tensor(0.7713, grad_fn=<NllLossBackward>) average train loss tensor(0.8388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45948491537895514 val_avg_loss: tensor(2.5560)\n",
      "epoch: 39 train_loss: tensor(0.6857, grad_fn=<NllLossBackward>) average train loss tensor(0.8134, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45933774834437086 val_avg_loss: tensor(2.5742)\n",
      "epoch: 40 train_loss: tensor(0.6864, grad_fn=<NllLossBackward>) average train loss tensor(0.7614, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.458925680647535 val_avg_loss: tensor(2.6153)\n",
      "epoch: 41 train_loss: tensor(0.6716, grad_fn=<NllLossBackward>) average train loss tensor(0.7457, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4579838116261957 val_avg_loss: tensor(2.6408)\n",
      "epoch: 42 train_loss: tensor(0.6565, grad_fn=<NllLossBackward>) average train loss tensor(0.7152, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45748344370860927 val_avg_loss: tensor(2.6801)\n",
      "epoch: 43 train_loss: tensor(0.5669, grad_fn=<NllLossBackward>) average train loss tensor(0.6767, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4565121412803532 val_avg_loss: tensor(2.7536)\n",
      "epoch: 44 train_loss: tensor(0.5892, grad_fn=<NllLossBackward>) average train loss tensor(0.6570, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45839587932303166 val_avg_loss: tensor(2.8097)\n",
      "epoch: 45 train_loss: tensor(0.5155, grad_fn=<NllLossBackward>) average train loss tensor(0.5922, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45604120676968357 val_avg_loss: tensor(2.8681)\n",
      "epoch: 46 train_loss: tensor(0.5491, grad_fn=<NllLossBackward>) average train loss tensor(0.5671, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.456158940397351 val_avg_loss: tensor(2.9558)\n",
      "epoch: 47 train_loss: tensor(0.5822, grad_fn=<NllLossBackward>) average train loss tensor(0.5931, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503605592347314 val_avg_loss: tensor(2.9586)\n",
      "epoch: 48 train_loss: tensor(0.5097, grad_fn=<NllLossBackward>) average train loss tensor(0.5689, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4558646063281825 val_avg_loss: tensor(2.9842)\n",
      "epoch: 49 train_loss: tensor(0.4144, grad_fn=<NllLossBackward>) average train loss tensor(0.5139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45327446651949965 val_avg_loss: tensor(2.9853)\n",
      "epoch: 50 train_loss: tensor(0.4304, grad_fn=<NllLossBackward>) average train loss tensor(0.4914, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45021339220014717 val_avg_loss: tensor(3.0298)\n",
      "epoch: 51 train_loss: tensor(0.4456, grad_fn=<NllLossBackward>) average train loss tensor(0.5034, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4518027961736571 val_avg_loss: tensor(3.1284)\n",
      "epoch: 52 train_loss: tensor(0.4078, grad_fn=<NllLossBackward>) average train loss tensor(0.4584, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44847682119205295 val_avg_loss: tensor(3.1863)\n",
      "epoch: 53 train_loss: tensor(0.3921, grad_fn=<NllLossBackward>) average train loss tensor(0.4771, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44815305371596764 val_avg_loss: tensor(3.2294)\n",
      "epoch: 54 train_loss: tensor(0.4199, grad_fn=<NllLossBackward>) average train loss tensor(0.4520, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45009565857247974 val_avg_loss: tensor(3.2519)\n",
      "epoch: 55 train_loss: tensor(0.3791, grad_fn=<NllLossBackward>) average train loss tensor(0.4046, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4475055187637969 val_avg_loss: tensor(3.2602)\n",
      "epoch: 56 train_loss: tensor(0.3761, grad_fn=<NllLossBackward>) average train loss tensor(0.4154, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4505077262693157 val_avg_loss: tensor(3.3264)\n",
      "epoch: 57 train_loss: tensor(0.3872, grad_fn=<NllLossBackward>) average train loss tensor(0.3894, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4489477557027226 val_avg_loss: tensor(3.3693)\n",
      "epoch: 58 train_loss: tensor(0.3184, grad_fn=<NllLossBackward>) average train loss tensor(0.3890, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45006622516556294 val_avg_loss: tensor(3.4147)\n",
      "epoch: 59 train_loss: tensor(0.3434, grad_fn=<NllLossBackward>) average train loss tensor(0.3730, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4454157468727005 val_avg_loss: tensor(3.3983)\n",
      "epoch: 60 train_loss: tensor(0.2909, grad_fn=<NllLossBackward>) average train loss tensor(0.3421, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4455334805003679 val_avg_loss: tensor(3.4620)\n",
      "epoch: 61 train_loss: tensor(0.3606, grad_fn=<NllLossBackward>) average train loss tensor(0.3513, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44618101545253863 val_avg_loss: tensor(3.5599)\n",
      "epoch: 62 train_loss: tensor(0.2599, grad_fn=<NllLossBackward>) average train loss tensor(0.3423, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44800588668138336 val_avg_loss: tensor(3.5296)\n",
      "epoch: 63 train_loss: tensor(0.2957, grad_fn=<NllLossBackward>) average train loss tensor(0.3231, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4493598233995585 val_avg_loss: tensor(3.5958)\n",
      "epoch: 64 train_loss: tensor(0.2723, grad_fn=<NllLossBackward>) average train loss tensor(0.3125, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44671081677704194 val_avg_loss: tensor(3.6641)\n",
      "epoch: 65 train_loss: tensor(0.2612, grad_fn=<NllLossBackward>) average train loss tensor(0.3082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44671081677704194 val_avg_loss: tensor(3.7074)\n",
      "epoch: 66 train_loss: tensor(0.2443, grad_fn=<NllLossBackward>) average train loss tensor(0.2929, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44379690949227374 val_avg_loss: tensor(3.7743)\n",
      "epoch: 67 train_loss: tensor(0.2974, grad_fn=<NllLossBackward>) average train loss tensor(0.2879, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44294334069168506 val_avg_loss: tensor(3.7720)\n",
      "epoch: 68 train_loss: tensor(0.2824, grad_fn=<NllLossBackward>) average train loss tensor(0.2776, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44282560706401763 val_avg_loss: tensor(3.7741)\n",
      "epoch: 69 train_loss: tensor(0.2160, grad_fn=<NllLossBackward>) average train loss tensor(0.2447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44311994113318615 val_avg_loss: tensor(3.8071)\n",
      "epoch: 70 train_loss: tensor(0.2083, grad_fn=<NllLossBackward>) average train loss tensor(0.2606, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4407064017660044 val_avg_loss: tensor(3.8825)\n",
      "epoch: 71 train_loss: tensor(0.2294, grad_fn=<NllLossBackward>) average train loss tensor(0.2526, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44347314201618837 val_avg_loss: tensor(3.9407)\n",
      "epoch: 72 train_loss: tensor(0.1988, grad_fn=<NllLossBackward>) average train loss tensor(0.2388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44126563649742456 val_avg_loss: tensor(3.9947)\n",
      "epoch: 73 train_loss: tensor(0.1739, grad_fn=<NllLossBackward>) average train loss tensor(0.2184, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4402943340691685 val_avg_loss: tensor(4.0346)\n",
      "epoch: 74 train_loss: tensor(0.1893, grad_fn=<NllLossBackward>) average train loss tensor(0.2493, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4426784400294334 val_avg_loss: tensor(4.0579)\n",
      "epoch: 75 train_loss: tensor(0.2081, grad_fn=<NllLossBackward>) average train loss tensor(0.2077, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44303164091243563 val_avg_loss: tensor(4.0991)\n",
      "epoch: 76 train_loss: tensor(0.1725, grad_fn=<NllLossBackward>) average train loss tensor(0.1956, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4417365710080942 val_avg_loss: tensor(4.0977)\n",
      "epoch: 77 train_loss: tensor(0.2051, grad_fn=<NllLossBackward>) average train loss tensor(0.2053, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4382634289919058 val_avg_loss: tensor(4.1170)\n",
      "epoch: 78 train_loss: tensor(0.1747, grad_fn=<NllLossBackward>) average train loss tensor(0.1976, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44211920529801324 val_avg_loss: tensor(4.1302)\n",
      "epoch: 79 train_loss: tensor(0.1956, grad_fn=<NllLossBackward>) average train loss tensor(0.2023, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4402354672553348 val_avg_loss: tensor(4.2108)\n",
      "epoch: 80 train_loss: tensor(0.1915, grad_fn=<NllLossBackward>) average train loss tensor(0.2026, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4370272259013981 val_avg_loss: tensor(4.2051)\n",
      "epoch: 81 train_loss: tensor(0.1557, grad_fn=<NllLossBackward>) average train loss tensor(0.1972, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4376158940397351 val_avg_loss: tensor(4.1826)\n",
      "epoch: 82 train_loss: tensor(0.1606, grad_fn=<NllLossBackward>) average train loss tensor(0.1953, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4403532008830022 val_avg_loss: tensor(4.2126)\n",
      "epoch: 83 train_loss: tensor(0.1745, grad_fn=<NllLossBackward>) average train loss tensor(0.1872, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4410007358351729 val_avg_loss: tensor(4.2356)\n",
      "epoch: 84 train_loss: tensor(0.1302, grad_fn=<NllLossBackward>) average train loss tensor(0.1643, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43858719646799116 val_avg_loss: tensor(4.2622)\n",
      "epoch: 85 train_loss: tensor(0.1800, grad_fn=<NllLossBackward>) average train loss tensor(0.1915, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43788079470198676 val_avg_loss: tensor(4.2979)\n",
      "epoch: 86 train_loss: tensor(0.1509, grad_fn=<NllLossBackward>) average train loss tensor(0.1679, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4390875643855776 val_avg_loss: tensor(4.3800)\n",
      "epoch: 87 train_loss: tensor(0.1652, grad_fn=<NllLossBackward>) average train loss tensor(0.1657, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4371743929359823 val_avg_loss: tensor(4.4652)\n",
      "epoch: 88 train_loss: tensor(0.1582, grad_fn=<NllLossBackward>) average train loss tensor(0.1767, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4364091243561442 val_avg_loss: tensor(4.5036)\n",
      "epoch: 89 train_loss: tensor(0.1617, grad_fn=<NllLossBackward>) average train loss tensor(0.1614, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43720382634289917 val_avg_loss: tensor(4.4998)\n",
      "epoch: 90 train_loss: tensor(0.1679, grad_fn=<NllLossBackward>) average train loss tensor(0.1603, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44020603384841794 val_avg_loss: tensor(4.5140)\n",
      "epoch: 91 train_loss: tensor(0.1490, grad_fn=<NllLossBackward>) average train loss tensor(0.1571, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44103016924208976 val_avg_loss: tensor(4.5295)\n",
      "epoch: 92 train_loss: tensor(0.1082, grad_fn=<NllLossBackward>) average train loss tensor(0.1280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4410890360559235 val_avg_loss: tensor(4.5807)\n",
      "epoch: 93 train_loss: tensor(0.1661, grad_fn=<NllLossBackward>) average train loss tensor(0.1633, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44247240618101547 val_avg_loss: tensor(4.5970)\n",
      "epoch: 94 train_loss: tensor(0.1415, grad_fn=<NllLossBackward>) average train loss tensor(0.1580, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43896983075791024 val_avg_loss: tensor(4.5710)\n",
      "epoch: 95 train_loss: tensor(0.1293, grad_fn=<NllLossBackward>) average train loss tensor(0.1291, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43796909492273733 val_avg_loss: tensor(4.5791)\n",
      "epoch: 96 train_loss: tensor(0.1422, grad_fn=<NllLossBackward>) average train loss tensor(0.1319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43705665930831494 val_avg_loss: tensor(4.6474)\n",
      "epoch: 97 train_loss: tensor(0.1380, grad_fn=<NllLossBackward>) average train loss tensor(0.1426, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4397645327446652 val_avg_loss: tensor(4.7155)\n",
      "epoch: 98 train_loss: tensor(0.1374, grad_fn=<NllLossBackward>) average train loss tensor(0.1226, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44182487122884473 val_avg_loss: tensor(4.7036)\n",
      "epoch: 99 train_loss: tensor(0.1126, grad_fn=<NllLossBackward>) average train loss tensor(0.1253, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44120676968359085 val_avg_loss: tensor(4.6803)\n",
      "epoch: 100 train_loss: tensor(0.1029, grad_fn=<NllLossBackward>) average train loss tensor(0.1157, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4413245033112583 val_avg_loss: tensor(4.7179)\n",
      "epoch: 101 train_loss: tensor(0.1251, grad_fn=<NllLossBackward>) average train loss tensor(0.1317, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4422075055187638 val_avg_loss: tensor(4.7420)\n",
      "epoch: 102 train_loss: tensor(0.1073, grad_fn=<NllLossBackward>) average train loss tensor(0.1180, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44088300220750554 val_avg_loss: tensor(4.7276)\n",
      "epoch: 103 train_loss: tensor(0.1129, grad_fn=<NllLossBackward>) average train loss tensor(0.1294, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43758646063281825 val_avg_loss: tensor(4.7825)\n",
      "epoch: 104 train_loss: tensor(0.1360, grad_fn=<NllLossBackward>) average train loss tensor(0.1369, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4363208241353937 val_avg_loss: tensor(4.7917)\n",
      "epoch: 105 train_loss: tensor(0.0878, grad_fn=<NllLossBackward>) average train loss tensor(0.1140, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43690949227373066 val_avg_loss: tensor(4.7555)\n",
      "epoch: 106 train_loss: tensor(0.0895, grad_fn=<NllLossBackward>) average train loss tensor(0.1053, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4387049300956586 val_avg_loss: tensor(4.8102)\n",
      "epoch: 107 train_loss: tensor(0.0873, grad_fn=<NllLossBackward>) average train loss tensor(0.0933, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44044150110375274 val_avg_loss: tensor(4.8913)\n",
      "epoch: 108 train_loss: tensor(0.1159, grad_fn=<NllLossBackward>) average train loss tensor(0.1235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4404120676968359 val_avg_loss: tensor(4.9421)\n",
      "epoch: 109 train_loss: tensor(0.0843, grad_fn=<NllLossBackward>) average train loss tensor(0.1170, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4333480500367918 val_avg_loss: tensor(4.9790)\n",
      "epoch: 110 train_loss: tensor(0.1096, grad_fn=<NllLossBackward>) average train loss tensor(0.1134, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.435467255334805 val_avg_loss: tensor(4.9362)\n",
      "epoch: 111 train_loss: tensor(0.0961, grad_fn=<NllLossBackward>) average train loss tensor(0.1218, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4369389256806475 val_avg_loss: tensor(4.9695)\n",
      "epoch: 112 train_loss: tensor(0.0685, grad_fn=<NllLossBackward>) average train loss tensor(0.0937, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4333186166298749 val_avg_loss: tensor(5.0241)\n",
      "epoch: 113 train_loss: tensor(0.0850, grad_fn=<NllLossBackward>) average train loss tensor(0.0941, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43252391464311996 val_avg_loss: tensor(5.0876)\n",
      "epoch: 114 train_loss: tensor(0.0943, grad_fn=<NllLossBackward>) average train loss tensor(0.1082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4349963208241354 val_avg_loss: tensor(5.1480)\n",
      "epoch: 115 train_loss: tensor(0.0855, grad_fn=<NllLossBackward>) average train loss tensor(0.1028, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44097130242825605 val_avg_loss: tensor(5.1278)\n",
      "epoch: 116 train_loss: tensor(0.1307, grad_fn=<NllLossBackward>) average train loss tensor(0.1218, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4389992641648271 val_avg_loss: tensor(5.1224)\n",
      "epoch: 117 train_loss: tensor(0.0729, grad_fn=<NllLossBackward>) average train loss tensor(0.0719, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4373804267844003 val_avg_loss: tensor(5.1923)\n",
      "epoch: 118 train_loss: tensor(0.0977, grad_fn=<NllLossBackward>) average train loss tensor(0.1143, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43944076526857984 val_avg_loss: tensor(5.1650)\n",
      "epoch: 119 train_loss: tensor(0.0753, grad_fn=<NllLossBackward>) average train loss tensor(0.0878, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4398233995584989 val_avg_loss: tensor(5.1079)\n",
      "epoch: 120 train_loss: tensor(0.0629, grad_fn=<NllLossBackward>) average train loss tensor(0.0861, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43858719646799116 val_avg_loss: tensor(5.0786)\n",
      "epoch: 121 train_loss: tensor(0.1142, grad_fn=<NllLossBackward>) average train loss tensor(0.0998, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.435467255334805 val_avg_loss: tensor(5.1174)\n",
      "epoch: 122 train_loss: tensor(0.0967, grad_fn=<NllLossBackward>) average train loss tensor(0.0893, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43711552612214866 val_avg_loss: tensor(5.1777)\n",
      "epoch: 123 train_loss: tensor(0.0934, grad_fn=<NllLossBackward>) average train loss tensor(0.1050, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4383222958057395 val_avg_loss: tensor(5.2235)\n",
      "epoch: 124 train_loss: tensor(0.0759, grad_fn=<NllLossBackward>) average train loss tensor(0.0905, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43758646063281825 val_avg_loss: tensor(5.1722)\n",
      "epoch: 125 train_loss: tensor(0.0834, grad_fn=<NllLossBackward>) average train loss tensor(0.0935, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4374981604120677 val_avg_loss: tensor(5.1370)\n",
      "epoch: 126 train_loss: tensor(0.0635, grad_fn=<NllLossBackward>) average train loss tensor(0.0914, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.43740986019131717 val_avg_loss: tensor(5.1584)\n",
      "epoch: 127 train_loss: tensor(0.1134, grad_fn=<NllLossBackward>) average train loss tensor(0.1082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43573215599705667 val_avg_loss: tensor(5.2414)\n",
      "epoch: 128 train_loss: tensor(0.0786, grad_fn=<NllLossBackward>) average train loss tensor(0.0857, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4363208241353937 val_avg_loss: tensor(5.2548)\n",
      "epoch: 129 train_loss: tensor(0.0783, grad_fn=<NllLossBackward>) average train loss tensor(0.0736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4364679911699779 val_avg_loss: tensor(5.2932)\n",
      "epoch: 130 train_loss: tensor(0.0643, grad_fn=<NllLossBackward>) average train loss tensor(0.0815, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4372626931567329 val_avg_loss: tensor(5.3277)\n",
      "epoch: 131 train_loss: tensor(0.0633, grad_fn=<NllLossBackward>) average train loss tensor(0.0818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43690949227373066 val_avg_loss: tensor(5.3900)\n",
      "epoch: 132 train_loss: tensor(0.0557, grad_fn=<NllLossBackward>) average train loss tensor(0.0725, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4348197203826343 val_avg_loss: tensor(5.4169)\n",
      "epoch: 133 train_loss: tensor(0.0646, grad_fn=<NllLossBackward>) average train loss tensor(0.0801, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.435467255334805 val_avg_loss: tensor(5.3863)\n",
      "epoch: 134 train_loss: tensor(0.0447, grad_fn=<NllLossBackward>) average train loss tensor(0.0654, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4340250183958793 val_avg_loss: tensor(5.3901)\n",
      "epoch: 135 train_loss: tensor(0.0895, grad_fn=<NllLossBackward>) average train loss tensor(0.0762, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4350257542310522 val_avg_loss: tensor(5.4131)\n",
      "epoch: 136 train_loss: tensor(0.0551, grad_fn=<NllLossBackward>) average train loss tensor(0.0724, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4351140544518028 val_avg_loss: tensor(5.4121)\n",
      "epoch: 137 train_loss: tensor(0.0647, grad_fn=<NllLossBackward>) average train loss tensor(0.0736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43549668874172187 val_avg_loss: tensor(5.4408)\n",
      "epoch: 138 train_loss: tensor(0.0635, grad_fn=<NllLossBackward>) average train loss tensor(0.0715, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4349963208241354 val_avg_loss: tensor(5.5319)\n",
      "epoch: 139 train_loss: tensor(0.0695, grad_fn=<NllLossBackward>) average train loss tensor(0.0688, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43437821927888154 val_avg_loss: tensor(5.6094)\n",
      "epoch: 0 train_loss: tensor(3.8150, grad_fn=<NllLossBackward>) average train loss tensor(3.8678, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.04906548933038999 val_avg_loss: tensor(3.7733)\n",
      "epoch: 1 train_loss: tensor(3.6999, grad_fn=<NllLossBackward>) average train loss tensor(3.7202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07111111111111111 val_avg_loss: tensor(3.6571)\n",
      "epoch: 2 train_loss: tensor(3.6022, grad_fn=<NllLossBackward>) average train loss tensor(3.6205, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.15914643119941133 val_avg_loss: tensor(3.5547)\n",
      "epoch: 3 train_loss: tensor(3.4752, grad_fn=<NllLossBackward>) average train loss tensor(3.5249, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20206033848417954 val_avg_loss: tensor(3.4432)\n",
      "epoch: 4 train_loss: tensor(3.3624, grad_fn=<NllLossBackward>) average train loss tensor(3.4214, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.23158204562178072 val_avg_loss: tensor(3.3135)\n",
      "epoch: 5 train_loss: tensor(3.2619, grad_fn=<NllLossBackward>) average train loss tensor(3.2994, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.25648270787343636 val_avg_loss: tensor(3.1603)\n",
      "epoch: 6 train_loss: tensor(3.1410, grad_fn=<NllLossBackward>) average train loss tensor(3.1779, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.29415746872700516 val_avg_loss: tensor(3.0050)\n",
      "epoch: 7 train_loss: tensor(2.9615, grad_fn=<NllLossBackward>) average train loss tensor(3.0032, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.31896983075791024 val_avg_loss: tensor(2.8508)\n",
      "epoch: 8 train_loss: tensor(2.8002, grad_fn=<NllLossBackward>) average train loss tensor(2.8633, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.34216335540838855 val_avg_loss: tensor(2.7022)\n",
      "epoch: 9 train_loss: tensor(2.6873, grad_fn=<NllLossBackward>) average train loss tensor(2.7170, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3589109639440765 val_avg_loss: tensor(2.5747)\n",
      "epoch: 10 train_loss: tensor(2.5378, grad_fn=<NllLossBackward>) average train loss tensor(2.6219, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3753936718175129 val_avg_loss: tensor(2.4714)\n",
      "epoch: 11 train_loss: tensor(2.3642, grad_fn=<NllLossBackward>) average train loss tensor(2.4711, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3887858719646799 val_avg_loss: tensor(2.3913)\n",
      "epoch: 12 train_loss: tensor(2.3024, grad_fn=<NllLossBackward>) average train loss tensor(2.3839, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3982045621780721 val_avg_loss: tensor(2.3240)\n",
      "epoch: 13 train_loss: tensor(2.2248, grad_fn=<NllLossBackward>) average train loss tensor(2.3190, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4070051508462105 val_avg_loss: tensor(2.2713)\n",
      "epoch: 14 train_loss: tensor(2.1635, grad_fn=<NllLossBackward>) average train loss tensor(2.2385, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.41398086828550407 val_avg_loss: tensor(2.2341)\n",
      "epoch: 15 train_loss: tensor(2.1534, grad_fn=<NllLossBackward>) average train loss tensor(2.2149, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4211626195732156 val_avg_loss: tensor(2.1939)\n",
      "epoch: 16 train_loss: tensor(1.9963, grad_fn=<NllLossBackward>) average train loss tensor(2.0837, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42478292862398825 val_avg_loss: tensor(2.1624)\n",
      "epoch: 17 train_loss: tensor(1.9657, grad_fn=<NllLossBackward>) average train loss tensor(2.0818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43013980868285506 val_avg_loss: tensor(2.1371)\n",
      "epoch: 18 train_loss: tensor(1.8444, grad_fn=<NllLossBackward>) average train loss tensor(1.9675, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44117733627667405 val_avg_loss: tensor(2.1078)\n",
      "epoch: 19 train_loss: tensor(1.8804, grad_fn=<NllLossBackward>) average train loss tensor(1.9435, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4475938189845475 val_avg_loss: tensor(2.0849)\n",
      "epoch: 20 train_loss: tensor(1.8056, grad_fn=<NllLossBackward>) average train loss tensor(1.9182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4536571008094187 val_avg_loss: tensor(2.0701)\n",
      "epoch: 21 train_loss: tensor(1.7296, grad_fn=<NllLossBackward>) average train loss tensor(1.8380, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4539514348785872 val_avg_loss: tensor(2.0594)\n",
      "epoch: 22 train_loss: tensor(1.6964, grad_fn=<NllLossBackward>) average train loss tensor(1.7844, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45718910963944076 val_avg_loss: tensor(2.0408)\n",
      "epoch: 23 train_loss: tensor(1.5952, grad_fn=<NllLossBackward>) average train loss tensor(1.8056, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4618395879323032 val_avg_loss: tensor(2.0351)\n",
      "epoch: 24 train_loss: tensor(1.6355, grad_fn=<NllLossBackward>) average train loss tensor(1.7189, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4664900662251656 val_avg_loss: tensor(2.0249)\n",
      "epoch: 25 train_loss: tensor(1.5674, grad_fn=<NllLossBackward>) average train loss tensor(1.6603, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46722590139808684 val_avg_loss: tensor(2.0194)\n",
      "epoch: 26 train_loss: tensor(1.5735, grad_fn=<NllLossBackward>) average train loss tensor(1.6284, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4684915378955114 val_avg_loss: tensor(2.0167)\n",
      "epoch: 27 train_loss: tensor(1.5306, grad_fn=<NllLossBackward>) average train loss tensor(1.6161, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47190581309786606 val_avg_loss: tensor(2.0162)\n",
      "epoch: 28 train_loss: tensor(1.4874, grad_fn=<NllLossBackward>) average train loss tensor(1.5949, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4728476821192053 val_avg_loss: tensor(2.0168)\n",
      "epoch: 29 train_loss: tensor(1.4776, grad_fn=<NllLossBackward>) average train loss tensor(1.5808, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47564385577630613 val_avg_loss: tensor(2.0116)\n",
      "epoch: 30 train_loss: tensor(1.3915, grad_fn=<NllLossBackward>) average train loss tensor(1.5356, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748491537895511 val_avg_loss: tensor(1.9997)\n",
      "epoch: 31 train_loss: tensor(1.3959, grad_fn=<NllLossBackward>) average train loss tensor(1.4896, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4745253863134658 val_avg_loss: tensor(2.0003)\n",
      "epoch: 32 train_loss: tensor(1.3786, grad_fn=<NllLossBackward>) average train loss tensor(1.4756, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4779690949227373 val_avg_loss: tensor(2.0160)\n",
      "epoch: 33 train_loss: tensor(1.3552, grad_fn=<NllLossBackward>) average train loss tensor(1.4148, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4757615894039735 val_avg_loss: tensor(2.0275)\n",
      "epoch: 34 train_loss: tensor(1.3257, grad_fn=<NllLossBackward>) average train loss tensor(1.4238, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4785871964679912 val_avg_loss: tensor(2.0258)\n",
      "epoch: 35 train_loss: tensor(1.2908, grad_fn=<NllLossBackward>) average train loss tensor(1.3996, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47846946284032377 val_avg_loss: tensor(2.0281)\n",
      "epoch: 36 train_loss: tensor(1.2750, grad_fn=<NllLossBackward>) average train loss tensor(1.3577, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4805298013245033 val_avg_loss: tensor(2.0323)\n",
      "epoch: 37 train_loss: tensor(1.2275, grad_fn=<NllLossBackward>) average train loss tensor(1.3371, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48264900662251653 val_avg_loss: tensor(2.0368)\n",
      "epoch: 38 train_loss: tensor(1.2299, grad_fn=<NllLossBackward>) average train loss tensor(1.3259, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48182487122884476 val_avg_loss: tensor(2.0450)\n",
      "epoch: 39 train_loss: tensor(1.1812, grad_fn=<NllLossBackward>) average train loss tensor(1.3020, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4814422369389257 val_avg_loss: tensor(2.0521)\n",
      "epoch: 40 train_loss: tensor(1.1619, grad_fn=<NllLossBackward>) average train loss tensor(1.2671, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4802943340691685 val_avg_loss: tensor(2.0701)\n",
      "epoch: 41 train_loss: tensor(1.1271, grad_fn=<NllLossBackward>) average train loss tensor(1.2297, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48108903605592346 val_avg_loss: tensor(2.0788)\n",
      "epoch: 42 train_loss: tensor(0.9875, grad_fn=<NllLossBackward>) average train loss tensor(1.1860, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48123620309050774 val_avg_loss: tensor(2.0851)\n",
      "epoch: 43 train_loss: tensor(1.1045, grad_fn=<NllLossBackward>) average train loss tensor(1.2042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48229580573951436 val_avg_loss: tensor(2.0958)\n",
      "epoch: 44 train_loss: tensor(1.1366, grad_fn=<NllLossBackward>) average train loss tensor(1.2199, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48306107431935247 val_avg_loss: tensor(2.1015)\n",
      "epoch: 45 train_loss: tensor(1.0348, grad_fn=<NllLossBackward>) average train loss tensor(1.1462, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4823252391464312 val_avg_loss: tensor(2.1072)\n",
      "epoch: 46 train_loss: tensor(1.0351, grad_fn=<NllLossBackward>) average train loss tensor(1.1625, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48206033848417956 val_avg_loss: tensor(2.1141)\n",
      "epoch: 47 train_loss: tensor(1.0793, grad_fn=<NllLossBackward>) average train loss tensor(1.1403, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48253127299484916 val_avg_loss: tensor(2.1211)\n",
      "epoch: 48 train_loss: tensor(1.0144, grad_fn=<NllLossBackward>) average train loss tensor(1.1008, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48282560706401767 val_avg_loss: tensor(2.1218)\n",
      "epoch: 49 train_loss: tensor(1.0607, grad_fn=<NllLossBackward>) average train loss tensor(1.1399, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4841795437821928 val_avg_loss: tensor(2.1283)\n",
      "epoch: 50 train_loss: tensor(1.0370, grad_fn=<NllLossBackward>) average train loss tensor(1.0847, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4837086092715232 val_avg_loss: tensor(2.1314)\n",
      "epoch: 51 train_loss: tensor(1.0943, grad_fn=<NllLossBackward>) average train loss tensor(1.0927, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48344370860927155 val_avg_loss: tensor(2.1447)\n",
      "epoch: 52 train_loss: tensor(0.9046, grad_fn=<NllLossBackward>) average train loss tensor(1.0438, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4848270787343635 val_avg_loss: tensor(2.1600)\n",
      "epoch: 53 train_loss: tensor(0.9672, grad_fn=<NllLossBackward>) average train loss tensor(1.0723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4834142752023547 val_avg_loss: tensor(2.1711)\n",
      "epoch: 54 train_loss: tensor(0.9144, grad_fn=<NllLossBackward>) average train loss tensor(1.0148, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4814128035320088 val_avg_loss: tensor(2.1746)\n",
      "epoch: 55 train_loss: tensor(0.9266, grad_fn=<NllLossBackward>) average train loss tensor(1.0307, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48176600441501105 val_avg_loss: tensor(2.1922)\n",
      "epoch: 56 train_loss: tensor(0.9447, grad_fn=<NllLossBackward>) average train loss tensor(1.0213, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48261957321559973 val_avg_loss: tensor(2.2082)\n",
      "epoch: 57 train_loss: tensor(0.8939, grad_fn=<NllLossBackward>) average train loss tensor(0.9955, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4834142752023547 val_avg_loss: tensor(2.2191)\n",
      "epoch: 58 train_loss: tensor(0.9226, grad_fn=<NllLossBackward>) average train loss tensor(0.9993, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48100073583517294 val_avg_loss: tensor(2.2192)\n",
      "epoch: 59 train_loss: tensor(0.8846, grad_fn=<NllLossBackward>) average train loss tensor(0.9786, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4835614422369389 val_avg_loss: tensor(2.2349)\n",
      "epoch: 60 train_loss: tensor(0.8807, grad_fn=<NllLossBackward>) average train loss tensor(0.9470, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4849448123620309 val_avg_loss: tensor(2.2518)\n",
      "epoch: 61 train_loss: tensor(0.8512, grad_fn=<NllLossBackward>) average train loss tensor(0.9432, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48270787343635024 val_avg_loss: tensor(2.2560)\n",
      "epoch: 62 train_loss: tensor(0.8637, grad_fn=<NllLossBackward>) average train loss tensor(0.9394, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47888153053715965 val_avg_loss: tensor(2.2595)\n",
      "epoch: 63 train_loss: tensor(0.8394, grad_fn=<NllLossBackward>) average train loss tensor(0.9139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4823841059602649 val_avg_loss: tensor(2.2744)\n",
      "epoch: 64 train_loss: tensor(0.8487, grad_fn=<NllLossBackward>) average train loss tensor(0.9241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48529801324503313 val_avg_loss: tensor(2.2892)\n",
      "epoch: 65 train_loss: tensor(0.8061, grad_fn=<NllLossBackward>) average train loss tensor(0.8844, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48485651214128034 val_avg_loss: tensor(2.2866)\n",
      "epoch: 66 train_loss: tensor(0.8073, grad_fn=<NllLossBackward>) average train loss tensor(0.8992, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4834142752023547 val_avg_loss: tensor(2.2920)\n",
      "epoch: 67 train_loss: tensor(0.8042, grad_fn=<NllLossBackward>) average train loss tensor(0.8811, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48038263428991906 val_avg_loss: tensor(2.3132)\n",
      "epoch: 68 train_loss: tensor(0.7104, grad_fn=<NllLossBackward>) average train loss tensor(0.8495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48123620309050774 val_avg_loss: tensor(2.3335)\n",
      "epoch: 69 train_loss: tensor(0.7705, grad_fn=<NllLossBackward>) average train loss tensor(0.8287, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4822663723325975 val_avg_loss: tensor(2.3540)\n",
      "epoch: 70 train_loss: tensor(0.7759, grad_fn=<NllLossBackward>) average train loss tensor(0.8524, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801766004415011 val_avg_loss: tensor(2.3431)\n",
      "epoch: 71 train_loss: tensor(0.8047, grad_fn=<NllLossBackward>) average train loss tensor(0.8482, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4786754966887417 val_avg_loss: tensor(2.3555)\n",
      "epoch: 72 train_loss: tensor(0.6965, grad_fn=<NllLossBackward>) average train loss tensor(0.7994, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4782928623988227 val_avg_loss: tensor(2.3790)\n",
      "epoch: 73 train_loss: tensor(0.7610, grad_fn=<NllLossBackward>) average train loss tensor(0.7967, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4815894039735099 val_avg_loss: tensor(2.3840)\n",
      "epoch: 74 train_loss: tensor(0.7047, grad_fn=<NllLossBackward>) average train loss tensor(0.7889, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4793524650478293 val_avg_loss: tensor(2.3878)\n",
      "epoch: 75 train_loss: tensor(0.7575, grad_fn=<NllLossBackward>) average train loss tensor(0.8433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48002943340691684 val_avg_loss: tensor(2.3936)\n",
      "epoch: 76 train_loss: tensor(0.7509, grad_fn=<NllLossBackward>) average train loss tensor(0.7800, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47835172921265634 val_avg_loss: tensor(2.4112)\n",
      "epoch: 77 train_loss: tensor(0.7235, grad_fn=<NllLossBackward>) average train loss tensor(0.8296, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47985283296541575 val_avg_loss: tensor(2.4061)\n",
      "epoch: 78 train_loss: tensor(0.7326, grad_fn=<NllLossBackward>) average train loss tensor(0.8005, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.479205298013245 val_avg_loss: tensor(2.4120)\n",
      "epoch: 79 train_loss: tensor(0.6769, grad_fn=<NllLossBackward>) average train loss tensor(0.7343, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4760853568800589 val_avg_loss: tensor(2.4381)\n",
      "epoch: 80 train_loss: tensor(0.6396, grad_fn=<NllLossBackward>) average train loss tensor(0.7094, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47673289183222956 val_avg_loss: tensor(2.4666)\n",
      "epoch: 81 train_loss: tensor(0.7241, grad_fn=<NllLossBackward>) average train loss tensor(0.7540, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47864606328182485 val_avg_loss: tensor(2.4840)\n",
      "epoch: 82 train_loss: tensor(0.6793, grad_fn=<NllLossBackward>) average train loss tensor(0.7270, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48032376747608535 val_avg_loss: tensor(2.4923)\n",
      "epoch: 83 train_loss: tensor(0.6688, grad_fn=<NllLossBackward>) average train loss tensor(0.7379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4764679911699779 val_avg_loss: tensor(2.5110)\n",
      "epoch: 84 train_loss: tensor(0.6410, grad_fn=<NllLossBackward>) average train loss tensor(0.7203, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47487858719646797 val_avg_loss: tensor(2.5101)\n",
      "epoch: 85 train_loss: tensor(0.6275, grad_fn=<NllLossBackward>) average train loss tensor(0.7324, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4787637969094923 val_avg_loss: tensor(2.5064)\n",
      "epoch: 86 train_loss: tensor(0.6165, grad_fn=<NllLossBackward>) average train loss tensor(0.6836, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48002943340691684 val_avg_loss: tensor(2.5257)\n",
      "epoch: 87 train_loss: tensor(0.6332, grad_fn=<NllLossBackward>) average train loss tensor(0.6928, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47932303164091244 val_avg_loss: tensor(2.5437)\n",
      "epoch: 88 train_loss: tensor(0.5341, grad_fn=<NllLossBackward>) average train loss tensor(0.6560, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47420161883738043 val_avg_loss: tensor(2.5564)\n",
      "epoch: 89 train_loss: tensor(0.6234, grad_fn=<NllLossBackward>) average train loss tensor(0.7008, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4749374540103017 val_avg_loss: tensor(2.5374)\n",
      "epoch: 90 train_loss: tensor(0.6353, grad_fn=<NllLossBackward>) average train loss tensor(0.6437, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478822663723326 val_avg_loss: tensor(2.5384)\n",
      "epoch: 91 train_loss: tensor(0.6073, grad_fn=<NllLossBackward>) average train loss tensor(0.6725, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47811626195732154 val_avg_loss: tensor(2.5620)\n",
      "epoch: 92 train_loss: tensor(0.5977, grad_fn=<NllLossBackward>) average train loss tensor(0.6546, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4752317880794702 val_avg_loss: tensor(2.5590)\n",
      "epoch: 93 train_loss: tensor(0.5923, grad_fn=<NllLossBackward>) average train loss tensor(0.6527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.473701250919794 val_avg_loss: tensor(2.5649)\n",
      "epoch: 94 train_loss: tensor(0.6078, grad_fn=<NllLossBackward>) average train loss tensor(0.6357, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47467255334805003 val_avg_loss: tensor(2.5826)\n",
      "epoch: 95 train_loss: tensor(0.6019, grad_fn=<NllLossBackward>) average train loss tensor(0.6379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4769683590875644 val_avg_loss: tensor(2.5966)\n",
      "epoch: 96 train_loss: tensor(0.5926, grad_fn=<NllLossBackward>) average train loss tensor(0.6515, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765857247976453 val_avg_loss: tensor(2.6091)\n",
      "epoch: 97 train_loss: tensor(0.5867, grad_fn=<NllLossBackward>) average train loss tensor(0.6026, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748491537895511 val_avg_loss: tensor(2.6285)\n",
      "epoch: 98 train_loss: tensor(0.5126, grad_fn=<NllLossBackward>) average train loss tensor(0.5991, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47496688741721854 val_avg_loss: tensor(2.6507)\n",
      "epoch: 99 train_loss: tensor(0.5751, grad_fn=<NllLossBackward>) average train loss tensor(0.5949, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47434878587196466 val_avg_loss: tensor(2.6788)\n",
      "epoch: 100 train_loss: tensor(0.5160, grad_fn=<NllLossBackward>) average train loss tensor(0.6016, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4744665194996321 val_avg_loss: tensor(2.6847)\n",
      "epoch: 101 train_loss: tensor(0.4978, grad_fn=<NllLossBackward>) average train loss tensor(0.5750, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4739955849889625 val_avg_loss: tensor(2.6844)\n",
      "epoch: 102 train_loss: tensor(0.4875, grad_fn=<NllLossBackward>) average train loss tensor(0.5699, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47358351729212655 val_avg_loss: tensor(2.6957)\n",
      "epoch: 103 train_loss: tensor(0.5304, grad_fn=<NllLossBackward>) average train loss tensor(0.5819, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4742310522442973 val_avg_loss: tensor(2.7042)\n",
      "epoch: 104 train_loss: tensor(0.5156, grad_fn=<NllLossBackward>) average train loss tensor(0.5683, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47352465047829284 val_avg_loss: tensor(2.7179)\n",
      "epoch: 105 train_loss: tensor(0.4877, grad_fn=<NllLossBackward>) average train loss tensor(0.5679, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4721707137601177 val_avg_loss: tensor(2.7480)\n",
      "epoch: 106 train_loss: tensor(0.5610, grad_fn=<NllLossBackward>) average train loss tensor(0.5780, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4733186166298749 val_avg_loss: tensor(2.7722)\n",
      "epoch: 107 train_loss: tensor(0.4927, grad_fn=<NllLossBackward>) average train loss tensor(0.5864, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4758204562178072 val_avg_loss: tensor(2.7636)\n",
      "epoch: 108 train_loss: tensor(0.5576, grad_fn=<NllLossBackward>) average train loss tensor(0.5556, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47240618101545256 val_avg_loss: tensor(2.7533)\n",
      "epoch: 109 train_loss: tensor(0.3978, grad_fn=<NllLossBackward>) average train loss tensor(0.5393, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47181751287711554 val_avg_loss: tensor(2.7511)\n",
      "epoch: 110 train_loss: tensor(0.5106, grad_fn=<NllLossBackward>) average train loss tensor(0.5525, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47043414275202355 val_avg_loss: tensor(2.7642)\n",
      "epoch: 111 train_loss: tensor(0.5454, grad_fn=<NllLossBackward>) average train loss tensor(0.5890, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47323031640912433 val_avg_loss: tensor(2.7595)\n",
      "epoch: 112 train_loss: tensor(0.4295, grad_fn=<NllLossBackward>) average train loss tensor(0.5185, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4733774834437086 val_avg_loss: tensor(2.7649)\n",
      "epoch: 113 train_loss: tensor(0.4805, grad_fn=<NllLossBackward>) average train loss tensor(0.5482, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47449595290654895 val_avg_loss: tensor(2.7786)\n",
      "epoch: 114 train_loss: tensor(0.4387, grad_fn=<NllLossBackward>) average train loss tensor(0.5226, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4754083885209713 val_avg_loss: tensor(2.7965)\n",
      "epoch: 115 train_loss: tensor(0.5092, grad_fn=<NllLossBackward>) average train loss tensor(0.5543, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47670345842531275 val_avg_loss: tensor(2.8038)\n",
      "epoch: 116 train_loss: tensor(0.4609, grad_fn=<NllLossBackward>) average train loss tensor(0.5467, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4723767476085357 val_avg_loss: tensor(2.8172)\n",
      "epoch: 117 train_loss: tensor(0.4542, grad_fn=<NllLossBackward>) average train loss tensor(0.5043, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47143487858719646 val_avg_loss: tensor(2.8198)\n",
      "epoch: 118 train_loss: tensor(0.4845, grad_fn=<NllLossBackward>) average train loss tensor(0.5280, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47455481972038266 val_avg_loss: tensor(2.8401)\n",
      "epoch: 119 train_loss: tensor(0.5010, grad_fn=<NllLossBackward>) average train loss tensor(0.4966, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4737601177336277 val_avg_loss: tensor(2.8430)\n",
      "epoch: 120 train_loss: tensor(0.4272, grad_fn=<NllLossBackward>) average train loss tensor(0.4958, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4713465783664459 val_avg_loss: tensor(2.8544)\n",
      "epoch: 121 train_loss: tensor(0.5375, grad_fn=<NllLossBackward>) average train loss tensor(0.5318, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4700220750551876 val_avg_loss: tensor(2.8792)\n",
      "epoch: 122 train_loss: tensor(0.4626, grad_fn=<NllLossBackward>) average train loss tensor(0.4840, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4697866077998528 val_avg_loss: tensor(2.9016)\n",
      "epoch: 123 train_loss: tensor(0.4039, grad_fn=<NllLossBackward>) average train loss tensor(0.4871, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4711111111111111 val_avg_loss: tensor(2.8971)\n",
      "epoch: 124 train_loss: tensor(0.4336, grad_fn=<NllLossBackward>) average train loss tensor(0.4636, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4736129506990434 val_avg_loss: tensor(2.9243)\n",
      "epoch: 125 train_loss: tensor(0.3358, grad_fn=<NllLossBackward>) average train loss tensor(0.4830, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4718469462840324 val_avg_loss: tensor(2.9398)\n",
      "epoch: 126 train_loss: tensor(0.4366, grad_fn=<NllLossBackward>) average train loss tensor(0.4932, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47013980868285504 val_avg_loss: tensor(2.9339)\n",
      "epoch: 127 train_loss: tensor(0.3655, grad_fn=<NllLossBackward>) average train loss tensor(0.4684, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.469168506254599 val_avg_loss: tensor(2.9238)\n",
      "epoch: 128 train_loss: tensor(0.4083, grad_fn=<NllLossBackward>) average train loss tensor(0.4843, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47181751287711554 val_avg_loss: tensor(2.9535)\n",
      "epoch: 129 train_loss: tensor(0.3882, grad_fn=<NllLossBackward>) average train loss tensor(0.4504, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4723767476085357 val_avg_loss: tensor(2.9844)\n",
      "epoch: 130 train_loss: tensor(0.3968, grad_fn=<NllLossBackward>) average train loss tensor(0.4469, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47105224429727743 val_avg_loss: tensor(3.0110)\n",
      "epoch: 131 train_loss: tensor(0.3727, grad_fn=<NllLossBackward>) average train loss tensor(0.4586, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47190581309786606 val_avg_loss: tensor(3.0033)\n",
      "epoch: 132 train_loss: tensor(0.3761, grad_fn=<NllLossBackward>) average train loss tensor(0.4462, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47328918322295804 val_avg_loss: tensor(2.9922)\n",
      "epoch: 133 train_loss: tensor(0.3807, grad_fn=<NllLossBackward>) average train loss tensor(0.4539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47105224429727743 val_avg_loss: tensor(2.9883)\n",
      "epoch: 134 train_loss: tensor(0.3915, grad_fn=<NllLossBackward>) average train loss tensor(0.4506, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46816777041942603 val_avg_loss: tensor(3.0005)\n",
      "epoch: 135 train_loss: tensor(0.3801, grad_fn=<NllLossBackward>) average train loss tensor(0.4249, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4686092715231788 val_avg_loss: tensor(3.0220)\n",
      "epoch: 136 train_loss: tensor(0.4208, grad_fn=<NllLossBackward>) average train loss tensor(0.4175, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4686387049300957 val_avg_loss: tensor(3.0273)\n",
      "epoch: 137 train_loss: tensor(0.3461, grad_fn=<NllLossBackward>) average train loss tensor(0.4202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4691979396615158 val_avg_loss: tensor(3.0162)\n",
      "epoch: 138 train_loss: tensor(0.3767, grad_fn=<NllLossBackward>) average train loss tensor(0.4445, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.470345842531273 val_avg_loss: tensor(3.0211)\n",
      "epoch: 139 train_loss: tensor(0.4189, grad_fn=<NllLossBackward>) average train loss tensor(0.4140, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4709933774834437 val_avg_loss: tensor(3.0366)\n",
      "epoch: 0 train_loss: tensor(3.8409, grad_fn=<NllLossBackward>) average train loss tensor(3.9052, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07387785136129507 val_avg_loss: tensor(3.8120)\n",
      "epoch: 1 train_loss: tensor(3.7292, grad_fn=<NllLossBackward>) average train loss tensor(3.7549, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07249448123620308 val_avg_loss: tensor(3.6797)\n",
      "epoch: 2 train_loss: tensor(3.6358, grad_fn=<NllLossBackward>) average train loss tensor(3.6306, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.08462104488594555 val_avg_loss: tensor(3.5623)\n",
      "epoch: 3 train_loss: tensor(3.4899, grad_fn=<NllLossBackward>) average train loss tensor(3.5379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.14201618837380428 val_avg_loss: tensor(3.4326)\n",
      "epoch: 4 train_loss: tensor(3.3745, grad_fn=<NllLossBackward>) average train loss tensor(3.4297, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.21183222958057396 val_avg_loss: tensor(3.2949)\n",
      "epoch: 5 train_loss: tensor(3.2183, grad_fn=<NllLossBackward>) average train loss tensor(3.2903, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.24906548933039 val_avg_loss: tensor(3.1415)\n",
      "epoch: 6 train_loss: tensor(3.0747, grad_fn=<NllLossBackward>) average train loss tensor(3.1640, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2598381162619573 val_avg_loss: tensor(2.9866)\n",
      "epoch: 7 train_loss: tensor(2.9552, grad_fn=<NllLossBackward>) average train loss tensor(3.0078, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2822663723325975 val_avg_loss: tensor(2.8392)\n",
      "epoch: 8 train_loss: tensor(2.8184, grad_fn=<NllLossBackward>) average train loss tensor(2.8803, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.314289919058131 val_avg_loss: tensor(2.7042)\n",
      "epoch: 9 train_loss: tensor(2.6940, grad_fn=<NllLossBackward>) average train loss tensor(2.7776, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.34219278881530535 val_avg_loss: tensor(2.5843)\n",
      "epoch: 10 train_loss: tensor(2.5586, grad_fn=<NllLossBackward>) average train loss tensor(2.6476, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.35908756438557765 val_avg_loss: tensor(2.4898)\n",
      "epoch: 11 train_loss: tensor(2.4423, grad_fn=<NllLossBackward>) average train loss tensor(2.5221, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3716850625459897 val_avg_loss: tensor(2.4155)\n",
      "epoch: 12 train_loss: tensor(2.3474, grad_fn=<NllLossBackward>) average train loss tensor(2.4505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38981604120676966 val_avg_loss: tensor(2.3444)\n",
      "epoch: 13 train_loss: tensor(2.2019, grad_fn=<NllLossBackward>) average train loss tensor(2.3062, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40247240618101543 val_avg_loss: tensor(2.2834)\n",
      "epoch: 14 train_loss: tensor(2.2053, grad_fn=<NllLossBackward>) average train loss tensor(2.2735, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.413598233995585 val_avg_loss: tensor(2.2362)\n",
      "epoch: 15 train_loss: tensor(2.1188, grad_fn=<NllLossBackward>) average train loss tensor(2.2036, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4209860191317145 val_avg_loss: tensor(2.2026)\n",
      "epoch: 16 train_loss: tensor(2.0411, grad_fn=<NllLossBackward>) average train loss tensor(2.1295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42693156732891835 val_avg_loss: tensor(2.1717)\n",
      "epoch: 17 train_loss: tensor(1.9256, grad_fn=<NllLossBackward>) average train loss tensor(2.0616, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4335540838852097 val_avg_loss: tensor(2.1361)\n",
      "epoch: 18 train_loss: tensor(1.9104, grad_fn=<NllLossBackward>) average train loss tensor(2.0107, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4402943340691685 val_avg_loss: tensor(2.1076)\n",
      "epoch: 19 train_loss: tensor(1.8471, grad_fn=<NllLossBackward>) average train loss tensor(1.9131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4458278145695364 val_avg_loss: tensor(2.0844)\n",
      "epoch: 20 train_loss: tensor(1.8416, grad_fn=<NllLossBackward>) average train loss tensor(1.9315, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.446504782928624 val_avg_loss: tensor(2.0743)\n",
      "epoch: 21 train_loss: tensor(1.7764, grad_fn=<NllLossBackward>) average train loss tensor(1.8579, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45612950699043414 val_avg_loss: tensor(2.0532)\n",
      "epoch: 22 train_loss: tensor(1.7661, grad_fn=<NllLossBackward>) average train loss tensor(1.8124, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45986754966887416 val_avg_loss: tensor(2.0397)\n",
      "epoch: 23 train_loss: tensor(1.7125, grad_fn=<NllLossBackward>) average train loss tensor(1.8004, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4574540103016924 val_avg_loss: tensor(2.0353)\n",
      "epoch: 24 train_loss: tensor(1.6976, grad_fn=<NllLossBackward>) average train loss tensor(1.7447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46166298749080203 val_avg_loss: tensor(2.0231)\n",
      "epoch: 25 train_loss: tensor(1.6680, grad_fn=<NllLossBackward>) average train loss tensor(1.7260, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4671081677704194 val_avg_loss: tensor(2.0204)\n",
      "epoch: 26 train_loss: tensor(1.6142, grad_fn=<NllLossBackward>) average train loss tensor(1.6584, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4690802060338484 val_avg_loss: tensor(2.0167)\n",
      "epoch: 27 train_loss: tensor(1.6604, grad_fn=<NllLossBackward>) average train loss tensor(1.6692, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46584253127299485 val_avg_loss: tensor(2.0247)\n",
      "epoch: 28 train_loss: tensor(1.5730, grad_fn=<NllLossBackward>) average train loss tensor(1.6239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46693156732891833 val_avg_loss: tensor(2.0234)\n",
      "epoch: 29 train_loss: tensor(1.4765, grad_fn=<NllLossBackward>) average train loss tensor(1.5870, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47143487858719646 val_avg_loss: tensor(2.0145)\n",
      "epoch: 30 train_loss: tensor(1.4435, grad_fn=<NllLossBackward>) average train loss tensor(1.5344, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.47543782192788814 val_avg_loss: tensor(2.0098)\n",
      "epoch: 31 train_loss: tensor(1.3598, grad_fn=<NllLossBackward>) average train loss tensor(1.5003, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47579102281089036 val_avg_loss: tensor(2.0117)\n",
      "epoch: 32 train_loss: tensor(1.4138, grad_fn=<NllLossBackward>) average train loss tensor(1.5334, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47443708609271523 val_avg_loss: tensor(2.0195)\n",
      "epoch: 33 train_loss: tensor(1.3916, grad_fn=<NllLossBackward>) average train loss tensor(1.4834, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4777336276674025 val_avg_loss: tensor(2.0111)\n",
      "epoch: 34 train_loss: tensor(1.3915, grad_fn=<NllLossBackward>) average train loss tensor(1.4596, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4789109639440765 val_avg_loss: tensor(2.0156)\n",
      "epoch: 35 train_loss: tensor(1.2922, grad_fn=<NllLossBackward>) average train loss tensor(1.3998, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47664459161147904 val_avg_loss: tensor(2.0283)\n",
      "epoch: 36 train_loss: tensor(1.3101, grad_fn=<NllLossBackward>) average train loss tensor(1.3720, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47846946284032377 val_avg_loss: tensor(2.0326)\n",
      "epoch: 37 train_loss: tensor(1.3359, grad_fn=<NllLossBackward>) average train loss tensor(1.3676, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48038263428991906 val_avg_loss: tensor(2.0315)\n",
      "epoch: 38 train_loss: tensor(1.2761, grad_fn=<NllLossBackward>) average train loss tensor(1.3680, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48002943340691684 val_avg_loss: tensor(2.0429)\n",
      "epoch: 39 train_loss: tensor(1.2308, grad_fn=<NllLossBackward>) average train loss tensor(1.3422, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47879323031640914 val_avg_loss: tensor(2.0528)\n",
      "epoch: 40 train_loss: tensor(1.2382, grad_fn=<NllLossBackward>) average train loss tensor(1.3125, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48114790286975717 val_avg_loss: tensor(2.0564)\n",
      "epoch: 41 train_loss: tensor(1.2414, grad_fn=<NllLossBackward>) average train loss tensor(1.3100, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4791169977924945 val_avg_loss: tensor(2.0681)\n",
      "epoch: 42 train_loss: tensor(1.1837, grad_fn=<NllLossBackward>) average train loss tensor(1.2594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47726269315673286 val_avg_loss: tensor(2.0811)\n",
      "epoch: 43 train_loss: tensor(1.1533, grad_fn=<NllLossBackward>) average train loss tensor(1.2041, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4825018395879323 val_avg_loss: tensor(2.0751)\n",
      "epoch: 44 train_loss: tensor(1.1637, grad_fn=<NllLossBackward>) average train loss tensor(1.2124, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4831199411331862 val_avg_loss: tensor(2.0894)\n",
      "epoch: 45 train_loss: tensor(1.2071, grad_fn=<NllLossBackward>) average train loss tensor(1.2581, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48129506990434145 val_avg_loss: tensor(2.0968)\n",
      "epoch: 46 train_loss: tensor(1.0606, grad_fn=<NllLossBackward>) average train loss tensor(1.1975, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48206033848417956 val_avg_loss: tensor(2.0938)\n",
      "epoch: 47 train_loss: tensor(1.0237, grad_fn=<NllLossBackward>) average train loss tensor(1.1803, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48085356880058866 val_avg_loss: tensor(2.0945)\n",
      "epoch: 48 train_loss: tensor(1.0515, grad_fn=<NllLossBackward>) average train loss tensor(1.1438, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4822663723325975 val_avg_loss: tensor(2.0969)\n",
      "epoch: 49 train_loss: tensor(1.0779, grad_fn=<NllLossBackward>) average train loss tensor(1.1399, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48103016924208974 val_avg_loss: tensor(2.1200)\n",
      "epoch: 50 train_loss: tensor(1.0604, grad_fn=<NllLossBackward>) average train loss tensor(1.1409, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4809124356144224 val_avg_loss: tensor(2.1266)\n",
      "epoch: 51 train_loss: tensor(1.0587, grad_fn=<NllLossBackward>) average train loss tensor(1.0778, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4817954378219279 val_avg_loss: tensor(2.1346)\n",
      "epoch: 52 train_loss: tensor(0.9397, grad_fn=<NllLossBackward>) average train loss tensor(1.0606, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4827373068432671 val_avg_loss: tensor(2.1563)\n",
      "epoch: 53 train_loss: tensor(1.0564, grad_fn=<NllLossBackward>) average train loss tensor(1.0619, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812656364974246 val_avg_loss: tensor(2.1723)\n",
      "epoch: 54 train_loss: tensor(1.0383, grad_fn=<NllLossBackward>) average train loss tensor(1.0758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4814422369389257 val_avg_loss: tensor(2.1828)\n",
      "epoch: 55 train_loss: tensor(0.9722, grad_fn=<NllLossBackward>) average train loss tensor(1.0513, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4819131714495953 val_avg_loss: tensor(2.1880)\n",
      "epoch: 56 train_loss: tensor(1.0060, grad_fn=<NllLossBackward>) average train loss tensor(1.0615, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48161883738042677 val_avg_loss: tensor(2.1891)\n",
      "epoch: 57 train_loss: tensor(0.9311, grad_fn=<NllLossBackward>) average train loss tensor(1.0386, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4794407652685798 val_avg_loss: tensor(2.2060)\n",
      "epoch: 58 train_loss: tensor(0.9307, grad_fn=<NllLossBackward>) average train loss tensor(1.0020, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4834142752023547 val_avg_loss: tensor(2.2005)\n",
      "epoch: 59 train_loss: tensor(0.9218, grad_fn=<NllLossBackward>) average train loss tensor(1.0176, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4850036791758646 val_avg_loss: tensor(2.2082)\n",
      "epoch: 60 train_loss: tensor(0.9116, grad_fn=<NllLossBackward>) average train loss tensor(1.0041, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48161883738042677 val_avg_loss: tensor(2.2212)\n",
      "epoch: 61 train_loss: tensor(0.9279, grad_fn=<NllLossBackward>) average train loss tensor(0.9963, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47723325974981606 val_avg_loss: tensor(2.2390)\n",
      "epoch: 62 train_loss: tensor(0.9115, grad_fn=<NllLossBackward>) average train loss tensor(0.9931, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4822663723325975 val_avg_loss: tensor(2.2318)\n",
      "epoch: 63 train_loss: tensor(0.9370, grad_fn=<NllLossBackward>) average train loss tensor(0.9567, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4826784400294334 val_avg_loss: tensor(2.2316)\n",
      "epoch: 64 train_loss: tensor(0.8555, grad_fn=<NllLossBackward>) average train loss tensor(0.9338, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48038263428991906 val_avg_loss: tensor(2.2426)\n",
      "epoch: 65 train_loss: tensor(0.8483, grad_fn=<NllLossBackward>) average train loss tensor(0.9278, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48247240618101545 val_avg_loss: tensor(2.2635)\n",
      "epoch: 66 train_loss: tensor(0.8941, grad_fn=<NllLossBackward>) average train loss tensor(0.9313, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48264900662251653 val_avg_loss: tensor(2.2891)\n",
      "epoch: 67 train_loss: tensor(0.8638, grad_fn=<NllLossBackward>) average train loss tensor(0.9239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4775570272259014 val_avg_loss: tensor(2.3147)\n",
      "epoch: 68 train_loss: tensor(0.7459, grad_fn=<NllLossBackward>) average train loss tensor(0.8813, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4770860927152318 val_avg_loss: tensor(2.2982)\n",
      "epoch: 69 train_loss: tensor(0.8526, grad_fn=<NllLossBackward>) average train loss tensor(0.8863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812067696835909 val_avg_loss: tensor(2.2883)\n",
      "epoch: 70 train_loss: tensor(0.8535, grad_fn=<NllLossBackward>) average train loss tensor(0.8867, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4823546725533481 val_avg_loss: tensor(2.3060)\n",
      "epoch: 71 train_loss: tensor(0.7889, grad_fn=<NllLossBackward>) average train loss tensor(0.8819, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48344370860927155 val_avg_loss: tensor(2.3280)\n",
      "epoch: 72 train_loss: tensor(0.8910, grad_fn=<NllLossBackward>) average train loss tensor(0.8667, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4806475349521707 val_avg_loss: tensor(2.3440)\n",
      "epoch: 73 train_loss: tensor(0.7966, grad_fn=<NllLossBackward>) average train loss tensor(0.8390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4806769683590876 val_avg_loss: tensor(2.3533)\n",
      "epoch: 74 train_loss: tensor(0.8132, grad_fn=<NllLossBackward>) average train loss tensor(0.8347, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4808241353936718 val_avg_loss: tensor(2.3656)\n",
      "epoch: 75 train_loss: tensor(0.7147, grad_fn=<NllLossBackward>) average train loss tensor(0.7964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4795879323031641 val_avg_loss: tensor(2.3800)\n",
      "epoch: 76 train_loss: tensor(0.7367, grad_fn=<NllLossBackward>) average train loss tensor(0.7942, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.478616629874908 val_avg_loss: tensor(2.3909)\n",
      "epoch: 77 train_loss: tensor(0.7989, grad_fn=<NllLossBackward>) average train loss tensor(0.8366, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48229580573951436 val_avg_loss: tensor(2.3860)\n",
      "epoch: 78 train_loss: tensor(0.7090, grad_fn=<NllLossBackward>) average train loss tensor(0.7965, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4816777041942605 val_avg_loss: tensor(2.3999)\n",
      "epoch: 79 train_loss: tensor(0.7760, grad_fn=<NllLossBackward>) average train loss tensor(0.8089, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47855776306107434 val_avg_loss: tensor(2.4014)\n",
      "epoch: 80 train_loss: tensor(0.7165, grad_fn=<NllLossBackward>) average train loss tensor(0.7628, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4780573951434879 val_avg_loss: tensor(2.4125)\n",
      "epoch: 81 train_loss: tensor(0.7574, grad_fn=<NllLossBackward>) average train loss tensor(0.7761, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47917586460632816 val_avg_loss: tensor(2.4220)\n",
      "epoch: 82 train_loss: tensor(0.7232, grad_fn=<NllLossBackward>) average train loss tensor(0.7877, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.479411331861663 val_avg_loss: tensor(2.4346)\n",
      "epoch: 83 train_loss: tensor(0.6879, grad_fn=<NllLossBackward>) average train loss tensor(0.7490, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.477439293598234 val_avg_loss: tensor(2.4385)\n",
      "epoch: 84 train_loss: tensor(0.7001, grad_fn=<NllLossBackward>) average train loss tensor(0.7379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47746872700515086 val_avg_loss: tensor(2.4543)\n",
      "epoch: 85 train_loss: tensor(0.6328, grad_fn=<NllLossBackward>) average train loss tensor(0.7336, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4777336276674025 val_avg_loss: tensor(2.4715)\n",
      "epoch: 86 train_loss: tensor(0.6576, grad_fn=<NllLossBackward>) average train loss tensor(0.7224, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4769094922737307 val_avg_loss: tensor(2.4967)\n",
      "epoch: 87 train_loss: tensor(0.6923, grad_fn=<NllLossBackward>) average train loss tensor(0.7320, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748197203826343 val_avg_loss: tensor(2.5210)\n",
      "epoch: 88 train_loss: tensor(0.6870, grad_fn=<NllLossBackward>) average train loss tensor(0.7174, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765268579838116 val_avg_loss: tensor(2.5192)\n",
      "epoch: 89 train_loss: tensor(0.7137, grad_fn=<NllLossBackward>) average train loss tensor(0.7436, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478027961736571 val_avg_loss: tensor(2.5163)\n",
      "epoch: 90 train_loss: tensor(0.6279, grad_fn=<NllLossBackward>) average train loss tensor(0.6674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47855776306107434 val_avg_loss: tensor(2.5263)\n",
      "epoch: 91 train_loss: tensor(0.6545, grad_fn=<NllLossBackward>) average train loss tensor(0.6910, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4770860927152318 val_avg_loss: tensor(2.5358)\n",
      "epoch: 92 train_loss: tensor(0.6345, grad_fn=<NllLossBackward>) average train loss tensor(0.6622, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4783811626195732 val_avg_loss: tensor(2.5439)\n",
      "epoch: 93 train_loss: tensor(0.6770, grad_fn=<NllLossBackward>) average train loss tensor(0.6674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47670345842531275 val_avg_loss: tensor(2.5615)\n",
      "epoch: 94 train_loss: tensor(0.6204, grad_fn=<NllLossBackward>) average train loss tensor(0.6841, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4775275938189846 val_avg_loss: tensor(2.5757)\n",
      "epoch: 95 train_loss: tensor(0.6387, grad_fn=<NllLossBackward>) average train loss tensor(0.6592, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47449595290654895 val_avg_loss: tensor(2.6225)\n",
      "epoch: 96 train_loss: tensor(0.5159, grad_fn=<NllLossBackward>) average train loss tensor(0.6375, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47405445180279615 val_avg_loss: tensor(2.6278)\n",
      "epoch: 97 train_loss: tensor(0.5885, grad_fn=<NllLossBackward>) average train loss tensor(0.6447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47526122148638705 val_avg_loss: tensor(2.6185)\n",
      "epoch: 98 train_loss: tensor(0.5989, grad_fn=<NllLossBackward>) average train loss tensor(0.6396, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47726269315673286 val_avg_loss: tensor(2.6264)\n",
      "epoch: 99 train_loss: tensor(0.5594, grad_fn=<NllLossBackward>) average train loss tensor(0.6317, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4776158940397351 val_avg_loss: tensor(2.6530)\n",
      "epoch: 100 train_loss: tensor(0.5972, grad_fn=<NllLossBackward>) average train loss tensor(0.6266, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47555555555555556 val_avg_loss: tensor(2.6712)\n",
      "epoch: 101 train_loss: tensor(0.6020, grad_fn=<NllLossBackward>) average train loss tensor(0.6387, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47587932303164093 val_avg_loss: tensor(2.6440)\n",
      "epoch: 102 train_loss: tensor(0.5836, grad_fn=<NllLossBackward>) average train loss tensor(0.6430, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765268579838116 val_avg_loss: tensor(2.6327)\n",
      "epoch: 103 train_loss: tensor(0.5758, grad_fn=<NllLossBackward>) average train loss tensor(0.6006, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4758204562178072 val_avg_loss: tensor(2.6535)\n",
      "epoch: 104 train_loss: tensor(0.5878, grad_fn=<NllLossBackward>) average train loss tensor(0.6447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759970566593083 val_avg_loss: tensor(2.6543)\n",
      "epoch: 105 train_loss: tensor(0.6089, grad_fn=<NllLossBackward>) average train loss tensor(0.6186, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.476850625459897 val_avg_loss: tensor(2.6495)\n",
      "epoch: 106 train_loss: tensor(0.5374, grad_fn=<NllLossBackward>) average train loss tensor(0.5933, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4779102281089036 val_avg_loss: tensor(2.6536)\n",
      "epoch: 107 train_loss: tensor(0.5956, grad_fn=<NllLossBackward>) average train loss tensor(0.6040, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47832229580573954 val_avg_loss: tensor(2.6751)\n",
      "epoch: 108 train_loss: tensor(0.5926, grad_fn=<NllLossBackward>) average train loss tensor(0.5843, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47602649006622516 val_avg_loss: tensor(2.6871)\n",
      "epoch: 109 train_loss: tensor(0.5026, grad_fn=<NllLossBackward>) average train loss tensor(0.5501, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47670345842531275 val_avg_loss: tensor(2.7006)\n",
      "epoch: 110 train_loss: tensor(0.5643, grad_fn=<NllLossBackward>) average train loss tensor(0.5627, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4779690949227373 val_avg_loss: tensor(2.7231)\n",
      "epoch: 111 train_loss: tensor(0.5574, grad_fn=<NllLossBackward>) average train loss tensor(0.5621, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47617365710080944 val_avg_loss: tensor(2.7448)\n",
      "epoch: 112 train_loss: tensor(0.5156, grad_fn=<NllLossBackward>) average train loss tensor(0.6002, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759970566593083 val_avg_loss: tensor(2.7605)\n",
      "epoch: 113 train_loss: tensor(0.5076, grad_fn=<NllLossBackward>) average train loss tensor(0.5812, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.473495217071376 val_avg_loss: tensor(2.7830)\n",
      "epoch: 114 train_loss: tensor(0.5050, grad_fn=<NllLossBackward>) average train loss tensor(0.5470, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4727888153053716 val_avg_loss: tensor(2.7882)\n",
      "epoch: 115 train_loss: tensor(0.5656, grad_fn=<NllLossBackward>) average train loss tensor(0.5528, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4738484179543782 val_avg_loss: tensor(2.7956)\n",
      "epoch: 116 train_loss: tensor(0.4715, grad_fn=<NllLossBackward>) average train loss tensor(0.5449, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47158204562178074 val_avg_loss: tensor(2.8010)\n",
      "epoch: 117 train_loss: tensor(0.5652, grad_fn=<NllLossBackward>) average train loss tensor(0.5619, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46975717439293596 val_avg_loss: tensor(2.8258)\n",
      "epoch: 118 train_loss: tensor(0.5130, grad_fn=<NllLossBackward>) average train loss tensor(0.5679, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4708756438557763 val_avg_loss: tensor(2.8199)\n",
      "epoch: 119 train_loss: tensor(0.4459, grad_fn=<NllLossBackward>) average train loss tensor(0.5268, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4726122148638705 val_avg_loss: tensor(2.8067)\n",
      "epoch: 120 train_loss: tensor(0.5566, grad_fn=<NllLossBackward>) average train loss tensor(0.5333, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4747019867549669 val_avg_loss: tensor(2.8139)\n",
      "epoch: 121 train_loss: tensor(0.4983, grad_fn=<NllLossBackward>) average train loss tensor(0.5487, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4717880794701987 val_avg_loss: tensor(2.8239)\n",
      "epoch: 122 train_loss: tensor(0.5314, grad_fn=<NllLossBackward>) average train loss tensor(0.5330, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.47381898454746135 val_avg_loss: tensor(2.8366)\n",
      "epoch: 123 train_loss: tensor(0.5214, grad_fn=<NllLossBackward>) average train loss tensor(0.5186, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47411331861662986 val_avg_loss: tensor(2.8755)\n",
      "epoch: 124 train_loss: tensor(0.4380, grad_fn=<NllLossBackward>) average train loss tensor(0.5240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4699337748344371 val_avg_loss: tensor(2.8821)\n",
      "epoch: 125 train_loss: tensor(0.5296, grad_fn=<NllLossBackward>) average train loss tensor(0.5361, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46937454010301694 val_avg_loss: tensor(2.8689)\n",
      "epoch: 126 train_loss: tensor(0.4964, grad_fn=<NllLossBackward>) average train loss tensor(0.5174, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4724944812362031 val_avg_loss: tensor(2.8714)\n",
      "epoch: 127 train_loss: tensor(0.4766, grad_fn=<NllLossBackward>) average train loss tensor(0.5119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47264164827078736 val_avg_loss: tensor(2.8723)\n",
      "epoch: 128 train_loss: tensor(0.4155, grad_fn=<NllLossBackward>) average train loss tensor(0.5198, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47402501839587935 val_avg_loss: tensor(2.8812)\n",
      "epoch: 129 train_loss: tensor(0.5598, grad_fn=<NllLossBackward>) average train loss tensor(0.5435, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4754083885209713 val_avg_loss: tensor(2.8649)\n",
      "epoch: 130 train_loss: tensor(0.4553, grad_fn=<NllLossBackward>) average train loss tensor(0.4963, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4734657836644592 val_avg_loss: tensor(2.8551)\n",
      "epoch: 131 train_loss: tensor(0.4307, grad_fn=<NllLossBackward>) average train loss tensor(0.4869, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47152317880794703 val_avg_loss: tensor(2.8607)\n",
      "epoch: 132 train_loss: tensor(0.4378, grad_fn=<NllLossBackward>) average train loss tensor(0.4752, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47187637969094925 val_avg_loss: tensor(2.8668)\n",
      "epoch: 133 train_loss: tensor(0.4172, grad_fn=<NllLossBackward>) average train loss tensor(0.4827, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4744076526857984 val_avg_loss: tensor(2.8904)\n",
      "epoch: 134 train_loss: tensor(0.4337, grad_fn=<NllLossBackward>) average train loss tensor(0.4728, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4739072847682119 val_avg_loss: tensor(2.9383)\n",
      "epoch: 135 train_loss: tensor(0.4013, grad_fn=<NllLossBackward>) average train loss tensor(0.4595, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4712288447387785 val_avg_loss: tensor(2.9965)\n",
      "epoch: 136 train_loss: tensor(0.3959, grad_fn=<NllLossBackward>) average train loss tensor(0.4608, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4704047093451067 val_avg_loss: tensor(3.0163)\n",
      "epoch: 137 train_loss: tensor(0.3375, grad_fn=<NllLossBackward>) average train loss tensor(0.4335, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4720824135393672 val_avg_loss: tensor(2.9956)\n",
      "epoch: 138 train_loss: tensor(0.4239, grad_fn=<NllLossBackward>) average train loss tensor(0.4862, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47211184694628405 val_avg_loss: tensor(2.9969)\n",
      "epoch: 139 train_loss: tensor(0.3612, grad_fn=<NllLossBackward>) average train loss tensor(0.4598, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47013980868285504 val_avg_loss: tensor(3.0166)\n",
      "epoch: 0 train_loss: tensor(3.8706, grad_fn=<NllLossBackward>) average train loss tensor(3.9026, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.06495952906548932 val_avg_loss: tensor(3.8555)\n",
      "epoch: 1 train_loss: tensor(3.7562, grad_fn=<NllLossBackward>) average train loss tensor(3.8000, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.147785136129507 val_avg_loss: tensor(3.7429)\n",
      "epoch: 2 train_loss: tensor(3.5983, grad_fn=<NllLossBackward>) average train loss tensor(3.6457, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.14125091979396615 val_avg_loss: tensor(3.5586)\n",
      "epoch: 3 train_loss: tensor(3.4159, grad_fn=<NllLossBackward>) average train loss tensor(3.4674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.17892568064753495 val_avg_loss: tensor(3.3963)\n",
      "epoch: 4 train_loss: tensor(3.2307, grad_fn=<NllLossBackward>) average train loss tensor(3.3151, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22990434142752023 val_avg_loss: tensor(3.2015)\n",
      "epoch: 5 train_loss: tensor(3.0252, grad_fn=<NllLossBackward>) average train loss tensor(3.1109, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3037821927888153 val_avg_loss: tensor(2.9933)\n",
      "epoch: 6 train_loss: tensor(2.8176, grad_fn=<NllLossBackward>) average train loss tensor(2.8939, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3229139072847682 val_avg_loss: tensor(2.7949)\n",
      "epoch: 7 train_loss: tensor(2.6210, grad_fn=<NllLossBackward>) average train loss tensor(2.7066, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3454598969830758 val_avg_loss: tensor(2.6265)\n",
      "epoch: 8 train_loss: tensor(2.4548, grad_fn=<NllLossBackward>) average train loss tensor(2.5285, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.37365710080941866 val_avg_loss: tensor(2.5047)\n",
      "epoch: 9 train_loss: tensor(2.2912, grad_fn=<NllLossBackward>) average train loss tensor(2.3794, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3915820456217807 val_avg_loss: tensor(2.3992)\n",
      "epoch: 10 train_loss: tensor(2.1533, grad_fn=<NllLossBackward>) average train loss tensor(2.2442, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40229580573951434 val_avg_loss: tensor(2.3181)\n",
      "epoch: 11 train_loss: tensor(2.0389, grad_fn=<NllLossBackward>) average train loss tensor(2.1319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4130684326710817 val_avg_loss: tensor(2.2574)\n",
      "epoch: 12 train_loss: tensor(1.8871, grad_fn=<NllLossBackward>) average train loss tensor(2.0102, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42572479764532745 val_avg_loss: tensor(2.2115)\n",
      "epoch: 13 train_loss: tensor(1.8519, grad_fn=<NllLossBackward>) average train loss tensor(1.9103, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4350257542310522 val_avg_loss: tensor(2.1826)\n",
      "epoch: 14 train_loss: tensor(1.7315, grad_fn=<NllLossBackward>) average train loss tensor(1.8165, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4413245033112583 val_avg_loss: tensor(2.1622)\n",
      "epoch: 15 train_loss: tensor(1.6825, grad_fn=<NllLossBackward>) average train loss tensor(1.7466, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44885945548197204 val_avg_loss: tensor(2.1444)\n",
      "epoch: 16 train_loss: tensor(1.5751, grad_fn=<NllLossBackward>) average train loss tensor(1.6568, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4515673289183223 val_avg_loss: tensor(2.1448)\n",
      "epoch: 17 train_loss: tensor(1.5474, grad_fn=<NllLossBackward>) average train loss tensor(1.6014, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45504047093451067 val_avg_loss: tensor(2.1474)\n",
      "epoch: 18 train_loss: tensor(1.4753, grad_fn=<NllLossBackward>) average train loss tensor(1.5430, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45833701250919795 val_avg_loss: tensor(2.1346)\n",
      "epoch: 19 train_loss: tensor(1.3849, grad_fn=<NllLossBackward>) average train loss tensor(1.4723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46478292862398823 val_avg_loss: tensor(2.1306)\n",
      "epoch: 20 train_loss: tensor(1.3060, grad_fn=<NllLossBackward>) average train loss tensor(1.4131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46731420161883735 val_avg_loss: tensor(2.1407)\n",
      "epoch: 21 train_loss: tensor(1.2343, grad_fn=<NllLossBackward>) average train loss tensor(1.3241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46719646799117 val_avg_loss: tensor(2.1631)\n",
      "epoch: 22 train_loss: tensor(1.1970, grad_fn=<NllLossBackward>) average train loss tensor(1.2814, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46654893303899925 val_avg_loss: tensor(2.1883)\n",
      "epoch: 23 train_loss: tensor(1.2224, grad_fn=<NllLossBackward>) average train loss tensor(1.2676, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4698749080206034 val_avg_loss: tensor(2.1984)\n",
      "epoch: 24 train_loss: tensor(1.1290, grad_fn=<NllLossBackward>) average train loss tensor(1.2103, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4672553348050037 val_avg_loss: tensor(2.2325)\n",
      "epoch: 25 train_loss: tensor(1.1046, grad_fn=<NllLossBackward>) average train loss tensor(1.1884, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46837380426784403 val_avg_loss: tensor(2.2538)\n",
      "epoch: 26 train_loss: tensor(1.0144, grad_fn=<NllLossBackward>) average train loss tensor(1.1066, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4721707137601177 val_avg_loss: tensor(2.2702)\n",
      "epoch: 27 train_loss: tensor(0.9833, grad_fn=<NllLossBackward>) average train loss tensor(1.0609, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47381898454746135 val_avg_loss: tensor(2.3019)\n",
      "epoch: 28 train_loss: tensor(0.9767, grad_fn=<NllLossBackward>) average train loss tensor(1.0390, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4719352465047829 val_avg_loss: tensor(2.3368)\n",
      "epoch: 29 train_loss: tensor(0.9584, grad_fn=<NllLossBackward>) average train loss tensor(0.9969, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4700515084621045 val_avg_loss: tensor(2.3663)\n",
      "epoch: 30 train_loss: tensor(0.8731, grad_fn=<NllLossBackward>) average train loss tensor(0.9611, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47096394407652686 val_avg_loss: tensor(2.4038)\n",
      "epoch: 31 train_loss: tensor(0.8242, grad_fn=<NllLossBackward>) average train loss tensor(0.9084, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4687858719646799 val_avg_loss: tensor(2.4348)\n",
      "epoch: 32 train_loss: tensor(0.7732, grad_fn=<NllLossBackward>) average train loss tensor(0.8901, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4661074319352465 val_avg_loss: tensor(2.4726)\n",
      "epoch: 33 train_loss: tensor(0.7483, grad_fn=<NllLossBackward>) average train loss tensor(0.8584, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4688447387785136 val_avg_loss: tensor(2.4899)\n",
      "epoch: 34 train_loss: tensor(0.7933, grad_fn=<NllLossBackward>) average train loss tensor(0.8310, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4705224429727741 val_avg_loss: tensor(2.5155)\n",
      "epoch: 35 train_loss: tensor(0.7297, grad_fn=<NllLossBackward>) average train loss tensor(0.7902, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46387049300956584 val_avg_loss: tensor(2.5671)\n",
      "epoch: 36 train_loss: tensor(0.7521, grad_fn=<NllLossBackward>) average train loss tensor(0.8045, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46545989698307577 val_avg_loss: tensor(2.6058)\n",
      "epoch: 37 train_loss: tensor(0.6084, grad_fn=<NllLossBackward>) average train loss tensor(0.7279, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4696394407652686 val_avg_loss: tensor(2.6378)\n",
      "epoch: 38 train_loss: tensor(0.6645, grad_fn=<NllLossBackward>) average train loss tensor(0.7272, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4674025018395879 val_avg_loss: tensor(2.6520)\n",
      "epoch: 39 train_loss: tensor(0.5976, grad_fn=<NllLossBackward>) average train loss tensor(0.6665, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4613980868285504 val_avg_loss: tensor(2.7077)\n",
      "epoch: 40 train_loss: tensor(0.6417, grad_fn=<NllLossBackward>) average train loss tensor(0.6640, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46210448859455483 val_avg_loss: tensor(2.7571)\n",
      "epoch: 41 train_loss: tensor(0.6385, grad_fn=<NllLossBackward>) average train loss tensor(0.6486, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46378219278881533 val_avg_loss: tensor(2.7952)\n",
      "epoch: 42 train_loss: tensor(0.5576, grad_fn=<NllLossBackward>) average train loss tensor(0.6479, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4605150846210449 val_avg_loss: tensor(2.8507)\n",
      "epoch: 43 train_loss: tensor(0.5916, grad_fn=<NllLossBackward>) average train loss tensor(0.6217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46086828550404707 val_avg_loss: tensor(2.9016)\n",
      "epoch: 44 train_loss: tensor(0.5243, grad_fn=<NllLossBackward>) average train loss tensor(0.5872, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46086828550404707 val_avg_loss: tensor(2.9353)\n",
      "epoch: 45 train_loss: tensor(0.5147, grad_fn=<NllLossBackward>) average train loss tensor(0.5854, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46001471670345845 val_avg_loss: tensor(2.9693)\n",
      "epoch: 46 train_loss: tensor(0.5118, grad_fn=<NllLossBackward>) average train loss tensor(0.5872, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4596909492273731 val_avg_loss: tensor(2.9971)\n",
      "epoch: 47 train_loss: tensor(0.4690, grad_fn=<NllLossBackward>) average train loss tensor(0.5113, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4572185430463576 val_avg_loss: tensor(3.0445)\n",
      "epoch: 48 train_loss: tensor(0.4810, grad_fn=<NllLossBackward>) average train loss tensor(0.5065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.459308314937454 val_avg_loss: tensor(3.0502)\n",
      "epoch: 49 train_loss: tensor(0.4776, grad_fn=<NllLossBackward>) average train loss tensor(0.4922, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45927888153053714 val_avg_loss: tensor(3.0821)\n",
      "epoch: 50 train_loss: tensor(0.4503, grad_fn=<NllLossBackward>) average train loss tensor(0.5047, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45833701250919795 val_avg_loss: tensor(3.1652)\n",
      "epoch: 51 train_loss: tensor(0.4167, grad_fn=<NllLossBackward>) average train loss tensor(0.4682, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4580132450331126 val_avg_loss: tensor(3.1896)\n",
      "epoch: 52 train_loss: tensor(0.4010, grad_fn=<NllLossBackward>) average train loss tensor(0.4541, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4577777777777778 val_avg_loss: tensor(3.2294)\n",
      "epoch: 53 train_loss: tensor(0.3998, grad_fn=<NllLossBackward>) average train loss tensor(0.4282, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46048565121412804 val_avg_loss: tensor(3.2575)\n",
      "epoch: 54 train_loss: tensor(0.3810, grad_fn=<NllLossBackward>) average train loss tensor(0.4365, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4567770419426049 val_avg_loss: tensor(3.3031)\n",
      "epoch: 55 train_loss: tensor(0.4006, grad_fn=<NllLossBackward>) average train loss tensor(0.4064, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45489330389992644 val_avg_loss: tensor(3.3591)\n",
      "epoch: 56 train_loss: tensor(0.3723, grad_fn=<NllLossBackward>) average train loss tensor(0.4110, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.457542310522443 val_avg_loss: tensor(3.4053)\n",
      "epoch: 57 train_loss: tensor(0.4000, grad_fn=<NllLossBackward>) average train loss tensor(0.4347, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4541280353200883 val_avg_loss: tensor(3.4502)\n",
      "epoch: 58 train_loss: tensor(0.3594, grad_fn=<NllLossBackward>) average train loss tensor(0.4172, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4481236203090508 val_avg_loss: tensor(3.4833)\n",
      "epoch: 59 train_loss: tensor(0.3615, grad_fn=<NllLossBackward>) average train loss tensor(0.3723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45559970566593083 val_avg_loss: tensor(3.4722)\n",
      "epoch: 60 train_loss: tensor(0.3163, grad_fn=<NllLossBackward>) average train loss tensor(0.3893, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45589403973509934 val_avg_loss: tensor(3.5291)\n",
      "epoch: 61 train_loss: tensor(0.3445, grad_fn=<NllLossBackward>) average train loss tensor(0.3811, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4518027961736571 val_avg_loss: tensor(3.5841)\n",
      "epoch: 62 train_loss: tensor(0.3329, grad_fn=<NllLossBackward>) average train loss tensor(0.3764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4499484915378955 val_avg_loss: tensor(3.5917)\n",
      "epoch: 63 train_loss: tensor(0.3289, grad_fn=<NllLossBackward>) average train loss tensor(0.3526, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4513318616629875 val_avg_loss: tensor(3.5932)\n",
      "epoch: 64 train_loss: tensor(0.3319, grad_fn=<NllLossBackward>) average train loss tensor(0.3628, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4503311258278146 val_avg_loss: tensor(3.6148)\n",
      "epoch: 65 train_loss: tensor(0.3396, grad_fn=<NllLossBackward>) average train loss tensor(0.3620, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4502722590139809 val_avg_loss: tensor(3.6579)\n",
      "epoch: 66 train_loss: tensor(0.3017, grad_fn=<NllLossBackward>) average train loss tensor(0.3484, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45321559970566594 val_avg_loss: tensor(3.6929)\n",
      "epoch: 67 train_loss: tensor(0.2494, grad_fn=<NllLossBackward>) average train loss tensor(0.3139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4533038999264165 val_avg_loss: tensor(3.7267)\n",
      "epoch: 68 train_loss: tensor(0.2924, grad_fn=<NllLossBackward>) average train loss tensor(0.3295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4493009565857248 val_avg_loss: tensor(3.7787)\n",
      "epoch: 69 train_loss: tensor(0.2625, grad_fn=<NllLossBackward>) average train loss tensor(0.2929, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44962472406181014 val_avg_loss: tensor(3.8060)\n",
      "epoch: 70 train_loss: tensor(0.2863, grad_fn=<NllLossBackward>) average train loss tensor(0.2940, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4494775570272259 val_avg_loss: tensor(3.8215)\n",
      "epoch: 71 train_loss: tensor(0.2753, grad_fn=<NllLossBackward>) average train loss tensor(0.2815, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45009565857247974 val_avg_loss: tensor(3.8664)\n",
      "epoch: 72 train_loss: tensor(0.2610, grad_fn=<NllLossBackward>) average train loss tensor(0.2784, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44685798381162617 val_avg_loss: tensor(3.9247)\n",
      "epoch: 73 train_loss: tensor(0.3261, grad_fn=<NllLossBackward>) average train loss tensor(0.2894, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4461515820456218 val_avg_loss: tensor(3.9669)\n",
      "epoch: 74 train_loss: tensor(0.2784, grad_fn=<NllLossBackward>) average train loss tensor(0.3091, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4458278145695364 val_avg_loss: tensor(3.9791)\n",
      "epoch: 75 train_loss: tensor(0.2675, grad_fn=<NllLossBackward>) average train loss tensor(0.2654, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4471228844738778 val_avg_loss: tensor(3.9755)\n",
      "epoch: 76 train_loss: tensor(0.2264, grad_fn=<NllLossBackward>) average train loss tensor(0.2612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4480353200883002 val_avg_loss: tensor(3.9991)\n",
      "epoch: 77 train_loss: tensor(0.2493, grad_fn=<NllLossBackward>) average train loss tensor(0.2578, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4508609271523179 val_avg_loss: tensor(4.0098)\n",
      "epoch: 78 train_loss: tensor(0.2441, grad_fn=<NllLossBackward>) average train loss tensor(0.2795, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44824135393671816 val_avg_loss: tensor(4.0737)\n",
      "epoch: 79 train_loss: tensor(0.2423, grad_fn=<NllLossBackward>) average train loss tensor(0.2319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44600441501103755 val_avg_loss: tensor(4.1167)\n",
      "epoch: 80 train_loss: tensor(0.1786, grad_fn=<NllLossBackward>) average train loss tensor(0.2378, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4447093451066961 val_avg_loss: tensor(4.1570)\n",
      "epoch: 81 train_loss: tensor(0.2296, grad_fn=<NllLossBackward>) average train loss tensor(0.2413, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4453568800588668 val_avg_loss: tensor(4.1916)\n",
      "epoch: 82 train_loss: tensor(0.2009, grad_fn=<NllLossBackward>) average train loss tensor(0.2146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4456806475349522 val_avg_loss: tensor(4.1904)\n",
      "epoch: 83 train_loss: tensor(0.2517, grad_fn=<NllLossBackward>) average train loss tensor(0.2465, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4456512141280353 val_avg_loss: tensor(4.2332)\n",
      "epoch: 84 train_loss: tensor(0.1983, grad_fn=<NllLossBackward>) average train loss tensor(0.2117, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44526857983811624 val_avg_loss: tensor(4.2710)\n",
      "epoch: 85 train_loss: tensor(0.2046, grad_fn=<NllLossBackward>) average train loss tensor(0.2168, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4444738778513613 val_avg_loss: tensor(4.3083)\n",
      "epoch: 86 train_loss: tensor(0.1947, grad_fn=<NllLossBackward>) average train loss tensor(0.2273, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4479764532744665 val_avg_loss: tensor(4.3154)\n",
      "epoch: 87 train_loss: tensor(0.1968, grad_fn=<NllLossBackward>) average train loss tensor(0.2079, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4457395143487859 val_avg_loss: tensor(4.3110)\n",
      "epoch: 88 train_loss: tensor(0.1808, grad_fn=<NllLossBackward>) average train loss tensor(0.2010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44088300220750554 val_avg_loss: tensor(4.3918)\n",
      "epoch: 89 train_loss: tensor(0.2071, grad_fn=<NllLossBackward>) average train loss tensor(0.2042, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44462104488594556 val_avg_loss: tensor(4.3945)\n",
      "epoch: 90 train_loss: tensor(0.1660, grad_fn=<NllLossBackward>) average train loss tensor(0.1897, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.447682119205298 val_avg_loss: tensor(4.4019)\n",
      "epoch: 91 train_loss: tensor(0.1935, grad_fn=<NllLossBackward>) average train loss tensor(0.2006, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4485651214128035 val_avg_loss: tensor(4.4698)\n",
      "epoch: 92 train_loss: tensor(0.1642, grad_fn=<NllLossBackward>) average train loss tensor(0.2135, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4452097130242826 val_avg_loss: tensor(4.5097)\n",
      "epoch: 93 train_loss: tensor(0.1917, grad_fn=<NllLossBackward>) average train loss tensor(0.1980, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4404709345106696 val_avg_loss: tensor(4.5842)\n",
      "epoch: 94 train_loss: tensor(0.1964, grad_fn=<NllLossBackward>) average train loss tensor(0.2015, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43896983075791024 val_avg_loss: tensor(4.5621)\n",
      "epoch: 95 train_loss: tensor(0.1765, grad_fn=<NllLossBackward>) average train loss tensor(0.1922, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43805739514348785 val_avg_loss: tensor(4.5681)\n",
      "epoch: 96 train_loss: tensor(0.1935, grad_fn=<NllLossBackward>) average train loss tensor(0.2008, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43944076526857984 val_avg_loss: tensor(4.6118)\n",
      "epoch: 97 train_loss: tensor(0.1770, grad_fn=<NllLossBackward>) average train loss tensor(0.1827, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.438027961736571 val_avg_loss: tensor(4.5857)\n",
      "epoch: 98 train_loss: tensor(0.1569, grad_fn=<NllLossBackward>) average train loss tensor(0.1946, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44079470198675497 val_avg_loss: tensor(4.5967)\n",
      "epoch: 99 train_loss: tensor(0.1830, grad_fn=<NllLossBackward>) average train loss tensor(0.1920, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44671081677704194 val_avg_loss: tensor(4.6043)\n",
      "epoch: 100 train_loss: tensor(0.1840, grad_fn=<NllLossBackward>) average train loss tensor(0.1877, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4477409860191317 val_avg_loss: tensor(4.6477)\n",
      "epoch: 101 train_loss: tensor(0.1626, grad_fn=<NllLossBackward>) average train loss tensor(0.1647, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4461221486387049 val_avg_loss: tensor(4.7203)\n",
      "epoch: 102 train_loss: tensor(0.1913, grad_fn=<NllLossBackward>) average train loss tensor(0.1713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44282560706401763 val_avg_loss: tensor(4.7345)\n",
      "epoch: 103 train_loss: tensor(0.1548, grad_fn=<NllLossBackward>) average train loss tensor(0.1674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44200147167034587 val_avg_loss: tensor(4.7212)\n",
      "epoch: 104 train_loss: tensor(0.1852, grad_fn=<NllLossBackward>) average train loss tensor(0.1731, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4421486387049301 val_avg_loss: tensor(4.7603)\n",
      "epoch: 105 train_loss: tensor(0.1535, grad_fn=<NllLossBackward>) average train loss tensor(0.1691, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4436791758646063 val_avg_loss: tensor(4.7345)\n",
      "epoch: 106 train_loss: tensor(0.1669, grad_fn=<NllLossBackward>) average train loss tensor(0.1526, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4442384105960265 val_avg_loss: tensor(4.7710)\n",
      "epoch: 107 train_loss: tensor(0.1280, grad_fn=<NllLossBackward>) average train loss tensor(0.1675, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44279617365710083 val_avg_loss: tensor(4.8093)\n",
      "epoch: 108 train_loss: tensor(0.1465, grad_fn=<NllLossBackward>) average train loss tensor(0.1480, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4409418690213392 val_avg_loss: tensor(4.8466)\n",
      "epoch: 109 train_loss: tensor(0.1204, grad_fn=<NllLossBackward>) average train loss tensor(0.1457, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44235467255334804 val_avg_loss: tensor(4.8847)\n",
      "epoch: 110 train_loss: tensor(0.1593, grad_fn=<NllLossBackward>) average train loss tensor(0.1545, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44538631346578367 val_avg_loss: tensor(4.8144)\n",
      "epoch: 111 train_loss: tensor(0.1400, grad_fn=<NllLossBackward>) average train loss tensor(0.1521, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4461221486387049 val_avg_loss: tensor(4.7874)\n",
      "epoch: 112 train_loss: tensor(0.1767, grad_fn=<NllLossBackward>) average train loss tensor(0.1645, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4459749816041207 val_avg_loss: tensor(4.8675)\n",
      "epoch: 113 train_loss: tensor(0.1409, grad_fn=<NllLossBackward>) average train loss tensor(0.1468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4477998528329654 val_avg_loss: tensor(4.8885)\n",
      "epoch: 114 train_loss: tensor(0.1540, grad_fn=<NllLossBackward>) average train loss tensor(0.1651, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4443561442236939 val_avg_loss: tensor(4.9077)\n",
      "epoch: 115 train_loss: tensor(0.1105, grad_fn=<NllLossBackward>) average train loss tensor(0.1425, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4400588668138337 val_avg_loss: tensor(4.9258)\n",
      "epoch: 116 train_loss: tensor(0.0962, grad_fn=<NllLossBackward>) average train loss tensor(0.1193, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4420603384841795 val_avg_loss: tensor(4.9324)\n",
      "epoch: 117 train_loss: tensor(0.1503, grad_fn=<NllLossBackward>) average train loss tensor(0.1564, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44279617365710083 val_avg_loss: tensor(4.9699)\n",
      "epoch: 118 train_loss: tensor(0.0978, grad_fn=<NllLossBackward>) average train loss tensor(0.1319, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4396467991169978 val_avg_loss: tensor(5.0163)\n",
      "epoch: 119 train_loss: tensor(0.0932, grad_fn=<NllLossBackward>) average train loss tensor(0.1146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44097130242825605 val_avg_loss: tensor(5.0781)\n",
      "epoch: 120 train_loss: tensor(0.1757, grad_fn=<NllLossBackward>) average train loss tensor(0.1453, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.44426784400294334 val_avg_loss: tensor(5.0849)\n",
      "epoch: 121 train_loss: tensor(0.1198, grad_fn=<NllLossBackward>) average train loss tensor(0.1294, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44379690949227374 val_avg_loss: tensor(5.1226)\n",
      "epoch: 122 train_loss: tensor(0.1262, grad_fn=<NllLossBackward>) average train loss tensor(0.1285, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.441383370125092 val_avg_loss: tensor(5.1736)\n",
      "epoch: 123 train_loss: tensor(0.1231, grad_fn=<NllLossBackward>) average train loss tensor(0.1440, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44515084621044887 val_avg_loss: tensor(5.1387)\n",
      "epoch: 124 train_loss: tensor(0.1083, grad_fn=<NllLossBackward>) average train loss tensor(0.1149, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.441972038263429 val_avg_loss: tensor(5.1484)\n",
      "epoch: 125 train_loss: tensor(0.1221, grad_fn=<NllLossBackward>) average train loss tensor(0.1463, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4407652685798381 val_avg_loss: tensor(5.1980)\n",
      "epoch: 126 train_loss: tensor(0.1131, grad_fn=<NllLossBackward>) average train loss tensor(0.1226, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4392935982339956 val_avg_loss: tensor(5.2324)\n",
      "epoch: 127 train_loss: tensor(0.1162, grad_fn=<NllLossBackward>) average train loss tensor(0.1291, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4390875643855776 val_avg_loss: tensor(5.2513)\n",
      "epoch: 128 train_loss: tensor(0.1463, grad_fn=<NllLossBackward>) average train loss tensor(0.1295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4415599705665931 val_avg_loss: tensor(5.2103)\n",
      "epoch: 129 train_loss: tensor(0.1222, grad_fn=<NllLossBackward>) average train loss tensor(0.1101, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44182487122884473 val_avg_loss: tensor(5.1963)\n",
      "epoch: 130 train_loss: tensor(0.0800, grad_fn=<NllLossBackward>) average train loss tensor(0.1127, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44362030905077265 val_avg_loss: tensor(5.2529)\n",
      "epoch: 131 train_loss: tensor(0.1137, grad_fn=<NllLossBackward>) average train loss tensor(0.1198, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44426784400294334 val_avg_loss: tensor(5.2887)\n",
      "epoch: 132 train_loss: tensor(0.1010, grad_fn=<NllLossBackward>) average train loss tensor(0.1143, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4426784400294334 val_avg_loss: tensor(5.3109)\n",
      "epoch: 133 train_loss: tensor(0.1358, grad_fn=<NllLossBackward>) average train loss tensor(0.1370, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44135393671817513 val_avg_loss: tensor(5.3412)\n",
      "epoch: 134 train_loss: tensor(0.1045, grad_fn=<NllLossBackward>) average train loss tensor(0.1219, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4406181015452539 val_avg_loss: tensor(5.4026)\n",
      "epoch: 135 train_loss: tensor(0.1084, grad_fn=<NllLossBackward>) average train loss tensor(0.1134, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44026490066225166 val_avg_loss: tensor(5.3505)\n",
      "epoch: 136 train_loss: tensor(0.1016, grad_fn=<NllLossBackward>) average train loss tensor(0.1252, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44067696835908754 val_avg_loss: tensor(5.3577)\n",
      "epoch: 137 train_loss: tensor(0.1199, grad_fn=<NllLossBackward>) average train loss tensor(0.1208, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43799852832965414 val_avg_loss: tensor(5.3565)\n",
      "epoch: 138 train_loss: tensor(0.1062, grad_fn=<NllLossBackward>) average train loss tensor(0.1270, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4392935982339956 val_avg_loss: tensor(5.4007)\n",
      "epoch: 139 train_loss: tensor(0.1218, grad_fn=<NllLossBackward>) average train loss tensor(0.1149, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43858719646799116 val_avg_loss: tensor(5.4624)\n",
      "epoch: 0 train_loss: tensor(3.8527, grad_fn=<NllLossBackward>) average train loss tensor(3.9359, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.057630610743193526 val_avg_loss: tensor(3.8162)\n",
      "epoch: 1 train_loss: tensor(3.7592, grad_fn=<NllLossBackward>) average train loss tensor(3.7583, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.0637233259749816 val_avg_loss: tensor(3.6834)\n",
      "epoch: 2 train_loss: tensor(3.6578, grad_fn=<NllLossBackward>) average train loss tensor(3.6638, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.11102281089036056 val_avg_loss: tensor(3.5945)\n",
      "epoch: 3 train_loss: tensor(3.5483, grad_fn=<NllLossBackward>) average train loss tensor(3.5651, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.145224429727741 val_avg_loss: tensor(3.5137)\n",
      "epoch: 4 train_loss: tensor(3.4494, grad_fn=<NllLossBackward>) average train loss tensor(3.4964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.18475349521707138 val_avg_loss: tensor(3.3978)\n",
      "epoch: 5 train_loss: tensor(3.3176, grad_fn=<NllLossBackward>) average train loss tensor(3.3762, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22634289919058131 val_avg_loss: tensor(3.2606)\n",
      "epoch: 6 train_loss: tensor(3.1941, grad_fn=<NllLossBackward>) average train loss tensor(3.2444, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.254775570272259 val_avg_loss: tensor(3.1311)\n",
      "epoch: 7 train_loss: tensor(3.0961, grad_fn=<NllLossBackward>) average train loss tensor(3.1278, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.275673289183223 val_avg_loss: tensor(3.0101)\n",
      "epoch: 8 train_loss: tensor(2.8908, grad_fn=<NllLossBackward>) average train loss tensor(2.9720, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.29433406916850624 val_avg_loss: tensor(2.8732)\n",
      "epoch: 9 train_loss: tensor(2.8131, grad_fn=<NllLossBackward>) average train loss tensor(2.8610, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.31155261221486386 val_avg_loss: tensor(2.7499)\n",
      "epoch: 10 train_loss: tensor(2.6490, grad_fn=<NllLossBackward>) average train loss tensor(2.7395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3398381162619573 val_avg_loss: tensor(2.6367)\n",
      "epoch: 11 train_loss: tensor(2.5310, grad_fn=<NllLossBackward>) average train loss tensor(2.5992, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3513171449595291 val_avg_loss: tensor(2.5378)\n",
      "epoch: 12 train_loss: tensor(2.4038, grad_fn=<NllLossBackward>) average train loss tensor(2.4920, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3672111846946284 val_avg_loss: tensor(2.4594)\n",
      "epoch: 13 train_loss: tensor(2.2801, grad_fn=<NllLossBackward>) average train loss tensor(2.3737, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3824282560706402 val_avg_loss: tensor(2.3841)\n",
      "epoch: 14 train_loss: tensor(2.2171, grad_fn=<NllLossBackward>) average train loss tensor(2.2594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40061810154525385 val_avg_loss: tensor(2.3106)\n",
      "epoch: 15 train_loss: tensor(2.0686, grad_fn=<NllLossBackward>) average train loss tensor(2.1441, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40618101545253865 val_avg_loss: tensor(2.2667)\n",
      "epoch: 16 train_loss: tensor(1.9898, grad_fn=<NllLossBackward>) average train loss tensor(2.0946, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4177777777777778 val_avg_loss: tensor(2.2291)\n",
      "epoch: 17 train_loss: tensor(1.9872, grad_fn=<NllLossBackward>) average train loss tensor(2.0304, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4305813097866078 val_avg_loss: tensor(2.1870)\n",
      "epoch: 18 train_loss: tensor(1.8982, grad_fn=<NllLossBackward>) average train loss tensor(1.9342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4321412803532009 val_avg_loss: tensor(2.1691)\n",
      "epoch: 19 train_loss: tensor(1.7523, grad_fn=<NllLossBackward>) average train loss tensor(1.8408, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43949963208241355 val_avg_loss: tensor(2.1477)\n",
      "epoch: 20 train_loss: tensor(1.6759, grad_fn=<NllLossBackward>) average train loss tensor(1.7583, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4450036791758646 val_avg_loss: tensor(2.1378)\n",
      "epoch: 21 train_loss: tensor(1.6834, grad_fn=<NllLossBackward>) average train loss tensor(1.7118, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4480353200883002 val_avg_loss: tensor(2.1455)\n",
      "epoch: 22 train_loss: tensor(1.5513, grad_fn=<NllLossBackward>) average train loss tensor(1.6271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45206769683590875 val_avg_loss: tensor(2.1369)\n",
      "epoch: 23 train_loss: tensor(1.4117, grad_fn=<NllLossBackward>) average train loss tensor(1.5336, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4520971302428256 val_avg_loss: tensor(2.1479)\n",
      "epoch: 24 train_loss: tensor(1.4236, grad_fn=<NllLossBackward>) average train loss tensor(1.4975, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4558057395143488 val_avg_loss: tensor(2.1641)\n",
      "epoch: 25 train_loss: tensor(1.4470, grad_fn=<NllLossBackward>) average train loss tensor(1.4311, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4583075791022811 val_avg_loss: tensor(2.1743)\n",
      "epoch: 26 train_loss: tensor(1.3038, grad_fn=<NllLossBackward>) average train loss tensor(1.3790, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4563061074319352 val_avg_loss: tensor(2.2058)\n",
      "epoch: 27 train_loss: tensor(1.2899, grad_fn=<NllLossBackward>) average train loss tensor(1.3835, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4627520235467255 val_avg_loss: tensor(2.1876)\n",
      "epoch: 28 train_loss: tensor(1.2327, grad_fn=<NllLossBackward>) average train loss tensor(1.2994, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4632818248712288 val_avg_loss: tensor(2.1873)\n",
      "epoch: 29 train_loss: tensor(1.2443, grad_fn=<NllLossBackward>) average train loss tensor(1.2691, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46239882266372334 val_avg_loss: tensor(2.2197)\n",
      "epoch: 30 train_loss: tensor(1.0999, grad_fn=<NllLossBackward>) average train loss tensor(1.1986, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4644885945548197 val_avg_loss: tensor(2.2494)\n",
      "epoch: 31 train_loss: tensor(1.0520, grad_fn=<NllLossBackward>) average train loss tensor(1.1190, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46357615894039733 val_avg_loss: tensor(2.3022)\n",
      "epoch: 32 train_loss: tensor(1.0576, grad_fn=<NllLossBackward>) average train loss tensor(1.0827, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4655187637969095 val_avg_loss: tensor(2.3258)\n",
      "epoch: 33 train_loss: tensor(0.9921, grad_fn=<NllLossBackward>) average train loss tensor(1.0530, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46422369389256807 val_avg_loss: tensor(2.3739)\n",
      "epoch: 34 train_loss: tensor(0.9359, grad_fn=<NllLossBackward>) average train loss tensor(1.0419, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4625754231052244 val_avg_loss: tensor(2.3966)\n",
      "epoch: 35 train_loss: tensor(0.9272, grad_fn=<NllLossBackward>) average train loss tensor(0.9488, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4588962472406181 val_avg_loss: tensor(2.4659)\n",
      "epoch: 36 train_loss: tensor(0.8823, grad_fn=<NllLossBackward>) average train loss tensor(0.9527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4596026490066225 val_avg_loss: tensor(2.4676)\n",
      "epoch: 37 train_loss: tensor(0.8437, grad_fn=<NllLossBackward>) average train loss tensor(0.9194, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4593671817512877 val_avg_loss: tensor(2.4786)\n",
      "epoch: 38 train_loss: tensor(0.7560, grad_fn=<NllLossBackward>) average train loss tensor(0.8594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45642384105960265 val_avg_loss: tensor(2.5373)\n",
      "epoch: 39 train_loss: tensor(0.8199, grad_fn=<NllLossBackward>) average train loss tensor(0.8557, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4555408388520971 val_avg_loss: tensor(2.5656)\n",
      "epoch: 40 train_loss: tensor(0.7629, grad_fn=<NllLossBackward>) average train loss tensor(0.8374, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4613392200147167 val_avg_loss: tensor(2.5883)\n",
      "epoch: 41 train_loss: tensor(0.6903, grad_fn=<NllLossBackward>) average train loss tensor(0.7433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4595437821927888 val_avg_loss: tensor(2.6435)\n",
      "epoch: 42 train_loss: tensor(0.7718, grad_fn=<NllLossBackward>) average train loss tensor(0.8034, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45439293598233993 val_avg_loss: tensor(2.7077)\n",
      "epoch: 43 train_loss: tensor(0.6444, grad_fn=<NllLossBackward>) average train loss tensor(0.7295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45283296541574686 val_avg_loss: tensor(2.7152)\n",
      "epoch: 44 train_loss: tensor(0.6310, grad_fn=<NllLossBackward>) average train loss tensor(0.6851, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45177336276674024 val_avg_loss: tensor(2.7836)\n",
      "epoch: 45 train_loss: tensor(0.6430, grad_fn=<NllLossBackward>) average train loss tensor(0.6962, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45165562913907287 val_avg_loss: tensor(2.8075)\n",
      "epoch: 46 train_loss: tensor(0.5568, grad_fn=<NllLossBackward>) average train loss tensor(0.6315, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4552465047829286 val_avg_loss: tensor(2.8277)\n",
      "epoch: 47 train_loss: tensor(0.5317, grad_fn=<NllLossBackward>) average train loss tensor(0.5914, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4488300220750552 val_avg_loss: tensor(2.9092)\n",
      "epoch: 48 train_loss: tensor(0.5938, grad_fn=<NllLossBackward>) average train loss tensor(0.5960, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44532744665194995 val_avg_loss: tensor(3.0032)\n",
      "epoch: 49 train_loss: tensor(0.6066, grad_fn=<NllLossBackward>) average train loss tensor(0.6258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4498896247240618 val_avg_loss: tensor(3.0278)\n",
      "epoch: 50 train_loss: tensor(0.4694, grad_fn=<NllLossBackward>) average train loss tensor(0.5620, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44724061810154525 val_avg_loss: tensor(3.0298)\n",
      "epoch: 51 train_loss: tensor(0.5251, grad_fn=<NllLossBackward>) average train loss tensor(0.5470, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4463576158940397 val_avg_loss: tensor(3.1038)\n",
      "epoch: 52 train_loss: tensor(0.4581, grad_fn=<NllLossBackward>) average train loss tensor(0.5239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44997792494481237 val_avg_loss: tensor(3.1067)\n",
      "epoch: 53 train_loss: tensor(0.4865, grad_fn=<NllLossBackward>) average train loss tensor(0.4985, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4462693156732892 val_avg_loss: tensor(3.1459)\n",
      "epoch: 54 train_loss: tensor(0.4017, grad_fn=<NllLossBackward>) average train loss tensor(0.4900, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44665194996320823 val_avg_loss: tensor(3.2378)\n",
      "epoch: 55 train_loss: tensor(0.3740, grad_fn=<NllLossBackward>) average train loss tensor(0.4639, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44279617365710083 val_avg_loss: tensor(3.2704)\n",
      "epoch: 56 train_loss: tensor(0.3952, grad_fn=<NllLossBackward>) average train loss tensor(0.4665, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4413245033112583 val_avg_loss: tensor(3.3028)\n",
      "epoch: 57 train_loss: tensor(0.4643, grad_fn=<NllLossBackward>) average train loss tensor(0.4433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4518027961736571 val_avg_loss: tensor(3.3296)\n",
      "epoch: 58 train_loss: tensor(0.3539, grad_fn=<NllLossBackward>) average train loss tensor(0.4109, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44738778513612953 val_avg_loss: tensor(3.3787)\n",
      "epoch: 59 train_loss: tensor(0.4106, grad_fn=<NllLossBackward>) average train loss tensor(0.4441, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4454451802796174 val_avg_loss: tensor(3.4441)\n",
      "epoch: 60 train_loss: tensor(0.3884, grad_fn=<NllLossBackward>) average train loss tensor(0.3973, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4471228844738778 val_avg_loss: tensor(3.4434)\n",
      "epoch: 61 train_loss: tensor(0.3181, grad_fn=<NllLossBackward>) average train loss tensor(0.3796, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4454157468727005 val_avg_loss: tensor(3.5013)\n",
      "epoch: 62 train_loss: tensor(0.3012, grad_fn=<NllLossBackward>) average train loss tensor(0.3726, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4469757174392936 val_avg_loss: tensor(3.5492)\n",
      "epoch: 63 train_loss: tensor(0.3105, grad_fn=<NllLossBackward>) average train loss tensor(0.3622, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4511552612214864 val_avg_loss: tensor(3.5527)\n",
      "epoch: 64 train_loss: tensor(0.3276, grad_fn=<NllLossBackward>) average train loss tensor(0.3460, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4452097130242826 val_avg_loss: tensor(3.6161)\n",
      "epoch: 65 train_loss: tensor(0.3194, grad_fn=<NllLossBackward>) average train loss tensor(0.3393, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44491537895511407 val_avg_loss: tensor(3.6424)\n",
      "epoch: 66 train_loss: tensor(0.3146, grad_fn=<NllLossBackward>) average train loss tensor(0.3428, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44562178072111847 val_avg_loss: tensor(3.6844)\n",
      "epoch: 67 train_loss: tensor(0.2340, grad_fn=<NllLossBackward>) average train loss tensor(0.3123, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4398528329654158 val_avg_loss: tensor(3.7613)\n",
      "epoch: 68 train_loss: tensor(0.2479, grad_fn=<NllLossBackward>) average train loss tensor(0.3058, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4419131714495953 val_avg_loss: tensor(3.7750)\n",
      "epoch: 69 train_loss: tensor(0.2744, grad_fn=<NllLossBackward>) average train loss tensor(0.2980, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44088300220750554 val_avg_loss: tensor(3.8291)\n",
      "epoch: 70 train_loss: tensor(0.2370, grad_fn=<NllLossBackward>) average train loss tensor(0.2713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4410890360559235 val_avg_loss: tensor(3.8476)\n",
      "epoch: 71 train_loss: tensor(0.2610, grad_fn=<NllLossBackward>) average train loss tensor(0.2721, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4419131714495953 val_avg_loss: tensor(3.9090)\n",
      "epoch: 72 train_loss: tensor(0.2592, grad_fn=<NllLossBackward>) average train loss tensor(0.2871, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.44032376747608537 val_avg_loss: tensor(3.9628)\n",
      "epoch: 73 train_loss: tensor(0.2483, grad_fn=<NllLossBackward>) average train loss tensor(0.2539, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44211920529801324 val_avg_loss: tensor(3.9786)\n",
      "epoch: 74 train_loss: tensor(0.2637, grad_fn=<NllLossBackward>) average train loss tensor(0.2623, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44235467255334804 val_avg_loss: tensor(4.0135)\n",
      "epoch: 75 train_loss: tensor(0.2359, grad_fn=<NllLossBackward>) average train loss tensor(0.2202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4412950699043414 val_avg_loss: tensor(4.1018)\n",
      "epoch: 76 train_loss: tensor(0.2091, grad_fn=<NllLossBackward>) average train loss tensor(0.2468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4397645327446652 val_avg_loss: tensor(4.1985)\n",
      "epoch: 77 train_loss: tensor(0.2243, grad_fn=<NllLossBackward>) average train loss tensor(0.2261, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4392347314201619 val_avg_loss: tensor(4.2250)\n",
      "epoch: 78 train_loss: tensor(0.2137, grad_fn=<NllLossBackward>) average train loss tensor(0.2221, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4402943340691685 val_avg_loss: tensor(4.2162)\n",
      "epoch: 79 train_loss: tensor(0.2063, grad_fn=<NllLossBackward>) average train loss tensor(0.2240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4405298013245033 val_avg_loss: tensor(4.2237)\n",
      "epoch: 80 train_loss: tensor(0.1721, grad_fn=<NllLossBackward>) average train loss tensor(0.2106, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4402354672553348 val_avg_loss: tensor(4.2543)\n",
      "epoch: 81 train_loss: tensor(0.1776, grad_fn=<NllLossBackward>) average train loss tensor(0.2130, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44182487122884473 val_avg_loss: tensor(4.2788)\n",
      "epoch: 82 train_loss: tensor(0.2023, grad_fn=<NllLossBackward>) average train loss tensor(0.2172, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4407652685798381 val_avg_loss: tensor(4.2923)\n",
      "epoch: 83 train_loss: tensor(0.2392, grad_fn=<NllLossBackward>) average train loss tensor(0.2105, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4411479028697572 val_avg_loss: tensor(4.3194)\n",
      "epoch: 84 train_loss: tensor(0.1737, grad_fn=<NllLossBackward>) average train loss tensor(0.1946, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4397056659308315 val_avg_loss: tensor(4.3527)\n",
      "epoch: 85 train_loss: tensor(0.1891, grad_fn=<NllLossBackward>) average train loss tensor(0.1896, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4357615894039735 val_avg_loss: tensor(4.3638)\n",
      "epoch: 86 train_loss: tensor(0.1468, grad_fn=<NllLossBackward>) average train loss tensor(0.1894, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43720382634289917 val_avg_loss: tensor(4.3567)\n",
      "epoch: 87 train_loss: tensor(0.1597, grad_fn=<NllLossBackward>) average train loss tensor(0.1965, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4434437086092715 val_avg_loss: tensor(4.3492)\n",
      "epoch: 88 train_loss: tensor(0.1703, grad_fn=<NllLossBackward>) average train loss tensor(0.1818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4422075055187638 val_avg_loss: tensor(4.4630)\n",
      "epoch: 89 train_loss: tensor(0.1778, grad_fn=<NllLossBackward>) average train loss tensor(0.1814, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4389992641648271 val_avg_loss: tensor(4.5030)\n",
      "epoch: 90 train_loss: tensor(0.1830, grad_fn=<NllLossBackward>) average train loss tensor(0.1803, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43935246504782927 val_avg_loss: tensor(4.5170)\n",
      "epoch: 91 train_loss: tensor(0.1746, grad_fn=<NllLossBackward>) average train loss tensor(0.1752, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43926416482707875 val_avg_loss: tensor(4.5759)\n",
      "epoch: 92 train_loss: tensor(0.1825, grad_fn=<NllLossBackward>) average train loss tensor(0.1701, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4399411331861663 val_avg_loss: tensor(4.5984)\n",
      "epoch: 93 train_loss: tensor(0.1858, grad_fn=<NllLossBackward>) average train loss tensor(0.1663, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4392935982339956 val_avg_loss: tensor(4.6103)\n",
      "epoch: 94 train_loss: tensor(0.1880, grad_fn=<NllLossBackward>) average train loss tensor(0.1651, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4417365710080942 val_avg_loss: tensor(4.6100)\n",
      "epoch: 95 train_loss: tensor(0.1438, grad_fn=<NllLossBackward>) average train loss tensor(0.1702, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4419131714495953 val_avg_loss: tensor(4.6511)\n",
      "epoch: 96 train_loss: tensor(0.1296, grad_fn=<NllLossBackward>) average train loss tensor(0.1444, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4367034584253127 val_avg_loss: tensor(4.6785)\n",
      "epoch: 97 train_loss: tensor(0.1302, grad_fn=<NllLossBackward>) average train loss tensor(0.1477, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43246504782928624 val_avg_loss: tensor(4.7082)\n",
      "epoch: 98 train_loss: tensor(0.1698, grad_fn=<NllLossBackward>) average train loss tensor(0.1587, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4347902869757174 val_avg_loss: tensor(4.7224)\n",
      "epoch: 99 train_loss: tensor(0.1246, grad_fn=<NllLossBackward>) average train loss tensor(0.1324, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4379396615158205 val_avg_loss: tensor(4.7453)\n",
      "epoch: 100 train_loss: tensor(0.1477, grad_fn=<NllLossBackward>) average train loss tensor(0.1400, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4361736571008094 val_avg_loss: tensor(4.8459)\n",
      "epoch: 101 train_loss: tensor(0.1482, grad_fn=<NllLossBackward>) average train loss tensor(0.1440, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4345548197203826 val_avg_loss: tensor(4.9243)\n",
      "epoch: 102 train_loss: tensor(0.1282, grad_fn=<NllLossBackward>) average train loss tensor(0.1485, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43393671817512874 val_avg_loss: tensor(4.9097)\n",
      "epoch: 103 train_loss: tensor(0.1405, grad_fn=<NllLossBackward>) average train loss tensor(0.1295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43461368653421634 val_avg_loss: tensor(4.8819)\n",
      "epoch: 104 train_loss: tensor(0.0788, grad_fn=<NllLossBackward>) average train loss tensor(0.1148, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4367917586460633 val_avg_loss: tensor(4.8917)\n",
      "epoch: 105 train_loss: tensor(0.1222, grad_fn=<NllLossBackward>) average train loss tensor(0.1457, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43629139072847684 val_avg_loss: tensor(4.8995)\n",
      "epoch: 106 train_loss: tensor(0.1248, grad_fn=<NllLossBackward>) average train loss tensor(0.1333, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4355849889624724 val_avg_loss: tensor(4.9076)\n",
      "epoch: 107 train_loss: tensor(0.1366, grad_fn=<NllLossBackward>) average train loss tensor(0.1496, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43829286239882265 val_avg_loss: tensor(4.8799)\n",
      "epoch: 108 train_loss: tensor(0.1372, grad_fn=<NllLossBackward>) average train loss tensor(0.1248, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4393230316409124 val_avg_loss: tensor(4.8905)\n",
      "epoch: 109 train_loss: tensor(0.0860, grad_fn=<NllLossBackward>) average train loss tensor(0.1211, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4383811626195732 val_avg_loss: tensor(4.8958)\n",
      "epoch: 110 train_loss: tensor(0.1090, grad_fn=<NllLossBackward>) average train loss tensor(0.1224, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43635025754231055 val_avg_loss: tensor(4.9328)\n",
      "epoch: 111 train_loss: tensor(0.1059, grad_fn=<NllLossBackward>) average train loss tensor(0.1148, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4331420161883738 val_avg_loss: tensor(5.0395)\n",
      "epoch: 112 train_loss: tensor(0.1001, grad_fn=<NllLossBackward>) average train loss tensor(0.1229, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43376011773362766 val_avg_loss: tensor(5.1083)\n",
      "epoch: 113 train_loss: tensor(0.1086, grad_fn=<NllLossBackward>) average train loss tensor(0.1273, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4387049300956586 val_avg_loss: tensor(5.1073)\n",
      "epoch: 114 train_loss: tensor(0.1028, grad_fn=<NllLossBackward>) average train loss tensor(0.1048, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43652685798381163 val_avg_loss: tensor(5.1555)\n",
      "epoch: 115 train_loss: tensor(0.1271, grad_fn=<NllLossBackward>) average train loss tensor(0.1391, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4363208241353937 val_avg_loss: tensor(5.1827)\n",
      "epoch: 116 train_loss: tensor(0.1295, grad_fn=<NllLossBackward>) average train loss tensor(0.1310, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43490802060338485 val_avg_loss: tensor(5.1185)\n",
      "epoch: 117 train_loss: tensor(0.0987, grad_fn=<NllLossBackward>) average train loss tensor(0.1109, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4342604856512141 val_avg_loss: tensor(5.0462)\n",
      "epoch: 118 train_loss: tensor(0.1134, grad_fn=<NllLossBackward>) average train loss tensor(0.1163, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.43473142016188376 val_avg_loss: tensor(5.0612)\n",
      "epoch: 119 train_loss: tensor(0.0794, grad_fn=<NllLossBackward>) average train loss tensor(0.0953, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4385577630610743 val_avg_loss: tensor(5.0963)\n",
      "epoch: 120 train_loss: tensor(0.1039, grad_fn=<NllLossBackward>) average train loss tensor(0.0971, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43844002943340693 val_avg_loss: tensor(5.1821)\n",
      "epoch: 121 train_loss: tensor(0.1152, grad_fn=<NllLossBackward>) average train loss tensor(0.1283, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4360853568800589 val_avg_loss: tensor(5.2550)\n",
      "epoch: 122 train_loss: tensor(0.1261, grad_fn=<NllLossBackward>) average train loss tensor(0.1126, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4355849889624724 val_avg_loss: tensor(5.2551)\n",
      "epoch: 123 train_loss: tensor(0.0928, grad_fn=<NllLossBackward>) average train loss tensor(0.1226, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43414275202354674 val_avg_loss: tensor(5.1819)\n",
      "epoch: 124 train_loss: tensor(0.0892, grad_fn=<NllLossBackward>) average train loss tensor(0.0977, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43228844738778516 val_avg_loss: tensor(5.1880)\n",
      "epoch: 125 train_loss: tensor(0.0794, grad_fn=<NllLossBackward>) average train loss tensor(0.0866, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43193524650478293 val_avg_loss: tensor(5.2645)\n",
      "epoch: 126 train_loss: tensor(0.0711, grad_fn=<NllLossBackward>) average train loss tensor(0.0869, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4339661515820456 val_avg_loss: tensor(5.3303)\n",
      "epoch: 127 train_loss: tensor(0.0665, grad_fn=<NllLossBackward>) average train loss tensor(0.0917, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4358204562178072 val_avg_loss: tensor(5.3893)\n",
      "epoch: 128 train_loss: tensor(0.0822, grad_fn=<NllLossBackward>) average train loss tensor(0.0771, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4371743929359823 val_avg_loss: tensor(5.4529)\n",
      "epoch: 129 train_loss: tensor(0.0893, grad_fn=<NllLossBackward>) average train loss tensor(0.0930, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4355849889624724 val_avg_loss: tensor(5.4513)\n",
      "epoch: 130 train_loss: tensor(0.0740, grad_fn=<NllLossBackward>) average train loss tensor(0.0781, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4333480500367918 val_avg_loss: tensor(5.4810)\n",
      "epoch: 131 train_loss: tensor(0.0723, grad_fn=<NllLossBackward>) average train loss tensor(0.0846, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43169977924944813 val_avg_loss: tensor(5.5740)\n",
      "epoch: 132 train_loss: tensor(0.0823, grad_fn=<NllLossBackward>) average train loss tensor(0.0856, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4327299484915379 val_avg_loss: tensor(5.5381)\n",
      "epoch: 133 train_loss: tensor(0.0825, grad_fn=<NllLossBackward>) average train loss tensor(0.0936, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4367034584253127 val_avg_loss: tensor(5.5055)\n",
      "epoch: 134 train_loss: tensor(0.1521, grad_fn=<NllLossBackward>) average train loss tensor(0.1077, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4362325239146431 val_avg_loss: tensor(5.5260)\n",
      "epoch: 135 train_loss: tensor(0.0831, grad_fn=<NllLossBackward>) average train loss tensor(0.0885, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4330831493745401 val_avg_loss: tensor(5.5303)\n",
      "epoch: 136 train_loss: tensor(0.1001, grad_fn=<NllLossBackward>) average train loss tensor(0.0797, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4320235467255335 val_avg_loss: tensor(5.5742)\n",
      "epoch: 137 train_loss: tensor(0.0685, grad_fn=<NllLossBackward>) average train loss tensor(0.0809, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4325533480500368 val_avg_loss: tensor(5.5592)\n",
      "epoch: 138 train_loss: tensor(0.0740, grad_fn=<NllLossBackward>) average train loss tensor(0.0894, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4316409124356144 val_avg_loss: tensor(5.5002)\n",
      "epoch: 139 train_loss: tensor(0.0690, grad_fn=<NllLossBackward>) average train loss tensor(0.0787, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42978660779985284 val_avg_loss: tensor(5.5509)\n",
      "epoch: 0 train_loss: tensor(3.8418, grad_fn=<NllLossBackward>) average train loss tensor(3.8983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07658572479764533 val_avg_loss: tensor(3.8095)\n",
      "epoch: 1 train_loss: tensor(3.7268, grad_fn=<NllLossBackward>) average train loss tensor(3.7500, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07740986019131714 val_avg_loss: tensor(3.6858)\n",
      "epoch: 2 train_loss: tensor(3.6199, grad_fn=<NllLossBackward>) average train loss tensor(3.6324, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.12573951434878589 val_avg_loss: tensor(3.5733)\n",
      "epoch: 3 train_loss: tensor(3.5297, grad_fn=<NllLossBackward>) average train loss tensor(3.5452, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1837821927888153 val_avg_loss: tensor(3.4558)\n",
      "epoch: 4 train_loss: tensor(3.3687, grad_fn=<NllLossBackward>) average train loss tensor(3.4228, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.25409860191317146 val_avg_loss: tensor(3.3163)\n",
      "epoch: 5 train_loss: tensor(3.2499, grad_fn=<NllLossBackward>) average train loss tensor(3.3048, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.27602649006622515 val_avg_loss: tensor(3.1646)\n",
      "epoch: 6 train_loss: tensor(3.1443, grad_fn=<NllLossBackward>) average train loss tensor(3.1713, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2948933038999264 val_avg_loss: tensor(3.0053)\n",
      "epoch: 7 train_loss: tensor(3.0059, grad_fn=<NllLossBackward>) average train loss tensor(3.0294, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3061662987490802 val_avg_loss: tensor(2.8571)\n",
      "epoch: 8 train_loss: tensor(2.7979, grad_fn=<NllLossBackward>) average train loss tensor(2.8978, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3242384105960265 val_avg_loss: tensor(2.7246)\n",
      "epoch: 9 train_loss: tensor(2.7268, grad_fn=<NllLossBackward>) average train loss tensor(2.7763, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.34943340691685065 val_avg_loss: tensor(2.6044)\n",
      "epoch: 10 train_loss: tensor(2.5915, grad_fn=<NllLossBackward>) average train loss tensor(2.6574, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.36362030905077264 val_avg_loss: tensor(2.5098)\n",
      "epoch: 11 train_loss: tensor(2.4852, grad_fn=<NllLossBackward>) average train loss tensor(2.5580, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.37565857247976453 val_avg_loss: tensor(2.4278)\n",
      "epoch: 12 train_loss: tensor(2.4516, grad_fn=<NllLossBackward>) average train loss tensor(2.4867, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38852097130242824 val_avg_loss: tensor(2.3605)\n",
      "epoch: 13 train_loss: tensor(2.2577, grad_fn=<NllLossBackward>) average train loss tensor(2.3586, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.40061810154525385 val_avg_loss: tensor(2.3022)\n",
      "epoch: 14 train_loss: tensor(2.2404, grad_fn=<NllLossBackward>) average train loss tensor(2.2745, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4106843267108168 val_avg_loss: tensor(2.2554)\n",
      "epoch: 15 train_loss: tensor(2.1345, grad_fn=<NllLossBackward>) average train loss tensor(2.2001, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42304635761589404 val_avg_loss: tensor(2.2076)\n",
      "epoch: 16 train_loss: tensor(2.0812, grad_fn=<NllLossBackward>) average train loss tensor(2.1292, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.43072847682119203 val_avg_loss: tensor(2.1668)\n",
      "epoch: 17 train_loss: tensor(1.9107, grad_fn=<NllLossBackward>) average train loss tensor(2.0607, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4370272259013981 val_avg_loss: tensor(2.1456)\n",
      "epoch: 18 train_loss: tensor(1.9566, grad_fn=<NllLossBackward>) average train loss tensor(2.0244, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4425018395879323 val_avg_loss: tensor(2.1216)\n",
      "epoch: 19 train_loss: tensor(1.8347, grad_fn=<NllLossBackward>) average train loss tensor(1.9305, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44547461368653424 val_avg_loss: tensor(2.0945)\n",
      "epoch: 20 train_loss: tensor(1.8310, grad_fn=<NllLossBackward>) average train loss tensor(1.9202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45356880058866816 val_avg_loss: tensor(2.0664)\n",
      "epoch: 21 train_loss: tensor(1.6859, grad_fn=<NllLossBackward>) average train loss tensor(1.8295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4554525386313466 val_avg_loss: tensor(2.0529)\n",
      "epoch: 22 train_loss: tensor(1.7404, grad_fn=<NllLossBackward>) average train loss tensor(1.7960, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.45986754966887416 val_avg_loss: tensor(2.0474)\n",
      "epoch: 23 train_loss: tensor(1.7712, grad_fn=<NllLossBackward>) average train loss tensor(1.8331, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46216335540838854 val_avg_loss: tensor(2.0378)\n",
      "epoch: 24 train_loss: tensor(1.6630, grad_fn=<NllLossBackward>) average train loss tensor(1.7509, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4664311994113319 val_avg_loss: tensor(2.0243)\n",
      "epoch: 25 train_loss: tensor(1.5879, grad_fn=<NllLossBackward>) average train loss tensor(1.7211, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4690213392200147 val_avg_loss: tensor(2.0141)\n",
      "epoch: 26 train_loss: tensor(1.5670, grad_fn=<NllLossBackward>) average train loss tensor(1.6549, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47172921265636497 val_avg_loss: tensor(2.0115)\n",
      "epoch: 27 train_loss: tensor(1.5610, grad_fn=<NllLossBackward>) average train loss tensor(1.6623, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4723767476085357 val_avg_loss: tensor(2.0064)\n",
      "epoch: 28 train_loss: tensor(1.5822, grad_fn=<NllLossBackward>) average train loss tensor(1.6294, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4739367181751288 val_avg_loss: tensor(2.0006)\n",
      "epoch: 29 train_loss: tensor(1.5302, grad_fn=<NllLossBackward>) average train loss tensor(1.5847, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4763208241353937 val_avg_loss: tensor(2.0047)\n",
      "epoch: 30 train_loss: tensor(1.4749, grad_fn=<NllLossBackward>) average train loss tensor(1.5412, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47573215599705665 val_avg_loss: tensor(2.0120)\n",
      "epoch: 31 train_loss: tensor(1.4675, grad_fn=<NllLossBackward>) average train loss tensor(1.5177, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4739955849889625 val_avg_loss: tensor(2.0169)\n",
      "epoch: 32 train_loss: tensor(1.3720, grad_fn=<NllLossBackward>) average train loss tensor(1.4670, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4820309050772627 val_avg_loss: tensor(2.0131)\n",
      "epoch: 33 train_loss: tensor(1.3893, grad_fn=<NllLossBackward>) average train loss tensor(1.4612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48161883738042677 val_avg_loss: tensor(2.0171)\n",
      "epoch: 34 train_loss: tensor(1.3636, grad_fn=<NllLossBackward>) average train loss tensor(1.5054, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47991169977924947 val_avg_loss: tensor(2.0198)\n",
      "epoch: 35 train_loss: tensor(1.3124, grad_fn=<NllLossBackward>) average train loss tensor(1.4238, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4809713024282561 val_avg_loss: tensor(2.0171)\n",
      "epoch: 36 train_loss: tensor(1.2996, grad_fn=<NllLossBackward>) average train loss tensor(1.4043, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48347314201618835 val_avg_loss: tensor(2.0181)\n",
      "epoch: 37 train_loss: tensor(1.2298, grad_fn=<NllLossBackward>) average train loss tensor(1.3474, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48400294334069166 val_avg_loss: tensor(2.0301)\n",
      "epoch: 38 train_loss: tensor(1.2328, grad_fn=<NllLossBackward>) average train loss tensor(1.3294, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4826784400294334 val_avg_loss: tensor(2.0412)\n",
      "epoch: 39 train_loss: tensor(1.2814, grad_fn=<NllLossBackward>) average train loss tensor(1.3171, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4827961736571008 val_avg_loss: tensor(2.0489)\n",
      "epoch: 40 train_loss: tensor(1.2828, grad_fn=<NllLossBackward>) average train loss tensor(1.3223, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48462104488594554 val_avg_loss: tensor(2.0496)\n",
      "epoch: 41 train_loss: tensor(1.2318, grad_fn=<NllLossBackward>) average train loss tensor(1.2856, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48432671081677703 val_avg_loss: tensor(2.0602)\n",
      "epoch: 42 train_loss: tensor(1.1298, grad_fn=<NllLossBackward>) average train loss tensor(1.2828, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4861810154525386 val_avg_loss: tensor(2.0663)\n",
      "epoch: 43 train_loss: tensor(1.1244, grad_fn=<NllLossBackward>) average train loss tensor(1.2205, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48653421633554084 val_avg_loss: tensor(2.0675)\n",
      "epoch: 44 train_loss: tensor(1.0969, grad_fn=<NllLossBackward>) average train loss tensor(1.2290, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48497424576894776 val_avg_loss: tensor(2.0804)\n",
      "epoch: 45 train_loss: tensor(1.0836, grad_fn=<NllLossBackward>) average train loss tensor(1.2123, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4834142752023547 val_avg_loss: tensor(2.0967)\n",
      "epoch: 46 train_loss: tensor(1.0737, grad_fn=<NllLossBackward>) average train loss tensor(1.1912, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4852685798381163 val_avg_loss: tensor(2.0933)\n",
      "epoch: 47 train_loss: tensor(1.0497, grad_fn=<NllLossBackward>) average train loss tensor(1.1706, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48835908756438556 val_avg_loss: tensor(2.0965)\n",
      "epoch: 48 train_loss: tensor(1.1027, grad_fn=<NllLossBackward>) average train loss tensor(1.1357, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48644591611479027 val_avg_loss: tensor(2.1063)\n",
      "epoch: 49 train_loss: tensor(1.0968, grad_fn=<NllLossBackward>) average train loss tensor(1.1307, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48338484179543784 val_avg_loss: tensor(2.1293)\n",
      "epoch: 50 train_loss: tensor(1.0718, grad_fn=<NllLossBackward>) average train loss tensor(1.1491, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48420897718910966 val_avg_loss: tensor(2.1411)\n",
      "epoch: 51 train_loss: tensor(0.9856, grad_fn=<NllLossBackward>) average train loss tensor(1.1065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48830022075055185 val_avg_loss: tensor(2.1360)\n",
      "epoch: 52 train_loss: tensor(1.0583, grad_fn=<NllLossBackward>) average train loss tensor(1.1388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48700515084621043 val_avg_loss: tensor(2.1406)\n",
      "epoch: 53 train_loss: tensor(1.0485, grad_fn=<NllLossBackward>) average train loss tensor(1.1080, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48753495217071374 val_avg_loss: tensor(2.1401)\n",
      "epoch: 54 train_loss: tensor(0.9427, grad_fn=<NllLossBackward>) average train loss tensor(1.0395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48582781456953644 val_avg_loss: tensor(2.1483)\n",
      "epoch: 55 train_loss: tensor(0.9449, grad_fn=<NllLossBackward>) average train loss tensor(1.0406, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48806475349521705 val_avg_loss: tensor(2.1483)\n",
      "epoch: 56 train_loss: tensor(0.9653, grad_fn=<NllLossBackward>) average train loss tensor(1.0316, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4859455481972038 val_avg_loss: tensor(2.1638)\n",
      "epoch: 57 train_loss: tensor(0.9424, grad_fn=<NllLossBackward>) average train loss tensor(1.0205, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48777041942604854 val_avg_loss: tensor(2.1885)\n",
      "epoch: 58 train_loss: tensor(0.8888, grad_fn=<NllLossBackward>) average train loss tensor(0.9959, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4850331125827815 val_avg_loss: tensor(2.2128)\n",
      "epoch: 59 train_loss: tensor(0.8629, grad_fn=<NllLossBackward>) average train loss tensor(0.9788, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48615158204562176 val_avg_loss: tensor(2.2163)\n",
      "epoch: 60 train_loss: tensor(0.9198, grad_fn=<NllLossBackward>) average train loss tensor(0.9875, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4890066225165563 val_avg_loss: tensor(2.2122)\n",
      "epoch: 61 train_loss: tensor(0.9006, grad_fn=<NllLossBackward>) average train loss tensor(0.9384, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48827078734363505 val_avg_loss: tensor(2.2343)\n",
      "epoch: 62 train_loss: tensor(0.9164, grad_fn=<NllLossBackward>) average train loss tensor(0.9224, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48827078734363505 val_avg_loss: tensor(2.2432)\n",
      "epoch: 63 train_loss: tensor(0.8780, grad_fn=<NllLossBackward>) average train loss tensor(0.9535, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48753495217071374 val_avg_loss: tensor(2.2638)\n",
      "epoch: 64 train_loss: tensor(0.8417, grad_fn=<NllLossBackward>) average train loss tensor(0.9352, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4848270787343635 val_avg_loss: tensor(2.2748)\n",
      "epoch: 65 train_loss: tensor(0.8546, grad_fn=<NllLossBackward>) average train loss tensor(0.9146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48606328182487124 val_avg_loss: tensor(2.2692)\n",
      "epoch: 66 train_loss: tensor(0.8610, grad_fn=<NllLossBackward>) average train loss tensor(0.9275, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4870345842531273 val_avg_loss: tensor(2.2836)\n",
      "epoch: 67 train_loss: tensor(0.8096, grad_fn=<NllLossBackward>) average train loss tensor(0.9082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4841206769683591 val_avg_loss: tensor(2.3105)\n",
      "epoch: 68 train_loss: tensor(0.8542, grad_fn=<NllLossBackward>) average train loss tensor(0.9052, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48544518027961736 val_avg_loss: tensor(2.3131)\n",
      "epoch: 69 train_loss: tensor(0.7687, grad_fn=<NllLossBackward>) average train loss tensor(0.8662, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48373804267844 val_avg_loss: tensor(2.3231)\n",
      "epoch: 70 train_loss: tensor(0.7997, grad_fn=<NllLossBackward>) average train loss tensor(0.8606, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.48491537895511405 val_avg_loss: tensor(2.3451)\n",
      "epoch: 71 train_loss: tensor(0.8476, grad_fn=<NllLossBackward>) average train loss tensor(0.8724, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4831788079470199 val_avg_loss: tensor(2.3598)\n",
      "epoch: 72 train_loss: tensor(0.7374, grad_fn=<NllLossBackward>) average train loss tensor(0.8440, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4860338484179544 val_avg_loss: tensor(2.3625)\n",
      "epoch: 73 train_loss: tensor(0.7164, grad_fn=<NllLossBackward>) average train loss tensor(0.7991, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48774098601913174 val_avg_loss: tensor(2.3610)\n",
      "epoch: 74 train_loss: tensor(0.7535, grad_fn=<NllLossBackward>) average train loss tensor(0.8231, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4816777041942605 val_avg_loss: tensor(2.3721)\n",
      "epoch: 75 train_loss: tensor(0.7130, grad_fn=<NllLossBackward>) average train loss tensor(0.8074, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4811184694628403 val_avg_loss: tensor(2.3933)\n",
      "epoch: 76 train_loss: tensor(0.8366, grad_fn=<NllLossBackward>) average train loss tensor(0.8365, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48485651214128034 val_avg_loss: tensor(2.4092)\n",
      "epoch: 77 train_loss: tensor(0.7595, grad_fn=<NllLossBackward>) average train loss tensor(0.7833, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48467991169977925 val_avg_loss: tensor(2.4119)\n",
      "epoch: 78 train_loss: tensor(0.7007, grad_fn=<NllLossBackward>) average train loss tensor(0.8236, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.482560706401766 val_avg_loss: tensor(2.4163)\n",
      "epoch: 79 train_loss: tensor(0.7463, grad_fn=<NllLossBackward>) average train loss tensor(0.7865, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48259013980868287 val_avg_loss: tensor(2.4284)\n",
      "epoch: 80 train_loss: tensor(0.6331, grad_fn=<NllLossBackward>) average train loss tensor(0.7414, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4837086092715232 val_avg_loss: tensor(2.4355)\n",
      "epoch: 81 train_loss: tensor(0.6807, grad_fn=<NllLossBackward>) average train loss tensor(0.7395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48506254598969833 val_avg_loss: tensor(2.4342)\n",
      "epoch: 82 train_loss: tensor(0.7414, grad_fn=<NllLossBackward>) average train loss tensor(0.7288, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4842384105960265 val_avg_loss: tensor(2.4515)\n",
      "epoch: 83 train_loss: tensor(0.7103, grad_fn=<NllLossBackward>) average train loss tensor(0.7571, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4829139072847682 val_avg_loss: tensor(2.4722)\n",
      "epoch: 84 train_loss: tensor(0.6651, grad_fn=<NllLossBackward>) average train loss tensor(0.7233, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4857983811626196 val_avg_loss: tensor(2.4852)\n",
      "epoch: 85 train_loss: tensor(0.7205, grad_fn=<NllLossBackward>) average train loss tensor(0.7281, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48553348050036793 val_avg_loss: tensor(2.4952)\n",
      "epoch: 86 train_loss: tensor(0.6850, grad_fn=<NllLossBackward>) average train loss tensor(0.7417, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48400294334069166 val_avg_loss: tensor(2.5066)\n",
      "epoch: 87 train_loss: tensor(0.6168, grad_fn=<NllLossBackward>) average train loss tensor(0.7115, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47841059602649005 val_avg_loss: tensor(2.5293)\n",
      "epoch: 88 train_loss: tensor(0.6568, grad_fn=<NllLossBackward>) average train loss tensor(0.7080, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4789698307579102 val_avg_loss: tensor(2.5466)\n",
      "epoch: 89 train_loss: tensor(0.5923, grad_fn=<NllLossBackward>) average train loss tensor(0.6726, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4835025754231052 val_avg_loss: tensor(2.5352)\n",
      "epoch: 90 train_loss: tensor(0.6146, grad_fn=<NllLossBackward>) average train loss tensor(0.6703, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48259013980868287 val_avg_loss: tensor(2.5315)\n",
      "epoch: 91 train_loss: tensor(0.7204, grad_fn=<NllLossBackward>) average train loss tensor(0.7298, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4816482707873436 val_avg_loss: tensor(2.5530)\n",
      "epoch: 92 train_loss: tensor(0.5883, grad_fn=<NllLossBackward>) average train loss tensor(0.6590, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48282560706401767 val_avg_loss: tensor(2.5728)\n",
      "epoch: 93 train_loss: tensor(0.6250, grad_fn=<NllLossBackward>) average train loss tensor(0.6550, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48147167034584254 val_avg_loss: tensor(2.5891)\n",
      "epoch: 94 train_loss: tensor(0.5024, grad_fn=<NllLossBackward>) average train loss tensor(0.6440, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4817365710080942 val_avg_loss: tensor(2.6038)\n",
      "epoch: 95 train_loss: tensor(0.5752, grad_fn=<NllLossBackward>) average train loss tensor(0.6339, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47846946284032377 val_avg_loss: tensor(2.6332)\n",
      "epoch: 96 train_loss: tensor(0.6077, grad_fn=<NllLossBackward>) average train loss tensor(0.6519, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48061810154525386 val_avg_loss: tensor(2.6287)\n",
      "epoch: 97 train_loss: tensor(0.5981, grad_fn=<NllLossBackward>) average train loss tensor(0.6320, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48385577630610743 val_avg_loss: tensor(2.6266)\n",
      "epoch: 98 train_loss: tensor(0.5441, grad_fn=<NllLossBackward>) average train loss tensor(0.6208, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4832082413539367 val_avg_loss: tensor(2.6407)\n",
      "epoch: 99 train_loss: tensor(0.5605, grad_fn=<NllLossBackward>) average train loss tensor(0.6220, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48026490066225164 val_avg_loss: tensor(2.6532)\n",
      "epoch: 100 train_loss: tensor(0.6171, grad_fn=<NllLossBackward>) average train loss tensor(0.6068, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48050036791758644 val_avg_loss: tensor(2.6630)\n",
      "epoch: 101 train_loss: tensor(0.5261, grad_fn=<NllLossBackward>) average train loss tensor(0.6041, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48055923473142015 val_avg_loss: tensor(2.6674)\n",
      "epoch: 102 train_loss: tensor(0.5529, grad_fn=<NllLossBackward>) average train loss tensor(0.6013, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4821192052980132 val_avg_loss: tensor(2.6745)\n",
      "epoch: 103 train_loss: tensor(0.4874, grad_fn=<NllLossBackward>) average train loss tensor(0.5918, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4851802796173657 val_avg_loss: tensor(2.6756)\n",
      "epoch: 104 train_loss: tensor(0.4868, grad_fn=<NllLossBackward>) average train loss tensor(0.5802, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48520971302428256 val_avg_loss: tensor(2.6927)\n",
      "epoch: 105 train_loss: tensor(0.5693, grad_fn=<NllLossBackward>) average train loss tensor(0.6402, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4830905077262693 val_avg_loss: tensor(2.6972)\n",
      "epoch: 106 train_loss: tensor(0.5370, grad_fn=<NllLossBackward>) average train loss tensor(0.5751, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48329654157468727 val_avg_loss: tensor(2.7021)\n",
      "epoch: 107 train_loss: tensor(0.5828, grad_fn=<NllLossBackward>) average train loss tensor(0.5830, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4830316409124356 val_avg_loss: tensor(2.7167)\n",
      "epoch: 108 train_loss: tensor(0.5277, grad_fn=<NllLossBackward>) average train loss tensor(0.5532, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47841059602649005 val_avg_loss: tensor(2.7462)\n",
      "epoch: 109 train_loss: tensor(0.5108, grad_fn=<NllLossBackward>) average train loss tensor(0.5683, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812656364974246 val_avg_loss: tensor(2.7595)\n",
      "epoch: 110 train_loss: tensor(0.5060, grad_fn=<NllLossBackward>) average train loss tensor(0.5584, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48453274466519497 val_avg_loss: tensor(2.7455)\n",
      "epoch: 111 train_loss: tensor(0.4663, grad_fn=<NllLossBackward>) average train loss tensor(0.5576, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48306107431935247 val_avg_loss: tensor(2.7576)\n",
      "epoch: 112 train_loss: tensor(0.4929, grad_fn=<NllLossBackward>) average train loss tensor(0.5431, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47961736571008096 val_avg_loss: tensor(2.7740)\n",
      "epoch: 113 train_loss: tensor(0.4832, grad_fn=<NllLossBackward>) average train loss tensor(0.5313, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801766004415011 val_avg_loss: tensor(2.7954)\n",
      "epoch: 114 train_loss: tensor(0.5118, grad_fn=<NllLossBackward>) average train loss tensor(0.5644, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801177336276674 val_avg_loss: tensor(2.7991)\n",
      "epoch: 115 train_loss: tensor(0.4680, grad_fn=<NllLossBackward>) average train loss tensor(0.5105, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.482560706401766 val_avg_loss: tensor(2.8100)\n",
      "epoch: 116 train_loss: tensor(0.4512, grad_fn=<NllLossBackward>) average train loss tensor(0.5189, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4814128035320088 val_avg_loss: tensor(2.8208)\n",
      "epoch: 117 train_loss: tensor(0.4968, grad_fn=<NllLossBackward>) average train loss tensor(0.5549, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47926416482707873 val_avg_loss: tensor(2.8226)\n",
      "epoch: 118 train_loss: tensor(0.4488, grad_fn=<NllLossBackward>) average train loss tensor(0.5107, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4787637969094923 val_avg_loss: tensor(2.8227)\n",
      "epoch: 119 train_loss: tensor(0.4641, grad_fn=<NllLossBackward>) average train loss tensor(0.5116, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47793966151582046 val_avg_loss: tensor(2.8507)\n",
      "epoch: 120 train_loss: tensor(0.4801, grad_fn=<NllLossBackward>) average train loss tensor(0.5295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4780573951434879 val_avg_loss: tensor(2.8720)\n",
      "epoch: 121 train_loss: tensor(0.5278, grad_fn=<NllLossBackward>) average train loss tensor(0.5273, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47970566593083147 val_avg_loss: tensor(2.8708)\n",
      "epoch: 122 train_loss: tensor(0.5056, grad_fn=<NllLossBackward>) average train loss tensor(0.5226, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4791169977924945 val_avg_loss: tensor(2.8496)\n",
      "epoch: 123 train_loss: tensor(0.5340, grad_fn=<NllLossBackward>) average train loss tensor(0.5064, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47841059602649005 val_avg_loss: tensor(2.8412)\n",
      "epoch: 124 train_loss: tensor(0.4460, grad_fn=<NllLossBackward>) average train loss tensor(0.4777, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4804120676968359 val_avg_loss: tensor(2.8595)\n",
      "epoch: 125 train_loss: tensor(0.4581, grad_fn=<NllLossBackward>) average train loss tensor(0.5010, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4783811626195732 val_avg_loss: tensor(2.8922)\n",
      "epoch: 126 train_loss: tensor(0.4858, grad_fn=<NllLossBackward>) average train loss tensor(0.4883, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759381898454746 val_avg_loss: tensor(2.9033)\n",
      "epoch: 127 train_loss: tensor(0.5100, grad_fn=<NllLossBackward>) average train loss tensor(0.5204, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4769977924944812 val_avg_loss: tensor(2.8880)\n",
      "epoch: 128 train_loss: tensor(0.4633, grad_fn=<NllLossBackward>) average train loss tensor(0.4927, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4814422369389257 val_avg_loss: tensor(2.8766)\n",
      "epoch: 129 train_loss: tensor(0.3792, grad_fn=<NllLossBackward>) average train loss tensor(0.4939, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4822663723325975 val_avg_loss: tensor(2.9075)\n",
      "epoch: 130 train_loss: tensor(0.4892, grad_fn=<NllLossBackward>) average train loss tensor(0.4863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4791464311994113 val_avg_loss: tensor(2.9669)\n",
      "epoch: 131 train_loss: tensor(0.4390, grad_fn=<NllLossBackward>) average train loss tensor(0.4709, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47596762325239145 val_avg_loss: tensor(2.9853)\n",
      "epoch: 132 train_loss: tensor(0.4675, grad_fn=<NllLossBackward>) average train loss tensor(0.5030, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759381898454746 val_avg_loss: tensor(2.9839)\n",
      "epoch: 133 train_loss: tensor(0.4514, grad_fn=<NllLossBackward>) average train loss tensor(0.4741, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478822663723326 val_avg_loss: tensor(2.9679)\n",
      "epoch: 134 train_loss: tensor(0.4572, grad_fn=<NllLossBackward>) average train loss tensor(0.4982, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47799852832965417 val_avg_loss: tensor(2.9769)\n",
      "epoch: 135 train_loss: tensor(0.4024, grad_fn=<NllLossBackward>) average train loss tensor(0.4426, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47702722590139807 val_avg_loss: tensor(2.9856)\n",
      "epoch: 136 train_loss: tensor(0.4609, grad_fn=<NllLossBackward>) average train loss tensor(0.4805, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47723325974981606 val_avg_loss: tensor(3.0107)\n",
      "epoch: 137 train_loss: tensor(0.4351, grad_fn=<NllLossBackward>) average train loss tensor(0.4790, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47846946284032377 val_avg_loss: tensor(3.0016)\n",
      "epoch: 138 train_loss: tensor(0.4889, grad_fn=<NllLossBackward>) average train loss tensor(0.4724, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47832229580573954 val_avg_loss: tensor(2.9929)\n",
      "epoch: 139 train_loss: tensor(0.3537, grad_fn=<NllLossBackward>) average train loss tensor(0.4205, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47364238410596027 val_avg_loss: tensor(3.0268)\n",
      "epoch: 0 train_loss: tensor(3.8290, grad_fn=<NllLossBackward>) average train loss tensor(3.8792, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.05751287711552612 val_avg_loss: tensor(3.7734)\n",
      "epoch: 1 train_loss: tensor(3.7424, grad_fn=<NllLossBackward>) average train loss tensor(3.7247, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.05607064017660044 val_avg_loss: tensor(3.6569)\n",
      "epoch: 2 train_loss: tensor(3.6470, grad_fn=<NllLossBackward>) average train loss tensor(3.6261, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.0778513612950699 val_avg_loss: tensor(3.5652)\n",
      "epoch: 3 train_loss: tensor(3.5776, grad_fn=<NllLossBackward>) average train loss tensor(3.5361, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1372185430463576 val_avg_loss: tensor(3.4716)\n",
      "epoch: 4 train_loss: tensor(3.4925, grad_fn=<NllLossBackward>) average train loss tensor(3.4463, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.20456217807211186 val_avg_loss: tensor(3.3648)\n",
      "epoch: 5 train_loss: tensor(3.3704, grad_fn=<NllLossBackward>) average train loss tensor(3.3355, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.21916114790286975 val_avg_loss: tensor(3.2399)\n",
      "epoch: 6 train_loss: tensor(3.2545, grad_fn=<NllLossBackward>) average train loss tensor(3.2262, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2635467255334805 val_avg_loss: tensor(3.0874)\n",
      "epoch: 7 train_loss: tensor(3.1064, grad_fn=<NllLossBackward>) average train loss tensor(3.0872, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-87c0a9747e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_train_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         )  \n",
      "\u001b[0;32m~/Desktop/Thesis/topics_ds/pytorch/torch_models.py\u001b[0m in \u001b[0;36mfit_topics_model\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, writer, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mloss_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for rs in range(1, 6):\n",
    "    \n",
    "    np.random.seed(rs)\n",
    "    training_indices = np.random.randint(low=0, high=x_img_train.shape[0], size=2000)\n",
    "\n",
    "    x_img_train_t_cur = torch.tensor(x_img_train[training_indices]).float()\n",
    "    x_txt_train_t_cur = torch.tensor(x_txt_train[training_indices]).float()\n",
    "    y_train_t_cur = torch.tensor(y_train[training_indices]).float()\n",
    "    \n",
    "    cur_train_ds = TensorDataset(x_img_train_t_cur, x_txt_train_t_cur, y_train_t_cur)\n",
    "    cur_train_loader = DataLoader(cur_train_ds, batch_size=512)\n",
    "    \n",
    "    for autoencoder_name in constructor_dict:\n",
    "        \n",
    "        cur_autoencoder_2000 = copy.deepcopy(autoencoder_dict[autoencoder_name])\n",
    "        cur_encoder_2000 = cur_autoencoder_2000.encoder\n",
    "        \n",
    "        cur_after_encoder_model_2000 = AfterEncoderModel(cur_encoder_2000, d=128, drop=0.5)\n",
    "        cur_optimizer_aem_2000 = torch.optim.Adam(cur_after_encoder_model_2000.parameters(), lr=1e-3)\n",
    "        \n",
    "        writer = SummaryWriter('runs/aem_2000_' + autoencoder_name + '_' + str(rs) + '_bs2048_rs42_d128_wd0005_drop05_100')\n",
    "\n",
    "        torch_models.fit_topics_model(\n",
    "            model=cur_after_encoder_model_2000,\n",
    "            optimizer=cur_optimizer_aem_2000,\n",
    "            epochs=140,\n",
    "            writer=writer,\n",
    "            train_loader=cur_train_loader,\n",
    "            val_loader=val_loader\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(2.2325, grad_fn=<NllLossBackward>) average train loss tensor(2.9030, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49792494481236205 val_avg_loss: tensor(1.8804)\n",
      "epoch: 1 train_loss: tensor(1.9070, grad_fn=<NllLossBackward>) average train loss tensor(2.0523, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5554966887417219 val_avg_loss: tensor(1.6535)\n",
      "epoch: 2 train_loss: tensor(1.8138, grad_fn=<NllLossBackward>) average train loss tensor(1.9079, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.576953642384106 val_avg_loss: tensor(1.5839)\n",
      "epoch: 3 train_loss: tensor(1.7867, grad_fn=<NllLossBackward>) average train loss tensor(1.8438, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5840765268579838 val_avg_loss: tensor(1.5450)\n",
      "epoch: 4 train_loss: tensor(1.7154, grad_fn=<NllLossBackward>) average train loss tensor(1.7971, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5900515084621045 val_avg_loss: tensor(1.5182)\n",
      "epoch: 5 train_loss: tensor(1.7385, grad_fn=<NllLossBackward>) average train loss tensor(1.7662, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.59467255334805 val_avg_loss: tensor(1.5014)\n",
      "epoch: 6 train_loss: tensor(1.7337, grad_fn=<NllLossBackward>) average train loss tensor(1.7431, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5969977924944813 val_avg_loss: tensor(1.4859)\n",
      "epoch: 7 train_loss: tensor(1.6365, grad_fn=<NllLossBackward>) average train loss tensor(1.7216, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5988226637233259 val_avg_loss: tensor(1.4739)\n",
      "epoch: 8 train_loss: tensor(1.6626, grad_fn=<NllLossBackward>) average train loss tensor(1.7066, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6005003679175864 val_avg_loss: tensor(1.4642)\n",
      "epoch: 9 train_loss: tensor(1.6569, grad_fn=<NllLossBackward>) average train loss tensor(1.6892, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6041501103752759 val_avg_loss: tensor(1.4553)\n",
      "epoch: 10 train_loss: tensor(1.5483, grad_fn=<NllLossBackward>) average train loss tensor(1.6780, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6050625459896983 val_avg_loss: tensor(1.4493)\n",
      "epoch: 11 train_loss: tensor(1.6306, grad_fn=<NllLossBackward>) average train loss tensor(1.6665, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.606710816777042 val_avg_loss: tensor(1.4437)\n",
      "epoch: 12 train_loss: tensor(1.5732, grad_fn=<NllLossBackward>) average train loss tensor(1.6564, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6084473877851362 val_avg_loss: tensor(1.4351)\n",
      "epoch: 13 train_loss: tensor(1.5373, grad_fn=<NllLossBackward>) average train loss tensor(1.6468, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6102722590139809 val_avg_loss: tensor(1.4294)\n",
      "epoch: 14 train_loss: tensor(1.5496, grad_fn=<NllLossBackward>) average train loss tensor(1.6377, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6112435614422369 val_avg_loss: tensor(1.4267)\n",
      "epoch: 15 train_loss: tensor(1.5284, grad_fn=<NllLossBackward>) average train loss tensor(1.6287, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6109786607799853 val_avg_loss: tensor(1.4209)\n",
      "epoch: 16 train_loss: tensor(1.5067, grad_fn=<NllLossBackward>) average train loss tensor(1.6208, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6131272994849154 val_avg_loss: tensor(1.4172)\n",
      "epoch: 17 train_loss: tensor(1.4747, grad_fn=<NllLossBackward>) average train loss tensor(1.6126, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6134805003679176 val_avg_loss: tensor(1.4139)\n",
      "epoch: 18 train_loss: tensor(1.5097, grad_fn=<NllLossBackward>) average train loss tensor(1.6059, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6140397350993377 val_avg_loss: tensor(1.4103)\n",
      "epoch: 19 train_loss: tensor(1.5357, grad_fn=<NllLossBackward>) average train loss tensor(1.6039, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6166593083149374 val_avg_loss: tensor(1.4051)\n",
      "epoch: 20 train_loss: tensor(1.4740, grad_fn=<NllLossBackward>) average train loss tensor(1.5957, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6167770419426049 val_avg_loss: tensor(1.4051)\n",
      "epoch: 21 train_loss: tensor(1.4743, grad_fn=<NllLossBackward>) average train loss tensor(1.5904, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6160706401766004 val_avg_loss: tensor(1.4022)\n",
      "epoch: 22 train_loss: tensor(1.4898, grad_fn=<NllLossBackward>) average train loss tensor(1.5816, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6173951434878587 val_avg_loss: tensor(1.3967)\n",
      "epoch: 23 train_loss: tensor(1.4629, grad_fn=<NllLossBackward>) average train loss tensor(1.5806, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6175128771155262 val_avg_loss: tensor(1.3978)\n",
      "epoch: 24 train_loss: tensor(1.4508, grad_fn=<NllLossBackward>) average train loss tensor(1.5699, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6178072111846946 val_avg_loss: tensor(1.3932)\n",
      "epoch: 25 train_loss: tensor(1.4672, grad_fn=<NllLossBackward>) average train loss tensor(1.5691, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6188668138337012 val_avg_loss: tensor(1.3932)\n",
      "epoch: 26 train_loss: tensor(1.4121, grad_fn=<NllLossBackward>) average train loss tensor(1.5650, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6193671817512877 val_avg_loss: tensor(1.3899)\n",
      "epoch: 27 train_loss: tensor(1.4242, grad_fn=<NllLossBackward>) average train loss tensor(1.5605, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6201618837380427 val_avg_loss: tensor(1.3881)\n",
      "epoch: 28 train_loss: tensor(1.4182, grad_fn=<NllLossBackward>) average train loss tensor(1.5531, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6201913171449596 val_avg_loss: tensor(1.3871)\n",
      "epoch: 29 train_loss: tensor(1.4270, grad_fn=<NllLossBackward>) average train loss tensor(1.5499, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6204267844002943 val_avg_loss: tensor(1.3851)\n",
      "epoch: 30 train_loss: tensor(1.4327, grad_fn=<NllLossBackward>) average train loss tensor(1.5445, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6193377483443708 val_avg_loss: tensor(1.3848)\n",
      "epoch: 31 train_loss: tensor(1.4734, grad_fn=<NllLossBackward>) average train loss tensor(1.5457, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6195732155997057 val_avg_loss: tensor(1.3818)\n",
      "epoch: 32 train_loss: tensor(1.3981, grad_fn=<NllLossBackward>) average train loss tensor(1.5359, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6213097866077999 val_avg_loss: tensor(1.3813)\n",
      "epoch: 33 train_loss: tensor(1.4323, grad_fn=<NllLossBackward>) average train loss tensor(1.5382, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6201913171449596 val_avg_loss: tensor(1.3813)\n",
      "epoch: 34 train_loss: tensor(1.3869, grad_fn=<NllLossBackward>) average train loss tensor(1.5327, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6212509197939662 val_avg_loss: tensor(1.3760)\n",
      "epoch: 35 train_loss: tensor(1.3727, grad_fn=<NllLossBackward>) average train loss tensor(1.5287, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.622457689477557 val_avg_loss: tensor(1.3760)\n",
      "epoch: 36 train_loss: tensor(1.3923, grad_fn=<NllLossBackward>) average train loss tensor(1.5244, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6231640912435614 val_avg_loss: tensor(1.3739)\n",
      "epoch: 37 train_loss: tensor(1.3856, grad_fn=<NllLossBackward>) average train loss tensor(1.5214, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6228403237674761 val_avg_loss: tensor(1.3725)\n",
      "epoch: 38 train_loss: tensor(1.4182, grad_fn=<NllLossBackward>) average train loss tensor(1.5190, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6221339220014717 val_avg_loss: tensor(1.3727)\n",
      "epoch: 39 train_loss: tensor(1.3674, grad_fn=<NllLossBackward>) average train loss tensor(1.5158, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6235761589403973 val_avg_loss: tensor(1.3688)\n",
      "epoch: 40 train_loss: tensor(1.3092, grad_fn=<NllLossBackward>) average train loss tensor(1.5120, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6236644591611479 val_avg_loss: tensor(1.3699)\n",
      "epoch: 41 train_loss: tensor(1.3985, grad_fn=<NllLossBackward>) average train loss tensor(1.5091, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241648270787343 val_avg_loss: tensor(1.3687)\n",
      "epoch: 42 train_loss: tensor(1.3269, grad_fn=<NllLossBackward>) average train loss tensor(1.5066, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6238704930095659 val_avg_loss: tensor(1.3676)\n",
      "epoch: 43 train_loss: tensor(1.3359, grad_fn=<NllLossBackward>) average train loss tensor(1.5047, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6245180279617366 val_avg_loss: tensor(1.3680)\n",
      "epoch: 44 train_loss: tensor(1.3135, grad_fn=<NllLossBackward>) average train loss tensor(1.4985, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6245474613686535 val_avg_loss: tensor(1.3658)\n",
      "epoch: 45 train_loss: tensor(1.3413, grad_fn=<NllLossBackward>) average train loss tensor(1.4941, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6236644591611479 val_avg_loss: tensor(1.3653)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(1.3499, grad_fn=<NllLossBackward>) average train loss tensor(1.4947, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6246946284032376 val_avg_loss: tensor(1.3648)\n",
      "epoch: 47 train_loss: tensor(1.3661, grad_fn=<NllLossBackward>) average train loss tensor(1.4951, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6245180279617366 val_avg_loss: tensor(1.3644)\n",
      "epoch: 48 train_loss: tensor(1.2814, grad_fn=<NllLossBackward>) average train loss tensor(1.4886, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6254598969830758 val_avg_loss: tensor(1.3607)\n",
      "epoch: 49 train_loss: tensor(1.3180, grad_fn=<NllLossBackward>) average train loss tensor(1.4828, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242825607064018 val_avg_loss: tensor(1.3627)\n",
      "epoch: 50 train_loss: tensor(1.2930, grad_fn=<NllLossBackward>) average train loss tensor(1.4815, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6253715967623252 val_avg_loss: tensor(1.3602)\n",
      "epoch: 51 train_loss: tensor(1.3329, grad_fn=<NllLossBackward>) average train loss tensor(1.4764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257247976453274 val_avg_loss: tensor(1.3589)\n",
      "epoch: 52 train_loss: tensor(1.2986, grad_fn=<NllLossBackward>) average train loss tensor(1.4765, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257836644591611 val_avg_loss: tensor(1.3573)\n",
      "epoch: 53 train_loss: tensor(1.2829, grad_fn=<NllLossBackward>) average train loss tensor(1.4716, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6244885945548198 val_avg_loss: tensor(1.3581)\n",
      "epoch: 54 train_loss: tensor(1.2530, grad_fn=<NllLossBackward>) average train loss tensor(1.4715, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6253421633554084 val_avg_loss: tensor(1.3570)\n",
      "epoch: 55 train_loss: tensor(1.2824, grad_fn=<NllLossBackward>) average train loss tensor(1.4699, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6259896983075791 val_avg_loss: tensor(1.3581)\n",
      "epoch: 56 train_loss: tensor(1.2979, grad_fn=<NllLossBackward>) average train loss tensor(1.4653, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6248417954378219 val_avg_loss: tensor(1.3577)\n",
      "epoch: 57 train_loss: tensor(1.2780, grad_fn=<NllLossBackward>) average train loss tensor(1.4619, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6256953642384105 val_avg_loss: tensor(1.3560)\n",
      "epoch: 58 train_loss: tensor(1.3187, grad_fn=<NllLossBackward>) average train loss tensor(1.4637, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6249595290654893 val_avg_loss: tensor(1.3569)\n",
      "epoch: 59 train_loss: tensor(1.2710, grad_fn=<NllLossBackward>) average train loss tensor(1.4607, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241648270787343 val_avg_loss: tensor(1.3553)\n",
      "epoch: 60 train_loss: tensor(1.2583, grad_fn=<NllLossBackward>) average train loss tensor(1.4553, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6251361295069904 val_avg_loss: tensor(1.3566)\n",
      "epoch: 61 train_loss: tensor(1.2445, grad_fn=<NllLossBackward>) average train loss tensor(1.4540, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257247976453274 val_avg_loss: tensor(1.3546)\n",
      "epoch: 62 train_loss: tensor(1.2708, grad_fn=<NllLossBackward>) average train loss tensor(1.4546, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6266961000735836 val_avg_loss: tensor(1.3534)\n",
      "epoch: 63 train_loss: tensor(1.2750, grad_fn=<NllLossBackward>) average train loss tensor(1.4527, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6260779985283297 val_avg_loss: tensor(1.3532)\n",
      "epoch: 64 train_loss: tensor(1.2318, grad_fn=<NllLossBackward>) average train loss tensor(1.4512, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62719646799117 val_avg_loss: tensor(1.3512)\n",
      "epoch: 65 train_loss: tensor(1.1949, grad_fn=<NllLossBackward>) average train loss tensor(1.4483, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261368653421634 val_avg_loss: tensor(1.3509)\n",
      "epoch: 66 train_loss: tensor(1.2846, grad_fn=<NllLossBackward>) average train loss tensor(1.4414, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626784400294334 val_avg_loss: tensor(1.3503)\n",
      "epoch: 67 train_loss: tensor(1.2535, grad_fn=<NllLossBackward>) average train loss tensor(1.4429, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6271670345842532 val_avg_loss: tensor(1.3495)\n",
      "epoch: 68 train_loss: tensor(1.2156, grad_fn=<NllLossBackward>) average train loss tensor(1.4370, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265194996320824 val_avg_loss: tensor(1.3512)\n",
      "epoch: 69 train_loss: tensor(1.2896, grad_fn=<NllLossBackward>) average train loss tensor(1.4389, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264900662251656 val_avg_loss: tensor(1.3496)\n",
      "epoch: 70 train_loss: tensor(1.2638, grad_fn=<NllLossBackward>) average train loss tensor(1.4342, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6267549668874172 val_avg_loss: tensor(1.3499)\n",
      "epoch: 71 train_loss: tensor(1.1851, grad_fn=<NllLossBackward>) average train loss tensor(1.4347, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272847682119206 val_avg_loss: tensor(1.3498)\n",
      "epoch: 72 train_loss: tensor(1.2093, grad_fn=<NllLossBackward>) average train loss tensor(1.4337, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6266961000735836 val_avg_loss: tensor(1.3515)\n",
      "epoch: 73 train_loss: tensor(1.1813, grad_fn=<NllLossBackward>) average train loss tensor(1.4341, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62719646799117 val_avg_loss: tensor(1.3513)\n",
      "epoch: 74 train_loss: tensor(1.1878, grad_fn=<NllLossBackward>) average train loss tensor(1.4260, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257247976453274 val_avg_loss: tensor(1.3498)\n",
      "epoch: 75 train_loss: tensor(1.2341, grad_fn=<NllLossBackward>) average train loss tensor(1.4239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6254598969830758 val_avg_loss: tensor(1.3495)\n",
      "epoch: 76 train_loss: tensor(1.2498, grad_fn=<NllLossBackward>) average train loss tensor(1.4233, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626607799852833 val_avg_loss: tensor(1.3499)\n",
      "epoch: 77 train_loss: tensor(1.2028, grad_fn=<NllLossBackward>) average train loss tensor(1.4233, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6266961000735836 val_avg_loss: tensor(1.3494)\n",
      "epoch: 78 train_loss: tensor(1.2423, grad_fn=<NllLossBackward>) average train loss tensor(1.4250, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264900662251656 val_avg_loss: tensor(1.3492)\n",
      "epoch: 79 train_loss: tensor(1.2448, grad_fn=<NllLossBackward>) average train loss tensor(1.4253, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264606328182487 val_avg_loss: tensor(1.3503)\n",
      "epoch: 80 train_loss: tensor(1.2279, grad_fn=<NllLossBackward>) average train loss tensor(1.4203, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261368653421634 val_avg_loss: tensor(1.3503)\n",
      "epoch: 81 train_loss: tensor(1.1941, grad_fn=<NllLossBackward>) average train loss tensor(1.4217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264606328182487 val_avg_loss: tensor(1.3486)\n",
      "epoch: 82 train_loss: tensor(1.1992, grad_fn=<NllLossBackward>) average train loss tensor(1.4131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62719646799117 val_avg_loss: tensor(1.3502)\n",
      "epoch: 83 train_loss: tensor(1.1874, grad_fn=<NllLossBackward>) average train loss tensor(1.4153, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626607799852833 val_avg_loss: tensor(1.3489)\n",
      "epoch: 84 train_loss: tensor(1.1723, grad_fn=<NllLossBackward>) average train loss tensor(1.4122, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265194996320824 val_avg_loss: tensor(1.3480)\n",
      "epoch: 85 train_loss: tensor(1.1865, grad_fn=<NllLossBackward>) average train loss tensor(1.4089, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626784400294334 val_avg_loss: tensor(1.3494)\n",
      "epoch: 86 train_loss: tensor(1.1449, grad_fn=<NllLossBackward>) average train loss tensor(1.4084, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272847682119206 val_avg_loss: tensor(1.3485)\n",
      "epoch: 87 train_loss: tensor(1.1941, grad_fn=<NllLossBackward>) average train loss tensor(1.4072, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6271376011773363 val_avg_loss: tensor(1.3503)\n",
      "epoch: 88 train_loss: tensor(1.1815, grad_fn=<NllLossBackward>) average train loss tensor(1.4107, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261368653421634 val_avg_loss: tensor(1.3494)\n",
      "epoch: 89 train_loss: tensor(1.1588, grad_fn=<NllLossBackward>) average train loss tensor(1.4038, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6263723325974981 val_avg_loss: tensor(1.3491)\n",
      "epoch: 90 train_loss: tensor(1.1729, grad_fn=<NllLossBackward>) average train loss tensor(1.4054, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268138337012509 val_avg_loss: tensor(1.3477)\n",
      "epoch: 91 train_loss: tensor(1.1863, grad_fn=<NllLossBackward>) average train loss tensor(1.4052, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62719646799117 val_avg_loss: tensor(1.3492)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 train_loss: tensor(1.1536, grad_fn=<NllLossBackward>) average train loss tensor(1.4025, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6260779985283297 val_avg_loss: tensor(1.3488)\n",
      "epoch: 93 train_loss: tensor(1.1414, grad_fn=<NllLossBackward>) average train loss tensor(1.4001, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272259013980869 val_avg_loss: tensor(1.3490)\n",
      "epoch: 94 train_loss: tensor(1.1609, grad_fn=<NllLossBackward>) average train loss tensor(1.3953, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270198675496689 val_avg_loss: tensor(1.3478)\n",
      "epoch: 95 train_loss: tensor(1.1853, grad_fn=<NllLossBackward>) average train loss tensor(1.3988, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626990434142752 val_avg_loss: tensor(1.3486)\n",
      "epoch: 96 train_loss: tensor(1.1346, grad_fn=<NllLossBackward>) average train loss tensor(1.3948, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258719646799117 val_avg_loss: tensor(1.3488)\n",
      "epoch: 97 train_loss: tensor(1.1848, grad_fn=<NllLossBackward>) average train loss tensor(1.3954, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6263723325974981 val_avg_loss: tensor(1.3498)\n",
      "epoch: 98 train_loss: tensor(1.1612, grad_fn=<NllLossBackward>) average train loss tensor(1.3957, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264606328182487 val_avg_loss: tensor(1.3503)\n",
      "epoch: 99 train_loss: tensor(1.1598, grad_fn=<NllLossBackward>) average train loss tensor(1.3924, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6276674025018396 val_avg_loss: tensor(1.3501)\n",
      "epoch: 0 train_loss: tensor(2.1964, grad_fn=<NllLossBackward>) average train loss tensor(2.8712, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4983075791022811 val_avg_loss: tensor(1.8702)\n",
      "epoch: 1 train_loss: tensor(1.9735, grad_fn=<NllLossBackward>) average train loss tensor(2.0438, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5526416482707873 val_avg_loss: tensor(1.6566)\n",
      "epoch: 2 train_loss: tensor(1.8526, grad_fn=<NllLossBackward>) average train loss tensor(1.9055, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5730978660779985 val_avg_loss: tensor(1.5866)\n",
      "epoch: 3 train_loss: tensor(1.7174, grad_fn=<NllLossBackward>) average train loss tensor(1.8424, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5827520235467255 val_avg_loss: tensor(1.5451)\n",
      "epoch: 4 train_loss: tensor(1.7400, grad_fn=<NllLossBackward>) average train loss tensor(1.8000, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5898160412067697 val_avg_loss: tensor(1.5218)\n",
      "epoch: 5 train_loss: tensor(1.7186, grad_fn=<NllLossBackward>) average train loss tensor(1.7685, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5920824135393672 val_avg_loss: tensor(1.5050)\n",
      "epoch: 6 train_loss: tensor(1.6802, grad_fn=<NllLossBackward>) average train loss tensor(1.7481, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.594878587196468 val_avg_loss: tensor(1.4910)\n",
      "epoch: 7 train_loss: tensor(1.6554, grad_fn=<NllLossBackward>) average train loss tensor(1.7246, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.597821927888153 val_avg_loss: tensor(1.4745)\n",
      "epoch: 8 train_loss: tensor(1.6483, grad_fn=<NllLossBackward>) average train loss tensor(1.7106, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.600971302428256 val_avg_loss: tensor(1.4641)\n",
      "epoch: 9 train_loss: tensor(1.6334, grad_fn=<NllLossBackward>) average train loss tensor(1.6956, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6010596026490066 val_avg_loss: tensor(1.4557)\n",
      "epoch: 10 train_loss: tensor(1.6572, grad_fn=<NllLossBackward>) average train loss tensor(1.6816, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6030905077262693 val_avg_loss: tensor(1.4506)\n",
      "epoch: 11 train_loss: tensor(1.5829, grad_fn=<NllLossBackward>) average train loss tensor(1.6674, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.604326710816777 val_avg_loss: tensor(1.4425)\n",
      "epoch: 12 train_loss: tensor(1.5681, grad_fn=<NllLossBackward>) average train loss tensor(1.6554, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6060927152317881 val_avg_loss: tensor(1.4367)\n",
      "epoch: 13 train_loss: tensor(1.6063, grad_fn=<NllLossBackward>) average train loss tensor(1.6484, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.605121412803532 val_avg_loss: tensor(1.4352)\n",
      "epoch: 14 train_loss: tensor(1.5854, grad_fn=<NllLossBackward>) average train loss tensor(1.6375, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6075055187637969 val_avg_loss: tensor(1.4284)\n",
      "epoch: 15 train_loss: tensor(1.5869, grad_fn=<NllLossBackward>) average train loss tensor(1.6324, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6092420897718911 val_avg_loss: tensor(1.4264)\n",
      "epoch: 16 train_loss: tensor(1.5027, grad_fn=<NllLossBackward>) average train loss tensor(1.6241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6087417218543046 val_avg_loss: tensor(1.4209)\n",
      "epoch: 17 train_loss: tensor(1.5390, grad_fn=<NllLossBackward>) average train loss tensor(1.6151, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6109197939661516 val_avg_loss: tensor(1.4192)\n",
      "epoch: 18 train_loss: tensor(1.5085, grad_fn=<NllLossBackward>) average train loss tensor(1.6112, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6107726269315673 val_avg_loss: tensor(1.4146)\n",
      "epoch: 19 train_loss: tensor(1.5094, grad_fn=<NllLossBackward>) average train loss tensor(1.6026, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6142163355408389 val_avg_loss: tensor(1.4096)\n",
      "epoch: 20 train_loss: tensor(1.5303, grad_fn=<NllLossBackward>) average train loss tensor(1.5939, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6135688005886681 val_avg_loss: tensor(1.4091)\n",
      "epoch: 21 train_loss: tensor(1.5254, grad_fn=<NllLossBackward>) average train loss tensor(1.5926, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6148050036791759 val_avg_loss: tensor(1.4040)\n",
      "epoch: 22 train_loss: tensor(1.4349, grad_fn=<NllLossBackward>) average train loss tensor(1.5850, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6146578366445916 val_avg_loss: tensor(1.4010)\n",
      "epoch: 23 train_loss: tensor(1.4031, grad_fn=<NllLossBackward>) average train loss tensor(1.5758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6142752023546726 val_avg_loss: tensor(1.4022)\n",
      "epoch: 24 train_loss: tensor(1.4173, grad_fn=<NllLossBackward>) average train loss tensor(1.5715, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6148344370860928 val_avg_loss: tensor(1.3991)\n",
      "epoch: 25 train_loss: tensor(1.4399, grad_fn=<NllLossBackward>) average train loss tensor(1.5692, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6164238410596027 val_avg_loss: tensor(1.3966)\n",
      "epoch: 26 train_loss: tensor(1.4043, grad_fn=<NllLossBackward>) average train loss tensor(1.5649, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6171008094186902 val_avg_loss: tensor(1.3937)\n",
      "epoch: 27 train_loss: tensor(1.4732, grad_fn=<NllLossBackward>) average train loss tensor(1.5601, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6175128771155262 val_avg_loss: tensor(1.3916)\n",
      "epoch: 28 train_loss: tensor(1.4480, grad_fn=<NllLossBackward>) average train loss tensor(1.5572, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6177483443708609 val_avg_loss: tensor(1.3878)\n",
      "epoch: 29 train_loss: tensor(1.4305, grad_fn=<NllLossBackward>) average train loss tensor(1.5538, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6199558498896247 val_avg_loss: tensor(1.3871)\n",
      "epoch: 30 train_loss: tensor(1.4151, grad_fn=<NllLossBackward>) average train loss tensor(1.5452, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6197498160412068 val_avg_loss: tensor(1.3835)\n",
      "epoch: 31 train_loss: tensor(1.4305, grad_fn=<NllLossBackward>) average train loss tensor(1.5439, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6186313465783665 val_avg_loss: tensor(1.3829)\n",
      "epoch: 32 train_loss: tensor(1.3392, grad_fn=<NllLossBackward>) average train loss tensor(1.5384, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.617924944812362 val_avg_loss: tensor(1.3825)\n",
      "epoch: 33 train_loss: tensor(1.3823, grad_fn=<NllLossBackward>) average train loss tensor(1.5350, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6207211184694629 val_avg_loss: tensor(1.3810)\n",
      "epoch: 34 train_loss: tensor(1.4065, grad_fn=<NllLossBackward>) average train loss tensor(1.5313, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.621280353200883 val_avg_loss: tensor(1.3777)\n",
      "epoch: 35 train_loss: tensor(1.3688, grad_fn=<NllLossBackward>) average train loss tensor(1.5291, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6211626195732156 val_avg_loss: tensor(1.3790)\n",
      "epoch: 36 train_loss: tensor(1.3624, grad_fn=<NllLossBackward>) average train loss tensor(1.5240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6207211184694629 val_avg_loss: tensor(1.3780)\n",
      "epoch: 37 train_loss: tensor(1.3775, grad_fn=<NllLossBackward>) average train loss tensor(1.5202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6214275202354672 val_avg_loss: tensor(1.3756)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 train_loss: tensor(1.3165, grad_fn=<NllLossBackward>) average train loss tensor(1.5155, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6213686534216335 val_avg_loss: tensor(1.3751)\n",
      "epoch: 39 train_loss: tensor(1.3419, grad_fn=<NllLossBackward>) average train loss tensor(1.5127, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6223988226637234 val_avg_loss: tensor(1.3718)\n",
      "epoch: 40 train_loss: tensor(1.3924, grad_fn=<NllLossBackward>) average train loss tensor(1.5126, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6228108903605593 val_avg_loss: tensor(1.3697)\n",
      "epoch: 41 train_loss: tensor(1.3734, grad_fn=<NllLossBackward>) average train loss tensor(1.5064, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6221044885945548 val_avg_loss: tensor(1.3712)\n",
      "epoch: 42 train_loss: tensor(1.3605, grad_fn=<NllLossBackward>) average train loss tensor(1.5035, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6239293598233996 val_avg_loss: tensor(1.3697)\n",
      "epoch: 43 train_loss: tensor(1.3585, grad_fn=<NllLossBackward>) average train loss tensor(1.5027, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6221927888153054 val_avg_loss: tensor(1.3685)\n",
      "epoch: 44 train_loss: tensor(1.3284, grad_fn=<NllLossBackward>) average train loss tensor(1.4984, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242825607064018 val_avg_loss: tensor(1.3667)\n",
      "epoch: 45 train_loss: tensor(1.2832, grad_fn=<NllLossBackward>) average train loss tensor(1.4972, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6236938925680647 val_avg_loss: tensor(1.3662)\n",
      "epoch: 46 train_loss: tensor(1.3404, grad_fn=<NllLossBackward>) average train loss tensor(1.4964, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6239293598233996 val_avg_loss: tensor(1.3640)\n",
      "epoch: 47 train_loss: tensor(1.2913, grad_fn=<NllLossBackward>) average train loss tensor(1.4890, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6229580573951435 val_avg_loss: tensor(1.3656)\n",
      "epoch: 48 train_loss: tensor(1.2790, grad_fn=<NllLossBackward>) average train loss tensor(1.4876, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242825607064018 val_avg_loss: tensor(1.3649)\n",
      "epoch: 49 train_loss: tensor(1.2828, grad_fn=<NllLossBackward>) average train loss tensor(1.4824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6238999264164827 val_avg_loss: tensor(1.3637)\n",
      "epoch: 50 train_loss: tensor(1.3210, grad_fn=<NllLossBackward>) average train loss tensor(1.4829, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241059602649006 val_avg_loss: tensor(1.3633)\n",
      "epoch: 51 train_loss: tensor(1.3234, grad_fn=<NllLossBackward>) average train loss tensor(1.4789, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.624429727740986 val_avg_loss: tensor(1.3618)\n",
      "epoch: 52 train_loss: tensor(1.3053, grad_fn=<NllLossBackward>) average train loss tensor(1.4764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.625224429727741 val_avg_loss: tensor(1.3589)\n",
      "epoch: 53 train_loss: tensor(1.2711, grad_fn=<NllLossBackward>) average train loss tensor(1.4730, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62345842531273 val_avg_loss: tensor(1.3606)\n",
      "epoch: 54 train_loss: tensor(1.2525, grad_fn=<NllLossBackward>) average train loss tensor(1.4689, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.624047093451067 val_avg_loss: tensor(1.3580)\n",
      "epoch: 55 train_loss: tensor(1.2698, grad_fn=<NllLossBackward>) average train loss tensor(1.4675, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6248417954378219 val_avg_loss: tensor(1.3580)\n",
      "epoch: 56 train_loss: tensor(1.2810, grad_fn=<NllLossBackward>) average train loss tensor(1.4678, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6233995584988963 val_avg_loss: tensor(1.3596)\n",
      "epoch: 57 train_loss: tensor(1.2893, grad_fn=<NllLossBackward>) average train loss tensor(1.4651, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6248712288447388 val_avg_loss: tensor(1.3590)\n",
      "epoch: 58 train_loss: tensor(1.2689, grad_fn=<NllLossBackward>) average train loss tensor(1.4636, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6245180279617366 val_avg_loss: tensor(1.3575)\n",
      "epoch: 59 train_loss: tensor(1.2755, grad_fn=<NllLossBackward>) average train loss tensor(1.4587, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6236938925680647 val_avg_loss: tensor(1.3567)\n",
      "epoch: 60 train_loss: tensor(1.2924, grad_fn=<NllLossBackward>) average train loss tensor(1.4602, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6246651949963208 val_avg_loss: tensor(1.3560)\n",
      "epoch: 61 train_loss: tensor(1.2879, grad_fn=<NllLossBackward>) average train loss tensor(1.4534, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6249889624724062 val_avg_loss: tensor(1.3571)\n",
      "epoch: 62 train_loss: tensor(1.2070, grad_fn=<NllLossBackward>) average train loss tensor(1.4541, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6255187637969095 val_avg_loss: tensor(1.3554)\n",
      "epoch: 63 train_loss: tensor(1.2467, grad_fn=<NllLossBackward>) average train loss tensor(1.4500, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.625224429727741 val_avg_loss: tensor(1.3548)\n",
      "epoch: 64 train_loss: tensor(1.2227, grad_fn=<NllLossBackward>) average train loss tensor(1.4498, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6252538631346578 val_avg_loss: tensor(1.3558)\n",
      "epoch: 65 train_loss: tensor(1.2031, grad_fn=<NllLossBackward>) average train loss tensor(1.4419, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261662987490803 val_avg_loss: tensor(1.3530)\n",
      "epoch: 66 train_loss: tensor(1.2790, grad_fn=<NllLossBackward>) average train loss tensor(1.4460, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6252832965415747 val_avg_loss: tensor(1.3532)\n",
      "epoch: 67 train_loss: tensor(1.2184, grad_fn=<NllLossBackward>) average train loss tensor(1.4455, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258719646799117 val_avg_loss: tensor(1.3534)\n",
      "epoch: 68 train_loss: tensor(1.2455, grad_fn=<NllLossBackward>) average train loss tensor(1.4395, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265783664459161 val_avg_loss: tensor(1.3519)\n",
      "epoch: 69 train_loss: tensor(1.2103, grad_fn=<NllLossBackward>) average train loss tensor(1.4390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6251361295069904 val_avg_loss: tensor(1.3534)\n",
      "epoch: 70 train_loss: tensor(1.2389, grad_fn=<NllLossBackward>) average train loss tensor(1.4384, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265194996320824 val_avg_loss: tensor(1.3522)\n",
      "epoch: 71 train_loss: tensor(1.2502, grad_fn=<NllLossBackward>) average train loss tensor(1.4373, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269610007358352 val_avg_loss: tensor(1.3517)\n",
      "epoch: 72 train_loss: tensor(1.2459, grad_fn=<NllLossBackward>) average train loss tensor(1.4341, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264900662251656 val_avg_loss: tensor(1.3539)\n",
      "epoch: 73 train_loss: tensor(1.2202, grad_fn=<NllLossBackward>) average train loss tensor(1.4313, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257247976453274 val_avg_loss: tensor(1.3525)\n",
      "epoch: 74 train_loss: tensor(1.1934, grad_fn=<NllLossBackward>) average train loss tensor(1.4289, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626607799852833 val_avg_loss: tensor(1.3540)\n",
      "epoch: 75 train_loss: tensor(1.2702, grad_fn=<NllLossBackward>) average train loss tensor(1.4293, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6276379690949228 val_avg_loss: tensor(1.3520)\n",
      "epoch: 76 train_loss: tensor(1.1869, grad_fn=<NllLossBackward>) average train loss tensor(1.4239, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270787343635026 val_avg_loss: tensor(1.3532)\n",
      "epoch: 77 train_loss: tensor(1.2176, grad_fn=<NllLossBackward>) average train loss tensor(1.4271, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6274319352465048 val_avg_loss: tensor(1.3510)\n",
      "epoch: 78 train_loss: tensor(1.2110, grad_fn=<NllLossBackward>) average train loss tensor(1.4229, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6276674025018396 val_avg_loss: tensor(1.3516)\n",
      "epoch: 79 train_loss: tensor(1.1901, grad_fn=<NllLossBackward>) average train loss tensor(1.4200, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6275496688741722 val_avg_loss: tensor(1.3521)\n",
      "epoch: 80 train_loss: tensor(1.1842, grad_fn=<NllLossBackward>) average train loss tensor(1.4224, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6263134657836644 val_avg_loss: tensor(1.3516)\n",
      "epoch: 81 train_loss: tensor(1.2061, grad_fn=<NllLossBackward>) average train loss tensor(1.4182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62719646799117 val_avg_loss: tensor(1.3498)\n",
      "epoch: 82 train_loss: tensor(1.2755, grad_fn=<NllLossBackward>) average train loss tensor(1.4164, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261074319352465 val_avg_loss: tensor(1.3507)\n",
      "epoch: 83 train_loss: tensor(1.1989, grad_fn=<NllLossBackward>) average train loss tensor(1.4116, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261662987490803 val_avg_loss: tensor(1.3506)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 train_loss: tensor(1.1849, grad_fn=<NllLossBackward>) average train loss tensor(1.4076, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6261662987490803 val_avg_loss: tensor(1.3494)\n",
      "epoch: 85 train_loss: tensor(1.1882, grad_fn=<NllLossBackward>) average train loss tensor(1.4069, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265783664459161 val_avg_loss: tensor(1.3517)\n",
      "epoch: 86 train_loss: tensor(1.1839, grad_fn=<NllLossBackward>) average train loss tensor(1.4104, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264311994113319 val_avg_loss: tensor(1.3508)\n",
      "epoch: 87 train_loss: tensor(1.2100, grad_fn=<NllLossBackward>) average train loss tensor(1.4104, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257542310522443 val_avg_loss: tensor(1.3501)\n",
      "epoch: 88 train_loss: tensor(1.1927, grad_fn=<NllLossBackward>) average train loss tensor(1.4059, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6256953642384105 val_avg_loss: tensor(1.3491)\n",
      "epoch: 89 train_loss: tensor(1.1571, grad_fn=<NllLossBackward>) average train loss tensor(1.4029, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270493009565857 val_avg_loss: tensor(1.3505)\n",
      "epoch: 90 train_loss: tensor(1.1932, grad_fn=<NllLossBackward>) average train loss tensor(1.4040, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6258719646799117 val_avg_loss: tensor(1.3510)\n",
      "epoch: 91 train_loss: tensor(1.1751, grad_fn=<NllLossBackward>) average train loss tensor(1.4053, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268727005150846 val_avg_loss: tensor(1.3516)\n",
      "epoch: 92 train_loss: tensor(1.1881, grad_fn=<NllLossBackward>) average train loss tensor(1.4014, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269021339220014 val_avg_loss: tensor(1.3520)\n",
      "epoch: 93 train_loss: tensor(1.1485, grad_fn=<NllLossBackward>) average train loss tensor(1.3985, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6265489330389993 val_avg_loss: tensor(1.3509)\n",
      "epoch: 94 train_loss: tensor(1.1764, grad_fn=<NllLossBackward>) average train loss tensor(1.3999, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272553348050037 val_avg_loss: tensor(1.3500)\n",
      "epoch: 95 train_loss: tensor(1.1863, grad_fn=<NllLossBackward>) average train loss tensor(1.3957, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268727005150846 val_avg_loss: tensor(1.3515)\n",
      "epoch: 96 train_loss: tensor(1.1957, grad_fn=<NllLossBackward>) average train loss tensor(1.3935, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.62719646799117 val_avg_loss: tensor(1.3501)\n",
      "epoch: 97 train_loss: tensor(1.1537, grad_fn=<NllLossBackward>) average train loss tensor(1.3915, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6278440029433406 val_avg_loss: tensor(1.3486)\n",
      "epoch: 98 train_loss: tensor(1.1483, grad_fn=<NllLossBackward>) average train loss tensor(1.3946, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6264311994113319 val_avg_loss: tensor(1.3524)\n",
      "epoch: 99 train_loss: tensor(1.1350, grad_fn=<NllLossBackward>) average train loss tensor(1.3901, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280794701986755 val_avg_loss: tensor(1.3504)\n"
     ]
    }
   ],
   "source": [
    "for autoencoder_name in ['trivial', 'complex']:\n",
    "    cur_autoencoder_full = copy.deepcopy(autoencoder_dict[autoencoder_name])\n",
    "    cur_encoder_full = cur_autoencoder_full.encoder\n",
    "        \n",
    "    cur_after_encoder_model_full = AfterEncoderModel(cur_encoder_full, d=128, drop=0.5)\n",
    "    cur_optimizer_aem_full = torch.optim.Adam(cur_after_encoder_model_full.parameters(), lr=1e-3)\n",
    "        \n",
    "    writer = SummaryWriter('runs/aem_full' + autoencoder_name + '_' + str(rs) + '_bs2048_rs42_d128_wd0005_drop05_100')\n",
    "\n",
    "    torch_models.fit_topics_model(\n",
    "        model=cur_after_encoder_model_full,\n",
    "        optimizer=cur_optimizer_aem_full,\n",
    "        epochs=100,\n",
    "        writer=writer,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wider autoencoder (maximum similarity to norm model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.567 txt_loss: 0.618 img + txt loss 1.185\n",
      "val img loss: 0.343 val txt_loss: 0.409 img + txt loss 0.752\n",
      "train img loss: 0.267 txt_loss: 0.326 img + txt loss 0.592\n",
      "val img loss: 0.214 val txt_loss: 0.264 img + txt loss 0.479\n",
      "train img loss: 0.187 txt_loss: 0.229 img + txt loss 0.416\n",
      "val img loss: 0.167 val txt_loss: 0.201 img + txt loss 0.368\n",
      "train img loss: 0.153 txt_loss: 0.181 img + txt loss 0.334\n",
      "val img loss: 0.143 val txt_loss: 0.165 img + txt loss 0.308\n",
      "train img loss: 0.134 txt_loss: 0.151 img + txt loss 0.285\n",
      "val img loss: 0.128 val txt_loss: 0.141 img + txt loss 0.268\n",
      "train img loss: 0.121 txt_loss: 0.131 img + txt loss 0.252\n",
      "val img loss: 0.117 val txt_loss: 0.124 img + txt loss 0.241\n",
      "train img loss: 0.111 txt_loss: 0.116 img + txt loss 0.228\n",
      "val img loss: 0.109 val txt_loss: 0.111 img + txt loss 0.219\n",
      "train img loss: 0.104 txt_loss: 0.104 img + txt loss 0.208\n",
      "val img loss: 0.102 val txt_loss: 0.099 img + txt loss 0.201\n",
      "train img loss: 0.098 txt_loss: 0.093 img + txt loss 0.191\n",
      "val img loss: 0.097 val txt_loss: 0.089 img + txt loss 0.186\n",
      "train img loss: 0.093 txt_loss: 0.084 img + txt loss 0.177\n",
      "val img loss: 0.093 val txt_loss: 0.081 img + txt loss 0.173\n",
      "train img loss: 0.090 txt_loss: 0.076 img + txt loss 0.166\n",
      "val img loss: 0.089 val txt_loss: 0.074 img + txt loss 0.163\n",
      "train img loss: 0.087 txt_loss: 0.070 img + txt loss 0.156\n",
      "val img loss: 0.087 val txt_loss: 0.068 img + txt loss 0.155\n",
      "train img loss: 0.084 txt_loss: 0.064 img + txt loss 0.148\n",
      "val img loss: 0.084 val txt_loss: 0.063 img + txt loss 0.147\n",
      "train img loss: 0.082 txt_loss: 0.058 img + txt loss 0.141\n",
      "val img loss: 0.083 val txt_loss: 0.057 img + txt loss 0.139\n",
      "train img loss: 0.081 txt_loss: 0.054 img + txt loss 0.135\n",
      "val img loss: 0.081 val txt_loss: 0.053 img + txt loss 0.135\n",
      "train img loss: 0.080 txt_loss: 0.051 img + txt loss 0.131\n",
      "val img loss: 0.080 val txt_loss: 0.051 img + txt loss 0.131\n",
      "train img loss: 0.078 txt_loss: 0.049 img + txt loss 0.128\n",
      "val img loss: 0.079 val txt_loss: 0.050 img + txt loss 0.128\n",
      "train img loss: 0.078 txt_loss: 0.048 img + txt loss 0.125\n",
      "val img loss: 0.078 val txt_loss: 0.048 img + txt loss 0.126\n",
      "train img loss: 0.077 txt_loss: 0.047 img + txt loss 0.123\n",
      "val img loss: 0.077 val txt_loss: 0.047 img + txt loss 0.124\n",
      "train img loss: 0.076 txt_loss: 0.046 img + txt loss 0.122\n",
      "val img loss: 0.077 val txt_loss: 0.046 img + txt loss 0.123\n",
      "train img loss: 0.076 txt_loss: 0.045 img + txt loss 0.121\n",
      "val img loss: 0.076 val txt_loss: 0.046 img + txt loss 0.122\n",
      "train img loss: 0.075 txt_loss: 0.045 img + txt loss 0.120\n",
      "val img loss: 0.076 val txt_loss: 0.045 img + txt loss 0.121\n",
      "train img loss: 0.075 txt_loss: 0.044 img + txt loss 0.119\n",
      "val img loss: 0.076 val txt_loss: 0.045 img + txt loss 0.120\n",
      "train img loss: 0.074 txt_loss: 0.044 img + txt loss 0.118\n",
      "val img loss: 0.076 val txt_loss: 0.044 img + txt loss 0.120\n",
      "train img loss: 0.074 txt_loss: 0.043 img + txt loss 0.117\n",
      "val img loss: 0.075 val txt_loss: 0.044 img + txt loss 0.119\n",
      "train img loss: 0.074 txt_loss: 0.043 img + txt loss 0.117\n",
      "val img loss: 0.075 val txt_loss: 0.044 img + txt loss 0.118\n",
      "train img loss: 0.074 txt_loss: 0.043 img + txt loss 0.116\n",
      "val img loss: 0.075 val txt_loss: 0.044 img + txt loss 0.119\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.116\n",
      "val img loss: 0.074 val txt_loss: 0.043 img + txt loss 0.117\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.116\n",
      "val img loss: 0.074 val txt_loss: 0.043 img + txt loss 0.117\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.074 val txt_loss: 0.043 img + txt loss 0.117\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.074 val txt_loss: 0.043 img + txt loss 0.117\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.115\n",
      "val img loss: 0.074 val txt_loss: 0.043 img + txt loss 0.117\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.114\n",
      "val img loss: 0.073 val txt_loss: 0.043 img + txt loss 0.116\n",
      "train img loss: 0.073 txt_loss: 0.042 img + txt loss 0.114\n",
      "val img loss: 0.074 val txt_loss: 0.042 img + txt loss 0.116\n",
      "train img loss: 0.073 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.074 val txt_loss: 0.042 img + txt loss 0.116\n",
      "train img loss: 0.073 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.116\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.074 val txt_loss: 0.042 img + txt loss 0.116\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.114\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.115\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.042 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.113\n",
      "val img loss: 0.076 val txt_loss: 0.042 img + txt loss 0.117\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.041 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.072 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.111\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.073 val txt_loss: 0.041 img + txt loss 0.114\n",
      "train img loss: 0.071 txt_loss: 0.040 img + txt loss 0.112\n",
      "val img loss: 0.072 val txt_loss: 0.041 img + txt loss 0.113\n",
      "autoencoder fitting finished for 1714.9169108867645 seconds\n"
     ]
    }
   ],
   "source": [
    "autoencoder_c_256 = AutoencoderComplex(d=256)\n",
    "optimizer_c_256 = torch.optim.Adam(autoencoder_c_256.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_c_256, optimizer_c_256, 100, [x_img_train, x_txt_train], [x_img_val, x_txt_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AfterEncoderModel2(nn.Module):\n",
    "    def __init__(self, encoder, d=128, drop=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "            \n",
    "        self.fc1 = nn.Linear(d * 4, d)\n",
    "        self.fc2 = nn.Linear(d, d)\n",
    "        self.out = nn.Linear(d, N_CLASSES)\n",
    "\n",
    "        self.dropout = nn.modules.Dropout(p=drop)\n",
    "\n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.out(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AfterEncoderModel2BN(nn.Module):\n",
    "    def __init__(self, encoder, d=128, drop=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.bn0 = nn.BatchNorm1d(num_features=d * 4)\n",
    "        self.fc1 = nn.Linear(d * 4, d)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=d)\n",
    "        self.fc2 = nn.Linear(d, d)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=d)\n",
    "        self.out = nn.Linear(d, N_CLASSES)\n",
    "\n",
    "        self.dropout = nn.modules.Dropout(p=drop)\n",
    "\n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x = self.dropout(self.bn0(x))\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(self.bn1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.log_softmax(self.out(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(2.1380, grad_fn=<NllLossBackward>) average train loss tensor(2.7222, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5221486387049301 val_avg_loss: tensor(1.7722)\n",
      "epoch: 1 train_loss: tensor(1.8335, grad_fn=<NllLossBackward>) average train loss tensor(1.9462, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5705960264900662 val_avg_loss: tensor(1.5953)\n",
      "epoch: 2 train_loss: tensor(1.8083, grad_fn=<NllLossBackward>) average train loss tensor(1.8222, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5823105224429728 val_avg_loss: tensor(1.5435)\n",
      "epoch: 3 train_loss: tensor(1.7105, grad_fn=<NllLossBackward>) average train loss tensor(1.7596, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5935540838852097 val_avg_loss: tensor(1.5034)\n",
      "epoch: 4 train_loss: tensor(1.6634, grad_fn=<NllLossBackward>) average train loss tensor(1.7258, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5985871964679912 val_avg_loss: tensor(1.4822)\n",
      "epoch: 5 train_loss: tensor(1.6554, grad_fn=<NllLossBackward>) average train loss tensor(1.6953, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6010301692420897 val_avg_loss: tensor(1.4669)\n",
      "epoch: 6 train_loss: tensor(1.6294, grad_fn=<NllLossBackward>) average train loss tensor(1.6705, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6039146431199411 val_avg_loss: tensor(1.4523)\n",
      "epoch: 7 train_loss: tensor(1.5740, grad_fn=<NllLossBackward>) average train loss tensor(1.6501, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.606122148638705 val_avg_loss: tensor(1.4393)\n",
      "epoch: 8 train_loss: tensor(1.5604, grad_fn=<NllLossBackward>) average train loss tensor(1.6353, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6073289183222959 val_avg_loss: tensor(1.4297)\n",
      "epoch: 9 train_loss: tensor(1.4851, grad_fn=<NllLossBackward>) average train loss tensor(1.6185, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6101250919793966 val_avg_loss: tensor(1.4236)\n",
      "epoch: 10 train_loss: tensor(1.5045, grad_fn=<NllLossBackward>) average train loss tensor(1.6079, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.611037527593819 val_avg_loss: tensor(1.4161)\n",
      "epoch: 11 train_loss: tensor(1.4970, grad_fn=<NllLossBackward>) average train loss tensor(1.5967, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6136865342163356 val_avg_loss: tensor(1.4080)\n",
      "epoch: 12 train_loss: tensor(1.5063, grad_fn=<NllLossBackward>) average train loss tensor(1.5857, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6138925680647535 val_avg_loss: tensor(1.4074)\n",
      "epoch: 13 train_loss: tensor(1.4656, grad_fn=<NllLossBackward>) average train loss tensor(1.5723, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6143340691685063 val_avg_loss: tensor(1.4020)\n",
      "epoch: 14 train_loss: tensor(1.4479, grad_fn=<NllLossBackward>) average train loss tensor(1.5600, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6164827078734364 val_avg_loss: tensor(1.3967)\n",
      "epoch: 15 train_loss: tensor(1.4306, grad_fn=<NllLossBackward>) average train loss tensor(1.5568, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6180132450331126 val_avg_loss: tensor(1.3913)\n",
      "epoch: 16 train_loss: tensor(1.3946, grad_fn=<NllLossBackward>) average train loss tensor(1.5462, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6183664459161148 val_avg_loss: tensor(1.3887)\n",
      "epoch: 17 train_loss: tensor(1.4095, grad_fn=<NllLossBackward>) average train loss tensor(1.5380, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6189551140544518 val_avg_loss: tensor(1.3838)\n",
      "epoch: 18 train_loss: tensor(1.4116, grad_fn=<NllLossBackward>) average train loss tensor(1.5327, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6199264164827079 val_avg_loss: tensor(1.3801)\n",
      "epoch: 19 train_loss: tensor(1.3874, grad_fn=<NllLossBackward>) average train loss tensor(1.5255, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6211626195732156 val_avg_loss: tensor(1.3764)\n",
      "epoch: 20 train_loss: tensor(1.3425, grad_fn=<NllLossBackward>) average train loss tensor(1.5188, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6214275202354672 val_avg_loss: tensor(1.3754)\n",
      "epoch: 21 train_loss: tensor(1.3513, grad_fn=<NllLossBackward>) average train loss tensor(1.5119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.622457689477557 val_avg_loss: tensor(1.3746)\n",
      "epoch: 22 train_loss: tensor(1.3263, grad_fn=<NllLossBackward>) average train loss tensor(1.5045, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.624223693892568 val_avg_loss: tensor(1.3702)\n",
      "epoch: 23 train_loss: tensor(1.3794, grad_fn=<NllLossBackward>) average train loss tensor(1.5009, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.622075055187638 val_avg_loss: tensor(1.3722)\n",
      "epoch: 24 train_loss: tensor(1.3448, grad_fn=<NllLossBackward>) average train loss tensor(1.4966, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.623252391464312 val_avg_loss: tensor(1.3682)\n",
      "epoch: 25 train_loss: tensor(1.2943, grad_fn=<NllLossBackward>) average train loss tensor(1.4878, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6235172921265637 val_avg_loss: tensor(1.3666)\n",
      "epoch: 26 train_loss: tensor(1.3099, grad_fn=<NllLossBackward>) average train loss tensor(1.4873, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6237821927888153 val_avg_loss: tensor(1.3614)\n",
      "epoch: 27 train_loss: tensor(1.2781, grad_fn=<NllLossBackward>) average train loss tensor(1.4811, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6255187637969095 val_avg_loss: tensor(1.3590)\n",
      "epoch: 28 train_loss: tensor(1.2675, grad_fn=<NllLossBackward>) average train loss tensor(1.4758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6260779985283297 val_avg_loss: tensor(1.3568)\n",
      "epoch: 29 train_loss: tensor(1.3505, grad_fn=<NllLossBackward>) average train loss tensor(1.4735, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6257247976453274 val_avg_loss: tensor(1.3557)\n",
      "epoch: 30 train_loss: tensor(1.2816, grad_fn=<NllLossBackward>) average train loss tensor(1.4647, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6254598969830758 val_avg_loss: tensor(1.3560)\n",
      "epoch: 31 train_loss: tensor(1.3009, grad_fn=<NllLossBackward>) average train loss tensor(1.4608, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6250478292862399 val_avg_loss: tensor(1.3524)\n",
      "epoch: 32 train_loss: tensor(1.2595, grad_fn=<NllLossBackward>) average train loss tensor(1.4580, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6269315673289183 val_avg_loss: tensor(1.3501)\n",
      "epoch: 33 train_loss: tensor(1.2863, grad_fn=<NllLossBackward>) average train loss tensor(1.4508, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6256364974245769 val_avg_loss: tensor(1.3512)\n",
      "epoch: 34 train_loss: tensor(1.3302, grad_fn=<NllLossBackward>) average train loss tensor(1.4495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6256070640176601 val_avg_loss: tensor(1.3494)\n",
      "epoch: 35 train_loss: tensor(1.2183, grad_fn=<NllLossBackward>) average train loss tensor(1.4426, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270493009565857 val_avg_loss: tensor(1.3483)\n",
      "epoch: 36 train_loss: tensor(1.2576, grad_fn=<NllLossBackward>) average train loss tensor(1.4403, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6276379690949228 val_avg_loss: tensor(1.3494)\n",
      "epoch: 37 train_loss: tensor(1.2446, grad_fn=<NllLossBackward>) average train loss tensor(1.4405, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280206033848418 val_avg_loss: tensor(1.3467)\n",
      "epoch: 38 train_loss: tensor(1.2275, grad_fn=<NllLossBackward>) average train loss tensor(1.4374, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272553348050037 val_avg_loss: tensor(1.3448)\n",
      "epoch: 39 train_loss: tensor(1.2266, grad_fn=<NllLossBackward>) average train loss tensor(1.4326, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6303164091243562 val_avg_loss: tensor(1.3424)\n",
      "epoch: 40 train_loss: tensor(1.2188, grad_fn=<NllLossBackward>) average train loss tensor(1.4276, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6294039735099338 val_avg_loss: tensor(1.3436)\n",
      "epoch: 41 train_loss: tensor(1.2171, grad_fn=<NllLossBackward>) average train loss tensor(1.4241, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6290507726269315 val_avg_loss: tensor(1.3432)\n",
      "epoch: 42 train_loss: tensor(1.2041, grad_fn=<NllLossBackward>) average train loss tensor(1.4243, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6279028697571744 val_avg_loss: tensor(1.3419)\n",
      "epoch: 43 train_loss: tensor(1.1689, grad_fn=<NllLossBackward>) average train loss tensor(1.4151, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280500367917586 val_avg_loss: tensor(1.3412)\n",
      "epoch: 44 train_loss: tensor(1.1978, grad_fn=<NllLossBackward>) average train loss tensor(1.4157, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.628373804267844 val_avg_loss: tensor(1.3389)\n",
      "epoch: 45 train_loss: tensor(1.1633, grad_fn=<NllLossBackward>) average train loss tensor(1.4131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6296394407652686 val_avg_loss: tensor(1.3383)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(1.2151, grad_fn=<NllLossBackward>) average train loss tensor(1.4092, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6290802060338484 val_avg_loss: tensor(1.3362)\n",
      "epoch: 47 train_loss: tensor(1.2394, grad_fn=<NllLossBackward>) average train loss tensor(1.4048, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6287270051508462 val_avg_loss: tensor(1.3368)\n",
      "epoch: 48 train_loss: tensor(1.2155, grad_fn=<NllLossBackward>) average train loss tensor(1.4059, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6289036055923473 val_avg_loss: tensor(1.3374)\n",
      "epoch: 49 train_loss: tensor(1.1734, grad_fn=<NllLossBackward>) average train loss tensor(1.4003, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6292273730684327 val_avg_loss: tensor(1.3355)\n",
      "epoch: 50 train_loss: tensor(1.1954, grad_fn=<NllLossBackward>) average train loss tensor(1.3992, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.630522442972774 val_avg_loss: tensor(1.3357)\n",
      "epoch: 51 train_loss: tensor(1.1943, grad_fn=<NllLossBackward>) average train loss tensor(1.3943, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6307873436350258 val_avg_loss: tensor(1.3336)\n",
      "epoch: 52 train_loss: tensor(1.1597, grad_fn=<NllLossBackward>) average train loss tensor(1.3912, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6295805739514349 val_avg_loss: tensor(1.3344)\n",
      "epoch: 53 train_loss: tensor(1.1855, grad_fn=<NllLossBackward>) average train loss tensor(1.3862, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6314054451802796 val_avg_loss: tensor(1.3316)\n",
      "epoch: 54 train_loss: tensor(1.1843, grad_fn=<NllLossBackward>) average train loss tensor(1.3857, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6297866077998528 val_avg_loss: tensor(1.3323)\n",
      "epoch: 55 train_loss: tensor(1.1381, grad_fn=<NllLossBackward>) average train loss tensor(1.3840, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6309050772626932 val_avg_loss: tensor(1.3320)\n",
      "epoch: 56 train_loss: tensor(1.1328, grad_fn=<NllLossBackward>) average train loss tensor(1.3796, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6308462104488595 val_avg_loss: tensor(1.3304)\n",
      "epoch: 57 train_loss: tensor(1.1177, grad_fn=<NllLossBackward>) average train loss tensor(1.3744, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6320824135393672 val_avg_loss: tensor(1.3311)\n",
      "epoch: 58 train_loss: tensor(1.1578, grad_fn=<NllLossBackward>) average train loss tensor(1.3706, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6319352465047829 val_avg_loss: tensor(1.3314)\n",
      "epoch: 59 train_loss: tensor(1.1060, grad_fn=<NllLossBackward>) average train loss tensor(1.3673, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6323767476085357 val_avg_loss: tensor(1.3320)\n",
      "epoch: 60 train_loss: tensor(1.1519, grad_fn=<NllLossBackward>) average train loss tensor(1.3725, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.631729212656365 val_avg_loss: tensor(1.3333)\n",
      "epoch: 61 train_loss: tensor(1.1354, grad_fn=<NllLossBackward>) average train loss tensor(1.3615, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6326122148638705 val_avg_loss: tensor(1.3309)\n",
      "epoch: 62 train_loss: tensor(1.0876, grad_fn=<NllLossBackward>) average train loss tensor(1.3661, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6320529801324504 val_avg_loss: tensor(1.3302)\n",
      "epoch: 63 train_loss: tensor(1.0824, grad_fn=<NllLossBackward>) average train loss tensor(1.3606, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6315820456217808 val_avg_loss: tensor(1.3307)\n",
      "epoch: 64 train_loss: tensor(1.1331, grad_fn=<NllLossBackward>) average train loss tensor(1.3600, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6317880794701987 val_avg_loss: tensor(1.3291)\n",
      "epoch: 65 train_loss: tensor(1.1126, grad_fn=<NllLossBackward>) average train loss tensor(1.3594, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6311994113318616 val_avg_loss: tensor(1.3307)\n",
      "epoch: 66 train_loss: tensor(1.1149, grad_fn=<NllLossBackward>) average train loss tensor(1.3535, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6321118469462841 val_avg_loss: tensor(1.3293)\n",
      "epoch: 67 train_loss: tensor(1.0876, grad_fn=<NllLossBackward>) average train loss tensor(1.3466, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6330242825607064 val_avg_loss: tensor(1.3269)\n",
      "epoch: 68 train_loss: tensor(1.1075, grad_fn=<NllLossBackward>) average train loss tensor(1.3522, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324650478292863 val_avg_loss: tensor(1.3261)\n",
      "epoch: 69 train_loss: tensor(1.0680, grad_fn=<NllLossBackward>) average train loss tensor(1.3482, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324650478292863 val_avg_loss: tensor(1.3275)\n",
      "epoch: 70 train_loss: tensor(1.0905, grad_fn=<NllLossBackward>) average train loss tensor(1.3451, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6327888153053716 val_avg_loss: tensor(1.3248)\n",
      "epoch: 71 train_loss: tensor(1.0756, grad_fn=<NllLossBackward>) average train loss tensor(1.3388, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6329948491537896 val_avg_loss: tensor(1.3280)\n",
      "epoch: 72 train_loss: tensor(1.1005, grad_fn=<NllLossBackward>) average train loss tensor(1.3375, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6326710816777041 val_avg_loss: tensor(1.3239)\n",
      "epoch: 73 train_loss: tensor(1.0285, grad_fn=<NllLossBackward>) average train loss tensor(1.3333, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.633112582781457 val_avg_loss: tensor(1.3267)\n",
      "epoch: 74 train_loss: tensor(1.0748, grad_fn=<NllLossBackward>) average train loss tensor(1.3335, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6328771155261221 val_avg_loss: tensor(1.3279)\n",
      "epoch: 75 train_loss: tensor(1.0748, grad_fn=<NllLossBackward>) average train loss tensor(1.3339, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.632317880794702 val_avg_loss: tensor(1.3263)\n",
      "epoch: 76 train_loss: tensor(1.0713, grad_fn=<NllLossBackward>) average train loss tensor(1.3294, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6332303164091243 val_avg_loss: tensor(1.3243)\n",
      "epoch: 77 train_loss: tensor(1.0636, grad_fn=<NllLossBackward>) average train loss tensor(1.3289, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6323767476085357 val_avg_loss: tensor(1.3247)\n",
      "epoch: 78 train_loss: tensor(1.0318, grad_fn=<NllLossBackward>) average train loss tensor(1.3262, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6327593818984547 val_avg_loss: tensor(1.3271)\n",
      "epoch: 79 train_loss: tensor(1.1042, grad_fn=<NllLossBackward>) average train loss tensor(1.3210, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6317586460632818 val_avg_loss: tensor(1.3246)\n",
      "epoch: 80 train_loss: tensor(1.0194, grad_fn=<NllLossBackward>) average train loss tensor(1.3202, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.630728476821192 val_avg_loss: tensor(1.3251)\n",
      "epoch: 81 train_loss: tensor(1.0417, grad_fn=<NllLossBackward>) average train loss tensor(1.3177, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6315231788079471 val_avg_loss: tensor(1.3260)\n",
      "epoch: 82 train_loss: tensor(1.0283, grad_fn=<NllLossBackward>) average train loss tensor(1.3137, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324061810154525 val_avg_loss: tensor(1.3246)\n",
      "epoch: 83 train_loss: tensor(1.0293, grad_fn=<NllLossBackward>) average train loss tensor(1.3152, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6321118469462841 val_avg_loss: tensor(1.3245)\n",
      "epoch: 84 train_loss: tensor(1.0717, grad_fn=<NllLossBackward>) average train loss tensor(1.3146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.63093451066961 val_avg_loss: tensor(1.3280)\n",
      "epoch: 85 train_loss: tensor(1.0155, grad_fn=<NllLossBackward>) average train loss tensor(1.3093, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6329948491537896 val_avg_loss: tensor(1.3247)\n",
      "epoch: 86 train_loss: tensor(1.0141, grad_fn=<NllLossBackward>) average train loss tensor(1.3088, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6307873436350258 val_avg_loss: tensor(1.3268)\n",
      "epoch: 87 train_loss: tensor(1.0312, grad_fn=<NllLossBackward>) average train loss tensor(1.3039, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6310816777041942 val_avg_loss: tensor(1.3264)\n",
      "epoch: 88 train_loss: tensor(1.0455, grad_fn=<NllLossBackward>) average train loss tensor(1.3065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6309933774834438 val_avg_loss: tensor(1.3253)\n",
      "epoch: 89 train_loss: tensor(1.0559, grad_fn=<NllLossBackward>) average train loss tensor(1.3052, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6320529801324504 val_avg_loss: tensor(1.3255)\n",
      "epoch: 90 train_loss: tensor(1.0194, grad_fn=<NllLossBackward>) average train loss tensor(1.2983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6310228108903606 val_avg_loss: tensor(1.3266)\n",
      "epoch: 91 train_loss: tensor(0.9730, grad_fn=<NllLossBackward>) average train loss tensor(1.2957, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6321118469462841 val_avg_loss: tensor(1.3236)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 train_loss: tensor(1.0466, grad_fn=<NllLossBackward>) average train loss tensor(1.2969, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6310228108903606 val_avg_loss: tensor(1.3246)\n",
      "epoch: 93 train_loss: tensor(1.0175, grad_fn=<NllLossBackward>) average train loss tensor(1.2926, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.63252391464312 val_avg_loss: tensor(1.3221)\n",
      "epoch: 94 train_loss: tensor(0.9986, grad_fn=<NllLossBackward>) average train loss tensor(1.2922, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324356144223694 val_avg_loss: tensor(1.3249)\n",
      "epoch: 95 train_loss: tensor(1.0250, grad_fn=<NllLossBackward>) average train loss tensor(1.2933, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324944812362031 val_avg_loss: tensor(1.3234)\n",
      "epoch: 96 train_loss: tensor(0.9667, grad_fn=<NllLossBackward>) average train loss tensor(1.2851, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6322001471670345 val_avg_loss: tensor(1.3251)\n",
      "epoch: 97 train_loss: tensor(0.9618, grad_fn=<NllLossBackward>) average train loss tensor(1.2878, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6335835172921266 val_avg_loss: tensor(1.3236)\n",
      "epoch: 98 train_loss: tensor(1.0023, grad_fn=<NllLossBackward>) average train loss tensor(1.2839, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6329948491537896 val_avg_loss: tensor(1.3227)\n",
      "epoch: 99 train_loss: tensor(0.9540, grad_fn=<NllLossBackward>) average train loss tensor(1.2811, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6332303164091243 val_avg_loss: tensor(1.3248)\n"
     ]
    }
   ],
   "source": [
    "encoder_c_256 = copy.deepcopy(autoencoder_c_256.encoder)\n",
    "        \n",
    "after_encoder_model_c_256 = AfterEncoderModel2(encoder_c_256, d=128, drop=0.5)\n",
    "optimizer_aem_c_256 = torch.optim.Adam(after_encoder_model_c_256.parameters(), lr=1e-3)\n",
    "        \n",
    "writer = SummaryWriter('runs/aem2_full_c_256_bs2048_rs42_d128_drop05_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_c_256,\n",
    "    optimizer=optimizer_aem_c_256,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(2.0852, grad_fn=<NllLossBackward>) average train loss tensor(2.7593, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5146431199411332 val_avg_loss: tensor(1.8053)\n",
      "epoch: 1 train_loss: tensor(1.8677, grad_fn=<NllLossBackward>) average train loss tensor(1.9506, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5687122884473877 val_avg_loss: tensor(1.5950)\n",
      "epoch: 2 train_loss: tensor(1.7715, grad_fn=<NllLossBackward>) average train loss tensor(1.8139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5848417954378219 val_avg_loss: tensor(1.5280)\n",
      "epoch: 3 train_loss: tensor(1.6716, grad_fn=<NllLossBackward>) average train loss tensor(1.7510, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5928771155261221 val_avg_loss: tensor(1.4999)\n",
      "epoch: 4 train_loss: tensor(1.6499, grad_fn=<NllLossBackward>) average train loss tensor(1.7125, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5967328918322296 val_avg_loss: tensor(1.4800)\n",
      "epoch: 5 train_loss: tensor(1.5739, grad_fn=<NllLossBackward>) average train loss tensor(1.6850, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6005003679175864 val_avg_loss: tensor(1.4631)\n",
      "epoch: 6 train_loss: tensor(1.5986, grad_fn=<NllLossBackward>) average train loss tensor(1.6573, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6027961736571008 val_avg_loss: tensor(1.4490)\n",
      "epoch: 7 train_loss: tensor(1.5445, grad_fn=<NllLossBackward>) average train loss tensor(1.6390, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6053568800588668 val_avg_loss: tensor(1.4373)\n",
      "epoch: 8 train_loss: tensor(1.5289, grad_fn=<NllLossBackward>) average train loss tensor(1.6217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6085356880058866 val_avg_loss: tensor(1.4315)\n",
      "epoch: 9 train_loss: tensor(1.5171, grad_fn=<NllLossBackward>) average train loss tensor(1.6065, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6082119205298013 val_avg_loss: tensor(1.4222)\n",
      "epoch: 10 train_loss: tensor(1.4986, grad_fn=<NllLossBackward>) average train loss tensor(1.5962, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6111258278145696 val_avg_loss: tensor(1.4161)\n",
      "epoch: 11 train_loss: tensor(1.4415, grad_fn=<NllLossBackward>) average train loss tensor(1.5876, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6122737306843267 val_avg_loss: tensor(1.4112)\n",
      "epoch: 12 train_loss: tensor(1.4735, grad_fn=<NllLossBackward>) average train loss tensor(1.5735, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6137159676232524 val_avg_loss: tensor(1.4034)\n",
      "epoch: 13 train_loss: tensor(1.4388, grad_fn=<NllLossBackward>) average train loss tensor(1.5644, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6158351729212657 val_avg_loss: tensor(1.3994)\n",
      "epoch: 14 train_loss: tensor(1.4815, grad_fn=<NllLossBackward>) average train loss tensor(1.5553, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6154231052244298 val_avg_loss: tensor(1.3964)\n",
      "epoch: 15 train_loss: tensor(1.4310, grad_fn=<NllLossBackward>) average train loss tensor(1.5480, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6166593083149374 val_avg_loss: tensor(1.3938)\n",
      "epoch: 16 train_loss: tensor(1.4119, grad_fn=<NllLossBackward>) average train loss tensor(1.5406, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6186902133922001 val_avg_loss: tensor(1.3865)\n",
      "epoch: 17 train_loss: tensor(1.3737, grad_fn=<NllLossBackward>) average train loss tensor(1.5338, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6188373804267844 val_avg_loss: tensor(1.3828)\n",
      "epoch: 18 train_loss: tensor(1.4031, grad_fn=<NllLossBackward>) average train loss tensor(1.5295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6202796173657101 val_avg_loss: tensor(1.3796)\n",
      "epoch: 19 train_loss: tensor(1.4106, grad_fn=<NllLossBackward>) average train loss tensor(1.5206, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.621074319352465 val_avg_loss: tensor(1.3780)\n",
      "epoch: 20 train_loss: tensor(1.3904, grad_fn=<NllLossBackward>) average train loss tensor(1.5130, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6185430463576159 val_avg_loss: tensor(1.3776)\n",
      "epoch: 21 train_loss: tensor(1.3674, grad_fn=<NllLossBackward>) average train loss tensor(1.5085, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.619514348785872 val_avg_loss: tensor(1.3762)\n",
      "epoch: 22 train_loss: tensor(1.3692, grad_fn=<NllLossBackward>) average train loss tensor(1.5031, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6219867549668874 val_avg_loss: tensor(1.3747)\n",
      "epoch: 23 train_loss: tensor(1.3693, grad_fn=<NllLossBackward>) average train loss tensor(1.5000, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6224871228844738 val_avg_loss: tensor(1.3693)\n",
      "epoch: 24 train_loss: tensor(1.3381, grad_fn=<NllLossBackward>) average train loss tensor(1.4920, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6225165562913907 val_avg_loss: tensor(1.3666)\n",
      "epoch: 25 train_loss: tensor(1.3365, grad_fn=<NllLossBackward>) average train loss tensor(1.4910, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241059602649006 val_avg_loss: tensor(1.3670)\n",
      "epoch: 26 train_loss: tensor(1.3542, grad_fn=<NllLossBackward>) average train loss tensor(1.4873, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6240765268579838 val_avg_loss: tensor(1.3677)\n",
      "epoch: 27 train_loss: tensor(1.3138, grad_fn=<NllLossBackward>) average train loss tensor(1.4808, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6242825607064018 val_avg_loss: tensor(1.3610)\n",
      "epoch: 28 train_loss: tensor(1.3361, grad_fn=<NllLossBackward>) average train loss tensor(1.4756, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6238999264164827 val_avg_loss: tensor(1.3630)\n",
      "epoch: 29 train_loss: tensor(1.3093, grad_fn=<NllLossBackward>) average train loss tensor(1.4756, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6251655629139072 val_avg_loss: tensor(1.3603)\n",
      "epoch: 30 train_loss: tensor(1.3135, grad_fn=<NllLossBackward>) average train loss tensor(1.4696, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241353936718175 val_avg_loss: tensor(1.3577)\n",
      "epoch: 31 train_loss: tensor(1.2945, grad_fn=<NllLossBackward>) average train loss tensor(1.4636, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6253715967623252 val_avg_loss: tensor(1.3573)\n",
      "epoch: 32 train_loss: tensor(1.2996, grad_fn=<NllLossBackward>) average train loss tensor(1.4602, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6241942604856512 val_avg_loss: tensor(1.3562)\n",
      "epoch: 33 train_loss: tensor(1.2756, grad_fn=<NllLossBackward>) average train loss tensor(1.4581, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6254598969830758 val_avg_loss: tensor(1.3548)\n",
      "epoch: 34 train_loss: tensor(1.3145, grad_fn=<NllLossBackward>) average train loss tensor(1.4575, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6250772626931568 val_avg_loss: tensor(1.3529)\n",
      "epoch: 35 train_loss: tensor(1.2446, grad_fn=<NllLossBackward>) average train loss tensor(1.4494, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6256364974245769 val_avg_loss: tensor(1.3500)\n",
      "epoch: 36 train_loss: tensor(1.2482, grad_fn=<NllLossBackward>) average train loss tensor(1.4464, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6263723325974981 val_avg_loss: tensor(1.3477)\n",
      "epoch: 37 train_loss: tensor(1.2952, grad_fn=<NllLossBackward>) average train loss tensor(1.4478, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.626607799852833 val_avg_loss: tensor(1.3495)\n",
      "epoch: 38 train_loss: tensor(1.2527, grad_fn=<NllLossBackward>) average train loss tensor(1.4443, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6263723325974981 val_avg_loss: tensor(1.3505)\n",
      "epoch: 39 train_loss: tensor(1.2784, grad_fn=<NllLossBackward>) average train loss tensor(1.4421, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6268727005150846 val_avg_loss: tensor(1.3467)\n",
      "epoch: 40 train_loss: tensor(1.2721, grad_fn=<NllLossBackward>) average train loss tensor(1.4369, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6272847682119206 val_avg_loss: tensor(1.3466)\n",
      "epoch: 41 train_loss: tensor(1.2495, grad_fn=<NllLossBackward>) average train loss tensor(1.4358, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6270198675496689 val_avg_loss: tensor(1.3472)\n",
      "epoch: 42 train_loss: tensor(1.2784, grad_fn=<NllLossBackward>) average train loss tensor(1.4326, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6273142016188373 val_avg_loss: tensor(1.3447)\n",
      "epoch: 43 train_loss: tensor(1.2892, grad_fn=<NllLossBackward>) average train loss tensor(1.4303, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.627785136129507 val_avg_loss: tensor(1.3468)\n",
      "epoch: 44 train_loss: tensor(1.2328, grad_fn=<NllLossBackward>) average train loss tensor(1.4287, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6278734363502575 val_avg_loss: tensor(1.3475)\n",
      "epoch: 45 train_loss: tensor(1.2348, grad_fn=<NllLossBackward>) average train loss tensor(1.4235, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6274613686534216 val_avg_loss: tensor(1.3448)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(1.2398, grad_fn=<NllLossBackward>) average train loss tensor(1.4201, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6280500367917586 val_avg_loss: tensor(1.3424)\n",
      "epoch: 47 train_loss: tensor(1.2275, grad_fn=<NllLossBackward>) average train loss tensor(1.4178, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.627785136129507 val_avg_loss: tensor(1.3407)\n",
      "epoch: 48 train_loss: tensor(1.2646, grad_fn=<NllLossBackward>) average train loss tensor(1.4186, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6278734363502575 val_avg_loss: tensor(1.3433)\n",
      "epoch: 49 train_loss: tensor(1.2030, grad_fn=<NllLossBackward>) average train loss tensor(1.4146, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6282266372332598 val_avg_loss: tensor(1.3435)\n",
      "epoch: 50 train_loss: tensor(1.1889, grad_fn=<NllLossBackward>) average train loss tensor(1.4130, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6271376011773363 val_avg_loss: tensor(1.3424)\n",
      "epoch: 51 train_loss: tensor(1.1937, grad_fn=<NllLossBackward>) average train loss tensor(1.4114, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6284032376747608 val_avg_loss: tensor(1.3373)\n",
      "epoch: 52 train_loss: tensor(1.2350, grad_fn=<NllLossBackward>) average train loss tensor(1.4111, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6291979396615158 val_avg_loss: tensor(1.3415)\n",
      "epoch: 53 train_loss: tensor(1.1939, grad_fn=<NllLossBackward>) average train loss tensor(1.4073, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6283149374540103 val_avg_loss: tensor(1.3390)\n",
      "epoch: 54 train_loss: tensor(1.1706, grad_fn=<NllLossBackward>) average train loss tensor(1.4037, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6300220750551876 val_avg_loss: tensor(1.3387)\n",
      "epoch: 55 train_loss: tensor(1.2202, grad_fn=<NllLossBackward>) average train loss tensor(1.4031, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6299337748344371 val_avg_loss: tensor(1.3387)\n",
      "epoch: 56 train_loss: tensor(1.2081, grad_fn=<NllLossBackward>) average train loss tensor(1.4036, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6298160412067697 val_avg_loss: tensor(1.3364)\n",
      "epoch: 57 train_loss: tensor(1.2113, grad_fn=<NllLossBackward>) average train loss tensor(1.3990, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6292273730684327 val_avg_loss: tensor(1.3367)\n",
      "epoch: 58 train_loss: tensor(1.2104, grad_fn=<NllLossBackward>) average train loss tensor(1.3977, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6290802060338484 val_avg_loss: tensor(1.3385)\n",
      "epoch: 59 train_loss: tensor(1.1732, grad_fn=<NllLossBackward>) average train loss tensor(1.3994, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.629374540103017 val_avg_loss: tensor(1.3384)\n",
      "epoch: 60 train_loss: tensor(1.1576, grad_fn=<NllLossBackward>) average train loss tensor(1.3968, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6301986754966887 val_avg_loss: tensor(1.3356)\n",
      "epoch: 61 train_loss: tensor(1.1613, grad_fn=<NllLossBackward>) average train loss tensor(1.3943, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.630345842531273 val_avg_loss: tensor(1.3348)\n",
      "epoch: 62 train_loss: tensor(1.2173, grad_fn=<NllLossBackward>) average train loss tensor(1.3920, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6292568064753495 val_avg_loss: tensor(1.3331)\n",
      "epoch: 63 train_loss: tensor(1.1662, grad_fn=<NllLossBackward>) average train loss tensor(1.3900, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6304635761589404 val_avg_loss: tensor(1.3372)\n",
      "epoch: 64 train_loss: tensor(1.1581, grad_fn=<NllLossBackward>) average train loss tensor(1.3888, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6298454746136866 val_avg_loss: tensor(1.3350)\n",
      "epoch: 65 train_loss: tensor(1.1587, grad_fn=<NllLossBackward>) average train loss tensor(1.3863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6314937454010302 val_avg_loss: tensor(1.3316)\n",
      "epoch: 66 train_loss: tensor(1.1751, grad_fn=<NllLossBackward>) average train loss tensor(1.3871, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6306107431935246 val_avg_loss: tensor(1.3343)\n",
      "epoch: 67 train_loss: tensor(1.1799, grad_fn=<NllLossBackward>) average train loss tensor(1.3861, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6300220750551876 val_avg_loss: tensor(1.3360)\n",
      "epoch: 68 train_loss: tensor(1.1675, grad_fn=<NllLossBackward>) average train loss tensor(1.3843, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6312582781456954 val_avg_loss: tensor(1.3332)\n",
      "epoch: 69 train_loss: tensor(1.1733, grad_fn=<NllLossBackward>) average train loss tensor(1.3824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6310228108903606 val_avg_loss: tensor(1.3330)\n",
      "epoch: 70 train_loss: tensor(1.1243, grad_fn=<NllLossBackward>) average train loss tensor(1.3817, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6292568064753495 val_avg_loss: tensor(1.3341)\n",
      "epoch: 71 train_loss: tensor(1.1862, grad_fn=<NllLossBackward>) average train loss tensor(1.3797, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6297866077998528 val_avg_loss: tensor(1.3332)\n",
      "epoch: 72 train_loss: tensor(1.1545, grad_fn=<NllLossBackward>) average train loss tensor(1.3783, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6307873436350258 val_avg_loss: tensor(1.3315)\n",
      "epoch: 73 train_loss: tensor(1.1385, grad_fn=<NllLossBackward>) average train loss tensor(1.3779, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6308167770419426 val_avg_loss: tensor(1.3331)\n",
      "epoch: 74 train_loss: tensor(1.2094, grad_fn=<NllLossBackward>) average train loss tensor(1.3788, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6315526122148639 val_avg_loss: tensor(1.3327)\n",
      "epoch: 75 train_loss: tensor(1.1679, grad_fn=<NllLossBackward>) average train loss tensor(1.3741, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.629551140544518 val_avg_loss: tensor(1.3304)\n",
      "epoch: 76 train_loss: tensor(1.1505, grad_fn=<NllLossBackward>) average train loss tensor(1.3711, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6304930095658573 val_avg_loss: tensor(1.3327)\n",
      "epoch: 77 train_loss: tensor(1.1612, grad_fn=<NllLossBackward>) average train loss tensor(1.3762, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6314054451802796 val_avg_loss: tensor(1.3337)\n",
      "epoch: 78 train_loss: tensor(1.1487, grad_fn=<NllLossBackward>) average train loss tensor(1.3764, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6311699779249448 val_avg_loss: tensor(1.3313)\n",
      "epoch: 79 train_loss: tensor(1.1526, grad_fn=<NllLossBackward>) average train loss tensor(1.3722, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6306990434142752 val_avg_loss: tensor(1.3319)\n",
      "epoch: 80 train_loss: tensor(1.1786, grad_fn=<NllLossBackward>) average train loss tensor(1.3724, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6311111111111111 val_avg_loss: tensor(1.3345)\n",
      "epoch: 81 train_loss: tensor(1.1190, grad_fn=<NllLossBackward>) average train loss tensor(1.3680, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6302281089036056 val_avg_loss: tensor(1.3343)\n",
      "epoch: 82 train_loss: tensor(1.0938, grad_fn=<NllLossBackward>) average train loss tensor(1.3669, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6304930095658573 val_avg_loss: tensor(1.3314)\n",
      "epoch: 83 train_loss: tensor(1.1408, grad_fn=<NllLossBackward>) average train loss tensor(1.3687, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6316114790286975 val_avg_loss: tensor(1.3308)\n",
      "epoch: 84 train_loss: tensor(1.1314, grad_fn=<NllLossBackward>) average train loss tensor(1.3658, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6311994113318616 val_avg_loss: tensor(1.3304)\n",
      "epoch: 85 train_loss: tensor(1.1351, grad_fn=<NllLossBackward>) average train loss tensor(1.3675, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6323767476085357 val_avg_loss: tensor(1.3294)\n",
      "epoch: 86 train_loss: tensor(1.1661, grad_fn=<NllLossBackward>) average train loss tensor(1.3659, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6313760117733628 val_avg_loss: tensor(1.3314)\n",
      "epoch: 87 train_loss: tensor(1.1289, grad_fn=<NllLossBackward>) average train loss tensor(1.3641, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6317880794701987 val_avg_loss: tensor(1.3302)\n",
      "epoch: 88 train_loss: tensor(1.1373, grad_fn=<NllLossBackward>) average train loss tensor(1.3621, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6317880794701987 val_avg_loss: tensor(1.3303)\n",
      "epoch: 89 train_loss: tensor(1.1539, grad_fn=<NllLossBackward>) average train loss tensor(1.3619, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.629963208241354 val_avg_loss: tensor(1.3323)\n",
      "epoch: 90 train_loss: tensor(1.1024, grad_fn=<NllLossBackward>) average train loss tensor(1.3592, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6308462104488595 val_avg_loss: tensor(1.3301)\n",
      "epoch: 91 train_loss: tensor(1.1754, grad_fn=<NllLossBackward>) average train loss tensor(1.3621, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6317880794701987 val_avg_loss: tensor(1.3313)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 train_loss: tensor(1.1189, grad_fn=<NllLossBackward>) average train loss tensor(1.3611, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6318763796909492 val_avg_loss: tensor(1.3310)\n",
      "epoch: 93 train_loss: tensor(1.0899, grad_fn=<NllLossBackward>) average train loss tensor(1.3613, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6324061810154525 val_avg_loss: tensor(1.3270)\n",
      "epoch: 94 train_loss: tensor(1.1107, grad_fn=<NllLossBackward>) average train loss tensor(1.3595, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6316409124356144 val_avg_loss: tensor(1.3303)\n",
      "epoch: 95 train_loss: tensor(1.1115, grad_fn=<NllLossBackward>) average train loss tensor(1.3561, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6312877115526122 val_avg_loss: tensor(1.3295)\n",
      "epoch: 96 train_loss: tensor(1.1393, grad_fn=<NllLossBackward>) average train loss tensor(1.3543, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6320529801324504 val_avg_loss: tensor(1.3286)\n",
      "epoch: 97 train_loss: tensor(1.0952, grad_fn=<NllLossBackward>) average train loss tensor(1.3577, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6309933774834438 val_avg_loss: tensor(1.3314)\n",
      "epoch: 98 train_loss: tensor(1.1484, grad_fn=<NllLossBackward>) average train loss tensor(1.3551, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6330831493745401 val_avg_loss: tensor(1.3296)\n",
      "epoch: 99 train_loss: tensor(1.0994, grad_fn=<NllLossBackward>) average train loss tensor(1.3534, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.6311994113318616 val_avg_loss: tensor(1.3288)\n"
     ]
    }
   ],
   "source": [
    "encoder_c_256_wd = copy.deepcopy(autoencoder_c_256.encoder)\n",
    "        \n",
    "after_encoder_model_c_256_wd = AfterEncoderModel2(encoder_c_256_wd, d=128, drop=0.5)\n",
    "optimizer_aem_c_256_wd = torch.optim.Adam(after_encoder_model_c_256_wd.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "        \n",
    "writer = SummaryWriter('runs/aem2_full_c_256_bs2048_rs42_d128_drop05_wd0005_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_c_256_wd,\n",
    "    optimizer=optimizer_aem_c_256_wd,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8078, grad_fn=<NllLossBackward>) average train loss tensor(3.8810, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.08688741721854305 val_avg_loss: tensor(3.7525)\n",
      "epoch: 1 train_loss: tensor(3.6504, grad_fn=<NllLossBackward>) average train loss tensor(3.6963, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.13200883002207506 val_avg_loss: tensor(3.5889)\n",
      "epoch: 2 train_loss: tensor(3.4808, grad_fn=<NllLossBackward>) average train loss tensor(3.5614, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.1746578366445916 val_avg_loss: tensor(3.4441)\n",
      "epoch: 3 train_loss: tensor(3.3523, grad_fn=<NllLossBackward>) average train loss tensor(3.4017, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2427373068432671 val_avg_loss: tensor(3.2909)\n",
      "epoch: 4 train_loss: tensor(3.1856, grad_fn=<NllLossBackward>) average train loss tensor(3.2596, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.25901398086828553 val_avg_loss: tensor(3.1374)\n",
      "epoch: 5 train_loss: tensor(3.0573, grad_fn=<NllLossBackward>) average train loss tensor(3.1272, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.29133186166298747 val_avg_loss: tensor(2.9698)\n",
      "epoch: 6 train_loss: tensor(2.8310, grad_fn=<NllLossBackward>) average train loss tensor(2.9424, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.32547461368653424 val_avg_loss: tensor(2.8161)\n",
      "epoch: 7 train_loss: tensor(2.6927, grad_fn=<NllLossBackward>) average train loss tensor(2.8043, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3416924208977189 val_avg_loss: tensor(2.6738)\n",
      "epoch: 8 train_loss: tensor(2.5851, grad_fn=<NllLossBackward>) average train loss tensor(2.6656, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.35979396615158205 val_avg_loss: tensor(2.5472)\n",
      "epoch: 9 train_loss: tensor(2.4083, grad_fn=<NllLossBackward>) average train loss tensor(2.5290, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3836644591611479 val_avg_loss: tensor(2.4427)\n",
      "epoch: 10 train_loss: tensor(2.3076, grad_fn=<NllLossBackward>) average train loss tensor(2.4076, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.39570272259013983 val_avg_loss: tensor(2.3539)\n",
      "epoch: 11 train_loss: tensor(2.2053, grad_fn=<NllLossBackward>) average train loss tensor(2.3107, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4077704194260486 val_avg_loss: tensor(2.2808)\n",
      "epoch: 12 train_loss: tensor(2.1259, grad_fn=<NllLossBackward>) average train loss tensor(2.2034, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42004415011037527 val_avg_loss: tensor(2.2179)\n",
      "epoch: 13 train_loss: tensor(2.0332, grad_fn=<NllLossBackward>) average train loss tensor(2.1289, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4351140544518028 val_avg_loss: tensor(2.1629)\n",
      "epoch: 14 train_loss: tensor(1.9826, grad_fn=<NllLossBackward>) average train loss tensor(2.0447, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44526857983811624 val_avg_loss: tensor(2.1162)\n",
      "epoch: 15 train_loss: tensor(1.8659, grad_fn=<NllLossBackward>) average train loss tensor(1.9574, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4530978660779985 val_avg_loss: tensor(2.0779)\n",
      "epoch: 16 train_loss: tensor(1.7819, grad_fn=<NllLossBackward>) average train loss tensor(1.8650, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4594260485651214 val_avg_loss: tensor(2.0509)\n",
      "epoch: 17 train_loss: tensor(1.7653, grad_fn=<NllLossBackward>) average train loss tensor(1.8192, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46566593083149377 val_avg_loss: tensor(2.0242)\n",
      "epoch: 18 train_loss: tensor(1.6821, grad_fn=<NllLossBackward>) average train loss tensor(1.7465, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46554819720382634 val_avg_loss: tensor(2.0116)\n",
      "epoch: 19 train_loss: tensor(1.6047, grad_fn=<NllLossBackward>) average train loss tensor(1.6806, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46881530537159677 val_avg_loss: tensor(2.0025)\n",
      "epoch: 20 train_loss: tensor(1.5890, grad_fn=<NllLossBackward>) average train loss tensor(1.6465, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4716997792494481 val_avg_loss: tensor(1.9990)\n",
      "epoch: 21 train_loss: tensor(1.5816, grad_fn=<NllLossBackward>) average train loss tensor(1.6171, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47320088300220753 val_avg_loss: tensor(1.9785)\n",
      "epoch: 22 train_loss: tensor(1.4621, grad_fn=<NllLossBackward>) average train loss tensor(1.5818, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47340691685062547 val_avg_loss: tensor(1.9755)\n",
      "epoch: 23 train_loss: tensor(1.4735, grad_fn=<NllLossBackward>) average train loss tensor(1.5230, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4761442236938926 val_avg_loss: tensor(1.9687)\n",
      "epoch: 24 train_loss: tensor(1.3342, grad_fn=<NllLossBackward>) average train loss tensor(1.4300, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47832229580573954 val_avg_loss: tensor(1.9697)\n",
      "epoch: 25 train_loss: tensor(1.3363, grad_fn=<NllLossBackward>) average train loss tensor(1.4287, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48070640176600443 val_avg_loss: tensor(1.9825)\n",
      "epoch: 26 train_loss: tensor(1.2428, grad_fn=<NllLossBackward>) average train loss tensor(1.3802, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48373804267844 val_avg_loss: tensor(1.9956)\n",
      "epoch: 27 train_loss: tensor(1.2972, grad_fn=<NllLossBackward>) average train loss tensor(1.3442, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48676968359087563 val_avg_loss: tensor(1.9910)\n",
      "epoch: 28 train_loss: tensor(1.3219, grad_fn=<NllLossBackward>) average train loss tensor(1.3240, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48806475349521705 val_avg_loss: tensor(1.9806)\n",
      "epoch: 29 train_loss: tensor(1.1512, grad_fn=<NllLossBackward>) average train loss tensor(1.3090, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4844738778513613 val_avg_loss: tensor(1.9918)\n",
      "epoch: 30 train_loss: tensor(1.2255, grad_fn=<NllLossBackward>) average train loss tensor(1.2804, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48429727740986017 val_avg_loss: tensor(2.0011)\n",
      "epoch: 31 train_loss: tensor(1.1313, grad_fn=<NllLossBackward>) average train loss tensor(1.2092, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4863281824871229 val_avg_loss: tensor(2.0047)\n",
      "epoch: 32 train_loss: tensor(1.1059, grad_fn=<NllLossBackward>) average train loss tensor(1.2003, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4890066225165563 val_avg_loss: tensor(2.0179)\n",
      "epoch: 33 train_loss: tensor(1.0827, grad_fn=<NllLossBackward>) average train loss tensor(1.1880, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4883296541574687 val_avg_loss: tensor(2.0274)\n",
      "epoch: 34 train_loss: tensor(1.0385, grad_fn=<NllLossBackward>) average train loss tensor(1.1229, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48806475349521705 val_avg_loss: tensor(2.0453)\n",
      "epoch: 35 train_loss: tensor(1.0613, grad_fn=<NllLossBackward>) average train loss tensor(1.0958, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4880941869021339 val_avg_loss: tensor(2.0695)\n",
      "epoch: 36 train_loss: tensor(0.9657, grad_fn=<NllLossBackward>) average train loss tensor(1.0869, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4915378955114054 val_avg_loss: tensor(2.0668)\n",
      "epoch: 37 train_loss: tensor(0.9698, grad_fn=<NllLossBackward>) average train loss tensor(1.0611, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4899484915378955 val_avg_loss: tensor(2.0711)\n",
      "epoch: 38 train_loss: tensor(0.9660, grad_fn=<NllLossBackward>) average train loss tensor(1.0758, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4869757174392936 val_avg_loss: tensor(2.0881)\n",
      "epoch: 39 train_loss: tensor(0.9661, grad_fn=<NllLossBackward>) average train loss tensor(1.0029, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4855040470934511 val_avg_loss: tensor(2.1090)\n",
      "epoch: 40 train_loss: tensor(0.9216, grad_fn=<NllLossBackward>) average train loss tensor(1.0179, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48991905813097864 val_avg_loss: tensor(2.1117)\n",
      "epoch: 41 train_loss: tensor(0.8607, grad_fn=<NllLossBackward>) average train loss tensor(0.9828, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49044885945548194 val_avg_loss: tensor(2.1260)\n",
      "epoch: 42 train_loss: tensor(0.8425, grad_fn=<NllLossBackward>) average train loss tensor(0.9270, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.487682119205298 val_avg_loss: tensor(2.1512)\n",
      "epoch: 43 train_loss: tensor(0.7905, grad_fn=<NllLossBackward>) average train loss tensor(0.9096, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48615158204562176 val_avg_loss: tensor(2.1772)\n",
      "epoch: 44 train_loss: tensor(0.7598, grad_fn=<NllLossBackward>) average train loss tensor(0.8799, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4859455481972038 val_avg_loss: tensor(2.1911)\n",
      "epoch: 45 train_loss: tensor(0.7569, grad_fn=<NllLossBackward>) average train loss tensor(0.9029, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4859455481972038 val_avg_loss: tensor(2.2170)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_loss: tensor(0.7724, grad_fn=<NllLossBackward>) average train loss tensor(0.8505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4861810154525386 val_avg_loss: tensor(2.2290)\n",
      "epoch: 47 train_loss: tensor(0.8126, grad_fn=<NllLossBackward>) average train loss tensor(0.8611, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48538631346578365 val_avg_loss: tensor(2.2224)\n",
      "epoch: 48 train_loss: tensor(0.7241, grad_fn=<NllLossBackward>) average train loss tensor(0.8139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.483944076526858 val_avg_loss: tensor(2.2390)\n",
      "epoch: 49 train_loss: tensor(0.8217, grad_fn=<NllLossBackward>) average train loss tensor(0.8322, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48515084621044885 val_avg_loss: tensor(2.2730)\n",
      "epoch: 50 train_loss: tensor(0.7340, grad_fn=<NllLossBackward>) average train loss tensor(0.7984, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4840323767476085 val_avg_loss: tensor(2.2836)\n",
      "epoch: 51 train_loss: tensor(0.6794, grad_fn=<NllLossBackward>) average train loss tensor(0.7841, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4854157468727005 val_avg_loss: tensor(2.2756)\n",
      "epoch: 52 train_loss: tensor(0.6490, grad_fn=<NllLossBackward>) average train loss tensor(0.7473, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4867108167770419 val_avg_loss: tensor(2.2899)\n",
      "epoch: 53 train_loss: tensor(0.7000, grad_fn=<NllLossBackward>) average train loss tensor(0.7420, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4866225165562914 val_avg_loss: tensor(2.3205)\n",
      "epoch: 54 train_loss: tensor(0.6717, grad_fn=<NllLossBackward>) average train loss tensor(0.7504, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48444444444444446 val_avg_loss: tensor(2.3449)\n",
      "epoch: 55 train_loss: tensor(0.6272, grad_fn=<NllLossBackward>) average train loss tensor(0.7429, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48353200883002206 val_avg_loss: tensor(2.3577)\n",
      "epoch: 56 train_loss: tensor(0.6737, grad_fn=<NllLossBackward>) average train loss tensor(0.7450, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48415011037527594 val_avg_loss: tensor(2.3439)\n",
      "epoch: 57 train_loss: tensor(0.6439, grad_fn=<NllLossBackward>) average train loss tensor(0.7379, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4837086092715232 val_avg_loss: tensor(2.3386)\n",
      "epoch: 58 train_loss: tensor(0.6058, grad_fn=<NllLossBackward>) average train loss tensor(0.7113, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4837969094922737 val_avg_loss: tensor(2.3659)\n",
      "epoch: 59 train_loss: tensor(0.5768, grad_fn=<NllLossBackward>) average train loss tensor(0.6729, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4779102281089036 val_avg_loss: tensor(2.4030)\n",
      "epoch: 60 train_loss: tensor(0.5868, grad_fn=<NllLossBackward>) average train loss tensor(0.6703, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4807358351729213 val_avg_loss: tensor(2.4229)\n",
      "epoch: 61 train_loss: tensor(0.6563, grad_fn=<NllLossBackward>) average train loss tensor(0.6788, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4854157468727005 val_avg_loss: tensor(2.4272)\n",
      "epoch: 62 train_loss: tensor(0.5792, grad_fn=<NllLossBackward>) average train loss tensor(0.6459, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48438557763061074 val_avg_loss: tensor(2.4433)\n",
      "epoch: 63 train_loss: tensor(0.5490, grad_fn=<NllLossBackward>) average train loss tensor(0.6457, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48253127299484916 val_avg_loss: tensor(2.4639)\n",
      "epoch: 64 train_loss: tensor(0.5740, grad_fn=<NllLossBackward>) average train loss tensor(0.6162, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48114790286975717 val_avg_loss: tensor(2.4756)\n",
      "epoch: 65 train_loss: tensor(0.5006, grad_fn=<NllLossBackward>) average train loss tensor(0.6139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48153053715967625 val_avg_loss: tensor(2.4823)\n",
      "epoch: 66 train_loss: tensor(0.5915, grad_fn=<NllLossBackward>) average train loss tensor(0.6189, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48200147167034585 val_avg_loss: tensor(2.4838)\n",
      "epoch: 67 train_loss: tensor(0.4860, grad_fn=<NllLossBackward>) average train loss tensor(0.5704, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47894039735099336 val_avg_loss: tensor(2.5079)\n",
      "epoch: 68 train_loss: tensor(0.5847, grad_fn=<NllLossBackward>) average train loss tensor(0.6252, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4812067696835909 val_avg_loss: tensor(2.5362)\n",
      "epoch: 69 train_loss: tensor(0.5163, grad_fn=<NllLossBackward>) average train loss tensor(0.5612, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48038263428991906 val_avg_loss: tensor(2.5628)\n",
      "epoch: 70 train_loss: tensor(0.5024, grad_fn=<NllLossBackward>) average train loss tensor(0.5435, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4832082413539367 val_avg_loss: tensor(2.5409)\n",
      "epoch: 71 train_loss: tensor(0.4692, grad_fn=<NllLossBackward>) average train loss tensor(0.5627, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4789992641648271 val_avg_loss: tensor(2.5663)\n",
      "epoch: 72 train_loss: tensor(0.4880, grad_fn=<NllLossBackward>) average train loss tensor(0.5688, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4801177336276674 val_avg_loss: tensor(2.5796)\n",
      "epoch: 73 train_loss: tensor(0.4306, grad_fn=<NllLossBackward>) average train loss tensor(0.5120, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4785871964679912 val_avg_loss: tensor(2.5844)\n",
      "epoch: 74 train_loss: tensor(0.4990, grad_fn=<NllLossBackward>) average train loss tensor(0.5352, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4791464311994113 val_avg_loss: tensor(2.5942)\n",
      "epoch: 75 train_loss: tensor(0.4318, grad_fn=<NllLossBackward>) average train loss tensor(0.4980, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47926416482707873 val_avg_loss: tensor(2.6282)\n",
      "epoch: 76 train_loss: tensor(0.4378, grad_fn=<NllLossBackward>) average train loss tensor(0.5143, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47902869757174393 val_avg_loss: tensor(2.6478)\n",
      "epoch: 77 train_loss: tensor(0.4909, grad_fn=<NllLossBackward>) average train loss tensor(0.5106, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48070640176600443 val_avg_loss: tensor(2.6433)\n",
      "epoch: 78 train_loss: tensor(0.4091, grad_fn=<NllLossBackward>) average train loss tensor(0.4830, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4811184694628403 val_avg_loss: tensor(2.6652)\n",
      "epoch: 79 train_loss: tensor(0.4240, grad_fn=<NllLossBackward>) average train loss tensor(0.5007, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.48123620309050774 val_avg_loss: tensor(2.6862)\n",
      "epoch: 80 train_loss: tensor(0.4062, grad_fn=<NllLossBackward>) average train loss tensor(0.4677, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4786754966887417 val_avg_loss: tensor(2.7030)\n",
      "epoch: 81 train_loss: tensor(0.4478, grad_fn=<NllLossBackward>) average train loss tensor(0.4920, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.478822663723326 val_avg_loss: tensor(2.7050)\n",
      "epoch: 82 train_loss: tensor(0.4443, grad_fn=<NllLossBackward>) average train loss tensor(0.4613, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.477439293598234 val_avg_loss: tensor(2.7132)\n",
      "epoch: 83 train_loss: tensor(0.4160, grad_fn=<NllLossBackward>) average train loss tensor(0.4816, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47841059602649005 val_avg_loss: tensor(2.7260)\n",
      "epoch: 84 train_loss: tensor(0.3816, grad_fn=<NllLossBackward>) average train loss tensor(0.4495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4781456953642384 val_avg_loss: tensor(2.7343)\n",
      "epoch: 85 train_loss: tensor(0.3479, grad_fn=<NllLossBackward>) average train loss tensor(0.4295, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4758498896247241 val_avg_loss: tensor(2.7503)\n",
      "epoch: 86 train_loss: tensor(0.3777, grad_fn=<NllLossBackward>) average train loss tensor(0.4505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47726269315673286 val_avg_loss: tensor(2.7600)\n",
      "epoch: 87 train_loss: tensor(0.3595, grad_fn=<NllLossBackward>) average train loss tensor(0.4140, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4769094922737307 val_avg_loss: tensor(2.7884)\n",
      "epoch: 88 train_loss: tensor(0.3410, grad_fn=<NllLossBackward>) average train loss tensor(0.4154, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4728476821192053 val_avg_loss: tensor(2.8419)\n",
      "epoch: 89 train_loss: tensor(0.4033, grad_fn=<NllLossBackward>) average train loss tensor(0.4183, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47673289183222956 val_avg_loss: tensor(2.8717)\n",
      "epoch: 90 train_loss: tensor(0.3732, grad_fn=<NllLossBackward>) average train loss tensor(0.4040, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.479205298013245 val_avg_loss: tensor(2.8641)\n",
      "epoch: 91 train_loss: tensor(0.3637, grad_fn=<NllLossBackward>) average train loss tensor(0.4139, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4782045621780721 val_avg_loss: tensor(2.8514)\n",
      "epoch: 92 train_loss: tensor(0.3410, grad_fn=<NllLossBackward>) average train loss tensor(0.4016, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.4772038263428992 val_avg_loss: tensor(2.8618)\n",
      "epoch: 93 train_loss: tensor(0.3567, grad_fn=<NllLossBackward>) average train loss tensor(0.3959, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47764532744665195 val_avg_loss: tensor(2.8741)\n",
      "epoch: 94 train_loss: tensor(0.3177, grad_fn=<NllLossBackward>) average train loss tensor(0.3947, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4768211920529801 val_avg_loss: tensor(2.8841)\n",
      "epoch: 95 train_loss: tensor(0.3443, grad_fn=<NllLossBackward>) average train loss tensor(0.3900, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.476055923473142 val_avg_loss: tensor(2.9000)\n",
      "epoch: 96 train_loss: tensor(0.3286, grad_fn=<NllLossBackward>) average train loss tensor(0.3766, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4770566593083149 val_avg_loss: tensor(2.9173)\n",
      "epoch: 97 train_loss: tensor(0.3123, grad_fn=<NllLossBackward>) average train loss tensor(0.3780, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47764532744665195 val_avg_loss: tensor(2.9187)\n",
      "epoch: 98 train_loss: tensor(0.2831, grad_fn=<NllLossBackward>) average train loss tensor(0.3710, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4767623252391464 val_avg_loss: tensor(2.9543)\n",
      "epoch: 99 train_loss: tensor(0.3537, grad_fn=<NllLossBackward>) average train loss tensor(0.3832, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47688005886681384 val_avg_loss: tensor(2.9693)\n",
      "epoch: 100 train_loss: tensor(0.3038, grad_fn=<NllLossBackward>) average train loss tensor(0.3643, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4769683590875644 val_avg_loss: tensor(2.9533)\n",
      "epoch: 101 train_loss: tensor(0.2903, grad_fn=<NllLossBackward>) average train loss tensor(0.3639, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4758204562178072 val_avg_loss: tensor(2.9286)\n",
      "epoch: 102 train_loss: tensor(0.3372, grad_fn=<NllLossBackward>) average train loss tensor(0.3767, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4775275938189846 val_avg_loss: tensor(2.9308)\n",
      "epoch: 103 train_loss: tensor(0.3110, grad_fn=<NllLossBackward>) average train loss tensor(0.3377, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47740986019131715 val_avg_loss: tensor(2.9698)\n",
      "epoch: 104 train_loss: tensor(0.2767, grad_fn=<NllLossBackward>) average train loss tensor(0.3419, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47334805003679176 val_avg_loss: tensor(2.9949)\n",
      "epoch: 105 train_loss: tensor(0.3295, grad_fn=<NllLossBackward>) average train loss tensor(0.3671, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4749374540103017 val_avg_loss: tensor(2.9895)\n",
      "epoch: 106 train_loss: tensor(0.2995, grad_fn=<NllLossBackward>) average train loss tensor(0.3326, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47240618101545256 val_avg_loss: tensor(3.0200)\n",
      "epoch: 107 train_loss: tensor(0.2805, grad_fn=<NllLossBackward>) average train loss tensor(0.3164, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47511405445180277 val_avg_loss: tensor(3.0552)\n",
      "epoch: 108 train_loss: tensor(0.2554, grad_fn=<NllLossBackward>) average train loss tensor(0.3257, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47573215599705665 val_avg_loss: tensor(3.0754)\n",
      "epoch: 109 train_loss: tensor(0.3072, grad_fn=<NllLossBackward>) average train loss tensor(0.3173, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4784988962472406 val_avg_loss: tensor(3.1128)\n",
      "epoch: 110 train_loss: tensor(0.2790, grad_fn=<NllLossBackward>) average train loss tensor(0.3114, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4765268579838116 val_avg_loss: tensor(3.1389)\n",
      "epoch: 111 train_loss: tensor(0.3329, grad_fn=<NllLossBackward>) average train loss tensor(0.3530, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4755849889624724 val_avg_loss: tensor(3.1376)\n",
      "epoch: 112 train_loss: tensor(0.2648, grad_fn=<NllLossBackward>) average train loss tensor(0.3198, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4752906548933039 val_avg_loss: tensor(3.1200)\n",
      "epoch: 113 train_loss: tensor(0.3175, grad_fn=<NllLossBackward>) average train loss tensor(0.3297, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47779249448123623 val_avg_loss: tensor(3.0896)\n",
      "epoch: 114 train_loss: tensor(0.2481, grad_fn=<NllLossBackward>) average train loss tensor(0.3082, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.473701250919794 val_avg_loss: tensor(3.0891)\n",
      "epoch: 115 train_loss: tensor(0.3075, grad_fn=<NllLossBackward>) average train loss tensor(0.2952, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47264164827078736 val_avg_loss: tensor(3.1139)\n",
      "epoch: 116 train_loss: tensor(0.2431, grad_fn=<NllLossBackward>) average train loss tensor(0.3000, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47473142016188374 val_avg_loss: tensor(3.1354)\n",
      "epoch: 117 train_loss: tensor(0.2356, grad_fn=<NllLossBackward>) average train loss tensor(0.2863, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47735099337748343 val_avg_loss: tensor(3.1549)\n",
      "epoch: 118 train_loss: tensor(0.3039, grad_fn=<NllLossBackward>) average train loss tensor(0.3131, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47617365710080944 val_avg_loss: tensor(3.1757)\n",
      "epoch: 119 train_loss: tensor(0.2589, grad_fn=<NllLossBackward>) average train loss tensor(0.3109, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47723325974981606 val_avg_loss: tensor(3.1612)\n",
      "epoch: 120 train_loss: tensor(0.2301, grad_fn=<NllLossBackward>) average train loss tensor(0.2814, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4762325239146431 val_avg_loss: tensor(3.1792)\n",
      "epoch: 121 train_loss: tensor(0.2284, grad_fn=<NllLossBackward>) average train loss tensor(0.2744, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4759970566593083 val_avg_loss: tensor(3.2029)\n",
      "epoch: 122 train_loss: tensor(0.2531, grad_fn=<NllLossBackward>) average train loss tensor(0.3087, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4744665194996321 val_avg_loss: tensor(3.2067)\n",
      "epoch: 123 train_loss: tensor(0.2798, grad_fn=<NllLossBackward>) average train loss tensor(0.2955, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748491537895511 val_avg_loss: tensor(3.2157)\n",
      "epoch: 124 train_loss: tensor(0.2228, grad_fn=<NllLossBackward>) average train loss tensor(0.2480, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4782928623988227 val_avg_loss: tensor(3.2221)\n",
      "epoch: 125 train_loss: tensor(0.2847, grad_fn=<NllLossBackward>) average train loss tensor(0.2786, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47879323031640914 val_avg_loss: tensor(3.2214)\n",
      "epoch: 126 train_loss: tensor(0.3191, grad_fn=<NllLossBackward>) average train loss tensor(0.2928, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4781456953642384 val_avg_loss: tensor(3.2368)\n",
      "epoch: 127 train_loss: tensor(0.2034, grad_fn=<NllLossBackward>) average train loss tensor(0.2719, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4750551876379691 val_avg_loss: tensor(3.2527)\n",
      "epoch: 128 train_loss: tensor(0.2553, grad_fn=<NllLossBackward>) average train loss tensor(0.2525, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47358351729212655 val_avg_loss: tensor(3.2790)\n",
      "epoch: 129 train_loss: tensor(0.2073, grad_fn=<NllLossBackward>) average train loss tensor(0.2571, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4735540838852097 val_avg_loss: tensor(3.2629)\n",
      "epoch: 130 train_loss: tensor(0.2228, grad_fn=<NllLossBackward>) average train loss tensor(0.2825, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47181751287711554 val_avg_loss: tensor(3.2682)\n",
      "epoch: 131 train_loss: tensor(0.2318, grad_fn=<NllLossBackward>) average train loss tensor(0.2695, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47358351729212655 val_avg_loss: tensor(3.2809)\n",
      "epoch: 132 train_loss: tensor(0.2275, grad_fn=<NllLossBackward>) average train loss tensor(0.2669, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47323031640912433 val_avg_loss: tensor(3.2708)\n",
      "epoch: 133 train_loss: tensor(0.2102, grad_fn=<NllLossBackward>) average train loss tensor(0.2505, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4723767476085357 val_avg_loss: tensor(3.2596)\n",
      "epoch: 134 train_loss: tensor(0.2394, grad_fn=<NllLossBackward>) average train loss tensor(0.2486, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47311258278145696 val_avg_loss: tensor(3.2611)\n",
      "epoch: 135 train_loss: tensor(0.1807, grad_fn=<NllLossBackward>) average train loss tensor(0.2378, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47287711552612216 val_avg_loss: tensor(3.2948)\n",
      "epoch: 136 train_loss: tensor(0.1777, grad_fn=<NllLossBackward>) average train loss tensor(0.2622, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47443708609271523 val_avg_loss: tensor(3.3138)\n",
      "epoch: 137 train_loss: tensor(0.1904, grad_fn=<NllLossBackward>) average train loss tensor(0.2398, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4725533480500368 val_avg_loss: tensor(3.3424)\n",
      "epoch: 138 train_loss: tensor(0.1741, grad_fn=<NllLossBackward>) average train loss tensor(0.2326, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc: 0.47220014716703457 val_avg_loss: tensor(3.3470)\n",
      "epoch: 139 train_loss: tensor(0.2061, grad_fn=<NllLossBackward>) average train loss tensor(0.2680, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.473701250919794 val_avg_loss: tensor(3.3273)\n",
      "epoch: 140 train_loss: tensor(0.2232, grad_fn=<NllLossBackward>) average train loss tensor(0.2372, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47220014716703457 val_avg_loss: tensor(3.3453)\n",
      "epoch: 141 train_loss: tensor(0.1922, grad_fn=<NllLossBackward>) average train loss tensor(0.2106, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4714643119941133 val_avg_loss: tensor(3.3346)\n",
      "epoch: 142 train_loss: tensor(0.2550, grad_fn=<NllLossBackward>) average train loss tensor(0.2474, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47299484915378953 val_avg_loss: tensor(3.3458)\n",
      "epoch: 143 train_loss: tensor(0.1932, grad_fn=<NllLossBackward>) average train loss tensor(0.2217, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4749963208241354 val_avg_loss: tensor(3.3816)\n",
      "epoch: 144 train_loss: tensor(0.2067, grad_fn=<NllLossBackward>) average train loss tensor(0.2328, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4760853568800589 val_avg_loss: tensor(3.3860)\n",
      "epoch: 145 train_loss: tensor(0.1943, grad_fn=<NllLossBackward>) average train loss tensor(0.2246, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47196467991169977 val_avg_loss: tensor(3.3624)\n",
      "epoch: 146 train_loss: tensor(0.1946, grad_fn=<NllLossBackward>) average train loss tensor(0.2134, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4733774834437086 val_avg_loss: tensor(3.3870)\n",
      "epoch: 147 train_loss: tensor(0.1821, grad_fn=<NllLossBackward>) average train loss tensor(0.2411, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4723767476085357 val_avg_loss: tensor(3.3909)\n",
      "epoch: 148 train_loss: tensor(0.2053, grad_fn=<NllLossBackward>) average train loss tensor(0.2182, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4748491537895511 val_avg_loss: tensor(3.3680)\n",
      "epoch: 149 train_loss: tensor(0.1848, grad_fn=<NllLossBackward>) average train loss tensor(0.2045, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4698160412067697 val_avg_loss: tensor(3.4033)\n"
     ]
    }
   ],
   "source": [
    "encoder_c_256_wd_2000 = copy.deepcopy(autoencoder_c_256.encoder)\n",
    "        \n",
    "after_encoder_model_c_256_wd_2000 = AfterEncoderModel2(encoder_c_256_wd_2000, d=128, drop=0.5)\n",
    "optimizer_aem_c_256_wd_2000 = torch.optim.Adam(after_encoder_model_c_256_wd_2000.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "        \n",
    "writer = SummaryWriter('runs/aem2_2000_c_256_bs2048_rs42_d128_drop05_wd0005_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_c_256_wd_2000,\n",
    "    optimizer=optimizer_aem_c_256_wd_2000,\n",
    "    epochs=150,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8102, grad_fn=<NllLossBackward>) average train loss tensor(3.9508, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.060456217807211186 val_avg_loss: tensor(3.8479)\n",
      "epoch: 1 train_loss: tensor(3.4707, grad_fn=<NllLossBackward>) average train loss tensor(3.5518, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.21816041206769685 val_avg_loss: tensor(3.6711)\n",
      "epoch: 2 train_loss: tensor(3.1964, grad_fn=<NllLossBackward>) average train loss tensor(3.2637, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.31620309050772627 val_avg_loss: tensor(3.4199)\n",
      "epoch: 3 train_loss: tensor(2.9629, grad_fn=<NllLossBackward>) average train loss tensor(3.0200, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3619131714495953 val_avg_loss: tensor(3.1346)\n",
      "epoch: 4 train_loss: tensor(2.7414, grad_fn=<NllLossBackward>) average train loss tensor(2.8060, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38631346578366443 val_avg_loss: tensor(2.8746)\n",
      "epoch: 5 train_loss: tensor(2.5161, grad_fn=<NllLossBackward>) average train loss tensor(2.6092, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4011184694628403 val_avg_loss: tensor(2.6681)\n",
      "epoch: 6 train_loss: tensor(2.3545, grad_fn=<NllLossBackward>) average train loss tensor(2.4555, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.41707137601177335 val_avg_loss: tensor(2.5076)\n",
      "epoch: 7 train_loss: tensor(2.2220, grad_fn=<NllLossBackward>) average train loss tensor(2.3104, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4333480500367918 val_avg_loss: tensor(2.3889)\n",
      "epoch: 8 train_loss: tensor(2.1249, grad_fn=<NllLossBackward>) average train loss tensor(2.1867, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4475055187637969 val_avg_loss: tensor(2.2989)\n",
      "epoch: 9 train_loss: tensor(2.0163, grad_fn=<NllLossBackward>) average train loss tensor(2.0773, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46154525386313466 val_avg_loss: tensor(2.2281)\n",
      "epoch: 10 train_loss: tensor(1.9043, grad_fn=<NllLossBackward>) average train loss tensor(1.9580, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4711699779249448 val_avg_loss: tensor(2.1716)\n",
      "epoch: 11 train_loss: tensor(1.7614, grad_fn=<NllLossBackward>) average train loss tensor(1.8495, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4789992641648271 val_avg_loss: tensor(2.1259)\n",
      "epoch: 12 train_loss: tensor(1.6565, grad_fn=<NllLossBackward>) average train loss tensor(1.7774, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4840323767476085 val_avg_loss: tensor(2.0885)\n",
      "epoch: 13 train_loss: tensor(1.6193, grad_fn=<NllLossBackward>) average train loss tensor(1.6593, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4880353200883002 val_avg_loss: tensor(2.0562)\n",
      "epoch: 14 train_loss: tensor(1.4819, grad_fn=<NllLossBackward>) average train loss tensor(1.5907, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49118469462840325 val_avg_loss: tensor(2.0290)\n",
      "epoch: 15 train_loss: tensor(1.4443, grad_fn=<NllLossBackward>) average train loss tensor(1.5114, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4949227373068433 val_avg_loss: tensor(2.0059)\n",
      "epoch: 16 train_loss: tensor(1.3333, grad_fn=<NllLossBackward>) average train loss tensor(1.4227, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.49839587932303164 val_avg_loss: tensor(1.9886)\n",
      "epoch: 17 train_loss: tensor(1.3001, grad_fn=<NllLossBackward>) average train loss tensor(1.3736, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.5003384841795437 val_avg_loss: tensor(1.9771)\n",
      "epoch: 18 train_loss: tensor(1.1994, grad_fn=<NllLossBackward>) average train loss tensor(1.3070, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoder_c_256_wd_2000 = copy.deepcopy(autoencoder_c_256.encoder)\n",
    "        \n",
    "after_encoder_model_c_256_wd_2000 = AfterEncoderModel2BN(encoder_c_256_wd_2000, d=128, drop=0.5)\n",
    "optimizer_aem_c_256_wd_2000 = torch.optim.Adam(after_encoder_model_c_256_wd_2000.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "        \n",
    "writer = SummaryWriter('runs/aem2bn_2000_c_256_bs2048_rs42_d128_drop05_wd0005_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_c_256_wd_2000,\n",
    "    optimizer=optimizer_aem_c_256_wd_2000,\n",
    "    epochs=80,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder similar to beggining of actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderComplex(nn.Module):\n",
    "    def __init__(self, d, drop=0.5):\n",
    "        super().__init__()\n",
    "        self.fc_img_1 = nn.Linear(IMG_LEN, d * 4)\n",
    "        self.fc_img_2 = nn.Linear(d * 4, d * 2)\n",
    "        \n",
    "        self.fc_txt_1 = nn.Linear(TXT_LEN, d * 2)\n",
    "        self.fc_txt_2 = nn.Linear(d * 2, d * 2)\n",
    "        \n",
    "        self.dropout = nn.modules.Dropout(p=drop)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x_img = self.dropout(F.relu(self.fc_img_1(inp_img)))\n",
    "        x_img = self.dropout(F.relu(self.fc_img_2(inp_img)))\n",
    "        \n",
    "        x_txt = self.dropout(F.relu(self.fc_txt_1(inp_txt)))\n",
    "        x_txt = self.dropout(F.relu(self.fc_txt_2(inp_txt)))\n",
    "        \n",
    "        x = F.relu(torch.cat((x_img, x_txt), 1))\n",
    "        return x\n",
    "    \n",
    "class DecoderComplex(nn.Module):\n",
    "    def __init__(self, d, drop=0.5):\n",
    "        super().__init__()\n",
    "        self.fc_img_1 = nn.Linear(2 * d, 4 * d)\n",
    "        self.fc_img_2 = nn.Linear(4 * d, IMG_LEN)\n",
    "        \n",
    "        self.fc_txt_1 = nn.Linear(2 * d, 2 * d)\n",
    "        self.fc_txt_2 = nn.Linear(2 * d, TXT_LEN)\n",
    "        \n",
    "        self.dropout = nn.modules.Dropout(p=drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_img = self.dropout(F.relu(self.fc_img_1(x)))\n",
    "        x_img = self.fc_img_2(x)\n",
    "        \n",
    "        x_txt = self.dropout(F.relu(self.fc_txt_1(x)))\n",
    "        x_txt = self.fc_txt_2(x)\n",
    "        \n",
    "        return x_img, x_txt\n",
    "\n",
    "class AutoencoderComplex(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d)\n",
    "        self.decoder = Decoder(d)\n",
    "        \n",
    "    def forward(self, inp_img, inp_txt):\n",
    "        x = self.encoder(inp_img, inp_txt)\n",
    "        x_img, x_txt = self.decoder(x)\n",
    "        return x_img, x_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img loss: 0.695 txt_loss: 0.717 img + txt loss 1.411\n",
      "val img loss: 0.125 val txt_loss: 0.136 img + txt loss 0.261\n",
      "train img loss: 0.407 txt_loss: 0.463 img + txt loss 0.870\n",
      "val img loss: 0.086 val txt_loss: 0.103 img + txt loss 0.189\n",
      "train img loss: 0.302 txt_loss: 0.376 img + txt loss 0.678\n",
      "val img loss: 0.069 val txt_loss: 0.089 img + txt loss 0.159\n",
      "train img loss: 0.254 txt_loss: 0.338 img + txt loss 0.592\n",
      "val img loss: 0.061 val txt_loss: 0.083 img + txt loss 0.143\n",
      "train img loss: 0.229 txt_loss: 0.317 img + txt loss 0.546\n",
      "val img loss: 0.056 val txt_loss: 0.078 img + txt loss 0.134\n",
      "train img loss: 0.213 txt_loss: 0.302 img + txt loss 0.516\n",
      "val img loss: 0.053 val txt_loss: 0.075 img + txt loss 0.128\n",
      "train img loss: 0.203 txt_loss: 0.290 img + txt loss 0.493\n",
      "val img loss: 0.051 val txt_loss: 0.072 img + txt loss 0.123\n",
      "train img loss: 0.195 txt_loss: 0.279 img + txt loss 0.475\n",
      "val img loss: 0.049 val txt_loss: 0.070 img + txt loss 0.119\n",
      "train img loss: 0.189 txt_loss: 0.269 img + txt loss 0.459\n",
      "val img loss: 0.048 val txt_loss: 0.067 img + txt loss 0.115\n",
      "train img loss: 0.185 txt_loss: 0.260 img + txt loss 0.445\n",
      "val img loss: 0.047 val txt_loss: 0.065 img + txt loss 0.112\n",
      "train img loss: 0.181 txt_loss: 0.252 img + txt loss 0.433\n",
      "val img loss: 0.046 val txt_loss: 0.063 img + txt loss 0.109\n",
      "train img loss: 0.178 txt_loss: 0.246 img + txt loss 0.425\n",
      "val img loss: 0.045 val txt_loss: 0.062 img + txt loss 0.107\n",
      "train img loss: 0.176 txt_loss: 0.242 img + txt loss 0.418\n",
      "val img loss: 0.045 val txt_loss: 0.061 img + txt loss 0.106\n",
      "train img loss: 0.174 txt_loss: 0.239 img + txt loss 0.413\n",
      "val img loss: 0.044 val txt_loss: 0.060 img + txt loss 0.105\n",
      "train img loss: 0.173 txt_loss: 0.236 img + txt loss 0.409\n",
      "val img loss: 0.044 val txt_loss: 0.060 img + txt loss 0.104\n",
      "train img loss: 0.171 txt_loss: 0.235 img + txt loss 0.406\n",
      "val img loss: 0.044 val txt_loss: 0.059 img + txt loss 0.103\n",
      "train img loss: 0.170 txt_loss: 0.233 img + txt loss 0.403\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.169 txt_loss: 0.232 img + txt loss 0.402\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.169 txt_loss: 0.231 img + txt loss 0.400\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.102\n",
      "train img loss: 0.168 txt_loss: 0.231 img + txt loss 0.399\n",
      "val img loss: 0.043 val txt_loss: 0.059 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.043 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.230 img + txt loss 0.397\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.167 txt_loss: 0.229 img + txt loss 0.396\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.101\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.395\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.166 txt_loss: 0.229 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.166 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.394\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.228 img + txt loss 0.393\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.165 txt_loss: 0.227 img + txt loss 0.392\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.100\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.227 img + txt loss 0.391\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.390\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.058 img + txt loss 0.099\n",
      "train img loss: 0.164 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.226 img + txt loss 0.389\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.389\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.042 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.163 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "train img loss: 0.162 txt_loss: 0.225 img + txt loss 0.388\n",
      "val img loss: 0.041 val txt_loss: 0.057 img + txt loss 0.099\n",
      "finished for 920.9207558631897 seconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0badc04124bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_img_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"autoencoder_c128_stat/trivial_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "autoencoder_c = AutoencoderComplex(d=128)\n",
    "optimizer_c = torch.optim.Adam(autoencoder_c.parameters(), lr=1e-3)\n",
    "\n",
    "stat = fit_autoencoder(autoencoder_c, optimizer_c, 100, [x_img_train, x_txt_train], [x_img_val, x_txt_val])\n",
    "pickle.dump(stat, open( \"autoencoder_c128_stat/trivial_\" + str(d) + \".pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: tensor(3.8203, grad_fn=<NllLossBackward>) average train loss tensor(3.8808, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.07929359823399558 val_avg_loss: tensor(3.7910)\n",
      "epoch: 1 train_loss: tensor(3.6845, grad_fn=<NllLossBackward>) average train loss tensor(3.7341, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.0866813833701251 val_avg_loss: tensor(3.6537)\n",
      "epoch: 2 train_loss: tensor(3.5847, grad_fn=<NllLossBackward>) average train loss tensor(3.6208, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.11935246504782929 val_avg_loss: tensor(3.5340)\n",
      "epoch: 3 train_loss: tensor(3.4435, grad_fn=<NllLossBackward>) average train loss tensor(3.5119, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.18949227373068434 val_avg_loss: tensor(3.4188)\n",
      "epoch: 4 train_loss: tensor(3.3281, grad_fn=<NllLossBackward>) average train loss tensor(3.3978, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.22740250183958793 val_avg_loss: tensor(3.2813)\n",
      "epoch: 5 train_loss: tensor(3.2015, grad_fn=<NllLossBackward>) average train loss tensor(3.2824, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.27172921265636496 val_avg_loss: tensor(3.1180)\n",
      "epoch: 6 train_loss: tensor(3.0592, grad_fn=<NllLossBackward>) average train loss tensor(3.1272, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.2841206769683591 val_avg_loss: tensor(2.9528)\n",
      "epoch: 7 train_loss: tensor(2.9060, grad_fn=<NllLossBackward>) average train loss tensor(3.0006, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.30286975717439296 val_avg_loss: tensor(2.8080)\n",
      "epoch: 8 train_loss: tensor(2.7752, grad_fn=<NllLossBackward>) average train loss tensor(2.8368, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.3399852832965416 val_avg_loss: tensor(2.6733)\n",
      "epoch: 9 train_loss: tensor(2.6015, grad_fn=<NllLossBackward>) average train loss tensor(2.7278, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.36606328182487125 val_avg_loss: tensor(2.5579)\n",
      "epoch: 10 train_loss: tensor(2.5028, grad_fn=<NllLossBackward>) average train loss tensor(2.5999, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.37777777777777777 val_avg_loss: tensor(2.4635)\n",
      "epoch: 11 train_loss: tensor(2.4148, grad_fn=<NllLossBackward>) average train loss tensor(2.5116, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.38666666666666666 val_avg_loss: tensor(2.3926)\n",
      "epoch: 12 train_loss: tensor(2.3350, grad_fn=<NllLossBackward>) average train loss tensor(2.4321, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4002649006622517 val_avg_loss: tensor(2.3230)\n",
      "epoch: 13 train_loss: tensor(2.2317, grad_fn=<NllLossBackward>) average train loss tensor(2.2972, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4169242089771891 val_avg_loss: tensor(2.2595)\n",
      "epoch: 14 train_loss: tensor(2.1841, grad_fn=<NllLossBackward>) average train loss tensor(2.2392, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.426607799852833 val_avg_loss: tensor(2.2091)\n",
      "epoch: 15 train_loss: tensor(2.0641, grad_fn=<NllLossBackward>) average train loss tensor(2.1578, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.42548933038999265 val_avg_loss: tensor(2.1726)\n",
      "epoch: 16 train_loss: tensor(2.0441, grad_fn=<NllLossBackward>) average train loss tensor(2.1245, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44026490066225166 val_avg_loss: tensor(2.1334)\n",
      "epoch: 17 train_loss: tensor(2.0262, grad_fn=<NllLossBackward>) average train loss tensor(2.0562, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.44791758646063284 val_avg_loss: tensor(2.1046)\n",
      "epoch: 18 train_loss: tensor(1.9288, grad_fn=<NllLossBackward>) average train loss tensor(1.9968, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4487122884473878 val_avg_loss: tensor(2.0839)\n",
      "epoch: 19 train_loss: tensor(1.9173, grad_fn=<NllLossBackward>) average train loss tensor(1.9820, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4559823399558499 val_avg_loss: tensor(2.0536)\n",
      "epoch: 20 train_loss: tensor(1.8044, grad_fn=<NllLossBackward>) average train loss tensor(1.8975, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.46186902133922003 val_avg_loss: tensor(2.0289)\n",
      "epoch: 21 train_loss: tensor(1.8155, grad_fn=<NllLossBackward>) average train loss tensor(1.8686, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4565121412803532 val_avg_loss: tensor(2.0219)\n",
      "epoch: 22 train_loss: tensor(1.7572, grad_fn=<NllLossBackward>) average train loss tensor(1.8120, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4631935246504783 val_avg_loss: tensor(2.0054)\n",
      "epoch: 23 train_loss: tensor(1.6368, grad_fn=<NllLossBackward>) average train loss tensor(1.7433, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4679617365710081 val_avg_loss: tensor(1.9953)\n",
      "epoch: 24 train_loss: tensor(1.6898, grad_fn=<NllLossBackward>) average train loss tensor(1.7312, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4708167770419426 val_avg_loss: tensor(1.9879)\n",
      "epoch: 25 train_loss: tensor(1.6167, grad_fn=<NllLossBackward>) average train loss tensor(1.6983, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4742310522442973 val_avg_loss: tensor(1.9769)\n",
      "epoch: 26 train_loss: tensor(1.5302, grad_fn=<NllLossBackward>) average train loss tensor(1.6222, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47817512877115526 val_avg_loss: tensor(1.9642)\n",
      "epoch: 27 train_loss: tensor(1.5177, grad_fn=<NllLossBackward>) average train loss tensor(1.6282, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47205298013245034 val_avg_loss: tensor(1.9690)\n",
      "epoch: 28 train_loss: tensor(1.4555, grad_fn=<NllLossBackward>) average train loss tensor(1.5667, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4750551876379691 val_avg_loss: tensor(1.9752)\n",
      "epoch: 29 train_loss: tensor(1.4812, grad_fn=<NllLossBackward>) average train loss tensor(1.5590, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.4811184694628403 val_avg_loss: tensor(1.9675)\n",
      "epoch: 30 train_loss: tensor(1.4299, grad_fn=<NllLossBackward>) average train loss tensor(1.5228, grad_fn=<DivBackward0>)\n",
      "val_acc: 0.47979396615158204 val_avg_loss: tensor(1.9607)\n",
      "epoch: 31 train_loss: tensor(1.3655, grad_fn=<NllLossBackward>) average train loss tensor(1.4830, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2a36571152a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader_2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/Thesis/topics_ds/pytorch/torch_models.py\u001b[0m in \u001b[0;36mfit_topics_model\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, writer, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mloss_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder_c_2 = autoencoder_c.encoder\n",
    "after_encoder_model_c_2 = AfterEncoderModel(encoder_c_2, d=128, drop=0.5)\n",
    "optimizer_aem_c_2 = torch.optim.Adam(after_encoder_model_c_2.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter('runs/aem_c_2_bs2048_rs42_d128_wd0005_drop05_100')\n",
    "\n",
    "torch_models.fit_topics_model(\n",
    "    model=after_encoder_model_c_2,\n",
    "    optimizer=optimizer_aem_c_2,\n",
    "    epochs=100,\n",
    "    writer=writer,\n",
    "    train_loader=train_loader_2000,\n",
    "    val_loader=val_loader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
