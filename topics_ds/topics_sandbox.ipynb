{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from struct import unpack\n",
    "from base64 import b64decode\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, concatenate, BatchNormalization, Multiply, Add\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dmitry/Downloads/topics_dataset.json\"\n",
    "df = pd.read_json(filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def unpck(l, x):\n",
    "    return unpack('%df' % l, b64decode(x.encode('utf-8')))\n",
    "\n",
    "unpck_img = partial(unpck, IMG_LEN)\n",
    "unpck_txt = partial(unpck, TXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = df.sample(frac=0.25)\n",
    "x_img_q = np.stack(df_q['x1'].map(unpck_img), axis=0)\n",
    "x_txt_q = np.stack(df_q['x2'].map(unpck_txt), axis=0)\n",
    "y_q = to_categorical(np.array(df_q['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "norm_x_img_q = normalize(x_img_q)\n",
    "# img_scaler = MinMaxScaler()\n",
    "# img_scaler.fit(norm_x_img_q)\n",
    "# scaled_x_img_q = img_scaler.transform(norm_x_img_q)\n",
    "\n",
    "norm_x_txt_q = normalize(x_txt_q)\n",
    "# txt_scaler = MinMaxScaler()\n",
    "# txt_scaler.fit(norm_x_txt_q)\n",
    "# scaled_x_txt_q = txt_scaler.transform(norm_x_txt_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(norm_x_img_q, norm_x_txt_q, y_q, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001, patience=3)\n",
    "\n",
    "def get_model_1():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(64, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(64, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(64, activation='relu')(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/10\n",
      "38221/38221 [==============================] - 8s 201us/sample - loss: 2.4772 - accuracy: 0.3424 - val_loss: 1.8027 - val_accuracy: 0.4996\n",
      "Epoch 2/10\n",
      "38221/38221 [==============================] - 5s 129us/sample - loss: 1.8880 - accuracy: 0.4850 - val_loss: 1.6310 - val_accuracy: 0.5411\n",
      "Epoch 3/10\n",
      "38221/38221 [==============================] - 5s 134us/sample - loss: 1.7716 - accuracy: 0.5190 - val_loss: 1.5922 - val_accuracy: 0.5595\n",
      "Epoch 4/10\n",
      "38221/38221 [==============================] - 5s 120us/sample - loss: 1.6992 - accuracy: 0.5394 - val_loss: 1.5362 - val_accuracy: 0.5757\n",
      "Epoch 5/10\n",
      "38221/38221 [==============================] - 5s 118us/sample - loss: 1.6483 - accuracy: 0.5549 - val_loss: 1.5240 - val_accuracy: 0.5844\n",
      "Epoch 6/10\n",
      "38221/38221 [==============================] - 5s 125us/sample - loss: 1.6074 - accuracy: 0.5646 - val_loss: 1.4939 - val_accuracy: 0.5863\n",
      "Epoch 7/10\n",
      "38221/38221 [==============================] - 5s 118us/sample - loss: 1.5782 - accuracy: 0.5699 - val_loss: 1.4974 - val_accuracy: 0.5910\n",
      "Epoch 8/10\n",
      "38221/38221 [==============================] - 4s 118us/sample - loss: 1.5435 - accuracy: 0.5767 - val_loss: 1.4812 - val_accuracy: 0.5894\n",
      "Epoch 9/10\n",
      "38221/38221 [==============================] - 5s 125us/sample - loss: 1.5226 - accuracy: 0.5827 - val_loss: 1.4819 - val_accuracy: 0.5948\n",
      "Epoch 10/10\n",
      "38221/38221 [==============================] - 5s 120us/sample - loss: 1.5019 - accuracy: 0.5880 - val_loss: 1.4681 - val_accuracy: 0.5969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1127d8450>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = get_model_1()\n",
    "model_1.fit([x_img_train, x_txt_train], y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_mult():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(64, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(64, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(64, activation='relu')(x_txt)\n",
    "\n",
    "    x = Multiply()([x_img, x_txt])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 2.6497 - accuracy: 0.2971 - val_loss: 1.8960 - val_accuracy: 0.4660\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 4s 108us/sample - loss: 1.9808 - accuracy: 0.4683 - val_loss: 1.7202 - val_accuracy: 0.5270\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 4s 95us/sample - loss: 1.8172 - accuracy: 0.5096 - val_loss: 1.6123 - val_accuracy: 0.5543\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 4s 94us/sample - loss: 1.7257 - accuracy: 0.5339 - val_loss: 1.5684 - val_accuracy: 0.5719\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 3s 91us/sample - loss: 1.6683 - accuracy: 0.5500 - val_loss: 1.5268 - val_accuracy: 0.5844\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 5s 124us/sample - loss: 1.6265 - accuracy: 0.5557 - val_loss: 1.5311 - val_accuracy: 0.5809\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 4s 105us/sample - loss: 1.5915 - accuracy: 0.5663 - val_loss: 1.4964 - val_accuracy: 0.5875\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 4s 98us/sample - loss: 1.5591 - accuracy: 0.5753 - val_loss: 1.4923 - val_accuracy: 0.5905\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 4s 95us/sample - loss: 1.5355 - accuracy: 0.5816 - val_loss: 1.4991 - val_accuracy: 0.5889\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 4s 113us/sample - loss: 1.5137 - accuracy: 0.5838 - val_loss: 1.4747 - val_accuracy: 0.5929\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 5s 135us/sample - loss: 1.4825 - accuracy: 0.5924 - val_loss: 1.4643 - val_accuracy: 0.5952\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 7s 180us/sample - loss: 1.4649 - accuracy: 0.5933 - val_loss: 1.4707 - val_accuracy: 0.5934\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 6s 170us/sample - loss: 1.4537 - accuracy: 0.5965 - val_loss: 1.4772 - val_accuracy: 0.5945\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 6s 154us/sample - loss: 1.4351 - accuracy: 0.6033 - val_loss: 1.4643 - val_accuracy: 0.5941\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 6s 162us/sample - loss: 1.4185 - accuracy: 0.6048 - val_loss: 1.4649 - val_accuracy: 0.5985\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 6s 149us/sample - loss: 1.3987 - accuracy: 0.6098 - val_loss: 1.4625 - val_accuracy: 0.5981\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 7s 181us/sample - loss: 1.3922 - accuracy: 0.6106 - val_loss: 1.4865 - val_accuracy: 0.5912\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 7s 174us/sample - loss: 1.3731 - accuracy: 0.6169 - val_loss: 1.4884 - val_accuracy: 0.5992\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 6s 159us/sample - loss: 1.3672 - accuracy: 0.6165 - val_loss: 1.4870 - val_accuracy: 0.5905\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 1.3607 - accuracy: 0.6182 - val_loss: 1.4865 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13bb9f250>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mult = get_model_mult()\n",
    "model_mult.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_add():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(64, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(64, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(64, activation='relu')(x_txt)\n",
    "\n",
    "    x = Add()([x_img, x_txt])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 6s 160us/sample - loss: 2.4678 - accuracy: 0.3417 - val_loss: 1.8103 - val_accuracy: 0.4881\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 5s 140us/sample - loss: 1.9026 - accuracy: 0.4805 - val_loss: 1.6574 - val_accuracy: 0.5460\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 146us/sample - loss: 1.7742 - accuracy: 0.5182 - val_loss: 1.6143 - val_accuracy: 0.5552\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 6s 146us/sample - loss: 1.6981 - accuracy: 0.5393 - val_loss: 1.5620 - val_accuracy: 0.5724\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 6s 164us/sample - loss: 1.6506 - accuracy: 0.5477 - val_loss: 1.5281 - val_accuracy: 0.5846\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 1.6117 - accuracy: 0.5635 - val_loss: 1.5159 - val_accuracy: 0.5849\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 6s 150us/sample - loss: 1.5716 - accuracy: 0.5696 - val_loss: 1.5047 - val_accuracy: 0.5903\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 6s 163us/sample - loss: 1.5417 - accuracy: 0.5773 - val_loss: 1.5184 - val_accuracy: 0.5839\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 1.5179 - accuracy: 0.5827 - val_loss: 1.4890 - val_accuracy: 0.6021\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 6s 166us/sample - loss: 1.4991 - accuracy: 0.5891 - val_loss: 1.4829 - val_accuracy: 0.5976\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 6s 148us/sample - loss: 1.4767 - accuracy: 0.5934 - val_loss: 1.4957 - val_accuracy: 0.5903\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 6s 169us/sample - loss: 1.4586 - accuracy: 0.5976 - val_loss: 1.4845 - val_accuracy: 0.6018\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 6s 159us/sample - loss: 1.4445 - accuracy: 0.6009 - val_loss: 1.5031 - val_accuracy: 0.5908\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 7s 180us/sample - loss: 1.4328 - accuracy: 0.6021 - val_loss: 1.4799 - val_accuracy: 0.5938\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 6s 154us/sample - loss: 1.4212 - accuracy: 0.6077 - val_loss: 1.4734 - val_accuracy: 0.5945\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 5s 143us/sample - loss: 1.4058 - accuracy: 0.6072 - val_loss: 1.4785 - val_accuracy: 0.5976\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 6s 150us/sample - loss: 1.3963 - accuracy: 0.6108 - val_loss: 1.4704 - val_accuracy: 0.5938\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 5s 143us/sample - loss: 1.3778 - accuracy: 0.6147 - val_loss: 1.4914 - val_accuracy: 0.5967\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 5s 136us/sample - loss: 1.3688 - accuracy: 0.6175 - val_loss: 1.4803 - val_accuracy: 0.6023\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 6s 144us/sample - loss: 1.3535 - accuracy: 0.6189 - val_loss: 1.4983 - val_accuracy: 0.5997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1656c9a90>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_add = get_model_add()\n",
    "model_add.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_mix():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(64, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(64, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(64, activation='relu')(x_txt)\n",
    "\n",
    "    add = Add()([x_img, x_txt])\n",
    "    add = Dense(128, activation='relu')(add)\n",
    "    add = Dropout(0.25)(add)\n",
    "    \n",
    "    mult = Multiply()([x_img, x_txt])\n",
    "    mult = Dense(128, activation='relu')(mult)\n",
    "    mult = Dropout(0.25)(mult)\n",
    "    \n",
    "    mix = concatenate([add, mult])\n",
    "    mix = Dense(128, activation='relu')(mix)\n",
    "    mix = Dropout(0.25)(mix)\n",
    "\n",
    "    out = Dense(50, activation='softmax')(mix)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_wide_mix():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(512, activation='relu')(x_txt)\n",
    "\n",
    "    add = Add()([x_img, x_txt])\n",
    "    add = Dense(512, activation='relu')(add)\n",
    "    add = Dropout(0.25)(add)\n",
    "    \n",
    "    mult = Multiply()([x_img, x_txt])\n",
    "    mult = Dense(512, activation='relu')(mult)\n",
    "    mult = Dropout(0.25)(mult)\n",
    "    \n",
    "    mix = concatenate([add, mult])\n",
    "    mix = Dense(512, activation='relu')(mix)\n",
    "    mix = Dropout(0.25)(mix)\n",
    "\n",
    "    out = Dense(50, activation='softmax')(mix)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 8s 203us/sample - loss: 2.5591 - accuracy: 0.3246 - val_loss: 1.8182 - val_accuracy: 0.5046\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 6s 149us/sample - loss: 1.9552 - accuracy: 0.4730 - val_loss: 1.7078 - val_accuracy: 0.5333\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 154us/sample - loss: 1.8238 - accuracy: 0.5088 - val_loss: 1.5978 - val_accuracy: 0.5663\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 5s 136us/sample - loss: 1.7495 - accuracy: 0.5280 - val_loss: 1.5621 - val_accuracy: 0.5764\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 4s 105us/sample - loss: 1.6896 - accuracy: 0.5443 - val_loss: 1.5329 - val_accuracy: 0.5738\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 4s 102us/sample - loss: 1.6471 - accuracy: 0.5526 - val_loss: 1.5321 - val_accuracy: 0.5828\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 4s 103us/sample - loss: 1.6050 - accuracy: 0.5660 - val_loss: 1.5257 - val_accuracy: 0.5858\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 5s 120us/sample - loss: 1.5821 - accuracy: 0.5743 - val_loss: 1.5015 - val_accuracy: 0.5917\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 5s 124us/sample - loss: 1.5503 - accuracy: 0.5785 - val_loss: 1.4854 - val_accuracy: 0.5919\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 1.5320 - accuracy: 0.5808 - val_loss: 1.4871 - val_accuracy: 0.5915\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 7s 192us/sample - loss: 1.5152 - accuracy: 0.5872 - val_loss: 1.4610 - val_accuracy: 0.6009\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 7s 180us/sample - loss: 1.4901 - accuracy: 0.5938 - val_loss: 1.4705 - val_accuracy: 0.6011\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 7s 185us/sample - loss: 1.4772 - accuracy: 0.5946 - val_loss: 1.4755 - val_accuracy: 0.6075\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 6s 163us/sample - loss: 1.4623 - accuracy: 0.5986 - val_loss: 1.4848 - val_accuracy: 0.6004\n",
      "Epoch 15/20\n",
      "38221/38221 [==============================] - 6s 166us/sample - loss: 1.4391 - accuracy: 0.6043 - val_loss: 1.4645 - val_accuracy: 0.6002\n",
      "Epoch 16/20\n",
      "38221/38221 [==============================] - 6s 155us/sample - loss: 1.4283 - accuracy: 0.6071 - val_loss: 1.4599 - val_accuracy: 0.6096\n",
      "Epoch 17/20\n",
      "38221/38221 [==============================] - 6s 152us/sample - loss: 1.4111 - accuracy: 0.6102 - val_loss: 1.4666 - val_accuracy: 0.6058\n",
      "Epoch 18/20\n",
      "38221/38221 [==============================] - 7s 175us/sample - loss: 1.3981 - accuracy: 0.6140 - val_loss: 1.4681 - val_accuracy: 0.6051\n",
      "Epoch 19/20\n",
      "38221/38221 [==============================] - 7s 184us/sample - loss: 1.3843 - accuracy: 0.6152 - val_loss: 1.4787 - val_accuracy: 0.6068\n",
      "Epoch 20/20\n",
      "38221/38221 [==============================] - 7s 183us/sample - loss: 1.3761 - accuracy: 0.6187 - val_loss: 1.4711 - val_accuracy: 0.6009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18082f190>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mix = get_model_mix()\n",
    "model_mix.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 42s 1ms/sample - loss: 2.1200 - accuracy: 0.4392 - val_loss: 1.5999 - val_accuracy: 0.5668\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 44s 1ms/sample - loss: 1.6445 - accuracy: 0.5581 - val_loss: 1.5601 - val_accuracy: 0.5764\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 47s 1ms/sample - loss: 1.5183 - accuracy: 0.5899 - val_loss: 1.5041 - val_accuracy: 0.5938\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 42s 1ms/sample - loss: 1.4271 - accuracy: 0.6100 - val_loss: 1.4988 - val_accuracy: 0.5919\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.3528 - accuracy: 0.6261 - val_loss: 1.4917 - val_accuracy: 0.5978\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 47s 1ms/sample - loss: 1.2845 - accuracy: 0.6426 - val_loss: 1.4658 - val_accuracy: 0.6124\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 41s 1ms/sample - loss: 1.2193 - accuracy: 0.6567 - val_loss: 1.4794 - val_accuracy: 0.6037\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.1540 - accuracy: 0.6688 - val_loss: 1.5188 - val_accuracy: 0.6004\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.0951 - accuracy: 0.6837 - val_loss: 1.5464 - val_accuracy: 0.6065\n",
      "Epoch 10/20\n",
      "11488/38221 [========>.....................] - ETA: 34s - loss: 0.9963 - accuracy: 0.7026"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-ee58ee464ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_wide_mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_wide_mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_wide_mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_wide_mix = get_model_wide_mix()\n",
    "model_wide_mix.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_long_horns():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(512)(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(512, activation='relu')(x_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(512, activation='relu')(x_txt)\n",
    "\n",
    "    add = Add()([x_img, x_txt])\n",
    "    add = Dense(512, activation='relu')(add)\n",
    "    add = Dropout(0.25)(add)\n",
    "    \n",
    "    mult = Multiply()([x_img, x_txt])\n",
    "    mult = Dense(512, activation='relu')(mult)\n",
    "    mult = Dropout(0.25)(mult)\n",
    "    \n",
    "    mix = concatenate([add, mult])\n",
    "    mix = Dense(512, activation='relu')(mix)\n",
    "    mix = Dropout(0.25)(mix)\n",
    "\n",
    "    out = Dense(50, activation='softmax')(mix)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/8\n",
      "38221/38221 [==============================] - 54s 1ms/sample - loss: 2.2581 - accuracy: 0.4020 - val_loss: 1.7444 - val_accuracy: 0.5220\n",
      "Epoch 2/8\n",
      "38221/38221 [==============================] - 55s 1ms/sample - loss: 1.7656 - accuracy: 0.5280 - val_loss: 1.6168 - val_accuracy: 0.5675\n",
      "Epoch 3/8\n",
      "38221/38221 [==============================] - 59s 2ms/sample - loss: 1.6464 - accuracy: 0.5600 - val_loss: 1.5306 - val_accuracy: 0.5905\n",
      "Epoch 4/8\n",
      "38221/38221 [==============================] - 61s 2ms/sample - loss: 1.5743 - accuracy: 0.5776 - val_loss: 1.5267 - val_accuracy: 0.5948\n",
      "Epoch 5/8\n",
      "38221/38221 [==============================] - 58s 2ms/sample - loss: 1.5105 - accuracy: 0.5935 - val_loss: 1.5469 - val_accuracy: 0.5854\n",
      "Epoch 6/8\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.4546 - accuracy: 0.6060 - val_loss: 1.5285 - val_accuracy: 0.5976\n",
      "Epoch 7/8\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.4164 - accuracy: 0.6160 - val_loss: 1.5352 - val_accuracy: 0.5938\n",
      "Epoch 8/8\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.3678 - accuracy: 0.6261 - val_loss: 1.5293 - val_accuracy: 0.6040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18aa5ed10>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_long_horns = get_model_long_horns()\n",
    "model_long_horns.fit([x_img_train, x_txt_train], y_train, epochs=8, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_highway_horns():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Highway()(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(512)(x_img)\n",
    "\n",
    "    x_txt = Highway()(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(512, activation='relu')(x_txt)\n",
    "\n",
    "    add = Add()([x_img, x_txt])\n",
    "    add = Dense(512, activation='relu')(add)\n",
    "    add = Dropout(0.25)(add)\n",
    "    \n",
    "    mult = Multiply()([x_img, x_txt])\n",
    "    mult = Dense(512, activation='relu')(mult)\n",
    "    mult = Dropout(0.25)(mult)\n",
    "    \n",
    "    mix = concatenate([add, mult])\n",
    "    mix = Dense(512, activation='relu')(mix)\n",
    "    mix = Dropout(0.25)(mix)\n",
    "\n",
    "    out = Dense(50, activation='softmax')(mix)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/10\n",
      "38221/38221 [==============================] - 59s 2ms/sample - loss: 2.0573 - accuracy: 0.4507 - val_loss: 1.6421 - val_accuracy: 0.5449\n",
      "Epoch 2/10\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.6481 - accuracy: 0.5581 - val_loss: 1.5112 - val_accuracy: 0.5849\n",
      "Epoch 3/10\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.5368 - accuracy: 0.5853 - val_loss: 1.5427 - val_accuracy: 0.5879\n",
      "Epoch 4/10\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.4504 - accuracy: 0.6040 - val_loss: 1.4784 - val_accuracy: 0.6007\n",
      "Epoch 5/10\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.3722 - accuracy: 0.6193 - val_loss: 1.4692 - val_accuracy: 0.6082\n",
      "Epoch 6/10\n",
      "38221/38221 [==============================] - 52s 1ms/sample - loss: 1.2939 - accuracy: 0.6339 - val_loss: 1.4904 - val_accuracy: 0.6054\n",
      "Epoch 7/10\n",
      "38221/38221 [==============================] - 58s 2ms/sample - loss: 1.2141 - accuracy: 0.6474 - val_loss: 1.5181 - val_accuracy: 0.6014\n",
      "Epoch 8/10\n",
      "38221/38221 [==============================] - 56s 1ms/sample - loss: 1.1374 - accuracy: 0.6645 - val_loss: 1.5602 - val_accuracy: 0.5971\n",
      "Epoch 9/10\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.0579 - accuracy: 0.6843 - val_loss: 1.5727 - val_accuracy: 0.5917\n",
      "Epoch 10/10\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 0.9896 - accuracy: 0.6961 - val_loss: 1.6702 - val_accuracy: 0.5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d166890>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_highway_horns = get_model_highway_horns()\n",
    "model_highway_horns.fit([x_img_train, x_txt_train], y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_img_1():\n",
    "    inp = Input(shape=(IMG_LEN,))\n",
    "    \n",
    "    x = Dense(1024, activation='relu')(inp)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/10\n",
      "38221/38221 [==============================] - 31s 801us/sample - loss: 2.7206 - accuracy: 0.2842 - val_loss: 2.3245 - val_accuracy: 0.3767\n",
      "Epoch 2/10\n",
      "38221/38221 [==============================] - 24s 623us/sample - loss: 2.3772 - accuracy: 0.3690 - val_loss: 2.2492 - val_accuracy: 0.3946\n",
      "Epoch 3/10\n",
      "38221/38221 [==============================] - 24s 639us/sample - loss: 2.2930 - accuracy: 0.3920 - val_loss: 2.2280 - val_accuracy: 0.4062\n",
      "Epoch 4/10\n",
      "38221/38221 [==============================] - 27s 716us/sample - loss: 2.2306 - accuracy: 0.4025 - val_loss: 2.1808 - val_accuracy: 0.4191\n",
      "Epoch 5/10\n",
      "38221/38221 [==============================] - 27s 697us/sample - loss: 2.1839 - accuracy: 0.4169 - val_loss: 2.1634 - val_accuracy: 0.4137\n",
      "Epoch 6/10\n",
      "38221/38221 [==============================] - 27s 709us/sample - loss: 2.1499 - accuracy: 0.4231 - val_loss: 2.1463 - val_accuracy: 0.4203\n",
      "Epoch 7/10\n",
      "38221/38221 [==============================] - 29s 746us/sample - loss: 2.1175 - accuracy: 0.4299 - val_loss: 2.1471 - val_accuracy: 0.4245\n",
      "Epoch 8/10\n",
      "38221/38221 [==============================] - 27s 718us/sample - loss: 2.0755 - accuracy: 0.4392 - val_loss: 2.1403 - val_accuracy: 0.4238\n",
      "Epoch 9/10\n",
      "38221/38221 [==============================] - 26s 682us/sample - loss: 2.0428 - accuracy: 0.4454 - val_loss: 2.1327 - val_accuracy: 0.4335\n",
      "Epoch 10/10\n",
      "38221/38221 [==============================] - 26s 684us/sample - loss: 2.0164 - accuracy: 0.4495 - val_loss: 2.1206 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f9ea490>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_img_1 = get_model_img_1()\n",
    "model_img_1.fit(x_img_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_txt_1():\n",
    "    inp = Input(shape=(TXT_LEN,))\n",
    "        \n",
    "        \n",
    "    x1 = Dense(512, activation='relu')(inp)\n",
    "    x1 = Dropout(0.25)(x1)\n",
    "    \n",
    "    x2 = Dense(512, activation='relu')(x1)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "    \n",
    "    x = concatenate([x1, x2])\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/10\n",
      "38221/38221 [==============================] - 19s 504us/sample - loss: 2.3747 - accuracy: 0.3932 - val_loss: 1.9832 - val_accuracy: 0.4827\n",
      "Epoch 2/10\n",
      "38221/38221 [==============================] - 19s 486us/sample - loss: 2.0407 - accuracy: 0.4706 - val_loss: 1.9111 - val_accuracy: 0.4926\n",
      "Epoch 3/10\n",
      "38221/38221 [==============================] - 20s 532us/sample - loss: 1.9414 - accuracy: 0.4901 - val_loss: 1.8837 - val_accuracy: 0.5015\n",
      "Epoch 4/10\n",
      "38221/38221 [==============================] - 20s 510us/sample - loss: 1.8688 - accuracy: 0.5062 - val_loss: 1.9051 - val_accuracy: 0.4933\n",
      "Epoch 5/10\n",
      "38221/38221 [==============================] - 21s 543us/sample - loss: 1.8086 - accuracy: 0.5162 - val_loss: 1.8612 - val_accuracy: 0.5069\n",
      "Epoch 6/10\n",
      "38221/38221 [==============================] - 23s 595us/sample - loss: 1.7497 - accuracy: 0.5283 - val_loss: 1.8907 - val_accuracy: 0.5077\n",
      "Epoch 7/10\n",
      "38221/38221 [==============================] - 21s 549us/sample - loss: 1.6935 - accuracy: 0.5393 - val_loss: 1.8772 - val_accuracy: 0.5102\n",
      "Epoch 8/10\n",
      "38221/38221 [==============================] - 20s 534us/sample - loss: 1.6393 - accuracy: 0.5514 - val_loss: 1.9019 - val_accuracy: 0.5051\n",
      "Epoch 9/10\n",
      "38221/38221 [==============================] - 18s 477us/sample - loss: 1.5766 - accuracy: 0.5643 - val_loss: 1.9451 - val_accuracy: 0.5121\n",
      "Epoch 10/10\n",
      "38221/38221 [==============================] - 18s 474us/sample - loss: 1.5200 - accuracy: 0.5760 - val_loss: 1.9373 - val_accuracy: 0.5062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b022dd0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_txt_1 = get_model_txt_1()\n",
    "model_txt_1.fit(x_txt_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2():\n",
    "    x_img = Dense(128, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(128, activation='tanh')(x_img)\n",
    "\n",
    "    x_txt = Dense(128, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(128, activation='tanh')(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256, activation='tanh')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 344us/sample - loss: 3.0224 - accuracy: 0.2210 - categorical_accuracy: 0.2210 - val_loss: 2.2648 - val_accuracy: 0.3740 - val_categorical_accuracy: 0.3740\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 179us/sample - loss: 2.1881 - accuracy: 0.4006 - categorical_accuracy: 0.4006 - val_loss: 2.0103 - val_accuracy: 0.4350 - val_categorical_accuracy: 0.4350\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 180us/sample - loss: 1.9779 - accuracy: 0.4573 - categorical_accuracy: 0.4573 - val_loss: 1.8241 - val_accuracy: 0.5070 - val_categorical_accuracy: 0.5070\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 177us/sample - loss: 1.8515 - accuracy: 0.4900 - categorical_accuracy: 0.4900 - val_loss: 1.8211 - val_accuracy: 0.4930 - val_categorical_accuracy: 0.4930\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 176us/sample - loss: 1.7367 - accuracy: 0.5242 - categorical_accuracy: 0.5242 - val_loss: 1.8064 - val_accuracy: 0.4930 - val_categorical_accuracy: 0.4930\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 177us/sample - loss: 1.6504 - accuracy: 0.5413 - categorical_accuracy: 0.5413 - val_loss: 1.7571 - val_accuracy: 0.5200 - val_categorical_accuracy: 0.5200\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 208us/sample - loss: 1.5913 - accuracy: 0.5608 - categorical_accuracy: 0.5608 - val_loss: 1.7082 - val_accuracy: 0.5210 - val_categorical_accuracy: 0.5210\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 172us/sample - loss: 1.5272 - accuracy: 0.5780 - categorical_accuracy: 0.5780 - val_loss: 1.7068 - val_accuracy: 0.5350 - val_categorical_accuracy: 0.5350\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 193us/sample - loss: 1.4570 - accuracy: 0.5843 - categorical_accuracy: 0.5843 - val_loss: 1.7199 - val_accuracy: 0.5350 - val_categorical_accuracy: 0.5350\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 230us/sample - loss: 1.4149 - accuracy: 0.5996 - categorical_accuracy: 0.5996 - val_loss: 1.6670 - val_accuracy: 0.5490 - val_categorical_accuracy: 0.5490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14fe712d0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_2()\n",
    "model.fit([x_img, x_txt], y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04970714685320854, 0.98471624]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upgrades:  \n",
    "1) bigger width of first layers  \n",
    "2) add dropout before concatenation  \n",
    "3) set dropout rate to 0.5  \n",
    "4) only relu activations  \n",
    "5) adadelt - decrease acc significantly  \n",
    "6) like in resnet 2.0 use batch normalization (bet that will not help) . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001, patience=3)\n",
    "\n",
    "def get_model_3():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = BatchNormalization()(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = BatchNormalization()(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    relu = Dense(256, activation='relu')(x)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x)\n",
    "    mult_1 = Multiply()([x, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x = Add()([mult_2, mult_1])\n",
    "\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = concatenate([x_img, x_txt, x]) # smth residual\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upgrades:  \n",
    "1) remove early stopping  \n",
    "2) epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/40\n",
      "38221/38221 [==============================] - 60s 2ms/sample - loss: 2.1722 - accuracy: 0.4370 - val_loss: 1.6440 - val_accuracy: 0.5675\n",
      "Epoch 2/40\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.8382 - accuracy: 0.5159 - val_loss: 1.5833 - val_accuracy: 0.5861\n",
      "Epoch 3/40\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.7720 - accuracy: 0.5251 - val_loss: 1.5624 - val_accuracy: 0.5962\n",
      "Epoch 4/40\n",
      "38221/38221 [==============================] - 55s 1ms/sample - loss: 1.7325 - accuracy: 0.5375 - val_loss: 1.5649 - val_accuracy: 0.5889\n",
      "Epoch 5/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.7034 - accuracy: 0.5407 - val_loss: 1.5711 - val_accuracy: 0.5863\n",
      "Epoch 6/40\n",
      "38221/38221 [==============================] - 55s 1ms/sample - loss: 1.6841 - accuracy: 0.5425 - val_loss: 1.5485 - val_accuracy: 0.5934\n",
      "Epoch 7/40\n",
      "38221/38221 [==============================] - 57s 1ms/sample - loss: 1.6648 - accuracy: 0.5512 - val_loss: 1.5471 - val_accuracy: 0.5960\n",
      "Epoch 8/40\n",
      "38221/38221 [==============================] - 52s 1ms/sample - loss: 1.6369 - accuracy: 0.5564 - val_loss: 1.5563 - val_accuracy: 0.5943\n",
      "Epoch 9/40\n",
      "38221/38221 [==============================] - 54s 1ms/sample - loss: 1.6232 - accuracy: 0.5607 - val_loss: 1.5481 - val_accuracy: 0.5938\n",
      "Epoch 10/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.6186 - accuracy: 0.5588 - val_loss: 1.5706 - val_accuracy: 0.5997\n",
      "Epoch 11/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.5888 - accuracy: 0.5627 - val_loss: 1.5589 - val_accuracy: 0.5927\n",
      "Epoch 12/40\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.5792 - accuracy: 0.5663 - val_loss: 1.5725 - val_accuracy: 0.5915\n",
      "Epoch 13/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.5664 - accuracy: 0.5716 - val_loss: 1.5507 - val_accuracy: 0.5990\n",
      "Epoch 14/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.5671 - accuracy: 0.5708 - val_loss: 1.5479 - val_accuracy: 0.5967\n",
      "Epoch 15/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.5623 - accuracy: 0.5728 - val_loss: 1.5549 - val_accuracy: 0.5929\n",
      "Epoch 16/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.5387 - accuracy: 0.5764 - val_loss: 1.5650 - val_accuracy: 0.5988\n",
      "Epoch 17/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.5312 - accuracy: 0.5759 - val_loss: 1.5490 - val_accuracy: 0.6009\n",
      "Epoch 18/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.5248 - accuracy: 0.5791 - val_loss: 1.5565 - val_accuracy: 0.6011\n",
      "Epoch 19/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.5067 - accuracy: 0.5820 - val_loss: 1.5804 - val_accuracy: 0.5974\n",
      "Epoch 20/40\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.4955 - accuracy: 0.5860 - val_loss: 1.5809 - val_accuracy: 0.5988\n",
      "Epoch 21/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.4882 - accuracy: 0.5862 - val_loss: 1.5729 - val_accuracy: 0.5985\n",
      "Epoch 22/40\n",
      "38221/38221 [==============================] - 47s 1ms/sample - loss: 1.4774 - accuracy: 0.5920 - val_loss: 1.5569 - val_accuracy: 0.5957\n",
      "Epoch 23/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.4806 - accuracy: 0.5866 - val_loss: 1.5615 - val_accuracy: 0.5957\n",
      "Epoch 24/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.4694 - accuracy: 0.5896 - val_loss: 1.5885 - val_accuracy: 0.5948\n",
      "Epoch 25/40\n",
      "38221/38221 [==============================] - 57s 1ms/sample - loss: 1.4680 - accuracy: 0.5918 - val_loss: 1.5586 - val_accuracy: 0.5934\n",
      "Epoch 26/40\n",
      "38221/38221 [==============================] - 56s 1ms/sample - loss: 1.4506 - accuracy: 0.5960 - val_loss: 1.5847 - val_accuracy: 0.5962\n",
      "Epoch 27/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.4445 - accuracy: 0.5969 - val_loss: 1.5707 - val_accuracy: 0.5960\n",
      "Epoch 28/40\n",
      "38221/38221 [==============================] - 52s 1ms/sample - loss: 1.4411 - accuracy: 0.5964 - val_loss: 1.5640 - val_accuracy: 0.5960\n",
      "Epoch 29/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.4316 - accuracy: 0.5997 - val_loss: 1.5755 - val_accuracy: 0.6016\n",
      "Epoch 30/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.4126 - accuracy: 0.6030 - val_loss: 1.6078 - val_accuracy: 0.5917\n",
      "Epoch 31/40\n",
      "38221/38221 [==============================] - 49s 1ms/sample - loss: 1.4182 - accuracy: 0.6020 - val_loss: 1.6193 - val_accuracy: 0.5976\n",
      "Epoch 32/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.4037 - accuracy: 0.6055 - val_loss: 1.5955 - val_accuracy: 0.5929\n",
      "Epoch 33/40\n",
      "38221/38221 [==============================] - 54s 1ms/sample - loss: 1.3892 - accuracy: 0.6080 - val_loss: 1.6268 - val_accuracy: 0.5941\n",
      "Epoch 34/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.3935 - accuracy: 0.6063 - val_loss: 1.5998 - val_accuracy: 0.5962\n",
      "Epoch 35/40\n",
      "38221/38221 [==============================] - 54s 1ms/sample - loss: 1.3768 - accuracy: 0.6128 - val_loss: 1.6103 - val_accuracy: 0.5948\n",
      "Epoch 36/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.3866 - accuracy: 0.6095 - val_loss: 1.5878 - val_accuracy: 0.5976\n",
      "Epoch 37/40\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 1.3823 - accuracy: 0.6091 - val_loss: 1.6135 - val_accuracy: 0.5945\n",
      "Epoch 38/40\n",
      "35488/38221 [==========================>...] - ETA: 4s - loss: 1.3730 - accuracy: 0.6119"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4c848a788e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_3 = get_model_3()\n",
    "model_3.fit([x_img_train, x_txt_train], y_train, epochs=40, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = get_model_3()\n",
    "model_3.fit([x_img_train, x_txt_train], y_train, epochs=40, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_more_highways():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = BatchNormalization()(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    relu = Dense(512, activation='relu')(x_img)\n",
    "    sigmoid = Dense(512, activation='sigmoid')(x_img)\n",
    "    mult_1 = Multiply()([x_img, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x_img = Add()([mult_2, mult_1])\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "                                         \n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = BatchNormalization()(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    relu = Dense(256, activation='relu')(x_txt)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x_txt)\n",
    "    mult_1 = Multiply()([x_txt, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x_txt = Add()([mult_2, mult_1])\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "                                         \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    relu = Dense(256, activation='relu')(x)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x)\n",
    "    mult_1 = Multiply()([x, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x = Add()([mult_2, mult_1])\n",
    "\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = concatenate([x_img, x_txt, x]) # smth residual\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/40\n",
      "38221/38221 [==============================] - 78s 2ms/sample - loss: 2.4668 - accuracy: 0.3681 - val_loss: 1.7522 - val_accuracy: 0.5477\n",
      "Epoch 2/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 2.0252 - accuracy: 0.4672 - val_loss: 1.6892 - val_accuracy: 0.5689\n",
      "Epoch 3/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.9499 - accuracy: 0.4912 - val_loss: 1.6681 - val_accuracy: 0.5698\n",
      "Epoch 4/40\n",
      "38221/38221 [==============================] - 70s 2ms/sample - loss: 1.8968 - accuracy: 0.5002 - val_loss: 1.6581 - val_accuracy: 0.5783\n",
      "Epoch 5/40\n",
      "38221/38221 [==============================] - 77s 2ms/sample - loss: 1.8602 - accuracy: 0.5067 - val_loss: 1.6336 - val_accuracy: 0.5781\n",
      "Epoch 6/40\n",
      "38221/38221 [==============================] - 74s 2ms/sample - loss: 1.8339 - accuracy: 0.5144 - val_loss: 1.6096 - val_accuracy: 0.5811\n",
      "Epoch 7/40\n",
      "38221/38221 [==============================] - 72s 2ms/sample - loss: 1.8196 - accuracy: 0.5151 - val_loss: 1.6124 - val_accuracy: 0.5872\n",
      "Epoch 8/40\n",
      "38221/38221 [==============================] - 85s 2ms/sample - loss: 1.7969 - accuracy: 0.5230 - val_loss: 1.6061 - val_accuracy: 0.5844\n",
      "Epoch 9/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.7787 - accuracy: 0.5248 - val_loss: 1.5939 - val_accuracy: 0.5861\n",
      "Epoch 10/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.7549 - accuracy: 0.5322 - val_loss: 1.5936 - val_accuracy: 0.5877\n",
      "Epoch 11/40\n",
      "38221/38221 [==============================] - 66s 2ms/sample - loss: 1.7509 - accuracy: 0.5279 - val_loss: 1.5870 - val_accuracy: 0.5903\n",
      "Epoch 12/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.7301 - accuracy: 0.5376 - val_loss: 1.5793 - val_accuracy: 0.5941\n",
      "Epoch 13/40\n",
      "38221/38221 [==============================] - 77s 2ms/sample - loss: 1.7165 - accuracy: 0.5393 - val_loss: 1.5843 - val_accuracy: 0.5879\n",
      "Epoch 14/40\n",
      "38221/38221 [==============================] - 76s 2ms/sample - loss: 1.7122 - accuracy: 0.5399 - val_loss: 1.5673 - val_accuracy: 0.5910\n",
      "Epoch 15/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.6885 - accuracy: 0.5496 - val_loss: 1.5514 - val_accuracy: 0.5936\n",
      "Epoch 16/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.6840 - accuracy: 0.5458 - val_loss: 1.5594 - val_accuracy: 0.5901\n",
      "Epoch 17/40\n",
      "38221/38221 [==============================] - 76s 2ms/sample - loss: 1.6622 - accuracy: 0.5510 - val_loss: 1.5470 - val_accuracy: 0.5931\n",
      "Epoch 18/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.6643 - accuracy: 0.5529 - val_loss: 1.5415 - val_accuracy: 0.5927\n",
      "Epoch 19/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.6563 - accuracy: 0.5522 - val_loss: 1.5557 - val_accuracy: 0.5903\n",
      "Epoch 20/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.6439 - accuracy: 0.5566 - val_loss: 1.5525 - val_accuracy: 0.5912\n",
      "Epoch 21/40\n",
      "38221/38221 [==============================] - 70s 2ms/sample - loss: 1.6363 - accuracy: 0.5572 - val_loss: 1.5665 - val_accuracy: 0.5950\n",
      "Epoch 22/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.6279 - accuracy: 0.5573 - val_loss: 1.5500 - val_accuracy: 0.5898\n",
      "Epoch 23/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.6164 - accuracy: 0.5620 - val_loss: 1.5580 - val_accuracy: 0.5985\n",
      "Epoch 24/40\n",
      "38221/38221 [==============================] - 69s 2ms/sample - loss: 1.6266 - accuracy: 0.5565 - val_loss: 1.5474 - val_accuracy: 0.5882\n",
      "Epoch 25/40\n",
      "38221/38221 [==============================] - 71s 2ms/sample - loss: 1.6091 - accuracy: 0.5623 - val_loss: 1.5418 - val_accuracy: 0.5931\n",
      "Epoch 26/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.5985 - accuracy: 0.5668 - val_loss: 1.5391 - val_accuracy: 0.5985\n",
      "Epoch 27/40\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.5889 - accuracy: 0.5678 - val_loss: 1.5529 - val_accuracy: 0.5960\n",
      "Epoch 28/40\n",
      "38221/38221 [==============================] - 66s 2ms/sample - loss: 1.5900 - accuracy: 0.5682 - val_loss: 1.5526 - val_accuracy: 0.6014\n",
      "Epoch 29/40\n",
      "38221/38221 [==============================] - 53s 1ms/sample - loss: 1.5664 - accuracy: 0.5736 - val_loss: 1.5501 - val_accuracy: 0.5985\n",
      "Epoch 30/40\n",
      "38221/38221 [==============================] - 48s 1ms/sample - loss: 1.5654 - accuracy: 0.5720 - val_loss: 1.5535 - val_accuracy: 0.5967\n",
      "Epoch 31/40\n",
      "38221/38221 [==============================] - 52s 1ms/sample - loss: 1.5698 - accuracy: 0.5736 - val_loss: 1.5436 - val_accuracy: 0.5957\n",
      "Epoch 32/40\n",
      "38221/38221 [==============================] - 53s 1ms/sample - loss: 1.5588 - accuracy: 0.5755 - val_loss: 1.5498 - val_accuracy: 0.5922\n",
      "Epoch 33/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.5522 - accuracy: 0.5757 - val_loss: 1.5697 - val_accuracy: 0.5910\n",
      "Epoch 34/40\n",
      "38221/38221 [==============================] - 52s 1ms/sample - loss: 1.5420 - accuracy: 0.5781 - val_loss: 1.5529 - val_accuracy: 0.5927\n",
      "Epoch 35/40\n",
      "38221/38221 [==============================] - 55s 1ms/sample - loss: 1.5455 - accuracy: 0.5790 - val_loss: 1.5554 - val_accuracy: 0.5924\n",
      "Epoch 36/40\n",
      "38221/38221 [==============================] - 46s 1ms/sample - loss: 1.5476 - accuracy: 0.5760 - val_loss: 1.5472 - val_accuracy: 0.5990\n",
      "Epoch 37/40\n",
      "38221/38221 [==============================] - 43s 1ms/sample - loss: 1.5347 - accuracy: 0.5799 - val_loss: 1.5423 - val_accuracy: 0.5960\n",
      "Epoch 38/40\n",
      "38221/38221 [==============================] - 44s 1ms/sample - loss: 1.5254 - accuracy: 0.5819 - val_loss: 1.5541 - val_accuracy: 0.5943\n",
      "Epoch 39/40\n",
      "38221/38221 [==============================] - 43s 1ms/sample - loss: 1.5276 - accuracy: 0.5831 - val_loss: 1.5492 - val_accuracy: 0.6002\n",
      "Epoch 40/40\n",
      "38221/38221 [==============================] - 50s 1ms/sample - loss: 1.5073 - accuracy: 0.5840 - val_loss: 1.5580 - val_accuracy: 0.5957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ea45a90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = get_model_more_highways()\n",
    "model_4.fit([x_img_train, x_txt_train], y_train, epochs=40, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_5():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = BatchNormalization()(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    relu = Dense(512, activation='relu')(x_img)\n",
    "    sigmoid = Dense(512, activation='sigmoid')(x_img)\n",
    "    mult_1 = Multiply()([x_img, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x_img = Add()([mult_2, mult_1])\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "                                         \n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = BatchNormalization()(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    relu = Dense(256, activation='relu')(x_txt)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x_txt)\n",
    "    mult_1 = Multiply()([x_txt, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x_txt = Add()([mult_2, mult_1])\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "                                         \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    relu = Dense(256, activation='relu')(x)\n",
    "    sigmoid = Dense(256, activation='sigmoid')(x)\n",
    "    mult_1 = Multiply()([x, sigmoid])\n",
    "    minus = Lambda(lambda x: 1.0 - x)(sigmoid)\n",
    "    mult_2 = Multiply()([minus, relu])\n",
    "    x = Add()([mult_2, mult_1])\n",
    "\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 53s 1ms/sample - loss: 2.8627 - accuracy: 0.2699 - val_loss: 2.0058 - val_accuracy: 0.4822\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 51s 1ms/sample - loss: 2.2518 - accuracy: 0.4131 - val_loss: 1.8349 - val_accuracy: 0.5147\n",
      "Epoch 3/30\n",
      "33568/38221 [=========================>....] - ETA: 6s - loss: 2.1166 - accuracy: 0.4468"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-1976cbfef5b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_5 = get_model_5()\n",
    "model_5.fit([x_img_train, x_txt_train], y_train, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.python.keras.utils.generic_utils import to_list\n",
    "from  tensorflow.keras import regularizers \n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "class Highway(Layer):\n",
    "    \"\"\"Densely connected highway network.\n",
    "    Highway layers are a natural extension of LSTMs to feedforward networks.\n",
    "    # Arguments\n",
    "        init: name of initialization function for the weights of the layer\n",
    "            (see [initializations](../initializations.md)),\n",
    "            or alternatively, Theano function to use for weights\n",
    "            initialization. This parameter is only relevant\n",
    "            if you don't pass a `weights` argument.\n",
    "        activation: name of activation function to use\n",
    "            (see [activations](../activations.md)),\n",
    "            or alternatively, elementwise Theano function.\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: a(x) = x).\n",
    "        weights: list of Numpy arrays to set as initial weights.\n",
    "            The list should have 2 elements, of shape `(input_dim, output_dim)`\n",
    "            and (output_dim,) for weights and biases respectively.\n",
    "        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n",
    "            (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n",
    "            applied to the bias.\n",
    "        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n",
    "            applied to the network output.\n",
    "        W_constraint: instance of the [constraints](../constraints.md) module\n",
    "            (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "        b_constraint: instance of the [constraints](../constraints.md) module,\n",
    "            applied to the bias.\n",
    "        bias: whether to include a bias\n",
    "            (i.e. make the layer affine rather than linear).\n",
    "        input_dim: dimensionality of the input (integer). This argument\n",
    "            (or alternatively, the keyword argument `input_shape`)\n",
    "            is required when using this layer as the first layer in a model.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(nb_samples, input_dim)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(nb_samples, input_dim)`.\n",
    "    # References\n",
    "        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 init='glorot_uniform',\n",
    "                 activation=None,\n",
    "                 weights=None,\n",
    "                 W_regularizer=None,\n",
    "                 b_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 W_constraint=None,\n",
    "                 b_constraint=None,\n",
    "                 bias=True,\n",
    "                 input_dim=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        if 'transform_bias' in kwargs:\n",
    "            kwargs.pop('transform_bias')\n",
    "            warnings.warn('`transform_bias` argument is deprecated and '\n",
    "                          'has been removed.')\n",
    "        self.init = initializers.get(init)\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "        super(Highway, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(),\n",
    "                                    shape=(None, input_dim))\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_dim, input_dim),\n",
    "                                 initializer=self.init,\n",
    "                                 name='W',\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.W_carry = self.add_weight(shape=(input_dim, input_dim),\n",
    "                                       initializer=self.init,\n",
    "                                       name='W_carry')\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='b',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.b_carry = self.add_weight(shape=(input_dim,),\n",
    "                                           initializer='one',\n",
    "                                           name='b_carry')\n",
    "        else:\n",
    "            self.b_carry = None\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        y = K.dot(x, self.W_carry)\n",
    "        if self.bias:\n",
    "            y += self.b_carry\n",
    "        transform_weight = activations.sigmoid(y)\n",
    "        y = K.dot(x, self.W)\n",
    "        if self.bias:\n",
    "            y += self.b\n",
    "        act = self.activation(y)\n",
    "        act *= transform_weight\n",
    "        output = act + (1 - transform_weight) * x\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'init': initializers.serialize(self.init),\n",
    "                  'activation': activations.serialize(self.activation),\n",
    "                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n",
    "                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n",
    "                  'activity_regularizer':\n",
    "                      regularizers.serialize(self.activity_regularizer),\n",
    "                  'W_constraint': constraints.serialize(self.W_constraint),\n",
    "                  'b_constraint': constraints.serialize(self.b_constraint),\n",
    "                  'bias': self.bias,\n",
    "                  'input_dim': self.input_dim}\n",
    "        base_config = super(Highway, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_6():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = BatchNormalization()(x_img)\n",
    "    x_img = Dense(512, activation='relu')(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = BatchNormalization()(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Highway()(x)\n",
    "    \n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     x = concatenate([x_img, x_txt, x]) # smth residual\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 2.4450 - accuracy: 0.3659 - val_loss: 1.7573 - val_accuracy: 0.5361\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 1.9604 - accuracy: 0.4817 - val_loss: 1.6509 - val_accuracy: 0.5587\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 38s 1ms/sample - loss: 1.8686 - accuracy: 0.5052 - val_loss: 1.6237 - val_accuracy: 0.5679\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 30s 796us/sample - loss: 1.8087 - accuracy: 0.5197 - val_loss: 1.6133 - val_accuracy: 0.5757\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 28s 741us/sample - loss: 1.7872 - accuracy: 0.5227 - val_loss: 1.6092 - val_accuracy: 0.5809\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 29s 751us/sample - loss: 1.7718 - accuracy: 0.5294 - val_loss: 1.6202 - val_accuracy: 0.5759\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 28s 728us/sample - loss: 1.7513 - accuracy: 0.5333 - val_loss: 1.6260 - val_accuracy: 0.5712\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 28s 734us/sample - loss: 1.7382 - accuracy: 0.5384 - val_loss: 1.5824 - val_accuracy: 0.5856\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 30s 796us/sample - loss: 1.7249 - accuracy: 0.5405 - val_loss: 1.6081 - val_accuracy: 0.5846\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 33s 853us/sample - loss: 1.7132 - accuracy: 0.5449 - val_loss: 1.5715 - val_accuracy: 0.5952\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 34s 895us/sample - loss: 1.6949 - accuracy: 0.5474 - val_loss: 1.5721 - val_accuracy: 0.5894\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 36s 942us/sample - loss: 1.6880 - accuracy: 0.5494 - val_loss: 1.5671 - val_accuracy: 0.5931\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 36s 938us/sample - loss: 1.6786 - accuracy: 0.5552 - val_loss: 1.5674 - val_accuracy: 0.5896\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 32s 828us/sample - loss: 1.6623 - accuracy: 0.5574 - val_loss: 1.5815 - val_accuracy: 0.5981\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 33s 871us/sample - loss: 1.6647 - accuracy: 0.5561 - val_loss: 1.5973 - val_accuracy: 0.5865\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 34s 899us/sample - loss: 1.6532 - accuracy: 0.5565 - val_loss: 1.5869 - val_accuracy: 0.5879\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 35s 907us/sample - loss: 1.6504 - accuracy: 0.5568 - val_loss: 1.5605 - val_accuracy: 0.5929\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 34s 897us/sample - loss: 1.6402 - accuracy: 0.5630 - val_loss: 1.5763 - val_accuracy: 0.5943\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 27s 714us/sample - loss: 1.6428 - accuracy: 0.5623 - val_loss: 1.5693 - val_accuracy: 0.5974\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 33s 875us/sample - loss: 1.6356 - accuracy: 0.5621 - val_loss: 1.5662 - val_accuracy: 0.5934\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 27s 714us/sample - loss: 1.6259 - accuracy: 0.5622 - val_loss: 1.5546 - val_accuracy: 0.5917\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 27s 715us/sample - loss: 1.6112 - accuracy: 0.5684 - val_loss: 1.5609 - val_accuracy: 0.5957\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 27s 716us/sample - loss: 1.6033 - accuracy: 0.5681 - val_loss: 1.5591 - val_accuracy: 0.5922\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 31s 813us/sample - loss: 1.6003 - accuracy: 0.5716 - val_loss: 1.5595 - val_accuracy: 0.5929\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 31s 799us/sample - loss: 1.6022 - accuracy: 0.5705 - val_loss: 1.5503 - val_accuracy: 0.5997\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 30s 775us/sample - loss: 1.5907 - accuracy: 0.5729 - val_loss: 1.5650 - val_accuracy: 0.5955\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 1.5978 - accuracy: 0.5710 - val_loss: 1.5710 - val_accuracy: 0.5967\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 37s 967us/sample - loss: 1.5773 - accuracy: 0.5758 - val_loss: 1.5728 - val_accuracy: 0.6007\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 32s 838us/sample - loss: 1.5695 - accuracy: 0.5776 - val_loss: 1.5658 - val_accuracy: 0.5955\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 35s 905us/sample - loss: 1.5743 - accuracy: 0.5783 - val_loss: 1.5696 - val_accuracy: 0.5936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c1e0450>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6 = get_model_6()\n",
    "model_6.fit([x_img_train, x_txt_train], y_train, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_7():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = Highway()(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = Highway()(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Highway()(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "#     x = concatenate([x_img, x_txt, x]) # smth residual\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 93s 2ms/sample - loss: 2.4309 - accuracy: 0.3687 - val_loss: 1.7812 - val_accuracy: 0.5248\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 81s 2ms/sample - loss: 1.9300 - accuracy: 0.4918 - val_loss: 1.6566 - val_accuracy: 0.5595\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 79s 2ms/sample - loss: 1.8102 - accuracy: 0.5204 - val_loss: 1.6344 - val_accuracy: 0.5696\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 80s 2ms/sample - loss: 1.7490 - accuracy: 0.5376 - val_loss: 1.6181 - val_accuracy: 0.5722\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 84s 2ms/sample - loss: 1.7099 - accuracy: 0.5489 - val_loss: 1.5988 - val_accuracy: 0.5814\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 83s 2ms/sample - loss: 1.6748 - accuracy: 0.5556 - val_loss: 1.5945 - val_accuracy: 0.5776\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 89s 2ms/sample - loss: 1.6358 - accuracy: 0.5665 - val_loss: 1.5738 - val_accuracy: 0.5856\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 82s 2ms/sample - loss: 1.6171 - accuracy: 0.5704 - val_loss: 1.5652 - val_accuracy: 0.5894\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 87s 2ms/sample - loss: 1.6013 - accuracy: 0.5747 - val_loss: 1.5629 - val_accuracy: 0.5858\n",
      "Epoch 10/30\n",
      "35104/38221 [==========================>...] - ETA: 7s - loss: 1.5851 - accuracy: 0.5768"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-86ffaec8811f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_7 = get_model_7()\n",
    "model_7.fit([x_img_train, x_txt_train], y_train, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_8():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = Highway()(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = Highway()(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Highway()(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = concatenate([x_img, x_txt, x]) # smth residual\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 97s 3ms/sample - loss: 2.1876 - accuracy: 0.4245 - val_loss: 1.6591 - val_accuracy: 0.5571\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 102s 3ms/sample - loss: 1.7865 - accuracy: 0.5209 - val_loss: 1.6180 - val_accuracy: 0.5708\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 82s 2ms/sample - loss: 1.6994 - accuracy: 0.5427 - val_loss: 1.6130 - val_accuracy: 0.5792\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 97s 3ms/sample - loss: 1.6455 - accuracy: 0.5540 - val_loss: 1.5814 - val_accuracy: 0.5776\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 108s 3ms/sample - loss: 1.5968 - accuracy: 0.5660 - val_loss: 1.5665 - val_accuracy: 0.5825\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 107s 3ms/sample - loss: 1.5662 - accuracy: 0.5726 - val_loss: 1.5382 - val_accuracy: 0.5943\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 109s 3ms/sample - loss: 1.5349 - accuracy: 0.5803 - val_loss: 1.5631 - val_accuracy: 0.5870\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 105s 3ms/sample - loss: 1.5180 - accuracy: 0.5822 - val_loss: 1.5589 - val_accuracy: 0.5821\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 99s 3ms/sample - loss: 1.4898 - accuracy: 0.5916 - val_loss: 1.5686 - val_accuracy: 0.5870\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 94s 2ms/sample - loss: 1.4681 - accuracy: 0.5954 - val_loss: 1.5455 - val_accuracy: 0.5898\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 92s 2ms/sample - loss: 1.4540 - accuracy: 0.5986 - val_loss: 1.5575 - val_accuracy: 0.5868\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 96s 3ms/sample - loss: 1.4348 - accuracy: 0.6028 - val_loss: 1.5834 - val_accuracy: 0.5846\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 96s 3ms/sample - loss: 1.4159 - accuracy: 0.6075 - val_loss: 1.5706 - val_accuracy: 0.5778\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 91s 2ms/sample - loss: 1.4046 - accuracy: 0.6094 - val_loss: 1.5593 - val_accuracy: 0.5934\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 108s 3ms/sample - loss: 1.3838 - accuracy: 0.6130 - val_loss: 1.5722 - val_accuracy: 0.5934\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 116s 3ms/sample - loss: 1.3793 - accuracy: 0.6153 - val_loss: 1.5524 - val_accuracy: 0.5964\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 65s 2ms/sample - loss: 1.3598 - accuracy: 0.6196 - val_loss: 1.5752 - val_accuracy: 0.5908\n",
      "Epoch 18/30\n",
      "29568/38221 [======================>.......] - ETA: 14s - loss: 1.3321 - accuracy: 0.6265"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-9fa2292051aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_txt_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_8 = get_model_8()\n",
    "model_8.fit([x_img_train, x_txt_train], y_train, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_9():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(1024, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "    x_img = Highway()(x_img)\n",
    "    x_img = Dropout(0.5)(x_img)\n",
    "\n",
    "    x_txt = Dense(512, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "    x_txt = Highway()(x_txt)\n",
    "    x_txt = Dropout(0.5)(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256)(x)\n",
    "    x = Highway()(x)\n",
    "    x1 = Dropout(0.5)(x)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt, x1]) # smth residual\n",
    "    x = Dense(256)(x)\n",
    "    x = Highway()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 63s 2ms/sample - loss: 2.4688 - accuracy: 0.3751 - val_loss: 1.9225 - val_accuracy: 0.5032\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 59s 2ms/sample - loss: 2.1493 - accuracy: 0.4545 - val_loss: 1.8679 - val_accuracy: 0.5166\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 58s 2ms/sample - loss: 2.0595 - accuracy: 0.4741 - val_loss: 1.8319 - val_accuracy: 0.5413\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 58s 2ms/sample - loss: 2.0058 - accuracy: 0.4850 - val_loss: 1.8237 - val_accuracy: 0.5286\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 58s 2ms/sample - loss: 1.9698 - accuracy: 0.4941 - val_loss: 1.7971 - val_accuracy: 0.5418\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 72s 2ms/sample - loss: 1.9207 - accuracy: 0.5018 - val_loss: 1.7599 - val_accuracy: 0.5493\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 67s 2ms/sample - loss: 1.8943 - accuracy: 0.5080 - val_loss: 1.7832 - val_accuracy: 0.5383\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 82s 2ms/sample - loss: 1.8702 - accuracy: 0.5115 - val_loss: 1.7708 - val_accuracy: 0.5371\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 72s 2ms/sample - loss: 1.8346 - accuracy: 0.5218 - val_loss: 1.7486 - val_accuracy: 0.5446\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 73s 2ms/sample - loss: 1.8214 - accuracy: 0.5225 - val_loss: 1.7624 - val_accuracy: 0.5373\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 72s 2ms/sample - loss: 1.7823 - accuracy: 0.5297 - val_loss: 1.7243 - val_accuracy: 0.5517\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 90s 2ms/sample - loss: 1.7721 - accuracy: 0.5364 - val_loss: 1.7250 - val_accuracy: 0.5467\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 71s 2ms/sample - loss: 1.7394 - accuracy: 0.5413 - val_loss: 1.7116 - val_accuracy: 0.5505\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 67s 2ms/sample - loss: 1.7238 - accuracy: 0.5410 - val_loss: 1.7099 - val_accuracy: 0.5486\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.7016 - accuracy: 0.5445 - val_loss: 1.7495 - val_accuracy: 0.5477\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 72s 2ms/sample - loss: 1.6881 - accuracy: 0.5505 - val_loss: 1.7356 - val_accuracy: 0.5434\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 68s 2ms/sample - loss: 1.6623 - accuracy: 0.5542 - val_loss: 1.7224 - val_accuracy: 0.5470\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 72s 2ms/sample - loss: 1.6524 - accuracy: 0.5574 - val_loss: 1.7426 - val_accuracy: 0.5463\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 67s 2ms/sample - loss: 1.6337 - accuracy: 0.5603 - val_loss: 1.7320 - val_accuracy: 0.5392\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 65s 2ms/sample - loss: 1.6223 - accuracy: 0.5652 - val_loss: 1.7121 - val_accuracy: 0.5547\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 93s 2ms/sample - loss: 1.6001 - accuracy: 0.5674 - val_loss: 1.7373 - val_accuracy: 0.5465\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 101s 3ms/sample - loss: 1.5880 - accuracy: 0.5690 - val_loss: 1.7664 - val_accuracy: 0.5387\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 105s 3ms/sample - loss: 1.5788 - accuracy: 0.5736 - val_loss: 1.7652 - val_accuracy: 0.5357\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 105s 3ms/sample - loss: 1.5709 - accuracy: 0.5765 - val_loss: 1.7837 - val_accuracy: 0.5463\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 96s 3ms/sample - loss: 1.5597 - accuracy: 0.5788 - val_loss: 1.7543 - val_accuracy: 0.5385\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 104s 3ms/sample - loss: 1.5400 - accuracy: 0.5794 - val_loss: 1.7528 - val_accuracy: 0.5418\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 101s 3ms/sample - loss: 1.5305 - accuracy: 0.5832 - val_loss: 1.7537 - val_accuracy: 0.5474\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 101s 3ms/sample - loss: 1.5166 - accuracy: 0.5858 - val_loss: 1.7851 - val_accuracy: 0.5354\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 104s 3ms/sample - loss: 1.5100 - accuracy: 0.5872 - val_loss: 1.7898 - val_accuracy: 0.5404\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 93s 2ms/sample - loss: 1.4907 - accuracy: 0.5904 - val_loss: 1.8069 - val_accuracy: 0.5456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18cc43150>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9 = get_model_9()\n",
    "model_9.fit([x_img_train, x_txt_train], y_train, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01431737 0.02877704 0.16622615 ... 0.92601949 0.55370623 1.17222333]\n"
     ]
    }
   ],
   "source": [
    "print(x_img_test[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(norm_x_img_q, norm_x_txt_q, y_q, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/30\n",
      "38221/38221 [==============================] - 36s 933us/sample - loss: 2.1534 - accuracy: 0.4437 - val_loss: 1.6515 - val_accuracy: 0.5637\n",
      "Epoch 2/30\n",
      "38221/38221 [==============================] - 33s 863us/sample - loss: 1.8393 - accuracy: 0.5168 - val_loss: 1.5814 - val_accuracy: 0.5877\n",
      "Epoch 3/30\n",
      "38221/38221 [==============================] - 32s 828us/sample - loss: 1.7804 - accuracy: 0.5280 - val_loss: 1.5548 - val_accuracy: 0.5854\n",
      "Epoch 4/30\n",
      "38221/38221 [==============================] - 32s 847us/sample - loss: 1.7407 - accuracy: 0.5386 - val_loss: 1.5312 - val_accuracy: 0.5943\n",
      "Epoch 5/30\n",
      "38221/38221 [==============================] - 31s 812us/sample - loss: 1.7070 - accuracy: 0.5442 - val_loss: 1.5338 - val_accuracy: 0.5992\n",
      "Epoch 6/30\n",
      "38221/38221 [==============================] - 31s 815us/sample - loss: 1.6805 - accuracy: 0.5546 - val_loss: 1.5188 - val_accuracy: 0.6028\n",
      "Epoch 7/30\n",
      "38221/38221 [==============================] - 35s 909us/sample - loss: 1.6589 - accuracy: 0.5576 - val_loss: 1.5330 - val_accuracy: 0.5955\n",
      "Epoch 8/30\n",
      "38221/38221 [==============================] - 39s 1ms/sample - loss: 1.6387 - accuracy: 0.5632 - val_loss: 1.5318 - val_accuracy: 0.6037\n",
      "Epoch 9/30\n",
      "38221/38221 [==============================] - 35s 923us/sample - loss: 1.6227 - accuracy: 0.5676 - val_loss: 1.5212 - val_accuracy: 0.6028\n",
      "Epoch 10/30\n",
      "38221/38221 [==============================] - 43s 1ms/sample - loss: 1.6072 - accuracy: 0.5688 - val_loss: 1.5246 - val_accuracy: 0.6042\n",
      "Epoch 11/30\n",
      "38221/38221 [==============================] - 32s 849us/sample - loss: 1.5994 - accuracy: 0.5696 - val_loss: 1.5028 - val_accuracy: 0.6108\n",
      "Epoch 12/30\n",
      "38221/38221 [==============================] - 62s 2ms/sample - loss: 1.5708 - accuracy: 0.5748 - val_loss: 1.5001 - val_accuracy: 0.6047\n",
      "Epoch 13/30\n",
      "38221/38221 [==============================] - 57s 1ms/sample - loss: 1.5535 - accuracy: 0.5793 - val_loss: 1.5198 - val_accuracy: 0.6094\n",
      "Epoch 14/30\n",
      "38221/38221 [==============================] - 54s 1ms/sample - loss: 1.5440 - accuracy: 0.5811 - val_loss: 1.5081 - val_accuracy: 0.6054\n",
      "Epoch 15/30\n",
      "38221/38221 [==============================] - 59s 2ms/sample - loss: 1.5325 - accuracy: 0.5834 - val_loss: 1.5030 - val_accuracy: 0.6073\n",
      "Epoch 16/30\n",
      "38221/38221 [==============================] - 59s 2ms/sample - loss: 1.5182 - accuracy: 0.5866 - val_loss: 1.5128 - val_accuracy: 0.6075\n",
      "Epoch 17/30\n",
      "38221/38221 [==============================] - 61s 2ms/sample - loss: 1.5071 - accuracy: 0.5870 - val_loss: 1.4955 - val_accuracy: 0.6051\n",
      "Epoch 18/30\n",
      "38221/38221 [==============================] - 42s 1ms/sample - loss: 1.5046 - accuracy: 0.5861 - val_loss: 1.5077 - val_accuracy: 0.6136\n",
      "Epoch 19/30\n",
      "38221/38221 [==============================] - 32s 838us/sample - loss: 1.4781 - accuracy: 0.5915 - val_loss: 1.5095 - val_accuracy: 0.6084\n",
      "Epoch 20/30\n",
      "38221/38221 [==============================] - 31s 810us/sample - loss: 1.4706 - accuracy: 0.5981 - val_loss: 1.5327 - val_accuracy: 0.6000\n",
      "Epoch 21/30\n",
      "38221/38221 [==============================] - 38s 989us/sample - loss: 1.4694 - accuracy: 0.5963 - val_loss: 1.5168 - val_accuracy: 0.6096\n",
      "Epoch 22/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 1.4545 - accuracy: 0.5988 - val_loss: 1.5352 - val_accuracy: 0.6037\n",
      "Epoch 23/30\n",
      "38221/38221 [==============================] - 28s 735us/sample - loss: 1.4308 - accuracy: 0.6040 - val_loss: 1.5318 - val_accuracy: 0.6077\n",
      "Epoch 24/30\n",
      "38221/38221 [==============================] - 28s 745us/sample - loss: 1.4270 - accuracy: 0.6056 - val_loss: 1.5279 - val_accuracy: 0.6084\n",
      "Epoch 25/30\n",
      "38221/38221 [==============================] - 28s 739us/sample - loss: 1.4122 - accuracy: 0.6092 - val_loss: 1.5383 - val_accuracy: 0.6143\n",
      "Epoch 26/30\n",
      "38221/38221 [==============================] - 28s 736us/sample - loss: 1.4021 - accuracy: 0.6098 - val_loss: 1.5534 - val_accuracy: 0.6098\n",
      "Epoch 27/30\n",
      "38221/38221 [==============================] - 29s 768us/sample - loss: 1.3953 - accuracy: 0.6127 - val_loss: 1.5496 - val_accuracy: 0.6025\n",
      "Epoch 28/30\n",
      "38221/38221 [==============================] - 35s 913us/sample - loss: 1.3842 - accuracy: 0.6152 - val_loss: 1.5389 - val_accuracy: 0.6103\n",
      "Epoch 29/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 1.3706 - accuracy: 0.6178 - val_loss: 1.5507 - val_accuracy: 0.6068\n",
      "Epoch 30/30\n",
      "38221/38221 [==============================] - 40s 1ms/sample - loss: 1.3671 - accuracy: 0.6191 - val_loss: 1.5357 - val_accuracy: 0.6058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f1e8490>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = get_model_3()\n",
    "model_3.fit([x_img_train, x_txt_train], y_train, epochs=30, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
