{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from struct import unpack\n",
    "from base64 import b64decode\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dmitry/Downloads/topics_dataset.json\"\n",
    "df = pd.read_json(filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 15427 to 149484\n",
      "Data columns (total 3 columns):\n",
      "x1    10000 non-null object\n",
      "x2    10000 non-null object\n",
      "y1    10000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 312.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cutted = df.sample(n=10000)\n",
    "df_cutted.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_img = Input(shape=(1024,))\n",
    "inp_txt = Input(shape=(300,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001, patience=3)\n",
    "\n",
    "def get_model_1():\n",
    "    x_img = Dense(64, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(64, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(64, activation='relu')(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def unpck(l, x):\n",
    "    return unpack('%df' % l, b64decode(x.encode('utf-8')))\n",
    "\n",
    "unpck_img = partial(unpck, IMG_LEN)\n",
    "unpck_txt = partial(unpck, TXT_LEN)\n",
    "\n",
    "x_img = np.stack(df_cutted['x1'].map(unpck_img), axis=0)\n",
    "x_txt = np.stack(df_cutted['x2'].map(unpck_txt), axis=0)\n",
    "y = to_categorical(np.array(df_cutted['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024) (10000, 300) (10000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(x_img.shape, x_txt.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 342us/sample - loss: 0.0842 - accuracy: 0.9804 - val_loss: 0.0699 - val_accuracy: 0.9811\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 1s 116us/sample - loss: 0.0661 - accuracy: 0.9816 - val_loss: 0.0572 - val_accuracy: 0.9825\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 1s 115us/sample - loss: 0.0589 - accuracy: 0.9826 - val_loss: 0.0549 - val_accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 1s 116us/sample - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.0514 - val_accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 1s 114us/sample - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.0507 - val_accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 1s 115us/sample - loss: 0.0510 - accuracy: 0.9841 - val_loss: 0.0493 - val_accuracy: 0.9844\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 1s 119us/sample - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0491 - val_accuracy: 0.9843\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 1s 115us/sample - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.0485 - val_accuracy: 0.9849\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 1s 116us/sample - loss: 0.0467 - accuracy: 0.9852 - val_loss: 0.0488 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 1s 116us/sample - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0480 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1489a95d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_img, x_txt], y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.sample(n=10000)\n",
    "x_img_test = np.stack(df_test['x1'].map(unpck_img), axis=0)\n",
    "x_txt_test = np.stack(df_test['x2'].map(unpck_txt), axis=0)\n",
    "y_test = to_categorical(np.array(df_test['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04970714685320854, 0.98471624]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = df.sample(frac=0.25)\n",
    "x_img_q = np.stack(df_q['x1'].map(unpck_img), axis=0)\n",
    "x_txt_q = np.stack(df_q['x2'].map(unpck_txt), axis=0)\n",
    "y_q = to_categorical(np.array(df_q['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47776 samples, validate on 5309 samples\n",
      "Epoch 1/20\n",
      "47776/47776 [==============================] - 6s 135us/sample - loss: 0.0648 - accuracy: 0.9821 - val_loss: 0.0505 - val_accuracy: 0.9844\n",
      "Epoch 2/20\n",
      "47776/47776 [==============================] - 5s 112us/sample - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.0478 - val_accuracy: 0.9852\n",
      "Epoch 3/20\n",
      "47776/47776 [==============================] - 5s 114us/sample - loss: 0.0502 - accuracy: 0.9845 - val_loss: 0.0471 - val_accuracy: 0.9853\n",
      "Epoch 4/20\n",
      "47776/47776 [==============================] - 5s 112us/sample - loss: 0.0487 - accuracy: 0.9850 - val_loss: 0.0455 - val_accuracy: 0.9858\n",
      "Epoch 5/20\n",
      "47776/47776 [==============================] - 5s 108us/sample - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.0452 - val_accuracy: 0.9858\n",
      "Epoch 6/20\n",
      "47776/47776 [==============================] - 5s 108us/sample - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.0450 - val_accuracy: 0.9859\n",
      "Epoch 7/20\n",
      "47776/47776 [==============================] - 5s 112us/sample - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.0448 - val_accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.043834722620248796, 0.98616064]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_1()\n",
    "model.fit([x_img_q, x_txt_q], y_q, epochs=20, validation_split=0.1, callbacks=[es])\n",
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(x_img_q, x_txt_q, y_q, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 7s 183us/sample - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.0413 - val_accuracy: 0.9868\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 4s 116us/sample - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9868\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 4s 117us/sample - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.0419 - val_accuracy: 0.9866\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 5s 118us/sample - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0416 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14eaec390>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04204885141142088, 0.986618]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
