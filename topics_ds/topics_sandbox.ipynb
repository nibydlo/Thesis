{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from struct import unpack\n",
    "from base64 import b64decode\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/dmitry/Downloads/topics_dataset.json\"\n",
    "df = pd.read_json(filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 194086 to 103402\n",
      "Data columns (total 3 columns):\n",
      "x1    10000 non-null object\n",
      "x2    10000 non-null object\n",
      "y1    10000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 312.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cutted = df.sample(n=10000)\n",
    "df_cutted.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_img = Input(shape=(1024,))\n",
    "inp_txt = Input(shape=(300,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001, patience=3)\n",
    "\n",
    "def get_model_1():\n",
    "    x_img = Dense(64, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "    x_txt = Dense(64, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(64, activation='relu')(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2():\n",
    "    x_img = Dense(128, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(128, activation='tanh')(x_img)\n",
    "\n",
    "    x_txt = Dense(128, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(128, activation='tanh')(x_txt)\n",
    "\n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256, activation='tanh')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_LEN = 1024\n",
    "TXT_LEN = 300\n",
    "N_CLASSES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def unpck(l, x):\n",
    "    return unpack('%df' % l, b64decode(x.encode('utf-8')))\n",
    "\n",
    "unpck_img = partial(unpck, IMG_LEN)\n",
    "unpck_txt = partial(unpck, TXT_LEN)\n",
    "\n",
    "x_img = np.stack(df_cutted['x1'].map(unpck_img), axis=0)\n",
    "x_txt = np.stack(df_cutted['x2'].map(unpck_txt), axis=0)\n",
    "y = to_categorical(np.array(df_cutted['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024) (10000, 300) (10000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(x_img.shape, x_txt.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 3s 344us/sample - loss: 3.0224 - accuracy: 0.2210 - categorical_accuracy: 0.2210 - val_loss: 2.2648 - val_accuracy: 0.3740 - val_categorical_accuracy: 0.3740\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s 179us/sample - loss: 2.1881 - accuracy: 0.4006 - categorical_accuracy: 0.4006 - val_loss: 2.0103 - val_accuracy: 0.4350 - val_categorical_accuracy: 0.4350\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s 180us/sample - loss: 1.9779 - accuracy: 0.4573 - categorical_accuracy: 0.4573 - val_loss: 1.8241 - val_accuracy: 0.5070 - val_categorical_accuracy: 0.5070\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s 177us/sample - loss: 1.8515 - accuracy: 0.4900 - categorical_accuracy: 0.4900 - val_loss: 1.8211 - val_accuracy: 0.4930 - val_categorical_accuracy: 0.4930\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s 176us/sample - loss: 1.7367 - accuracy: 0.5242 - categorical_accuracy: 0.5242 - val_loss: 1.8064 - val_accuracy: 0.4930 - val_categorical_accuracy: 0.4930\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s 177us/sample - loss: 1.6504 - accuracy: 0.5413 - categorical_accuracy: 0.5413 - val_loss: 1.7571 - val_accuracy: 0.5200 - val_categorical_accuracy: 0.5200\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s 208us/sample - loss: 1.5913 - accuracy: 0.5608 - categorical_accuracy: 0.5608 - val_loss: 1.7082 - val_accuracy: 0.5210 - val_categorical_accuracy: 0.5210\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s 172us/sample - loss: 1.5272 - accuracy: 0.5780 - categorical_accuracy: 0.5780 - val_loss: 1.7068 - val_accuracy: 0.5350 - val_categorical_accuracy: 0.5350\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s 193us/sample - loss: 1.4570 - accuracy: 0.5843 - categorical_accuracy: 0.5843 - val_loss: 1.7199 - val_accuracy: 0.5350 - val_categorical_accuracy: 0.5350\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s 230us/sample - loss: 1.4149 - accuracy: 0.5996 - categorical_accuracy: 0.5996 - val_loss: 1.6670 - val_accuracy: 0.5490 - val_categorical_accuracy: 0.5490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14fe712d0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_2()\n",
    "model.fit([x_img, x_txt], y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.sample(n=10000)\n",
    "x_img_test = np.stack(df_test['x1'].map(unpck_img), axis=0)\n",
    "x_txt_test = np.stack(df_test['x2'].map(unpck_txt), axis=0)\n",
    "y_test = to_categorical(np.array(df_test['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04970714685320854, 0.98471624]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = df.sample(frac=0.25)\n",
    "x_img_q = np.stack(df_q['x1'].map(unpck_img), axis=0)\n",
    "x_txt_q = np.stack(df_q['x2'].map(unpck_txt), axis=0)\n",
    "y_q = to_categorical(np.array(df_q['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_img_train, x_img_test, x_txt_train, x_txt_test, y_train, y_test = train_test_split(x_img_q, x_txt_q, y_q, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5349045181112728, 0.58839595]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([x_img_test, x_txt_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10617,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.79       403\n",
      "           1       0.53      0.72      0.61       386\n",
      "           2       0.58      0.57      0.58        54\n",
      "           3       0.77      0.90      0.83       441\n",
      "           4       0.59      0.43      0.50        81\n",
      "           5       0.45      0.42      0.44       160\n",
      "           6       0.81      0.84      0.82       261\n",
      "           7       0.59      0.76      0.66       116\n",
      "           8       0.44      0.73      0.55       128\n",
      "           9       0.68      0.72      0.70       208\n",
      "          10       0.74      0.92      0.82       310\n",
      "          11       0.71      0.86      0.78       273\n",
      "          12       0.51      0.54      0.53       307\n",
      "          13       0.65      0.78      0.71       272\n",
      "          14       0.61      0.63      0.62       186\n",
      "          15       0.45      0.55      0.49       120\n",
      "          16       0.72      0.75      0.73       456\n",
      "          17       0.46      0.53      0.49       169\n",
      "          18       0.57      0.52      0.55       206\n",
      "          19       0.38      0.17      0.24       213\n",
      "          20       0.58      0.61      0.60       223\n",
      "          21       0.57      0.42      0.48       147\n",
      "          22       0.69      0.91      0.78       162\n",
      "          23       0.72      0.80      0.75       332\n",
      "          24       0.58      0.48      0.53       284\n",
      "          25       0.61      0.62      0.62       242\n",
      "          26       0.56      0.50      0.53       321\n",
      "          27       0.67      0.72      0.70       259\n",
      "          28       0.19      0.04      0.06       487\n",
      "          29       0.67      0.53      0.59       242\n",
      "          30       0.75      0.62      0.68       198\n",
      "          31       0.65      0.76      0.70       294\n",
      "          32       0.36      0.37      0.37       538\n",
      "          33       0.55      0.13      0.21       121\n",
      "          34       0.47      0.52      0.50       150\n",
      "          35       0.61      0.58      0.59        76\n",
      "          36       0.56      0.89      0.68       106\n",
      "          37       0.72      0.59      0.65        78\n",
      "          38       0.46      0.33      0.39        39\n",
      "          39       0.15      0.03      0.05        65\n",
      "          40       0.00      0.00      0.00        26\n",
      "          41       0.39      0.19      0.26       149\n",
      "          42       0.00      0.00      0.00         8\n",
      "          43       0.69      0.85      0.76       253\n",
      "          44       0.00      0.00      0.00        57\n",
      "          45       0.47      0.62      0.53       184\n",
      "          46       0.10      0.02      0.04        45\n",
      "          47       0.00      0.00      0.00        28\n",
      "          48       0.57      0.73      0.64       641\n",
      "          49       0.50      0.02      0.03       112\n",
      "\n",
      "    accuracy                           0.61     10617\n",
      "   macro avg       0.52      0.52      0.50     10617\n",
      "weighted avg       0.57      0.61      0.58     10617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 8s 207us/sample - loss: 2.2304 - accuracy: 0.3987 - categorical_accuracy: 0.3987 - val_loss: 1.8064 - val_accuracy: 0.5093 - val_categorical_accuracy: 0.5093\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 9s 226us/sample - loss: 1.8030 - accuracy: 0.5084 - categorical_accuracy: 0.5084 - val_loss: 1.6472 - val_accuracy: 0.5533 - val_categorical_accuracy: 0.5533\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 6s 163us/sample - loss: 1.6941 - accuracy: 0.5388 - categorical_accuracy: 0.5388 - val_loss: 1.6123 - val_accuracy: 0.5672 - val_categorical_accuracy: 0.5672\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 6s 153us/sample - loss: 1.6280 - accuracy: 0.5564 - categorical_accuracy: 0.5564 - val_loss: 1.6030 - val_accuracy: 0.5686 - val_categorical_accuracy: 0.5686\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 6s 153us/sample - loss: 1.5898 - accuracy: 0.5666 - categorical_accuracy: 0.5666 - val_loss: 1.6130 - val_accuracy: 0.5682 - val_categorical_accuracy: 0.5682\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 6s 168us/sample - loss: 1.5447 - accuracy: 0.5773 - categorical_accuracy: 0.5773 - val_loss: 1.5491 - val_accuracy: 0.5856 - val_categorical_accuracy: 0.5856\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 6s 161us/sample - loss: 1.5069 - accuracy: 0.5878 - categorical_accuracy: 0.5878 - val_loss: 1.5255 - val_accuracy: 0.5865 - val_categorical_accuracy: 0.5865\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 6s 167us/sample - loss: 1.4814 - accuracy: 0.5929 - categorical_accuracy: 0.5929 - val_loss: 1.5697 - val_accuracy: 0.5814 - val_categorical_accuracy: 0.5814\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 6s 165us/sample - loss: 1.4593 - accuracy: 0.5966 - categorical_accuracy: 0.5966 - val_loss: 1.5425 - val_accuracy: 0.5924 - val_categorical_accuracy: 0.5924\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 7s 178us/sample - loss: 1.4380 - accuracy: 0.6035 - categorical_accuracy: 0.6035 - val_loss: 1.5397 - val_accuracy: 0.5839 - val_categorical_accuracy: 0.5839\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 7s 174us/sample - loss: 1.4212 - accuracy: 0.6070 - categorical_accuracy: 0.6070 - val_loss: 1.5590 - val_accuracy: 0.5931 - val_categorical_accuracy: 0.5931\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 7s 172us/sample - loss: 1.3968 - accuracy: 0.6121 - categorical_accuracy: 0.6121 - val_loss: 1.5589 - val_accuracy: 0.5931 - val_categorical_accuracy: 0.5931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x160006390>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_2()\n",
    "model.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5739775799622562, 0.5870773, 0.5870773]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.921098195081648, 0.030988038]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_1()\n",
    "model.evaluate([x_img_test, x_txt_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img_f = np.stack(df['x1'].map(unpck_img), axis=0)\n",
    "x_txt_f = np.stack(df['x2'].map(unpck_txt), axis=0)\n",
    "y_f = to_categorical(np.array(df['y1']), N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 169872 samples, validate on 42468 samples\n",
      "Epoch 1/30\n",
      "169872/169872 [==============================] - 58s 339us/sample - loss: 1.9808 - accuracy: 0.4706 - val_loss: 1.6033 - val_accuracy: 0.5681\n",
      "Epoch 2/30\n",
      "169872/169872 [==============================] - 26s 156us/sample - loss: 1.6915 - accuracy: 0.5478 - val_loss: 1.5385 - val_accuracy: 0.5886\n",
      "Epoch 3/30\n",
      "169872/169872 [==============================] - 27s 158us/sample - loss: 1.6293 - accuracy: 0.5625 - val_loss: 1.4914 - val_accuracy: 0.5969\n",
      "Epoch 4/30\n",
      "169872/169872 [==============================] - 29s 173us/sample - loss: 1.5934 - accuracy: 0.5703 - val_loss: 1.4868 - val_accuracy: 0.5971\n",
      "Epoch 5/30\n",
      "169872/169872 [==============================] - 35s 205us/sample - loss: 1.5657 - accuracy: 0.5765 - val_loss: 1.4703 - val_accuracy: 0.6001\n",
      "Epoch 6/30\n",
      "169872/169872 [==============================] - 38s 222us/sample - loss: 1.5490 - accuracy: 0.5803 - val_loss: 1.4647 - val_accuracy: 0.6025\n",
      "Epoch 7/30\n",
      "169872/169872 [==============================] - 22s 130us/sample - loss: 1.5381 - accuracy: 0.5827 - val_loss: 1.4615 - val_accuracy: 0.6043\n",
      "Epoch 8/30\n",
      "169872/169872 [==============================] - 20s 120us/sample - loss: 1.5288 - accuracy: 0.5854 - val_loss: 1.4583 - val_accuracy: 0.6026\n",
      "Epoch 9/30\n",
      "169872/169872 [==============================] - 21s 122us/sample - loss: 1.5197 - accuracy: 0.5877 - val_loss: 1.4590 - val_accuracy: 0.6055\n",
      "Epoch 10/30\n",
      "169872/169872 [==============================] - 21s 124us/sample - loss: 1.5113 - accuracy: 0.5894 - val_loss: 1.4499 - val_accuracy: 0.6066\n",
      "Epoch 11/30\n",
      "169872/169872 [==============================] - 23s 134us/sample - loss: 1.5033 - accuracy: 0.5913 - val_loss: 1.4455 - val_accuracy: 0.6074\n",
      "Epoch 12/30\n",
      "169872/169872 [==============================] - 23s 137us/sample - loss: 1.5007 - accuracy: 0.5927 - val_loss: 1.4432 - val_accuracy: 0.6067\n",
      "Epoch 13/30\n",
      "169872/169872 [==============================] - 29s 168us/sample - loss: 1.4951 - accuracy: 0.5930 - val_loss: 1.4407 - val_accuracy: 0.6098\n",
      "Epoch 14/30\n",
      "169872/169872 [==============================] - 25s 148us/sample - loss: 1.4890 - accuracy: 0.5957 - val_loss: 1.4399 - val_accuracy: 0.6093\n",
      "Epoch 15/30\n",
      "169872/169872 [==============================] - 25s 148us/sample - loss: 1.4867 - accuracy: 0.5952 - val_loss: 1.4344 - val_accuracy: 0.6095\n",
      "Epoch 16/30\n",
      "169872/169872 [==============================] - 27s 161us/sample - loss: 1.4822 - accuracy: 0.5965 - val_loss: 1.4435 - val_accuracy: 0.6072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x165ba4290>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_1()\n",
    "model.fit([x_img_f, x_txt_f], y_f, epochs=30, validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001, patience=3)\n",
    "\n",
    "def get_model_3():\n",
    "    inp_img = Input(shape=(1024,))\n",
    "    inp_txt = Input(shape=(300,))\n",
    "    \n",
    "    x_img = Dense(256, activation='relu')(inp_img)\n",
    "    x_img = Dropout(0.25)(x_img)\n",
    "    x_img = Dense(256, activation='relu')(x_img)\n",
    "    \n",
    "    x_txt = Dense(256, activation='relu')(inp_txt)\n",
    "    x_txt = Dropout(0.25)(x_txt)\n",
    "    x_txt = Dense(256, activation='relu')(x_txt)\n",
    "    \n",
    "    x = concatenate([x_img, x_txt])\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    out = Dense(50, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[inp_img, inp_txt], outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38221 samples, validate on 4247 samples\n",
      "Epoch 1/20\n",
      "38221/38221 [==============================] - 17s 444us/sample - loss: 2.8724 - accuracy: 0.2714 - val_loss: 2.1465 - val_accuracy: 0.4243\n",
      "Epoch 2/20\n",
      "38221/38221 [==============================] - 10s 259us/sample - loss: 1.9512 - accuracy: 0.4669 - val_loss: 1.7643 - val_accuracy: 0.5133\n",
      "Epoch 3/20\n",
      "38221/38221 [==============================] - 10s 265us/sample - loss: 1.6953 - accuracy: 0.5341 - val_loss: 1.6432 - val_accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "38221/38221 [==============================] - 11s 290us/sample - loss: 1.5812 - accuracy: 0.5626 - val_loss: 1.5807 - val_accuracy: 0.5700\n",
      "Epoch 5/20\n",
      "38221/38221 [==============================] - 10s 264us/sample - loss: 1.5007 - accuracy: 0.5831 - val_loss: 1.5364 - val_accuracy: 0.5797\n",
      "Epoch 6/20\n",
      "38221/38221 [==============================] - 8s 205us/sample - loss: 1.4467 - accuracy: 0.5983 - val_loss: 1.5350 - val_accuracy: 0.5743\n",
      "Epoch 7/20\n",
      "38221/38221 [==============================] - 8s 204us/sample - loss: 1.4038 - accuracy: 0.6051 - val_loss: 1.5429 - val_accuracy: 0.5778\n",
      "Epoch 8/20\n",
      "38221/38221 [==============================] - 9s 226us/sample - loss: 1.3606 - accuracy: 0.6175 - val_loss: 1.5010 - val_accuracy: 0.5929\n",
      "Epoch 9/20\n",
      "38221/38221 [==============================] - 6s 154us/sample - loss: 1.3168 - accuracy: 0.6292 - val_loss: 1.4979 - val_accuracy: 0.5908\n",
      "Epoch 10/20\n",
      "38221/38221 [==============================] - 7s 173us/sample - loss: 1.2835 - accuracy: 0.6363 - val_loss: 1.4861 - val_accuracy: 0.5910\n",
      "Epoch 11/20\n",
      "38221/38221 [==============================] - 8s 212us/sample - loss: 1.2472 - accuracy: 0.6433 - val_loss: 1.4859 - val_accuracy: 0.5955\n",
      "Epoch 12/20\n",
      "38221/38221 [==============================] - 8s 196us/sample - loss: 1.2277 - accuracy: 0.6482 - val_loss: 1.4829 - val_accuracy: 0.5922\n",
      "Epoch 13/20\n",
      "38221/38221 [==============================] - 7s 175us/sample - loss: 1.1927 - accuracy: 0.6558 - val_loss: 1.4796 - val_accuracy: 0.5948\n",
      "Epoch 14/20\n",
      "38221/38221 [==============================] - 5s 134us/sample - loss: 1.1614 - accuracy: 0.6647 - val_loss: 1.4810 - val_accuracy: 0.5943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x139fed7d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = get_model_3()\n",
    "model_3.fit([x_img_train, x_txt_train], y_train, epochs=20, validation_split=0.1, callbacks=[es], batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
